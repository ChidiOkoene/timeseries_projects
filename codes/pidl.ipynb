{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import LSTM, GRU, Bidirectional, LayerNormalization, Conv1D, Dense, Concatenate, Dropout, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class PhysicsInformedNN(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 seq_length=30,\n",
    "                 num_features=23,\n",
    "                 use_black_scholes=False,\n",
    "                 risk_free_rate=0.0001,\n",
    "                 strike_idx=3,\n",
    "                 maturity_idx=4,\n",
    "                 dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        assert seq_length >= 2, \"Sequence length must be at least 2\"\n",
    "        self.seq_length = seq_length\n",
    "        self.num_features = num_features\n",
    "        self.use_black_scholes = use_black_scholes\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "        self.strike_idx = strike_idx\n",
    "        self.maturity_idx = maturity_idx\n",
    "        # Adaptive physics weight network\n",
    "        self.weight_net = tf.keras.Sequential([\n",
    "            Dense(16, activation='relu', input_shape=(3,)),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        # Curriculum phase flag\n",
    "        self.curr_phase = tf.Variable(0, trainable=False, dtype=tf.int32)\n",
    "        # Layers\n",
    "        self.lstm_branch = Bidirectional(LSTM(64, return_sequences=True))\n",
    "        self.norm_branch = LayerNormalization()\n",
    "        self.conv_branch = tf.keras.Sequential([\n",
    "            Conv1D(32, 3, activation='relu', padding='same'),\n",
    "            Bidirectional(GRU(32, return_sequences=True)),\n",
    "            Conv1D(64, 1, padding='same')\n",
    "        ])\n",
    "        self.fusion = Dense(64, activation='relu')\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        # Output heads\n",
    "        self.mean_head = TimeDistributed(Dense(1), name='mean_head')\n",
    "        self.logvar_head = TimeDistributed(Dense(1), name='logvar_head')\n",
    "        self.vol_head = TimeDistributed(Dense(1), name='vol_head')\n",
    "        # Moving averages\n",
    "        self.loss_ma = {'nll': tf.Variable(1.0, trainable=False),\n",
    "                        'phys': tf.Variable(1.0, trainable=False),\n",
    "                        'bs': tf.Variable(1.0, trainable=False)}\n",
    "        # Metrics\n",
    "        self.nll_tracker = tf.keras.metrics.Mean(name='nll')\n",
    "        self.phys_tracker = tf.keras.metrics.Mean(name='phys_loss')\n",
    "        self.total_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.nll_tracker, self.phys_tracker, self.total_tracker]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        h1 = self.lstm_branch(inputs, training=training)\n",
    "        h1 = self.norm_branch(h1, training=training)\n",
    "        h2 = self.conv_branch(inputs, training=training)\n",
    "        h = Concatenate()([h1, h2])\n",
    "        h = self.fusion(h)\n",
    "        h = self.dropout(h, training=training)\n",
    "        mu_seq = self.mean_head(h)\n",
    "        logvar_seq = self.logvar_head(h)\n",
    "        vol_seq = self.vol_head(h)\n",
    "        return mu_seq, logvar_seq, vol_seq\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.reshape(y_true, (-1,1))\n",
    "        with tf.GradientTape() as tape:\n",
    "            mu_seq, logvar_seq, vol_seq = self(x, training=True)\n",
    "            mu = mu_seq[:, -1, :]\n",
    "            logvar = tf.clip_by_value(logvar_seq[:, -1, :], -10.0, 10.0)\n",
    "            var = tf.clip_by_value(tf.exp(logvar), 1e-6, 1e6)\n",
    "            # Loss components\n",
    "            mse_loss = tf.reduce_mean(tf.square(y_true - mu))\n",
    "            nll_loss = 0.5 * tf.reduce_mean(logvar + tf.square(y_true - mu) / var)\n",
    "            phys_loss = tf.math.nan_to_num(self._physics_loss(mu_seq, x))\n",
    "            bs_loss = tf.nan_to_num(self._bs_penalty(mu, x)) if self.use_black_scholes else 0.0\n",
    "            # Adaptive weight\n",
    "            norms_vec = tf.stack([nll_loss / self.loss_ma['nll'], phys_loss / self.loss_ma['phys'], bs_loss / self.loss_ma['bs']], axis=0)\n",
    "            norms = tf.reshape(norms_vec, (1, 3))\n",
    "            physics_w = self.weight_net(norms)[0, 0]\n",
    "            # Auxiliary volatility supervision\n",
    "            vol_true = tf.math.sqrt(tf.math.reduce_variance(x[:,:,4], axis=1, keepdims=True))\n",
    "            aux_loss = tf.reduce_mean(tf.square(vol_seq[:,-1,:] - vol_true))\n",
    "            # Total loss by phase\n",
    "            phase = self.curr_phase.read_value()\n",
    "            def phase0(): return mse_loss\n",
    "            def phase1(): return nll_loss + phys_loss + aux_loss\n",
    "            def phase2(): return nll_loss + physics_w * phys_loss + bs_loss + aux_loss\n",
    "            total_loss = tf.switch_case(phase, branch_fns={0: phase0, 1: phase1, 2: phase2}, default=phase2)\n",
    "        grads = tape.gradient(total_loss, self.trainable_variables)\n",
    "        grads = [tf.clip_by_norm(g, 1.0) for g in grads]\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        # Update moving averages\n",
    "        self.loss_ma['nll'].assign(0.99 * self.loss_ma['nll'] + 0.01 * nll_loss)\n",
    "        self.loss_ma['phys'].assign(0.99 * self.loss_ma['phys'] + 0.01 * phys_loss)\n",
    "        self.loss_ma['bs'].assign(0.99 * self.loss_ma['bs'] + 0.01 * bs_loss)\n",
    "        # Track metrics\n",
    "        self.nll_tracker.update_state(nll_loss)\n",
    "        self.phys_tracker.update_state(phys_loss)\n",
    "        self.total_tracker.update_state(total_loss)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.reshape(y_true, (-1,1))\n",
    "        mu_seq, logvar_seq, _ = self(x, training=False)\n",
    "        mu = mu_seq[:, -1, :]\n",
    "        logvar = tf.clip_by_value(logvar_seq[:, -1, :], -10.0, 10.0)\n",
    "        var = tf.clip_by_value(tf.exp(logvar), 1e-6, 1e6)\n",
    "        nll_loss = 0.5 * tf.reduce_mean(logvar + tf.square(y_true - mu) / var)\n",
    "        phys_loss = tf.nan_to_num(self._physics_loss(mu_seq, x))\n",
    "        bs_loss = tf.nan_to_num(self._bs_penalty(mu, x)) if self.use_black_scholes else 0.0\n",
    "        total_loss = nll_loss + phys_loss + bs_loss\n",
    "        self.nll_tracker.update_state(nll_loss)\n",
    "        self.phys_tracker.update_state(phys_loss)\n",
    "        self.total_tracker.update_state(total_loss)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def _physics_loss(self, mu_seq, inputs):\n",
    "        returns = mu_seq[:,1:,:] - mu_seq[:,:-1,:]\n",
    "        comp_vol = tf.math.reduce_std(returns, axis=1)\n",
    "        upper = inputs[:,-1,19]\n",
    "        lower = inputs[:,-1,20]\n",
    "        v = tf.squeeze(comp_vol)\n",
    "        vol_l = tf.reduce_mean(tf.square(tf.nn.relu(upper - v) + tf.nn.relu(v - lower)))\n",
    "        r = tf.squeeze(returns, -1)\n",
    "        vchg = inputs[:,1:,4] - inputs[:,:-1,4]\n",
    "        r_m = tf.reduce_mean(r,1,keepdims=True); v_m = tf.reduce_mean(vchg,1,keepdims=True)\n",
    "        cov = tf.reduce_mean((r - r_m) * (vchg - v_m), axis=1)\n",
    "        corr = cov / (tf.math.reduce_std(r,1) * tf.math.reduce_std(vchg,1) + 1e-7)\n",
    "        pv_l = tf.reduce_mean(tf.square(tf.nn.relu(0.5 - corr)))\n",
    "        P = mu_seq[:, :-1, :]\n",
    "        drift_res = returns - self.risk_free_rate * P\n",
    "        drift_l = tf.reduce_mean(tf.square(tf.reduce_mean(drift_res, axis=1)))\n",
    "        data_vol = (upper + lower) * 0.5\n",
    "        diff_res = tf.math.reduce_variance(returns, axis=1) - data_vol**2\n",
    "        diff_l = tf.reduce_mean(diff_res**2)\n",
    "        return vol_l * 0.55 + pv_l * 0.43 + drift_l * 0.02 + diff_l\n",
    "\n",
    "    def _bs_penalty(self, mu, inputs):\n",
    "        S = tf.squeeze(mu, -1)\n",
    "        sigma = (inputs[:,-1,19] + inputs[:,-1,20]) * 0.5\n",
    "        K = inputs[:,-1,self.strike_idx]\n",
    "        T = inputs[:,-1,self.maturity_idx]\n",
    "        r = self.risk_free_rate\n",
    "        sqrtT = tf.sqrt(T) + 1e-7\n",
    "        d1 = (tf.math.log(S/K) + (r + 0.5 * sigma**2) * T) / (sigma * sqrtT)\n",
    "        d2 = d1 - sigma * sqrtT\n",
    "        normal = tfp.distributions.Normal(0.,1.)\n",
    "        BS = S * normal.cdf(d1) - K * tf.exp(-r*T) * normal.cdf(d2)\n",
    "        return tf.reduce_mean(tf.square(S - BS))\n",
    "\n",
    "    def next_phase(self):\n",
    "        self.curr_phase.assign_add(1)\n",
    "\n",
    "    def online_update(self, x, y_true, lr=1e-4):\n",
    "        optimizer = tf.keras.optimizers.Adam(lr)\n",
    "        with tf.GradientTape() as tape:\n",
    "            mu_seq, logvar_seq, _ = self(x, training=True)\n",
    "            mu = mu_seq[:, -1, :]\n",
    "            logvar = tf.clip_by_value(logvar_seq[:, -1, :], -10.0, 10.0)\n",
    "            var = tf.clip_by_value(tf.exp(logvar), 1e-6, 1e6)\n",
    "            y_true = tf.reshape(y_true, (-1,1))\n",
    "            nll_loss = 0.5 * tf.reduce_mean(logvar + tf.square(y_true - mu) / var)\n",
    "        grads = tape.gradient(nll_loss, self.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "    def predict_intervals(self, x, num_samples=100, q=(0.05,0.95)):\n",
    "        preds = [tf.squeeze(self(x, training=True)[0], -1) for _ in range(num_samples)]\n",
    "        stack = tf.stack(preds)\n",
    "        return (tfp.stats.percentile(stack, q[0]*100, axis=0),\n",
    "                tfp.stats.percentile(stack, q[1]*100, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from scikit-learn) (2.0.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "class TimeSeriesPipeline:\n",
    "    def __init__(self, seq_length=30, val_size=0.2, test_size=0.1):\n",
    "        self.seq_length = seq_length\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "        self.scalers = {}\n",
    "        self.price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', '7_hour_SMA', \n",
    "                           '30_hour_SMA', '7_hour_EMA', '30_hour_EMA', '12_hour_EMA', '26_hour_EMA', '20_hour_SMA']\n",
    "        self.volatility_cols = ['20_hour_STD', 'Upper_Band', 'Lower_Band']\n",
    "        self.momentum_cols = ['RSI', 'MACD', 'Signal_Line']\n",
    "        self.lag_cols = ['lag_1', 'lag_2', 'lag_3']\n",
    "\n",
    "    def preprocess_data(self, df, fit_scalers=True, save_scalers=True, scalers_path=\"scalers.pkl\"):\n",
    "        \"\"\"\n",
    "        Preprocess DataFrame and split into train (70%), validation (20%), test (10%).\n",
    "        Returns scaled and unscaled splits for X and y.\n",
    "        \"\"\"\n",
    "        print(\"Starting data preprocessing...\")\n",
    "        unscaled_data = df.copy()\n",
    "        # Fit or load scalers\n",
    "        if not fit_scalers:\n",
    "            with open(scalers_path, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "        else:\n",
    "            self._fit_scalers(df, self.price_cols, self.volatility_cols,\n",
    "                               self.momentum_cols, self.lag_cols)\n",
    "            if save_scalers:\n",
    "                with open(scalers_path, 'wb') as f:\n",
    "                    pickle.dump(self.scalers, f)\n",
    "        # Transform features\n",
    "        df_scaled = self._transform_features(df.copy(), self.price_cols,\n",
    "                                            self.volatility_cols,\n",
    "                                            self.momentum_cols,\n",
    "                                            self.lag_cols)\n",
    "        # Create sequences\n",
    "        X_scaled, y_scaled = self.create_sequences(df_scaled)\n",
    "        X_unscaled, y_unscaled = self.create_sequences(unscaled_data)\n",
    "        # Compute split indices\n",
    "        total = len(X_scaled)\n",
    "        train_end = int((1 - self.val_size - self.test_size) * total)\n",
    "        val_end = int((1 - self.test_size) * total)\n",
    "        # Scaled\n",
    "        X_train_scaled = X_scaled[:train_end]\n",
    "        y_train_scaled = y_scaled[:train_end]\n",
    "        X_val_scaled = X_scaled[train_end:val_end]\n",
    "        y_val_scaled = y_scaled[train_end:val_end]\n",
    "        X_test_scaled = X_scaled[val_end:]\n",
    "        y_test_scaled = y_scaled[val_end:]\n",
    "        # Unscaled\n",
    "        X_train_unscaled = X_unscaled[:train_end]\n",
    "        y_train_unscaled = y_unscaled[:train_end]\n",
    "        X_val_unscaled = X_unscaled[train_end:val_end]\n",
    "        y_val_unscaled = y_unscaled[train_end:val_end]\n",
    "        X_test_unscaled = X_unscaled[val_end:]\n",
    "        y_test_unscaled = y_unscaled[val_end:]\n",
    "        print(f\"Data preprocessing finished. Training: {len(X_train_scaled)}, Validation: {len(X_val_scaled)}, Test: {len(X_test_scaled)}\")\n",
    "        return (X_train_scaled, X_val_scaled, X_test_scaled,\n",
    "                y_train_scaled, y_val_scaled, y_test_scaled,\n",
    "                X_train_unscaled, X_val_unscaled, X_test_unscaled,\n",
    "                y_train_unscaled, y_val_unscaled, y_test_unscaled)\n",
    "\n",
    "    def _fit_scalers(self, df, price_cols, volatility_cols, momentum_cols, lag_cols):\n",
    "        self.scalers = {\n",
    "            'price': RobustScaler().fit(df[price_cols]),\n",
    "            'volume': RobustScaler().fit(np.log1p(df[['volume']])),\n",
    "            'volatility': StandardScaler().fit(df[volatility_cols]),\n",
    "            'momentum': MinMaxScaler().fit(df[momentum_cols]),\n",
    "            'lag': RobustScaler().fit(df[lag_cols])\n",
    "        }\n",
    "\n",
    "    def _transform_features(self, df, price_cols, volatility_cols, momentum_cols, lag_cols):\n",
    "        df[price_cols] = self.scalers['price'].transform(df[price_cols])\n",
    "        df['volume'] = self.scalers['volume'].transform(np.log1p(df[['volume']]))\n",
    "        df[volatility_cols] = self.scalers['volatility'].transform(df[volatility_cols])\n",
    "        df[momentum_cols] = self.scalers['momentum'].transform(df[momentum_cols])\n",
    "        df[lag_cols] = self.scalers['lag'].transform(df[lag_cols])\n",
    "        return df\n",
    "\n",
    "    def transform_for_prediction(self, df):\n",
    "        df_transformed = self._transform_features(df.copy(),\n",
    "                                                  self.price_cols,\n",
    "                                                  self.volatility_cols,\n",
    "                                                  self.momentum_cols,\n",
    "                                                  self.lag_cols)\n",
    "        if len(df_transformed) == self.seq_length:\n",
    "            return np.array([df_transformed.values])\n",
    "        elif len(df_transformed) > self.seq_length:\n",
    "            X, _ = self.create_sequences(df_transformed)\n",
    "            return X\n",
    "        else:\n",
    "            raise ValueError(\"Not enough data for a full sequence\")\n",
    "\n",
    "    def create_sequences(self, data):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - self.seq_length):\n",
    "            seq = data.iloc[i:i+self.seq_length].values\n",
    "            target = data.iloc[i+self.seq_length]['close']\n",
    "            X.append(seq)\n",
    "            y.append(target)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def inverse_transform_predictions(self, pred_scaled, feature_name='close'):\n",
    "        if feature_name == 'close':\n",
    "            scaler = self.scalers['price']\n",
    "            col_index = self.price_cols.index('close')\n",
    "            pred_scaled = np.array(pred_scaled)\n",
    "            return pred_scaled * scaler.scale_[col_index] + scaler.center_[col_index]\n",
    "        raise ValueError(f\"Unsupported feature for inversion: {feature_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n",
      "Data preprocessing finished. Training: 41808, Validation: 11945, Test: 5973\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.math' has no attribute 'nan_to_num'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m phase_cb \u001b[38;5;241m=\u001b[39m PhaseCallback(switch_epochs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m15\u001b[39m])  \u001b[38;5;66;03m# switch after 5th and 15th epochs\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# 5. Train model across all phases\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_s\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mphase_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m     56\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# 6. Evaluate on test set\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Point forecasts\u001b[39;00m\n\u001b[0;32m     60\u001b[0m mu_seq, logvar_seq, vol_seq \u001b[38;5;241m=\u001b[39m model(X_test_s, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[29], line 80\u001b[0m, in \u001b[0;36mPhysicsInformedNN.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     78\u001b[0m mse_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(y_true \u001b[38;5;241m-\u001b[39m mu))\n\u001b[0;32m     79\u001b[0m nll_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(logvar \u001b[38;5;241m+\u001b[39m tf\u001b[38;5;241m.\u001b[39msquare(y_true \u001b[38;5;241m-\u001b[39m mu) \u001b[38;5;241m/\u001b[39m var)\n\u001b[1;32m---> 80\u001b[0m phys_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan_to_num\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_physics_loss(mu_seq, x))\n\u001b[0;32m     81\u001b[0m bs_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnan_to_num(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bs_penalty(mu, x)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_black_scholes \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Adaptive weight\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.math' has no attribute 'nan_to_num'"
     ]
    }
   ],
   "source": [
    "# ====================== Example Usage ======================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# 1. Load your raw DataFrame\n",
    "df = pd.read_csv(r'C:\\Users\\chidi\\Documents\\timeseries_projects\\data\\xrpusdt_hourly_dataset_with_features_bn.csv')\n",
    "\n",
    "# 2. Preprocess and split\n",
    "pipeline = TimeSeriesPipeline(seq_length=30, val_size=0.2, test_size=0.1)\n",
    "(X_train_s, X_val_s, X_test_s,\n",
    " y_train_s, y_val_s, y_test_s,\n",
    " X_train_u, X_val_u, X_test_u,\n",
    " y_train_u, y_val_u, y_test_u) = pipeline.preprocess_data(\n",
    "    df, fit_scalers=True, save_scalers=True, scalers_path='scalers.pkl'\n",
    ")\n",
    "\n",
    "# 3. Instantiate the model\n",
    "strike_idx = pipeline.price_cols.index('av_pr')\n",
    "maturity_idx = pipeline.price_cols.index('diff')\n",
    "model = PhysicsInformedNN(\n",
    "    seq_length=30,\n",
    "    num_features=len(df.columns),\n",
    "    use_black_scholes=True,\n",
    "    risk_free_rate=0.0001,\n",
    "    strike_idx=strike_idx,\n",
    "    maturity_idx=maturity_idx,\n",
    "    dropout_rate=0.2\n",
    ")\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3))\n",
    "\n",
    "# 4. Define a callback to advance curriculum phases\n",
    "class PhaseCallback(Callback):\n",
    "    def __init__(self, switch_epochs):\n",
    "        super().__init__()\n",
    "        self.switch_epochs = switch_epochs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch + 1 in self.switch_epochs:\n",
    "            print(f\"Advancing to next curriculum phase at epoch {epoch+1}\")\n",
    "            self.model.next_phase()\n",
    "\n",
    "phase_cb = PhaseCallback(switch_epochs=[5, 15])  # switch after 5th and 15th epochs\n",
    "\n",
    "# 5. Train model across all phases\n",
    "history = model.fit(\n",
    "    X_train_s, y_train_s,\n",
    "    validation_data=(X_val_s, y_val_s),\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    callbacks=[phase_cb],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 6. Evaluate on test set\n",
    "# Point forecasts\n",
    "mu_seq, logvar_seq, vol_seq = model(X_test_s, training=False)\n",
    "y_pred_scaled = mu_seq[:, -1, 0]\n",
    "# Inverse transform\n",
    "y_pred = pipeline.inverse_transform_predictions(y_pred_scaled, feature_name='close')\n",
    "y_true = y_test_u\n",
    "# Compute metrics\n",
    "mae = np.mean(np.abs(y_true - y_pred))\n",
    "rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}, MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Physics and total loss metrics via evaluate\n",
    "test_metrics = model.evaluate(X_test_s, y_test_s, verbose=2)\n",
    "print(\"Test metrics (NLL, physics loss, total loss):\", test_metrics)\n",
    "\n",
    "# 7. Make predictive interval forecasts\n",
    "lower_q, upper_q = model.predict_intervals(\n",
    "    X_test_s, num_samples=100, q=(0.05, 0.95)\n",
    ")\n",
    "# Inverse transform intervals\n",
    "lower = pipeline.inverse_transform_predictions(lower_q, feature_name='close')\n",
    "upper = pipeline.inverse_transform_predictions(upper_q, feature_name='close')\n",
    "print(\"First 5 lower bounds:\", lower[:5])\n",
    "print(\"First 5 upper bounds:\", upper[:5])\n",
    "\n",
    "# ====================== Visualization ======================\n",
    "# 8. Overlay True vs Predicted with Intervals\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(y_true, label='True Price')\n",
    "plt.plot(y_pred, label='Predicted Price')\n",
    "plt.fill_between(np.arange(len(y_true)), lower, upper, color='gray', alpha=0.3, label='90% Interval')\n",
    "plt.title('True vs Predicted Price with 90% Prediction Interval')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 9. Residual Histogram\n",
    "residuals = y_true - y_pred\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(residuals, bins=30, edgecolor='k')\n",
    "plt.title('Residuals Distribution')\n",
    "plt.xlabel('Residual (True - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 10. Predicted vs Actual Scatter\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_true, y_pred, alpha=0.6)\n",
    "minv = min(y_true.min(), y_pred.min())\n",
    "maxv = max(y_true.max(), y_pred.max())\n",
    "plt.plot([minv, maxv], [minv, maxv], 'r--')\n",
    "plt.title('Predicted vs Actual Price')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf_keras\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tf_keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.0.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf_keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.1.2)\n",
      "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 18.8 MB/s eta 0:00:00\n",
      "Installing collected packages: tf_keras\n",
      "Successfully installed tf_keras-2.19.0\n"
     ]
    }
   ],
   "source": [
    "! pip install tf_keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (2.19.0)\n",
      "Collecting tensorflow-probability\n",
      "  Downloading tensorflow_probability-0.25.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow-probability) (5.2.1)\n",
      "Collecting cloudpickle>=1.3 (from tensorflow-probability)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting dm-tree (from tensorflow-probability)\n",
      "  Downloading dm_tree-0.1.9-cp310-cp310-win_amd64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from dm-tree->tensorflow-probability) (25.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow_probability-0.25.0-py2.py3-none-any.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/7.0 MB 17.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.1/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.1/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.2/7.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.2/7.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 6.0 MB/s eta 0:00:00\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading dm_tree-0.1.9-cp310-cp310-win_amd64.whl (101 kB)\n",
      "Installing collected packages: dm-tree, cloudpickle, tensorflow-probability\n",
      "Successfully installed cloudpickle-3.1.1 dm-tree-0.1.9 tensorflow-probability-0.25.0\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.22.0-cp310-cp310-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\chidi\\anaconda3\\envs\\dl_envc\\lib\\site-packages (from tensorflow-addons) (25.0)\n",
      "Downloading tensorflow_addons-0.22.0-cp310-cp310-win_amd64.whl (719 kB)\n",
      "   ---------------------------------------- 0.0/719.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 719.8/719.8 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.22.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow tensorflow-probability\n",
    "! pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_envc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
