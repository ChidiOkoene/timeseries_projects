{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_tradingview_data.py\n",
    "\n",
    "from tvDatafeed import TvDatafeed, Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"chidiokoene\"\n",
    "password = \"DaVinci30&87\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TvDatafeed(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.search_symbol('XRP', 'BINANCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"XRPUSDT\"\n",
    "exchange = \"BINANCE\"\n",
    "interval = Interval.in_daily\n",
    "\n",
    "n_bars = 3660\n",
    "\n",
    "xrp_usdt = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"XRPUSDT\"\n",
    "exchange = \"BINANCE\"\n",
    "interval = Interval.in_daily\n",
    "\n",
    "n_bars = 66\n",
    "\n",
    "xrp_usdt = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1e731ea5-d746-4a67-9db7-64318869f575",
       "rows": [
        [
         "2024-12-20 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2391",
         "2.355",
         "1.9601",
         "2.2793",
         "1110347016.0"
        ],
        [
         "2024-12-21 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2793",
         "2.3858",
         "2.1915",
         "2.238",
         "451599864.0"
        ],
        [
         "2024-12-22 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2379",
         "2.2938",
         "2.1604",
         "2.2031",
         "310318499.0"
        ],
        [
         "2024-12-23 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2032",
         "2.2789",
         "2.1308",
         "2.2617",
         "388820902.0"
        ],
        [
         "2024-12-24 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2616",
         "2.3507",
         "2.2138",
         "2.3238",
         "249021066.0"
        ],
        [
         "2024-12-25 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3238",
         "2.3325",
         "2.2615",
         "2.2973",
         "162014998.0"
        ],
        [
         "2024-12-26 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2973",
         "2.3164",
         "2.1277",
         "2.1559",
         "266397920.0"
        ],
        [
         "2024-12-27 01:00:00",
         "BINANCE:XRPUSDT",
         "2.1559",
         "2.2379",
         "2.1149",
         "2.1466",
         "254236575.0"
        ],
        [
         "2024-12-28 01:00:00",
         "BINANCE:XRPUSDT",
         "2.1467",
         "2.2076",
         "2.1343",
         "2.1843",
         "106144470.0"
        ],
        [
         "2024-12-29 01:00:00",
         "BINANCE:XRPUSDT",
         "2.1843",
         "2.1976",
         "2.0711",
         "2.0942",
         "129587392.0"
        ],
        [
         "2024-12-30 01:00:00",
         "BINANCE:XRPUSDT",
         "2.0941",
         "2.1526",
         "1.9954",
         "2.0587",
         "326304793.0"
        ],
        [
         "2024-12-31 01:00:00",
         "BINANCE:XRPUSDT",
         "2.0587",
         "2.1491",
         "2.0126",
         "2.0836",
         "202867597.0"
        ],
        [
         "2025-01-01 01:00:00",
         "BINANCE:XRPUSDT",
         "2.0836",
         "2.3545",
         "2.0811",
         "2.3328",
         "340770274.0"
        ],
        [
         "2025-01-02 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3329",
         "2.4522",
         "2.3297",
         "2.4024",
         "361196381.0"
        ],
        [
         "2025-01-03 01:00:00",
         "BINANCE:XRPUSDT",
         "2.4024",
         "2.4798",
         "2.3966",
         "2.4547",
         "233672728.0"
        ],
        [
         "2025-01-04 01:00:00",
         "BINANCE:XRPUSDT",
         "2.4546",
         "2.509",
         "2.3999",
         "2.4201",
         "179793926.0"
        ],
        [
         "2025-01-05 01:00:00",
         "BINANCE:XRPUSDT",
         "2.4201",
         "2.4285",
         "2.3273",
         "2.3994",
         "155537860.0"
        ],
        [
         "2025-01-06 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3993",
         "2.4584",
         "2.3674",
         "2.42",
         "194293277.0"
        ],
        [
         "2025-01-07 01:00:00",
         "BINANCE:XRPUSDT",
         "2.42",
         "2.4683",
         "2.2572",
         "2.2712",
         "342477338.0"
        ],
        [
         "2025-01-08 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2712",
         "2.3986",
         "2.2001",
         "2.3731",
         "401036029.0"
        ],
        [
         "2025-01-09 01:00:00",
         "BINANCE:XRPUSDT",
         "2.373",
         "2.3956",
         "2.2351",
         "2.2722",
         "294585086.0"
        ],
        [
         "2025-01-10 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2722",
         "2.3699",
         "2.2465",
         "2.3414",
         "248018278.0"
        ],
        [
         "2025-01-11 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3414",
         "2.6036",
         "2.3249",
         "2.5764",
         "349172496.0"
        ],
        [
         "2025-01-12 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5764",
         "2.5835",
         "2.47",
         "2.5046",
         "222912333.0"
        ],
        [
         "2025-01-13 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5045",
         "2.5634",
         "2.3297",
         "2.5232",
         "515356746.0"
        ],
        [
         "2025-01-14 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5232",
         "2.7",
         "2.5126",
         "2.6673",
         "397227342.0"
        ],
        [
         "2025-01-15 01:00:00",
         "BINANCE:XRPUSDT",
         "2.6673",
         "3.2",
         "2.6492",
         "3.1429",
         "1062630122.2299999"
        ],
        [
         "2025-01-16 01:00:00",
         "BINANCE:XRPUSDT",
         "3.143",
         "3.4",
         "2.9228",
         "3.2451",
         "1110371222.1999998"
        ],
        [
         "2025-01-17 01:00:00",
         "BINANCE:XRPUSDT",
         "3.245",
         "3.3544",
         "3.1758",
         "3.2922",
         "529933494.0"
        ],
        [
         "2025-01-18 01:00:00",
         "BINANCE:XRPUSDT",
         "3.2923",
         "3.2996",
         "3.058",
         "3.2697",
         "458088944.0"
        ],
        [
         "2025-01-19 01:00:00",
         "BINANCE:XRPUSDT",
         "3.2697",
         "3.2929",
         "2.8277",
         "2.9587",
         "663328805.0"
        ],
        [
         "2025-01-20 01:00:00",
         "BINANCE:XRPUSDT",
         "2.9586",
         "3.3695",
         "2.909",
         "3.1053",
         "838761258.0"
        ],
        [
         "2025-01-21 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1053",
         "3.246",
         "3.0124",
         "3.1738",
         "376423502.0"
        ],
        [
         "2025-01-22 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1739",
         "3.2854",
         "3.1237",
         "3.1803",
         "291761274.0"
        ],
        [
         "2025-01-23 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1802",
         "3.1868",
         "3.0374",
         "3.1194",
         "305314846.0"
        ],
        [
         "2025-01-24 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1194",
         "3.2031",
         "3.055",
         "3.1009",
         "232626964.0"
        ],
        [
         "2025-01-25 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1008",
         "3.1446",
         "3.0784",
         "3.108",
         "99489857.0"
        ],
        [
         "2025-01-26 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1079",
         "3.1443",
         "3.0115",
         "3.0223",
         "128937813.0"
        ],
        [
         "2025-01-27 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0222",
         "3.0587",
         "2.6559",
         "3.0552",
         "660056174.0"
        ],
        [
         "2025-01-28 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0552",
         "3.214",
         "3.0062",
         "3.0572",
         "369470786.0"
        ],
        [
         "2025-01-29 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0572",
         "3.1363",
         "2.9673",
         "3.0683",
         "254756655.0"
        ],
        [
         "2025-01-30 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0683",
         "3.1544",
         "3.0466",
         "3.1276",
         "173143314.0"
        ],
        [
         "2025-01-31 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1276",
         "3.1333",
         "3.003",
         "3.0361",
         "162235322.0"
        ],
        [
         "2025-02-01 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0361",
         "3.0727",
         "2.8281",
         "2.8778",
         "173601404.0"
        ],
        [
         "2025-02-02 01:00:00",
         "BINANCE:XRPUSDT",
         "2.8779",
         "2.9559",
         "2.4603",
         "2.58",
         "684089012.0"
        ],
        [
         "2025-02-03 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5801",
         "2.7814",
         "1.7711",
         "2.7001",
         "1866758972.0"
        ],
        [
         "2025-02-04 01:00:00",
         "BINANCE:XRPUSDT",
         "2.7",
         "2.7874",
         "2.4209",
         "2.5274",
         "621552965.0"
        ],
        [
         "2025-02-05 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5275",
         "2.5692",
         "2.3384",
         "2.381",
         "338815093.0"
        ],
        [
         "2025-02-06 01:00:00",
         "BINANCE:XRPUSDT",
         "2.381",
         "2.4699",
         "2.2772",
         "2.325",
         "322896937.0"
        ],
        [
         "2025-02-07 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3251",
         "2.542",
         "2.2655",
         "2.3968",
         "447487945.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 66
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-12-20 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2391</td>\n",
       "      <td>2.3550</td>\n",
       "      <td>1.9601</td>\n",
       "      <td>2.2793</td>\n",
       "      <td>1.110347e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-21 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2793</td>\n",
       "      <td>2.3858</td>\n",
       "      <td>2.1915</td>\n",
       "      <td>2.2380</td>\n",
       "      <td>4.515999e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-22 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2379</td>\n",
       "      <td>2.2938</td>\n",
       "      <td>2.1604</td>\n",
       "      <td>2.2031</td>\n",
       "      <td>3.103185e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-23 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2032</td>\n",
       "      <td>2.2789</td>\n",
       "      <td>2.1308</td>\n",
       "      <td>2.2617</td>\n",
       "      <td>3.888209e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2616</td>\n",
       "      <td>2.3507</td>\n",
       "      <td>2.2138</td>\n",
       "      <td>2.3238</td>\n",
       "      <td>2.490211e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5629</td>\n",
       "      <td>2.7470</td>\n",
       "      <td>2.5121</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.082441e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-20 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.7490</td>\n",
       "      <td>2.6671</td>\n",
       "      <td>2.6877</td>\n",
       "      <td>1.616046e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6878</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.5076</td>\n",
       "      <td>2.5721</td>\n",
       "      <td>2.577774e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5722</td>\n",
       "      <td>2.6099</td>\n",
       "      <td>2.5505</td>\n",
       "      <td>2.5740</td>\n",
       "      <td>9.267673e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-23 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5740</td>\n",
       "      <td>2.6016</td>\n",
       "      <td>2.5408</td>\n",
       "      <td>2.5673</td>\n",
       "      <td>4.397890e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              symbol    open    high     low   close  \\\n",
       "datetime                                                               \n",
       "2024-12-20 01:00:00  BINANCE:XRPUSDT  2.2391  2.3550  1.9601  2.2793   \n",
       "2024-12-21 01:00:00  BINANCE:XRPUSDT  2.2793  2.3858  2.1915  2.2380   \n",
       "2024-12-22 01:00:00  BINANCE:XRPUSDT  2.2379  2.2938  2.1604  2.2031   \n",
       "2024-12-23 01:00:00  BINANCE:XRPUSDT  2.2032  2.2789  2.1308  2.2617   \n",
       "2024-12-24 01:00:00  BINANCE:XRPUSDT  2.2616  2.3507  2.2138  2.3238   \n",
       "...                              ...     ...     ...     ...     ...   \n",
       "2025-02-19 01:00:00  BINANCE:XRPUSDT  2.5629  2.7470  2.5121  2.7378   \n",
       "2025-02-20 01:00:00  BINANCE:XRPUSDT  2.7378  2.7490  2.6671  2.6877   \n",
       "2025-02-21 01:00:00  BINANCE:XRPUSDT  2.6878  2.7160  2.5076  2.5721   \n",
       "2025-02-22 01:00:00  BINANCE:XRPUSDT  2.5722  2.6099  2.5505  2.5740   \n",
       "2025-02-23 01:00:00  BINANCE:XRPUSDT  2.5740  2.6016  2.5408  2.5673   \n",
       "\n",
       "                           volume  \n",
       "datetime                           \n",
       "2024-12-20 01:00:00  1.110347e+09  \n",
       "2024-12-21 01:00:00  4.515999e+08  \n",
       "2024-12-22 01:00:00  3.103185e+08  \n",
       "2024-12-23 01:00:00  3.888209e+08  \n",
       "2024-12-24 01:00:00  2.490211e+08  \n",
       "...                           ...  \n",
       "2025-02-19 01:00:00  2.082441e+08  \n",
       "2025-02-20 01:00:00  1.616046e+08  \n",
       "2025-02-21 01:00:00  2.577774e+08  \n",
       "2025-02-22 01:00:00  9.267673e+07  \n",
       "2025-02-23 01:00:00  4.397890e+07  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrp_usdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrp_usdt.to_csv(\"xrpusdt_daily_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tvDatafeed.main:Connection timed out\n",
      "ERROR:tvDatafeed.main:no data, please check the exchange and symbol\n"
     ]
    }
   ],
   "source": [
    "symbol = \"XRPUSDT\"\n",
    "exchange = \"BINANCE\"\n",
    "interval = Interval.in_weekly\n",
    "\n",
    "n_bars = 540\n",
    "\n",
    "xrp_usdt_wk = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8ea113fc-273f-4749-b6a9-ebd198eae221",
       "rows": [
        [
         "2018-04-30 02:00:00",
         "BINANCE:XRPUSDT",
         "0.5",
         "1.5",
         "0.5",
         "0.86483",
         "53708414.92"
        ],
        [
         "2018-05-07 02:00:00",
         "BINANCE:XRPUSDT",
         "0.86482",
         "0.86886",
         "0.62519",
         "0.72999",
         "121388954.11999999"
        ],
        [
         "2018-05-14 02:00:00",
         "BINANCE:XRPUSDT",
         "0.72999",
         "0.7499",
         "0.646",
         "0.6994",
         "81034091.66999997"
        ],
        [
         "2018-05-21 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6994",
         "0.705",
         "0.5731",
         "0.60416",
         "119363181.71999991"
        ],
        [
         "2018-05-28 02:00:00",
         "BINANCE:XRPUSDT",
         "0.60417",
         "0.69101",
         "0.54303",
         "0.6901",
         "234446288.8900001"
        ],
        [
         "2018-06-04 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6901",
         "0.707",
         "0.55",
         "0.58201",
         "271258795.2400001"
        ],
        [
         "2018-06-11 02:00:00",
         "BINANCE:XRPUSDT",
         "0.58202",
         "0.6",
         "0.50401",
         "0.52617",
         "210360409.30999994"
        ],
        [
         "2018-06-18 02:00:00",
         "BINANCE:XRPUSDT",
         "0.52669",
         "0.56185",
         "0.43724",
         "0.47331",
         "237851499.46999994"
        ],
        [
         "2018-06-25 02:00:00",
         "BINANCE:XRPUSDT",
         "0.47418",
         "0.4992",
         "0.42393",
         "0.46222",
         "221559857.99999997"
        ],
        [
         "2018-07-02 02:00:00",
         "BINANCE:XRPUSDT",
         "0.46222",
         "0.52",
         "0.452",
         "0.47915",
         "228489152.79999992"
        ],
        [
         "2018-07-09 02:00:00",
         "BINANCE:XRPUSDT",
         "0.47872",
         "0.48201",
         "0.4236",
         "0.44681",
         "210551925.79999995"
        ],
        [
         "2018-07-16 02:00:00",
         "BINANCE:XRPUSDT",
         "0.44695",
         "0.52525",
         "0.431",
         "0.44859",
         "276395688.70000005"
        ],
        [
         "2018-07-23 02:00:00",
         "BINANCE:XRPUSDT",
         "0.44859",
         "0.4715",
         "0.438",
         "0.45315",
         "248825450.5000001"
        ],
        [
         "2018-07-30 02:00:00",
         "BINANCE:XRPUSDT",
         "0.45315",
         "0.46382",
         "0.4253",
         "0.4345",
         "251962379.7999999"
        ],
        [
         "2018-08-06 02:00:00",
         "BINANCE:XRPUSDT",
         "0.43437",
         "0.43699",
         "0.2874",
         "0.29547",
         "329337770.8100002"
        ],
        [
         "2018-08-13 02:00:00",
         "BINANCE:XRPUSDT",
         "0.29575",
         "0.37506",
         "0.24672",
         "0.34201",
         "447467944.04"
        ],
        [
         "2018-08-20 02:00:00",
         "BINANCE:XRPUSDT",
         "0.34201",
         "0.35499",
         "0.31039",
         "0.32276",
         "319657665.20000005"
        ],
        [
         "2018-08-27 02:00:00",
         "BINANCE:XRPUSDT",
         "0.32277",
         "0.35809",
         "0.32145",
         "0.34253",
         "340787215.30000013"
        ],
        [
         "2018-09-03 02:00:00",
         "BINANCE:XRPUSDT",
         "0.34237",
         "0.34387",
         "0.2676",
         "0.2766",
         "345372033.59999996"
        ],
        [
         "2018-09-10 02:00:00",
         "BINANCE:XRPUSDT",
         "0.27699",
         "0.2867",
         "0.25261",
         "0.28122",
         "315998295.1000001"
        ],
        [
         "2018-09-17 02:00:00",
         "BINANCE:XRPUSDT",
         "0.28122",
         "0.8",
         "0.26662",
         "0.5719",
         "1848231045.4399977"
        ],
        [
         "2018-09-24 02:00:00",
         "BINANCE:XRPUSDT",
         "0.5719",
         "0.62604",
         "0.43558",
         "0.58257",
         "1852610826.600001"
        ],
        [
         "2018-10-01 02:00:00",
         "BINANCE:XRPUSDT",
         "0.58257",
         "0.6059",
         "0.46666",
         "0.48269",
         "1065317910.1000001"
        ],
        [
         "2018-10-08 02:00:00",
         "BINANCE:XRPUSDT",
         "0.4826",
         "0.50449",
         "0.37685",
         "0.40994",
         "846410261.2000003"
        ],
        [
         "2018-10-15 02:00:00",
         "BINANCE:XRPUSDT",
         "0.40951",
         "0.52179",
         "0.39771",
         "0.46458",
         "789297869.2999997"
        ],
        [
         "2018-10-22 02:00:00",
         "BINANCE:XRPUSDT",
         "0.46458",
         "0.48649",
         "0.444",
         "0.46472",
         "280789996.8"
        ],
        [
         "2018-10-29 01:00:00",
         "BINANCE:XRPUSDT",
         "0.46483",
         "0.47959",
         "0.4343",
         "0.46999",
         "255062271.60000005"
        ],
        [
         "2018-11-05 01:00:00",
         "BINANCE:XRPUSDT",
         "0.46999",
         "0.56878",
         "0.461",
         "0.51019",
         "540162399.8000001"
        ],
        [
         "2018-11-12 01:00:00",
         "BINANCE:XRPUSDT",
         "0.51018",
         "0.53499",
         "0.422",
         "0.51611",
         "795614369.7000002"
        ],
        [
         "2018-11-19 01:00:00",
         "BINANCE:XRPUSDT",
         "0.51608",
         "0.51695",
         "0.32802",
         "0.382",
         "1495928889.8000007"
        ],
        [
         "2018-11-26 01:00:00",
         "BINANCE:XRPUSDT",
         "0.38186",
         "0.40319",
         "0.34625",
         "0.36963",
         "866160179.5000006"
        ],
        [
         "2018-12-03 01:00:00",
         "BINANCE:XRPUSDT",
         "0.36974",
         "0.371",
         "0.2865",
         "0.30914",
         "540876691.4999999"
        ],
        [
         "2018-12-10 01:00:00",
         "BINANCE:XRPUSDT",
         "0.30944",
         "0.31377",
         "0.2805",
         "0.28669",
         "332181523.09999985"
        ],
        [
         "2018-12-17 01:00:00",
         "BINANCE:XRPUSDT",
         "0.28669",
         "0.39265",
         "0.285",
         "0.3669",
         "1018531472.1000004"
        ],
        [
         "2018-12-24 01:00:00",
         "BINANCE:XRPUSDT",
         "0.36691",
         "0.45",
         "0.325",
         "0.36489",
         "1033361262.2999996"
        ],
        [
         "2018-12-31 01:00:00",
         "BINANCE:XRPUSDT",
         "0.36488",
         "0.3745",
         "0.3435",
         "0.36042",
         "415447214.2999999"
        ],
        [
         "2019-01-07 01:00:00",
         "BINANCE:XRPUSDT",
         "0.36042",
         "0.37963",
         "0.30796",
         "0.31132",
         "558053696.5000001"
        ],
        [
         "2019-01-14 01:00:00",
         "BINANCE:XRPUSDT",
         "0.31139",
         "0.33593",
         "0.31089",
         "0.3168",
         "329972703.3"
        ],
        [
         "2019-01-21 01:00:00",
         "BINANCE:XRPUSDT",
         "0.31697",
         "0.32163",
         "0.30272",
         "0.30646",
         "238355730.8"
        ],
        [
         "2019-01-28 01:00:00",
         "BINANCE:XRPUSDT",
         "0.30653",
         "0.3358",
         "0.28089",
         "0.30219",
         "629460408.8000003"
        ],
        [
         "2019-02-04 01:00:00",
         "BINANCE:XRPUSDT",
         "0.30204",
         "0.32129",
         "0.28809",
         "0.30988",
         "415476528.9000001"
        ],
        [
         "2019-02-11 01:00:00",
         "BINANCE:XRPUSDT",
         "0.30985",
         "0.31373",
         "0.296",
         "0.30318",
         "303284489.0999999"
        ],
        [
         "2019-02-18 01:00:00",
         "BINANCE:XRPUSDT",
         "0.3031",
         "0.34777",
         "0.29371",
         "0.29757",
         "830088176.6"
        ],
        [
         "2019-02-25 01:00:00",
         "BINANCE:XRPUSDT",
         "0.29757",
         "0.33975",
         "0.29672",
         "0.31114",
         "691760105.2999997"
        ],
        [
         "2019-03-04 01:00:00",
         "BINANCE:XRPUSDT",
         "0.31115",
         "0.32186",
         "0.29728",
         "0.31289",
         "395923440.49999994"
        ],
        [
         "2019-03-11 01:00:00",
         "BINANCE:XRPUSDT",
         "0.31279",
         "0.32555",
         "0.30585",
         "0.3154",
         "351513621.20000017"
        ],
        [
         "2019-03-18 01:00:00",
         "BINANCE:XRPUSDT",
         "0.31546",
         "0.32275",
         "0.29",
         "0.30787",
         "325521487.40000004"
        ],
        [
         "2019-03-25 01:00:00",
         "BINANCE:XRPUSDT",
         "0.30792",
         "0.31834",
         "0.294",
         "0.30889",
         "332594397.7"
        ],
        [
         "2019-04-01 02:00:00",
         "BINANCE:XRPUSDT",
         "0.30889",
         "0.37999",
         "0.30739",
         "0.3612",
         "1273438659.5999997"
        ],
        [
         "2019-04-08 02:00:00",
         "BINANCE:XRPUSDT",
         "0.36149",
         "0.37012",
         "0.31391",
         "0.32762",
         "590131129.6999999"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 356
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-30 02:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.86483</td>\n",
       "      <td>5.370841e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-07 02:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.86482</td>\n",
       "      <td>0.86886</td>\n",
       "      <td>0.62519</td>\n",
       "      <td>0.72999</td>\n",
       "      <td>1.213890e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14 02:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.72999</td>\n",
       "      <td>0.74990</td>\n",
       "      <td>0.64600</td>\n",
       "      <td>0.69940</td>\n",
       "      <td>8.103409e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-21 02:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.69940</td>\n",
       "      <td>0.70500</td>\n",
       "      <td>0.57310</td>\n",
       "      <td>0.60416</td>\n",
       "      <td>1.193632e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-28 02:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.60417</td>\n",
       "      <td>0.69101</td>\n",
       "      <td>0.54303</td>\n",
       "      <td>0.69010</td>\n",
       "      <td>2.344463e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-20 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.95860</td>\n",
       "      <td>3.36950</td>\n",
       "      <td>2.90900</td>\n",
       "      <td>3.02230</td>\n",
       "      <td>2.273316e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-27 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>3.02220</td>\n",
       "      <td>3.21400</td>\n",
       "      <td>2.46030</td>\n",
       "      <td>2.58000</td>\n",
       "      <td>2.477353e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-03 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.58010</td>\n",
       "      <td>2.78740</td>\n",
       "      <td>1.77110</td>\n",
       "      <td>2.39280</td>\n",
       "      <td>3.956435e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-10 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.39280</td>\n",
       "      <td>2.83560</td>\n",
       "      <td>2.32350</td>\n",
       "      <td>2.72830</td>\n",
       "      <td>1.620221e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-17 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76480</td>\n",
       "      <td>2.46930</td>\n",
       "      <td>2.56460</td>\n",
       "      <td>1.169534e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              symbol     open     high      low    close  \\\n",
       "datetime                                                                   \n",
       "2018-04-30 02:00:00  BINANCE:XRPUSDT  0.50000  1.50000  0.50000  0.86483   \n",
       "2018-05-07 02:00:00  BINANCE:XRPUSDT  0.86482  0.86886  0.62519  0.72999   \n",
       "2018-05-14 02:00:00  BINANCE:XRPUSDT  0.72999  0.74990  0.64600  0.69940   \n",
       "2018-05-21 02:00:00  BINANCE:XRPUSDT  0.69940  0.70500  0.57310  0.60416   \n",
       "2018-05-28 02:00:00  BINANCE:XRPUSDT  0.60417  0.69101  0.54303  0.69010   \n",
       "...                              ...      ...      ...      ...      ...   \n",
       "2025-01-20 01:00:00  BINANCE:XRPUSDT  2.95860  3.36950  2.90900  3.02230   \n",
       "2025-01-27 01:00:00  BINANCE:XRPUSDT  3.02220  3.21400  2.46030  2.58000   \n",
       "2025-02-03 01:00:00  BINANCE:XRPUSDT  2.58010  2.78740  1.77110  2.39280   \n",
       "2025-02-10 01:00:00  BINANCE:XRPUSDT  2.39280  2.83560  2.32350  2.72830   \n",
       "2025-02-17 01:00:00  BINANCE:XRPUSDT  2.72830  2.76480  2.46930  2.56460   \n",
       "\n",
       "                           volume  \n",
       "datetime                           \n",
       "2018-04-30 02:00:00  5.370841e+07  \n",
       "2018-05-07 02:00:00  1.213890e+08  \n",
       "2018-05-14 02:00:00  8.103409e+07  \n",
       "2018-05-21 02:00:00  1.193632e+08  \n",
       "2018-05-28 02:00:00  2.344463e+08  \n",
       "...                           ...  \n",
       "2025-01-20 01:00:00  2.273316e+09  \n",
       "2025-01-27 01:00:00  2.477353e+09  \n",
       "2025-02-03 01:00:00  3.956435e+09  \n",
       "2025-02-10 01:00:00  1.620221e+09  \n",
       "2025-02-17 01:00:00  1.169534e+09  \n",
       "\n",
       "[356 rows x 6 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrp_usdt_wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"XRPUSDT\"\n",
    "exchange = \"BINANCE\"\n",
    "interval = Interval.in_1_hour\n",
    "\n",
    "n_bars = 24\n",
    "\n",
    "xrp_usdt_hr = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ee8ab9ae-d218-46c6-ae15-e1db13c1fa40",
       "rows": [
        [
         "2025-02-21 13:00:00",
         "BINANCE:XRPUSDT",
         "2.6508",
         "2.6661",
         "2.6454",
         "2.6656",
         "4207626.0"
        ],
        [
         "2025-02-21 14:00:00",
         "BINANCE:XRPUSDT",
         "2.6656",
         "2.716",
         "2.6655",
         "2.6987",
         "16416120.0"
        ],
        [
         "2025-02-21 15:00:00",
         "BINANCE:XRPUSDT",
         "2.6987",
         "2.7012",
         "2.65",
         "2.6685",
         "12461739.0"
        ],
        [
         "2025-02-21 16:00:00",
         "BINANCE:XRPUSDT",
         "2.6685",
         "2.6981",
         "2.5644",
         "2.6144",
         "42109724.0"
        ],
        [
         "2025-02-21 17:00:00",
         "BINANCE:XRPUSDT",
         "2.6144",
         "2.6473",
         "2.5944",
         "2.6297",
         "20388867.0"
        ],
        [
         "2025-02-21 18:00:00",
         "BINANCE:XRPUSDT",
         "2.6297",
         "2.6394",
         "2.558",
         "2.5688",
         "18645968.0"
        ],
        [
         "2025-02-21 19:00:00",
         "BINANCE:XRPUSDT",
         "2.5687",
         "2.5858",
         "2.5539",
         "2.5756",
         "10053707.0"
        ],
        [
         "2025-02-21 20:00:00",
         "BINANCE:XRPUSDT",
         "2.5755",
         "2.5833",
         "2.5076",
         "2.5257",
         "17604034.0"
        ],
        [
         "2025-02-21 21:00:00",
         "BINANCE:XRPUSDT",
         "2.5257",
         "2.5489",
         "2.5158",
         "2.5279",
         "13147681.0"
        ],
        [
         "2025-02-21 22:00:00",
         "BINANCE:XRPUSDT",
         "2.5279",
         "2.5474",
         "2.527",
         "2.536",
         "10341231.0"
        ],
        [
         "2025-02-21 23:00:00",
         "BINANCE:XRPUSDT",
         "2.536",
         "2.5718",
         "2.5336",
         "2.5638",
         "14656355.0"
        ],
        [
         "2025-02-22 00:00:00",
         "BINANCE:XRPUSDT",
         "2.5638",
         "2.5763",
         "2.5537",
         "2.5721",
         "8168208.0"
        ],
        [
         "2025-02-22 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5722",
         "2.5878",
         "2.5505",
         "2.583",
         "6768689.0"
        ],
        [
         "2025-02-22 02:00:00",
         "BINANCE:XRPUSDT",
         "2.583",
         "2.5987",
         "2.5776",
         "2.5902",
         "4713115.0"
        ],
        [
         "2025-02-22 03:00:00",
         "BINANCE:XRPUSDT",
         "2.5902",
         "2.5902",
         "2.5626",
         "2.5733",
         "7816813.0"
        ],
        [
         "2025-02-22 04:00:00",
         "BINANCE:XRPUSDT",
         "2.5732",
         "2.5756",
         "2.5599",
         "2.5724",
         "5356849.0"
        ],
        [
         "2025-02-22 05:00:00",
         "BINANCE:XRPUSDT",
         "2.5724",
         "2.586",
         "2.5672",
         "2.5821",
         "3884029.0"
        ],
        [
         "2025-02-22 06:00:00",
         "BINANCE:XRPUSDT",
         "2.5822",
         "2.5858",
         "2.5715",
         "2.583",
         "2582501.0"
        ],
        [
         "2025-02-22 07:00:00",
         "BINANCE:XRPUSDT",
         "2.583",
         "2.5881",
         "2.578",
         "2.5855",
         "2237085.0"
        ],
        [
         "2025-02-22 08:00:00",
         "BINANCE:XRPUSDT",
         "2.5856",
         "2.5954",
         "2.5811",
         "2.5815",
         "2636432.0"
        ],
        [
         "2025-02-22 09:00:00",
         "BINANCE:XRPUSDT",
         "2.5815",
         "2.5854",
         "2.5641",
         "2.5721",
         "6850252.0"
        ],
        [
         "2025-02-22 10:00:00",
         "BINANCE:XRPUSDT",
         "2.5722",
         "2.5846",
         "2.5722",
         "2.583",
         "3307102.0"
        ],
        [
         "2025-02-22 11:00:00",
         "BINANCE:XRPUSDT",
         "2.583",
         "2.5967",
         "2.578",
         "2.5858",
         "6167358.0"
        ],
        [
         "2025-02-22 12:00:00",
         "BINANCE:XRPUSDT",
         "2.5858",
         "2.5915",
         "2.5842",
         "2.5843",
         "660616.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 24
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-02-21 13:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6508</td>\n",
       "      <td>2.6661</td>\n",
       "      <td>2.6454</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>4207626.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 14:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.6655</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>16416120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 15:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.7012</td>\n",
       "      <td>2.6500</td>\n",
       "      <td>2.6685</td>\n",
       "      <td>12461739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 16:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6685</td>\n",
       "      <td>2.6981</td>\n",
       "      <td>2.5644</td>\n",
       "      <td>2.6144</td>\n",
       "      <td>42109724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 17:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6144</td>\n",
       "      <td>2.6473</td>\n",
       "      <td>2.5944</td>\n",
       "      <td>2.6297</td>\n",
       "      <td>20388867.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 18:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6297</td>\n",
       "      <td>2.6394</td>\n",
       "      <td>2.5580</td>\n",
       "      <td>2.5688</td>\n",
       "      <td>18645968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 19:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5687</td>\n",
       "      <td>2.5858</td>\n",
       "      <td>2.5539</td>\n",
       "      <td>2.5756</td>\n",
       "      <td>10053707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 20:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5755</td>\n",
       "      <td>2.5833</td>\n",
       "      <td>2.5076</td>\n",
       "      <td>2.5257</td>\n",
       "      <td>17604034.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 21:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5257</td>\n",
       "      <td>2.5489</td>\n",
       "      <td>2.5158</td>\n",
       "      <td>2.5279</td>\n",
       "      <td>13147681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 22:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5279</td>\n",
       "      <td>2.5474</td>\n",
       "      <td>2.5270</td>\n",
       "      <td>2.5360</td>\n",
       "      <td>10341231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 23:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5360</td>\n",
       "      <td>2.5718</td>\n",
       "      <td>2.5336</td>\n",
       "      <td>2.5638</td>\n",
       "      <td>14656355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 00:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5638</td>\n",
       "      <td>2.5763</td>\n",
       "      <td>2.5537</td>\n",
       "      <td>2.5721</td>\n",
       "      <td>8168208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5722</td>\n",
       "      <td>2.5878</td>\n",
       "      <td>2.5505</td>\n",
       "      <td>2.5830</td>\n",
       "      <td>6768689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 02:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5830</td>\n",
       "      <td>2.5987</td>\n",
       "      <td>2.5776</td>\n",
       "      <td>2.5902</td>\n",
       "      <td>4713115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 03:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5902</td>\n",
       "      <td>2.5902</td>\n",
       "      <td>2.5626</td>\n",
       "      <td>2.5733</td>\n",
       "      <td>7816813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 04:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5732</td>\n",
       "      <td>2.5756</td>\n",
       "      <td>2.5599</td>\n",
       "      <td>2.5724</td>\n",
       "      <td>5356849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 05:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5724</td>\n",
       "      <td>2.5860</td>\n",
       "      <td>2.5672</td>\n",
       "      <td>2.5821</td>\n",
       "      <td>3884029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 06:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5822</td>\n",
       "      <td>2.5858</td>\n",
       "      <td>2.5715</td>\n",
       "      <td>2.5830</td>\n",
       "      <td>2582501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 07:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5830</td>\n",
       "      <td>2.5881</td>\n",
       "      <td>2.5780</td>\n",
       "      <td>2.5855</td>\n",
       "      <td>2237085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 08:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5856</td>\n",
       "      <td>2.5954</td>\n",
       "      <td>2.5811</td>\n",
       "      <td>2.5815</td>\n",
       "      <td>2636432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 09:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5815</td>\n",
       "      <td>2.5854</td>\n",
       "      <td>2.5641</td>\n",
       "      <td>2.5721</td>\n",
       "      <td>6850252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 10:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5722</td>\n",
       "      <td>2.5846</td>\n",
       "      <td>2.5722</td>\n",
       "      <td>2.5830</td>\n",
       "      <td>3307102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 11:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5830</td>\n",
       "      <td>2.5967</td>\n",
       "      <td>2.5780</td>\n",
       "      <td>2.5858</td>\n",
       "      <td>6167358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 12:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5858</td>\n",
       "      <td>2.5915</td>\n",
       "      <td>2.5842</td>\n",
       "      <td>2.5843</td>\n",
       "      <td>660616.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              symbol    open    high     low   close  \\\n",
       "datetime                                                               \n",
       "2025-02-21 13:00:00  BINANCE:XRPUSDT  2.6508  2.6661  2.6454  2.6656   \n",
       "2025-02-21 14:00:00  BINANCE:XRPUSDT  2.6656  2.7160  2.6655  2.6987   \n",
       "2025-02-21 15:00:00  BINANCE:XRPUSDT  2.6987  2.7012  2.6500  2.6685   \n",
       "2025-02-21 16:00:00  BINANCE:XRPUSDT  2.6685  2.6981  2.5644  2.6144   \n",
       "2025-02-21 17:00:00  BINANCE:XRPUSDT  2.6144  2.6473  2.5944  2.6297   \n",
       "2025-02-21 18:00:00  BINANCE:XRPUSDT  2.6297  2.6394  2.5580  2.5688   \n",
       "2025-02-21 19:00:00  BINANCE:XRPUSDT  2.5687  2.5858  2.5539  2.5756   \n",
       "2025-02-21 20:00:00  BINANCE:XRPUSDT  2.5755  2.5833  2.5076  2.5257   \n",
       "2025-02-21 21:00:00  BINANCE:XRPUSDT  2.5257  2.5489  2.5158  2.5279   \n",
       "2025-02-21 22:00:00  BINANCE:XRPUSDT  2.5279  2.5474  2.5270  2.5360   \n",
       "2025-02-21 23:00:00  BINANCE:XRPUSDT  2.5360  2.5718  2.5336  2.5638   \n",
       "2025-02-22 00:00:00  BINANCE:XRPUSDT  2.5638  2.5763  2.5537  2.5721   \n",
       "2025-02-22 01:00:00  BINANCE:XRPUSDT  2.5722  2.5878  2.5505  2.5830   \n",
       "2025-02-22 02:00:00  BINANCE:XRPUSDT  2.5830  2.5987  2.5776  2.5902   \n",
       "2025-02-22 03:00:00  BINANCE:XRPUSDT  2.5902  2.5902  2.5626  2.5733   \n",
       "2025-02-22 04:00:00  BINANCE:XRPUSDT  2.5732  2.5756  2.5599  2.5724   \n",
       "2025-02-22 05:00:00  BINANCE:XRPUSDT  2.5724  2.5860  2.5672  2.5821   \n",
       "2025-02-22 06:00:00  BINANCE:XRPUSDT  2.5822  2.5858  2.5715  2.5830   \n",
       "2025-02-22 07:00:00  BINANCE:XRPUSDT  2.5830  2.5881  2.5780  2.5855   \n",
       "2025-02-22 08:00:00  BINANCE:XRPUSDT  2.5856  2.5954  2.5811  2.5815   \n",
       "2025-02-22 09:00:00  BINANCE:XRPUSDT  2.5815  2.5854  2.5641  2.5721   \n",
       "2025-02-22 10:00:00  BINANCE:XRPUSDT  2.5722  2.5846  2.5722  2.5830   \n",
       "2025-02-22 11:00:00  BINANCE:XRPUSDT  2.5830  2.5967  2.5780  2.5858   \n",
       "2025-02-22 12:00:00  BINANCE:XRPUSDT  2.5858  2.5915  2.5842  2.5843   \n",
       "\n",
       "                         volume  \n",
       "datetime                         \n",
       "2025-02-21 13:00:00   4207626.0  \n",
       "2025-02-21 14:00:00  16416120.0  \n",
       "2025-02-21 15:00:00  12461739.0  \n",
       "2025-02-21 16:00:00  42109724.0  \n",
       "2025-02-21 17:00:00  20388867.0  \n",
       "2025-02-21 18:00:00  18645968.0  \n",
       "2025-02-21 19:00:00  10053707.0  \n",
       "2025-02-21 20:00:00  17604034.0  \n",
       "2025-02-21 21:00:00  13147681.0  \n",
       "2025-02-21 22:00:00  10341231.0  \n",
       "2025-02-21 23:00:00  14656355.0  \n",
       "2025-02-22 00:00:00   8168208.0  \n",
       "2025-02-22 01:00:00   6768689.0  \n",
       "2025-02-22 02:00:00   4713115.0  \n",
       "2025-02-22 03:00:00   7816813.0  \n",
       "2025-02-22 04:00:00   5356849.0  \n",
       "2025-02-22 05:00:00   3884029.0  \n",
       "2025-02-22 06:00:00   2582501.0  \n",
       "2025-02-22 07:00:00   2237085.0  \n",
       "2025-02-22 08:00:00   2636432.0  \n",
       "2025-02-22 09:00:00   6850252.0  \n",
       "2025-02-22 10:00:00   3307102.0  \n",
       "2025-02-22 11:00:00   6167358.0  \n",
       "2025-02-22 12:00:00    660616.0  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrp_usdt_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xrp_usdt_hr['av_pr'] = xrp_usdt_hr.apply(ave, axis=1)\n",
    "xrp_usdt_hr['diff'] = xrp_usdt_hr.apply(diff, axis=1)\n",
    "xrp_usdt_hr['candle'] = xrp_usdt_hr.apply(candle, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"XRPUSDT\"\n",
    "exchange = \"BINANCE\"\n",
    "interval = Interval.in_1_hour\n",
    "\n",
    "n_bars = 35136\n",
    "\n",
    "xrp_usdt_hr_main = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"BTCUSDT\"\n",
    "exchange = \"BINANCE\"\n",
    "interval = Interval.in_daily\n",
    "\n",
    "n_bars = 4380\n",
    "\n",
    "btc_usdt_main = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_usdt_main.to_csv('btcusdt_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_usdt_hr_main.to_csv('btcusdt_hourly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e2db013d-d4f0-48b0-bbb2-f9a71b80afe3",
       "rows": [
        [
         "2024-01-01 01:00:00",
         "BINANCE:XRPUSDT",
         "0.6155",
         "0.6172",
         "0.6146",
         "0.6162",
         "14498728.0"
        ],
        [
         "2024-01-01 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6161",
         "0.619",
         "0.615",
         "0.6185",
         "9029149.0"
        ],
        [
         "2024-01-01 03:00:00",
         "BINANCE:XRPUSDT",
         "0.6184",
         "0.6186",
         "0.6149",
         "0.6154",
         "6553752.0"
        ],
        [
         "2024-01-01 04:00:00",
         "BINANCE:XRPUSDT",
         "0.6154",
         "0.6157",
         "0.6112",
         "0.613",
         "8001610.0"
        ],
        [
         "2024-01-01 05:00:00",
         "BINANCE:XRPUSDT",
         "0.6129",
         "0.6134",
         "0.6093",
         "0.6116",
         "10514620.0"
        ],
        [
         "2024-01-01 06:00:00",
         "BINANCE:XRPUSDT",
         "0.6116",
         "0.6124",
         "0.6083",
         "0.6087",
         "7622323.0"
        ],
        [
         "2024-01-01 07:00:00",
         "BINANCE:XRPUSDT",
         "0.6087",
         "0.6129",
         "0.6084",
         "0.6127",
         "5515748.0"
        ],
        [
         "2024-01-01 08:00:00",
         "BINANCE:XRPUSDT",
         "0.6127",
         "0.6153",
         "0.6127",
         "0.615",
         "3607686.0"
        ],
        [
         "2024-01-01 09:00:00",
         "BINANCE:XRPUSDT",
         "0.615",
         "0.6163",
         "0.6143",
         "0.6161",
         "4436880.0"
        ],
        [
         "2024-01-01 10:00:00",
         "BINANCE:XRPUSDT",
         "0.6161",
         "0.6177",
         "0.6152",
         "0.6175",
         "4422313.0"
        ],
        [
         "2024-01-01 11:00:00",
         "BINANCE:XRPUSDT",
         "0.6175",
         "0.619",
         "0.6173",
         "0.6188",
         "4925516.0"
        ],
        [
         "2024-01-01 12:00:00",
         "BINANCE:XRPUSDT",
         "0.6188",
         "0.6207",
         "0.6177",
         "0.6205",
         "6067891.0"
        ],
        [
         "2024-01-01 13:00:00",
         "BINANCE:XRPUSDT",
         "0.6205",
         "0.6213",
         "0.6191",
         "0.6196",
         "5869164.0"
        ],
        [
         "2024-01-01 14:00:00",
         "BINANCE:XRPUSDT",
         "0.6197",
         "0.6216",
         "0.619",
         "0.621",
         "5679263.0"
        ],
        [
         "2024-01-01 15:00:00",
         "BINANCE:XRPUSDT",
         "0.6209",
         "0.621",
         "0.6183",
         "0.6193",
         "6224809.0"
        ],
        [
         "2024-01-01 16:00:00",
         "BINANCE:XRPUSDT",
         "0.6193",
         "0.6219",
         "0.619",
         "0.6213",
         "5328702.0"
        ],
        [
         "2024-01-01 17:00:00",
         "BINANCE:XRPUSDT",
         "0.6213",
         "0.622",
         "0.6198",
         "0.6209",
         "6248474.0"
        ],
        [
         "2024-01-01 18:00:00",
         "BINANCE:XRPUSDT",
         "0.6208",
         "0.6237",
         "0.6206",
         "0.6232",
         "4728255.0"
        ],
        [
         "2024-01-01 19:00:00",
         "BINANCE:XRPUSDT",
         "0.6233",
         "0.6254",
         "0.6231",
         "0.6237",
         "7106348.0"
        ],
        [
         "2024-01-01 20:00:00",
         "BINANCE:XRPUSDT",
         "0.6238",
         "0.626",
         "0.6237",
         "0.6258",
         "6658451.0"
        ],
        [
         "2024-01-01 21:00:00",
         "BINANCE:XRPUSDT",
         "0.6258",
         "0.6289",
         "0.6255",
         "0.6276",
         "11038195.0"
        ],
        [
         "2024-01-01 22:00:00",
         "BINANCE:XRPUSDT",
         "0.6277",
         "0.6283",
         "0.6266",
         "0.6282",
         "6331827.0"
        ],
        [
         "2024-01-01 23:00:00",
         "BINANCE:XRPUSDT",
         "0.6281",
         "0.6286",
         "0.6257",
         "0.6269",
         "5483173.0"
        ],
        [
         "2024-01-02 00:00:00",
         "BINANCE:XRPUSDT",
         "0.6269",
         "0.6309",
         "0.6269",
         "0.6294",
         "9976523.0"
        ],
        [
         "2024-01-02 01:00:00",
         "BINANCE:XRPUSDT",
         "0.6295",
         "0.6327",
         "0.6287",
         "0.6314",
         "27514701.0"
        ],
        [
         "2024-01-02 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6314",
         "0.6344",
         "0.631",
         "0.6323",
         "14919889.0"
        ],
        [
         "2024-01-02 03:00:00",
         "BINANCE:XRPUSDT",
         "0.6323",
         "0.6354",
         "0.6317",
         "0.634",
         "11160952.0"
        ],
        [
         "2024-01-02 04:00:00",
         "BINANCE:XRPUSDT",
         "0.634",
         "0.6348",
         "0.6317",
         "0.6339",
         "9683658.0"
        ],
        [
         "2024-01-02 05:00:00",
         "BINANCE:XRPUSDT",
         "0.6339",
         "0.6343",
         "0.6327",
         "0.6334",
         "8161331.0"
        ],
        [
         "2024-01-02 06:00:00",
         "BINANCE:XRPUSDT",
         "0.6333",
         "0.6343",
         "0.6289",
         "0.6301",
         "11923852.0"
        ],
        [
         "2024-01-02 07:00:00",
         "BINANCE:XRPUSDT",
         "0.6301",
         "0.6306",
         "0.6277",
         "0.6282",
         "23775317.0"
        ],
        [
         "2024-01-02 08:00:00",
         "BINANCE:XRPUSDT",
         "0.6282",
         "0.6321",
         "0.6281",
         "0.6307",
         "17415828.0"
        ],
        [
         "2024-01-02 09:00:00",
         "BINANCE:XRPUSDT",
         "0.6307",
         "0.6334",
         "0.6291",
         "0.6329",
         "24496588.0"
        ],
        [
         "2024-01-02 10:00:00",
         "BINANCE:XRPUSDT",
         "0.6328",
         "0.6405",
         "0.6313",
         "0.6377",
         "25115367.0"
        ],
        [
         "2024-01-02 11:00:00",
         "BINANCE:XRPUSDT",
         "0.6377",
         "0.6381",
         "0.634",
         "0.6366",
         "21126103.0"
        ],
        [
         "2024-01-02 12:00:00",
         "BINANCE:XRPUSDT",
         "0.6366",
         "0.6367",
         "0.63",
         "0.632",
         "22137767.0"
        ],
        [
         "2024-01-02 13:00:00",
         "BINANCE:XRPUSDT",
         "0.632",
         "0.634",
         "0.6278",
         "0.6298",
         "18026227.0"
        ],
        [
         "2024-01-02 14:00:00",
         "BINANCE:XRPUSDT",
         "0.6297",
         "0.6329",
         "0.6288",
         "0.6317",
         "10862122.0"
        ],
        [
         "2024-01-02 15:00:00",
         "BINANCE:XRPUSDT",
         "0.6316",
         "0.6324",
         "0.623",
         "0.6254",
         "27806283.0"
        ],
        [
         "2024-01-02 16:00:00",
         "BINANCE:XRPUSDT",
         "0.6253",
         "0.6282",
         "0.6218",
         "0.6256",
         "16160486.0"
        ],
        [
         "2024-01-02 17:00:00",
         "BINANCE:XRPUSDT",
         "0.6255",
         "0.6272",
         "0.6224",
         "0.6272",
         "12275659.0"
        ],
        [
         "2024-01-02 18:00:00",
         "BINANCE:XRPUSDT",
         "0.6271",
         "0.6272",
         "0.6213",
         "0.6228",
         "11171014.0"
        ],
        [
         "2024-01-02 19:00:00",
         "BINANCE:XRPUSDT",
         "0.6229",
         "0.6264",
         "0.6226",
         "0.6256",
         "11738872.0"
        ],
        [
         "2024-01-02 20:00:00",
         "BINANCE:XRPUSDT",
         "0.6256",
         "0.6292",
         "0.625",
         "0.6276",
         "11702497.0"
        ],
        [
         "2024-01-02 21:00:00",
         "BINANCE:XRPUSDT",
         "0.6276",
         "0.629",
         "0.6253",
         "0.6259",
         "9379802.0"
        ],
        [
         "2024-01-02 22:00:00",
         "BINANCE:XRPUSDT",
         "0.6259",
         "0.628",
         "0.6237",
         "0.6272",
         "8102154.0"
        ],
        [
         "2024-01-02 23:00:00",
         "BINANCE:XRPUSDT",
         "0.6272",
         "0.6283",
         "0.6248",
         "0.6273",
         "7594774.0"
        ],
        [
         "2024-01-03 00:00:00",
         "BINANCE:XRPUSDT",
         "0.6273",
         "0.628",
         "0.624",
         "0.6246",
         "8818251.0"
        ],
        [
         "2024-01-03 01:00:00",
         "BINANCE:XRPUSDT",
         "0.6245",
         "0.6273",
         "0.6226",
         "0.6266",
         "18827999.0"
        ],
        [
         "2024-01-03 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6265",
         "0.6279",
         "0.6264",
         "0.6274",
         "6271377.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10023
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6155</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.6146</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>14498728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 02:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>9029149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 03:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.6186</td>\n",
       "      <td>0.6149</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>6553752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 04:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.6157</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>8001610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 05:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6129</td>\n",
       "      <td>0.6134</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>10514620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 11:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6787</td>\n",
       "      <td>2.6601</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>4420326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 12:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6758</td>\n",
       "      <td>2.6773</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>6597897.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 13:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6508</td>\n",
       "      <td>2.6661</td>\n",
       "      <td>2.6454</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>4207626.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 14:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.6655</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>16416120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 15:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.7012</td>\n",
       "      <td>2.6793</td>\n",
       "      <td>2.6851</td>\n",
       "      <td>3973640.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10023 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              symbol    open    high     low   close  \\\n",
       "datetime                                                               \n",
       "2024-01-01 01:00:00  BINANCE:XRPUSDT  0.6155  0.6172  0.6146  0.6162   \n",
       "2024-01-01 02:00:00  BINANCE:XRPUSDT  0.6161  0.6190  0.6150  0.6185   \n",
       "2024-01-01 03:00:00  BINANCE:XRPUSDT  0.6184  0.6186  0.6149  0.6154   \n",
       "2024-01-01 04:00:00  BINANCE:XRPUSDT  0.6154  0.6157  0.6112  0.6130   \n",
       "2024-01-01 05:00:00  BINANCE:XRPUSDT  0.6129  0.6134  0.6093  0.6116   \n",
       "...                              ...     ...     ...     ...     ...   \n",
       "2025-02-21 11:00:00  BINANCE:XRPUSDT  2.6670  2.6787  2.6601  2.6757   \n",
       "2025-02-21 12:00:00  BINANCE:XRPUSDT  2.6758  2.6773  2.6507  2.6507   \n",
       "2025-02-21 13:00:00  BINANCE:XRPUSDT  2.6508  2.6661  2.6454  2.6656   \n",
       "2025-02-21 14:00:00  BINANCE:XRPUSDT  2.6656  2.7160  2.6655  2.6987   \n",
       "2025-02-21 15:00:00  BINANCE:XRPUSDT  2.6987  2.7012  2.6793  2.6851   \n",
       "\n",
       "                         volume  \n",
       "datetime                         \n",
       "2024-01-01 01:00:00  14498728.0  \n",
       "2024-01-01 02:00:00   9029149.0  \n",
       "2024-01-01 03:00:00   6553752.0  \n",
       "2024-01-01 04:00:00   8001610.0  \n",
       "2024-01-01 05:00:00  10514620.0  \n",
       "...                         ...  \n",
       "2025-02-21 11:00:00   4420326.0  \n",
       "2025-02-21 12:00:00   6597897.0  \n",
       "2025-02-21 13:00:00   4207626.0  \n",
       "2025-02-21 14:00:00  16416120.0  \n",
       "2025-02-21 15:00:00   3973640.0  \n",
       "\n",
       "[10023 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrp_usdt_hr_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrp_usdt_hr_main['candle'] = xrp_usdt_hr_main.apply(candle, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "73b5c23c-4ee8-4854-b3a0-927fa2bad913",
       "rows": [
        [
         "2024-01-01 01:00:00",
         "BINANCE:XRPUSDT",
         "0.6155",
         "0.6172",
         "0.6146",
         "0.6162",
         "14498728.0",
         "0.6159",
         "0.0006999999999999229",
         "1"
        ],
        [
         "2024-01-01 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6161",
         "0.619",
         "0.615",
         "0.6185",
         "9029149.0",
         "0.617",
         "0.0024000000000000687",
         "1"
        ],
        [
         "2024-01-01 03:00:00",
         "BINANCE:XRPUSDT",
         "0.6184",
         "0.6186",
         "0.6149",
         "0.6154",
         "6553752.0",
         "0.61675",
         "-0.0030000000000000027",
         "0"
        ],
        [
         "2024-01-01 04:00:00",
         "BINANCE:XRPUSDT",
         "0.6154",
         "0.6157",
         "0.6112",
         "0.613",
         "8001610.0",
         "0.61345",
         "-0.0023999999999999577",
         "0"
        ],
        [
         "2024-01-01 05:00:00",
         "BINANCE:XRPUSDT",
         "0.6129",
         "0.6134",
         "0.6093",
         "0.6116",
         "10514620.0",
         "0.61135",
         "-0.0012999999999999678",
         "0"
        ],
        [
         "2024-01-01 06:00:00",
         "BINANCE:XRPUSDT",
         "0.6116",
         "0.6124",
         "0.6083",
         "0.6087",
         "7622323.0",
         "0.61035",
         "-0.0029000000000000137",
         "0"
        ],
        [
         "2024-01-01 07:00:00",
         "BINANCE:XRPUSDT",
         "0.6087",
         "0.6129",
         "0.6084",
         "0.6127",
         "5515748.0",
         "0.61065",
         "0.0040000000000000036",
         "1"
        ],
        [
         "2024-01-01 08:00:00",
         "BINANCE:XRPUSDT",
         "0.6127",
         "0.6153",
         "0.6127",
         "0.615",
         "3607686.0",
         "0.614",
         "0.0022999999999999687",
         "1"
        ],
        [
         "2024-01-01 09:00:00",
         "BINANCE:XRPUSDT",
         "0.615",
         "0.6163",
         "0.6143",
         "0.6161",
         "4436880.0",
         "0.6153",
         "0.0010999999999999899",
         "1"
        ],
        [
         "2024-01-01 10:00:00",
         "BINANCE:XRPUSDT",
         "0.6161",
         "0.6177",
         "0.6152",
         "0.6175",
         "4422313.0",
         "0.6164499999999999",
         "0.0014000000000000679",
         "1"
        ],
        [
         "2024-01-01 11:00:00",
         "BINANCE:XRPUSDT",
         "0.6175",
         "0.619",
         "0.6173",
         "0.6188",
         "4925516.0",
         "0.61815",
         "0.0012999999999999678",
         "1"
        ],
        [
         "2024-01-01 12:00:00",
         "BINANCE:XRPUSDT",
         "0.6188",
         "0.6207",
         "0.6177",
         "0.6205",
         "6067891.0",
         "0.6192",
         "0.0017000000000000348",
         "1"
        ],
        [
         "2024-01-01 13:00:00",
         "BINANCE:XRPUSDT",
         "0.6205",
         "0.6213",
         "0.6191",
         "0.6196",
         "5869164.0",
         "0.6202",
         "-0.0009000000000000119",
         "0"
        ],
        [
         "2024-01-01 14:00:00",
         "BINANCE:XRPUSDT",
         "0.6197",
         "0.6216",
         "0.619",
         "0.621",
         "5679263.0",
         "0.6203000000000001",
         "0.0012999999999999678",
         "1"
        ],
        [
         "2024-01-01 15:00:00",
         "BINANCE:XRPUSDT",
         "0.6209",
         "0.621",
         "0.6183",
         "0.6193",
         "6224809.0",
         "0.61965",
         "-0.0016000000000000458",
         "0"
        ],
        [
         "2024-01-01 16:00:00",
         "BINANCE:XRPUSDT",
         "0.6193",
         "0.6219",
         "0.619",
         "0.6213",
         "5328702.0",
         "0.62045",
         "0.0020000000000000018",
         "1"
        ],
        [
         "2024-01-01 17:00:00",
         "BINANCE:XRPUSDT",
         "0.6213",
         "0.622",
         "0.6198",
         "0.6209",
         "6248474.0",
         "0.6209",
         "-0.00039999999999995595",
         "0"
        ],
        [
         "2024-01-01 18:00:00",
         "BINANCE:XRPUSDT",
         "0.6208",
         "0.6237",
         "0.6206",
         "0.6232",
         "4728255.0",
         "0.62215",
         "0.0023999999999999577",
         "1"
        ],
        [
         "2024-01-01 19:00:00",
         "BINANCE:XRPUSDT",
         "0.6233",
         "0.6254",
         "0.6231",
         "0.6237",
         "7106348.0",
         "0.62425",
         "0.00040000000000006697",
         "1"
        ],
        [
         "2024-01-01 20:00:00",
         "BINANCE:XRPUSDT",
         "0.6238",
         "0.626",
         "0.6237",
         "0.6258",
         "6658451.0",
         "0.62485",
         "0.0020000000000000018",
         "1"
        ],
        [
         "2024-01-01 21:00:00",
         "BINANCE:XRPUSDT",
         "0.6258",
         "0.6289",
         "0.6255",
         "0.6276",
         "11038195.0",
         "0.6272",
         "0.0018000000000000238",
         "1"
        ],
        [
         "2024-01-01 22:00:00",
         "BINANCE:XRPUSDT",
         "0.6277",
         "0.6283",
         "0.6266",
         "0.6282",
         "6331827.0",
         "0.6274500000000001",
         "0.0004999999999999449",
         "1"
        ],
        [
         "2024-01-01 23:00:00",
         "BINANCE:XRPUSDT",
         "0.6281",
         "0.6286",
         "0.6257",
         "0.6269",
         "5483173.0",
         "0.6271500000000001",
         "-0.0011999999999999789",
         "0"
        ],
        [
         "2024-01-02 00:00:00",
         "BINANCE:XRPUSDT",
         "0.6269",
         "0.6309",
         "0.6269",
         "0.6294",
         "9976523.0",
         "0.6289",
         "0.0024999999999999467",
         "1"
        ],
        [
         "2024-01-02 01:00:00",
         "BINANCE:XRPUSDT",
         "0.6295",
         "0.6327",
         "0.6287",
         "0.6314",
         "27514701.0",
         "0.6307",
         "0.0019000000000000128",
         "1"
        ],
        [
         "2024-01-02 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6314",
         "0.6344",
         "0.631",
         "0.6323",
         "14919889.0",
         "0.6327",
         "0.0009000000000000119",
         "1"
        ],
        [
         "2024-01-02 03:00:00",
         "BINANCE:XRPUSDT",
         "0.6323",
         "0.6354",
         "0.6317",
         "0.634",
         "11160952.0",
         "0.6335500000000001",
         "0.0017000000000000348",
         "1"
        ],
        [
         "2024-01-02 04:00:00",
         "BINANCE:XRPUSDT",
         "0.634",
         "0.6348",
         "0.6317",
         "0.6339",
         "9683658.0",
         "0.6332500000000001",
         "-9.999999999998899e-05",
         "0"
        ],
        [
         "2024-01-02 05:00:00",
         "BINANCE:XRPUSDT",
         "0.6339",
         "0.6343",
         "0.6327",
         "0.6334",
         "8161331.0",
         "0.6335",
         "-0.000500000000000056",
         "0"
        ],
        [
         "2024-01-02 06:00:00",
         "BINANCE:XRPUSDT",
         "0.6333",
         "0.6343",
         "0.6289",
         "0.6301",
         "11923852.0",
         "0.6315999999999999",
         "-0.0031999999999999806",
         "0"
        ],
        [
         "2024-01-02 07:00:00",
         "BINANCE:XRPUSDT",
         "0.6301",
         "0.6306",
         "0.6277",
         "0.6282",
         "23775317.0",
         "0.6291500000000001",
         "-0.0019000000000000128",
         "0"
        ],
        [
         "2024-01-02 08:00:00",
         "BINANCE:XRPUSDT",
         "0.6282",
         "0.6321",
         "0.6281",
         "0.6307",
         "17415828.0",
         "0.6301",
         "0.0025000000000000577",
         "1"
        ],
        [
         "2024-01-02 09:00:00",
         "BINANCE:XRPUSDT",
         "0.6307",
         "0.6334",
         "0.6291",
         "0.6329",
         "24496588.0",
         "0.63125",
         "0.0021999999999999797",
         "1"
        ],
        [
         "2024-01-02 10:00:00",
         "BINANCE:XRPUSDT",
         "0.6328",
         "0.6405",
         "0.6313",
         "0.6377",
         "25115367.0",
         "0.6358999999999999",
         "0.0049000000000000155",
         "1"
        ],
        [
         "2024-01-02 11:00:00",
         "BINANCE:XRPUSDT",
         "0.6377",
         "0.6381",
         "0.634",
         "0.6366",
         "21126103.0",
         "0.63605",
         "-0.0010999999999999899",
         "0"
        ],
        [
         "2024-01-02 12:00:00",
         "BINANCE:XRPUSDT",
         "0.6366",
         "0.6367",
         "0.63",
         "0.632",
         "22137767.0",
         "0.6333500000000001",
         "-0.0046000000000000485",
         "0"
        ],
        [
         "2024-01-02 13:00:00",
         "BINANCE:XRPUSDT",
         "0.632",
         "0.634",
         "0.6278",
         "0.6298",
         "18026227.0",
         "0.6309",
         "-0.0021999999999999797",
         "0"
        ],
        [
         "2024-01-02 14:00:00",
         "BINANCE:XRPUSDT",
         "0.6297",
         "0.6329",
         "0.6288",
         "0.6317",
         "10862122.0",
         "0.63085",
         "0.0020000000000000018",
         "1"
        ],
        [
         "2024-01-02 15:00:00",
         "BINANCE:XRPUSDT",
         "0.6316",
         "0.6324",
         "0.623",
         "0.6254",
         "27806283.0",
         "0.6276999999999999",
         "-0.006200000000000094",
         "0"
        ],
        [
         "2024-01-02 16:00:00",
         "BINANCE:XRPUSDT",
         "0.6253",
         "0.6282",
         "0.6218",
         "0.6256",
         "16160486.0",
         "0.625",
         "0.000300000000000078",
         "1"
        ],
        [
         "2024-01-02 17:00:00",
         "BINANCE:XRPUSDT",
         "0.6255",
         "0.6272",
         "0.6224",
         "0.6272",
         "12275659.0",
         "0.6248",
         "0.0017000000000000348",
         "1"
        ],
        [
         "2024-01-02 18:00:00",
         "BINANCE:XRPUSDT",
         "0.6271",
         "0.6272",
         "0.6213",
         "0.6228",
         "11171014.0",
         "0.62425",
         "-0.0042999999999999705",
         "0"
        ],
        [
         "2024-01-02 19:00:00",
         "BINANCE:XRPUSDT",
         "0.6229",
         "0.6264",
         "0.6226",
         "0.6256",
         "11738872.0",
         "0.6245",
         "0.0027000000000000357",
         "1"
        ],
        [
         "2024-01-02 20:00:00",
         "BINANCE:XRPUSDT",
         "0.6256",
         "0.6292",
         "0.625",
         "0.6276",
         "11702497.0",
         "0.6271",
         "0.0020000000000000018",
         "1"
        ],
        [
         "2024-01-02 21:00:00",
         "BINANCE:XRPUSDT",
         "0.6276",
         "0.629",
         "0.6253",
         "0.6259",
         "9379802.0",
         "0.62715",
         "-0.0017000000000000348",
         "0"
        ],
        [
         "2024-01-02 22:00:00",
         "BINANCE:XRPUSDT",
         "0.6259",
         "0.628",
         "0.6237",
         "0.6272",
         "8102154.0",
         "0.62585",
         "0.0012999999999999678",
         "1"
        ],
        [
         "2024-01-02 23:00:00",
         "BINANCE:XRPUSDT",
         "0.6272",
         "0.6283",
         "0.6248",
         "0.6273",
         "7594774.0",
         "0.6265499999999999",
         "9.999999999998899e-05",
         "1"
        ],
        [
         "2024-01-03 00:00:00",
         "BINANCE:XRPUSDT",
         "0.6273",
         "0.628",
         "0.624",
         "0.6246",
         "8818251.0",
         "0.626",
         "-0.0026999999999999247",
         "0"
        ],
        [
         "2024-01-03 01:00:00",
         "BINANCE:XRPUSDT",
         "0.6245",
         "0.6273",
         "0.6226",
         "0.6266",
         "18827999.0",
         "0.62495",
         "0.0020999999999999908",
         "1"
        ],
        [
         "2024-01-03 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6265",
         "0.6279",
         "0.6264",
         "0.6274",
         "6271377.0",
         "0.62715",
         "0.0009000000000000119",
         "1"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 10023
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6155</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.6146</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>14498728.0</td>\n",
       "      <td>0.61590</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 02:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>9029149.0</td>\n",
       "      <td>0.61700</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 03:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.6186</td>\n",
       "      <td>0.6149</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>6553752.0</td>\n",
       "      <td>0.61675</td>\n",
       "      <td>-0.0030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 04:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.6157</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>8001610.0</td>\n",
       "      <td>0.61345</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 05:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6129</td>\n",
       "      <td>0.6134</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>10514620.0</td>\n",
       "      <td>0.61135</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 11:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6787</td>\n",
       "      <td>2.6601</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>4420326.0</td>\n",
       "      <td>2.66940</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 12:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6758</td>\n",
       "      <td>2.6773</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>6597897.0</td>\n",
       "      <td>2.66400</td>\n",
       "      <td>-0.0251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 13:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6508</td>\n",
       "      <td>2.6661</td>\n",
       "      <td>2.6454</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>4207626.0</td>\n",
       "      <td>2.65575</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 14:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.6655</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>16416120.0</td>\n",
       "      <td>2.69075</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 15:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.7012</td>\n",
       "      <td>2.6793</td>\n",
       "      <td>2.6851</td>\n",
       "      <td>3973640.0</td>\n",
       "      <td>2.69025</td>\n",
       "      <td>-0.0136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10023 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              symbol    open    high     low   close  \\\n",
       "datetime                                                               \n",
       "2024-01-01 01:00:00  BINANCE:XRPUSDT  0.6155  0.6172  0.6146  0.6162   \n",
       "2024-01-01 02:00:00  BINANCE:XRPUSDT  0.6161  0.6190  0.6150  0.6185   \n",
       "2024-01-01 03:00:00  BINANCE:XRPUSDT  0.6184  0.6186  0.6149  0.6154   \n",
       "2024-01-01 04:00:00  BINANCE:XRPUSDT  0.6154  0.6157  0.6112  0.6130   \n",
       "2024-01-01 05:00:00  BINANCE:XRPUSDT  0.6129  0.6134  0.6093  0.6116   \n",
       "...                              ...     ...     ...     ...     ...   \n",
       "2025-02-21 11:00:00  BINANCE:XRPUSDT  2.6670  2.6787  2.6601  2.6757   \n",
       "2025-02-21 12:00:00  BINANCE:XRPUSDT  2.6758  2.6773  2.6507  2.6507   \n",
       "2025-02-21 13:00:00  BINANCE:XRPUSDT  2.6508  2.6661  2.6454  2.6656   \n",
       "2025-02-21 14:00:00  BINANCE:XRPUSDT  2.6656  2.7160  2.6655  2.6987   \n",
       "2025-02-21 15:00:00  BINANCE:XRPUSDT  2.6987  2.7012  2.6793  2.6851   \n",
       "\n",
       "                         volume    av_pr    diff  candle  \n",
       "datetime                                                  \n",
       "2024-01-01 01:00:00  14498728.0  0.61590  0.0007       1  \n",
       "2024-01-01 02:00:00   9029149.0  0.61700  0.0024       1  \n",
       "2024-01-01 03:00:00   6553752.0  0.61675 -0.0030       0  \n",
       "2024-01-01 04:00:00   8001610.0  0.61345 -0.0024       0  \n",
       "2024-01-01 05:00:00  10514620.0  0.61135 -0.0013       0  \n",
       "...                         ...      ...     ...     ...  \n",
       "2025-02-21 11:00:00   4420326.0  2.66940  0.0087       1  \n",
       "2025-02-21 12:00:00   6597897.0  2.66400 -0.0251       0  \n",
       "2025-02-21 13:00:00   4207626.0  2.65575  0.0148       1  \n",
       "2025-02-21 14:00:00  16416120.0  2.69075  0.0331       1  \n",
       "2025-02-21 15:00:00   3973640.0  2.69025 -0.0136       0  \n",
       "\n",
       "[10023 rows x 9 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrp_usdt_hr_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrp_usdt_hr_main.to_csv(\"xrpusdt_hourly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = xrp_usdt_hr_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrpdata = pd.read_csv(\"xrpusdt_daily_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "133e4d98-70f8-4a42-8adc-7ba8b2a51349",
       "rows": [
        [
         "0",
         "2024-12-20 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2391",
         "2.355",
         "1.9601",
         "2.2793",
         "1110347016.0"
        ],
        [
         "1",
         "2024-12-21 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2793",
         "2.3858",
         "2.1915",
         "2.238",
         "451599864.0"
        ],
        [
         "2",
         "2024-12-22 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2379",
         "2.2938",
         "2.1604",
         "2.2031",
         "310318499.0"
        ],
        [
         "3",
         "2024-12-23 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2032",
         "2.2789",
         "2.1308",
         "2.2617",
         "388820902.0"
        ],
        [
         "4",
         "2024-12-24 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2616",
         "2.3507",
         "2.2138",
         "2.3238",
         "249021066.0"
        ],
        [
         "5",
         "2024-12-25 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3238",
         "2.3325",
         "2.2615",
         "2.2973",
         "162014998.0"
        ],
        [
         "6",
         "2024-12-26 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2973",
         "2.3164",
         "2.1277",
         "2.1559",
         "266397920.0"
        ],
        [
         "7",
         "2024-12-27 01:00:00",
         "BINANCE:XRPUSDT",
         "2.1559",
         "2.2379",
         "2.1149",
         "2.1466",
         "254236575.0"
        ],
        [
         "8",
         "2024-12-28 01:00:00",
         "BINANCE:XRPUSDT",
         "2.1467",
         "2.2076",
         "2.1343",
         "2.1843",
         "106144470.0"
        ],
        [
         "9",
         "2024-12-29 01:00:00",
         "BINANCE:XRPUSDT",
         "2.1843",
         "2.1976",
         "2.0711",
         "2.0942",
         "129587392.0"
        ],
        [
         "10",
         "2024-12-30 01:00:00",
         "BINANCE:XRPUSDT",
         "2.0941",
         "2.1526",
         "1.9954",
         "2.0587",
         "326304793.0"
        ],
        [
         "11",
         "2024-12-31 01:00:00",
         "BINANCE:XRPUSDT",
         "2.0587",
         "2.1491",
         "2.0126",
         "2.0836",
         "202867597.0"
        ],
        [
         "12",
         "2025-01-01 01:00:00",
         "BINANCE:XRPUSDT",
         "2.0836",
         "2.3545",
         "2.0811",
         "2.3328",
         "340770274.0"
        ],
        [
         "13",
         "2025-01-02 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3329",
         "2.4522",
         "2.3297",
         "2.4024",
         "361196381.0"
        ],
        [
         "14",
         "2025-01-03 01:00:00",
         "BINANCE:XRPUSDT",
         "2.4024",
         "2.4798",
         "2.3966",
         "2.4547",
         "233672728.0"
        ],
        [
         "15",
         "2025-01-04 01:00:00",
         "BINANCE:XRPUSDT",
         "2.4546",
         "2.509",
         "2.3999",
         "2.4201",
         "179793926.0"
        ],
        [
         "16",
         "2025-01-05 01:00:00",
         "BINANCE:XRPUSDT",
         "2.4201",
         "2.4285",
         "2.3273",
         "2.3994",
         "155537860.0"
        ],
        [
         "17",
         "2025-01-06 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3993",
         "2.4584",
         "2.3674",
         "2.42",
         "194293277.0"
        ],
        [
         "18",
         "2025-01-07 01:00:00",
         "BINANCE:XRPUSDT",
         "2.42",
         "2.4683",
         "2.2572",
         "2.2712",
         "342477338.0"
        ],
        [
         "19",
         "2025-01-08 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2712",
         "2.3986",
         "2.2001",
         "2.3731",
         "401036029.0"
        ],
        [
         "20",
         "2025-01-09 01:00:00",
         "BINANCE:XRPUSDT",
         "2.373",
         "2.3956",
         "2.2351",
         "2.2722",
         "294585086.0"
        ],
        [
         "21",
         "2025-01-10 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2722",
         "2.3699",
         "2.2465",
         "2.3414",
         "248018278.0"
        ],
        [
         "22",
         "2025-01-11 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3414",
         "2.6036",
         "2.3249",
         "2.5764",
         "349172496.0"
        ],
        [
         "23",
         "2025-01-12 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5764",
         "2.5835",
         "2.47",
         "2.5046",
         "222912333.0"
        ],
        [
         "24",
         "2025-01-13 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5045",
         "2.5634",
         "2.3297",
         "2.5232",
         "515356746.0"
        ],
        [
         "25",
         "2025-01-14 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5232",
         "2.7",
         "2.5126",
         "2.6673",
         "397227342.0"
        ],
        [
         "26",
         "2025-01-15 01:00:00",
         "BINANCE:XRPUSDT",
         "2.6673",
         "3.2",
         "2.6492",
         "3.1429",
         "1062630122.23"
        ],
        [
         "27",
         "2025-01-16 01:00:00",
         "BINANCE:XRPUSDT",
         "3.143",
         "3.4",
         "2.9228",
         "3.2451",
         "1110371222.1999998"
        ],
        [
         "28",
         "2025-01-17 01:00:00",
         "BINANCE:XRPUSDT",
         "3.245",
         "3.3544",
         "3.1758",
         "3.2922",
         "529933494.0"
        ],
        [
         "29",
         "2025-01-18 01:00:00",
         "BINANCE:XRPUSDT",
         "3.2923",
         "3.2996",
         "3.058",
         "3.2697",
         "458088944.0"
        ],
        [
         "30",
         "2025-01-19 01:00:00",
         "BINANCE:XRPUSDT",
         "3.2697",
         "3.2929",
         "2.8277",
         "2.9587",
         "663328805.0"
        ],
        [
         "31",
         "2025-01-20 01:00:00",
         "BINANCE:XRPUSDT",
         "2.9586",
         "3.3695",
         "2.909",
         "3.1053",
         "838761258.0"
        ],
        [
         "32",
         "2025-01-21 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1053",
         "3.246",
         "3.0124",
         "3.1738",
         "376423502.0"
        ],
        [
         "33",
         "2025-01-22 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1739",
         "3.2854",
         "3.1237",
         "3.1803",
         "291761274.0"
        ],
        [
         "34",
         "2025-01-23 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1802",
         "3.1868",
         "3.0374",
         "3.1194",
         "305314846.0"
        ],
        [
         "35",
         "2025-01-24 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1194",
         "3.2031",
         "3.055",
         "3.1009",
         "232626964.0"
        ],
        [
         "36",
         "2025-01-25 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1008",
         "3.1446",
         "3.0784",
         "3.108",
         "99489857.0"
        ],
        [
         "37",
         "2025-01-26 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1079",
         "3.1443",
         "3.0115",
         "3.0223",
         "128937813.0"
        ],
        [
         "38",
         "2025-01-27 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0222",
         "3.0587",
         "2.6559",
         "3.0552",
         "660056174.0"
        ],
        [
         "39",
         "2025-01-28 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0552",
         "3.214",
         "3.0062",
         "3.0572",
         "369470786.0"
        ],
        [
         "40",
         "2025-01-29 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0572",
         "3.1363",
         "2.9673",
         "3.0683",
         "254756655.0"
        ],
        [
         "41",
         "2025-01-30 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0683",
         "3.1544",
         "3.0466",
         "3.1276",
         "173143314.0"
        ],
        [
         "42",
         "2025-01-31 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1276",
         "3.1333",
         "3.003",
         "3.0361",
         "162235322.0"
        ],
        [
         "43",
         "2025-02-01 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0361",
         "3.0727",
         "2.8281",
         "2.8778",
         "173601404.0"
        ],
        [
         "44",
         "2025-02-02 01:00:00",
         "BINANCE:XRPUSDT",
         "2.8779",
         "2.9559",
         "2.4603",
         "2.58",
         "684089012.0"
        ],
        [
         "45",
         "2025-02-03 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5801",
         "2.7814",
         "1.7711",
         "2.7001",
         "1866758972.0"
        ],
        [
         "46",
         "2025-02-04 01:00:00",
         "BINANCE:XRPUSDT",
         "2.7",
         "2.7874",
         "2.4209",
         "2.5274",
         "621552965.0"
        ],
        [
         "47",
         "2025-02-05 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5275",
         "2.5692",
         "2.3384",
         "2.381",
         "338815093.0"
        ],
        [
         "48",
         "2025-02-06 01:00:00",
         "BINANCE:XRPUSDT",
         "2.381",
         "2.4699",
         "2.2772",
         "2.325",
         "322896937.0"
        ],
        [
         "49",
         "2025-02-07 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3251",
         "2.542",
         "2.2655",
         "2.3968",
         "447487945.0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 66
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-20 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2391</td>\n",
       "      <td>2.3550</td>\n",
       "      <td>1.9601</td>\n",
       "      <td>2.2793</td>\n",
       "      <td>1.110347e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-21 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2793</td>\n",
       "      <td>2.3858</td>\n",
       "      <td>2.1915</td>\n",
       "      <td>2.2380</td>\n",
       "      <td>4.515999e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-22 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2379</td>\n",
       "      <td>2.2938</td>\n",
       "      <td>2.1604</td>\n",
       "      <td>2.2031</td>\n",
       "      <td>3.103185e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-23 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2032</td>\n",
       "      <td>2.2789</td>\n",
       "      <td>2.1308</td>\n",
       "      <td>2.2617</td>\n",
       "      <td>3.888209e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-24 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2616</td>\n",
       "      <td>2.3507</td>\n",
       "      <td>2.2138</td>\n",
       "      <td>2.3238</td>\n",
       "      <td>2.490211e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2025-02-19 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5629</td>\n",
       "      <td>2.7470</td>\n",
       "      <td>2.5121</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.082441e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2025-02-20 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.7490</td>\n",
       "      <td>2.6671</td>\n",
       "      <td>2.6877</td>\n",
       "      <td>1.616046e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2025-02-21 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6878</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.5076</td>\n",
       "      <td>2.5721</td>\n",
       "      <td>2.577774e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2025-02-22 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5722</td>\n",
       "      <td>2.6099</td>\n",
       "      <td>2.5505</td>\n",
       "      <td>2.5740</td>\n",
       "      <td>9.267673e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2025-02-23 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5740</td>\n",
       "      <td>2.6016</td>\n",
       "      <td>2.5408</td>\n",
       "      <td>2.5673</td>\n",
       "      <td>4.397890e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime           symbol    open    high     low   close  \\\n",
       "0   2024-12-20 01:00:00  BINANCE:XRPUSDT  2.2391  2.3550  1.9601  2.2793   \n",
       "1   2024-12-21 01:00:00  BINANCE:XRPUSDT  2.2793  2.3858  2.1915  2.2380   \n",
       "2   2024-12-22 01:00:00  BINANCE:XRPUSDT  2.2379  2.2938  2.1604  2.2031   \n",
       "3   2024-12-23 01:00:00  BINANCE:XRPUSDT  2.2032  2.2789  2.1308  2.2617   \n",
       "4   2024-12-24 01:00:00  BINANCE:XRPUSDT  2.2616  2.3507  2.2138  2.3238   \n",
       "..                  ...              ...     ...     ...     ...     ...   \n",
       "61  2025-02-19 01:00:00  BINANCE:XRPUSDT  2.5629  2.7470  2.5121  2.7378   \n",
       "62  2025-02-20 01:00:00  BINANCE:XRPUSDT  2.7378  2.7490  2.6671  2.6877   \n",
       "63  2025-02-21 01:00:00  BINANCE:XRPUSDT  2.6878  2.7160  2.5076  2.5721   \n",
       "64  2025-02-22 01:00:00  BINANCE:XRPUSDT  2.5722  2.6099  2.5505  2.5740   \n",
       "65  2025-02-23 01:00:00  BINANCE:XRPUSDT  2.5740  2.6016  2.5408  2.5673   \n",
       "\n",
       "          volume  \n",
       "0   1.110347e+09  \n",
       "1   4.515999e+08  \n",
       "2   3.103185e+08  \n",
       "3   3.888209e+08  \n",
       "4   2.490211e+08  \n",
       "..           ...  \n",
       "61  2.082441e+08  \n",
       "62  1.616046e+08  \n",
       "63  2.577774e+08  \n",
       "64  9.267673e+07  \n",
       "65  4.397890e+07  \n",
       "\n",
       "[66 rows x 7 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrpdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrpdata['av_pr'] = xrpdata.apply(ave, axis=1)\n",
    "xrpdata['diff'] = xrpdata.apply(diff, axis=1)\n",
    "xrpdata['candle'] = xrpdata.apply(candle, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = xrpdata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4bdb14d5-45d9-4062-bddb-a03d17e6b3c4",
       "rows": [
        [
         "0",
         "2024-12-20 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2391",
         "2.355",
         "1.9601",
         "2.2793",
         "1110347016.0",
         "2.15755",
         "0.040200000000000014",
         "1"
        ],
        [
         "1",
         "2024-12-21 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2793",
         "2.3858",
         "2.1915",
         "2.238",
         "451599864.0",
         "2.28865",
         "-0.041300000000000114",
         "0"
        ],
        [
         "2",
         "2024-12-22 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2379",
         "2.2938",
         "2.1604",
         "2.2031",
         "310318499.0",
         "2.2271",
         "-0.03479999999999972",
         "0"
        ],
        [
         "3",
         "2024-12-23 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2032",
         "2.2789",
         "2.1308",
         "2.2617",
         "388820902.0",
         "2.20485",
         "0.058499999999999996",
         "1"
        ],
        [
         "4",
         "2024-12-24 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2616",
         "2.3507",
         "2.2138",
         "2.3238",
         "249021066.0",
         "2.28225",
         "0.06219999999999981",
         "1"
        ],
        [
         "5",
         "2024-12-25 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3238",
         "2.3325",
         "2.2615",
         "2.2973",
         "162014998.0",
         "2.2969999999999997",
         "-0.026499999999999968",
         "0"
        ],
        [
         "6",
         "2024-12-26 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2973",
         "2.3164",
         "2.1277",
         "2.1559",
         "266397920.0",
         "2.22205",
         "-0.14139999999999997",
         "0"
        ],
        [
         "7",
         "2024-12-27 01:00:00",
         "BINANCE:XRPUSDT",
         "2.1559",
         "2.2379",
         "2.1149",
         "2.1466",
         "254236575.0",
         "2.1764",
         "-0.009300000000000086",
         "0"
        ],
        [
         "8",
         "2024-12-28 01:00:00",
         "BINANCE:XRPUSDT",
         "2.1467",
         "2.2076",
         "2.1343",
         "2.1843",
         "106144470.0",
         "2.17095",
         "0.037599999999999856",
         "1"
        ],
        [
         "9",
         "2024-12-29 01:00:00",
         "BINANCE:XRPUSDT",
         "2.1843",
         "2.1976",
         "2.0711",
         "2.0942",
         "129587392.0",
         "2.13435",
         "-0.09010000000000007",
         "0"
        ],
        [
         "10",
         "2024-12-30 01:00:00",
         "BINANCE:XRPUSDT",
         "2.0941",
         "2.1526",
         "1.9954",
         "2.0587",
         "326304793.0",
         "2.074",
         "-0.0354000000000001",
         "0"
        ],
        [
         "11",
         "2024-12-31 01:00:00",
         "BINANCE:XRPUSDT",
         "2.0587",
         "2.1491",
         "2.0126",
         "2.0836",
         "202867597.0",
         "2.08085",
         "0.024900000000000144",
         "1"
        ],
        [
         "12",
         "2025-01-01 01:00:00",
         "BINANCE:XRPUSDT",
         "2.0836",
         "2.3545",
         "2.0811",
         "2.3328",
         "340770274.0",
         "2.2178",
         "0.2492000000000001",
         "1"
        ],
        [
         "13",
         "2025-01-02 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3329",
         "2.4522",
         "2.3297",
         "2.4024",
         "361196381.0",
         "2.39095",
         "0.06950000000000012",
         "1"
        ],
        [
         "14",
         "2025-01-03 01:00:00",
         "BINANCE:XRPUSDT",
         "2.4024",
         "2.4798",
         "2.3966",
         "2.4547",
         "233672728.0",
         "2.4382",
         "0.05229999999999979",
         "1"
        ],
        [
         "15",
         "2025-01-04 01:00:00",
         "BINANCE:XRPUSDT",
         "2.4546",
         "2.509",
         "2.3999",
         "2.4201",
         "179793926.0",
         "2.45445",
         "-0.034499999999999975",
         "0"
        ],
        [
         "16",
         "2025-01-05 01:00:00",
         "BINANCE:XRPUSDT",
         "2.4201",
         "2.4285",
         "2.3273",
         "2.3994",
         "155537860.0",
         "2.3779000000000003",
         "-0.020700000000000163",
         "0"
        ],
        [
         "17",
         "2025-01-06 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3993",
         "2.4584",
         "2.3674",
         "2.42",
         "194293277.0",
         "2.4129",
         "0.02069999999999972",
         "1"
        ],
        [
         "18",
         "2025-01-07 01:00:00",
         "BINANCE:XRPUSDT",
         "2.42",
         "2.4683",
         "2.2572",
         "2.2712",
         "342477338.0",
         "2.36275",
         "-0.14880000000000004",
         "0"
        ],
        [
         "19",
         "2025-01-08 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2712",
         "2.3986",
         "2.2001",
         "2.3731",
         "401036029.0",
         "2.29935",
         "0.1019000000000001",
         "1"
        ],
        [
         "20",
         "2025-01-09 01:00:00",
         "BINANCE:XRPUSDT",
         "2.373",
         "2.3956",
         "2.2351",
         "2.2722",
         "294585086.0",
         "2.31535",
         "-0.1008",
         "0"
        ],
        [
         "21",
         "2025-01-10 01:00:00",
         "BINANCE:XRPUSDT",
         "2.2722",
         "2.3699",
         "2.2465",
         "2.3414",
         "248018278.0",
         "2.3082000000000003",
         "0.06919999999999993",
         "1"
        ],
        [
         "22",
         "2025-01-11 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3414",
         "2.6036",
         "2.3249",
         "2.5764",
         "349172496.0",
         "2.46425",
         "0.23499999999999988",
         "1"
        ],
        [
         "23",
         "2025-01-12 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5764",
         "2.5835",
         "2.47",
         "2.5046",
         "222912333.0",
         "2.52675",
         "-0.07180000000000009",
         "0"
        ],
        [
         "24",
         "2025-01-13 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5045",
         "2.5634",
         "2.3297",
         "2.5232",
         "515356746.0",
         "2.4465500000000002",
         "0.01869999999999994",
         "1"
        ],
        [
         "25",
         "2025-01-14 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5232",
         "2.7",
         "2.5126",
         "2.6673",
         "397227342.0",
         "2.6063",
         "0.1440999999999999",
         "1"
        ],
        [
         "26",
         "2025-01-15 01:00:00",
         "BINANCE:XRPUSDT",
         "2.6673",
         "3.2",
         "2.6492",
         "3.1429",
         "1062630122.23",
         "2.9246",
         "0.4756",
         "1"
        ],
        [
         "27",
         "2025-01-16 01:00:00",
         "BINANCE:XRPUSDT",
         "3.143",
         "3.4",
         "2.9228",
         "3.2451",
         "1110371222.1999998",
         "3.1614",
         "0.10210000000000008",
         "1"
        ],
        [
         "28",
         "2025-01-17 01:00:00",
         "BINANCE:XRPUSDT",
         "3.245",
         "3.3544",
         "3.1758",
         "3.2922",
         "529933494.0",
         "3.2651000000000003",
         "0.04719999999999969",
         "1"
        ],
        [
         "29",
         "2025-01-18 01:00:00",
         "BINANCE:XRPUSDT",
         "3.2923",
         "3.2996",
         "3.058",
         "3.2697",
         "458088944.0",
         "3.1788",
         "-0.022600000000000176",
         "0"
        ],
        [
         "30",
         "2025-01-19 01:00:00",
         "BINANCE:XRPUSDT",
         "3.2697",
         "3.2929",
         "2.8277",
         "2.9587",
         "663328805.0",
         "3.0603",
         "-0.31099999999999994",
         "0"
        ],
        [
         "31",
         "2025-01-20 01:00:00",
         "BINANCE:XRPUSDT",
         "2.9586",
         "3.3695",
         "2.909",
         "3.1053",
         "838761258.0",
         "3.1392499999999997",
         "0.14670000000000005",
         "1"
        ],
        [
         "32",
         "2025-01-21 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1053",
         "3.246",
         "3.0124",
         "3.1738",
         "376423502.0",
         "3.1292",
         "0.06849999999999978",
         "1"
        ],
        [
         "33",
         "2025-01-22 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1739",
         "3.2854",
         "3.1237",
         "3.1803",
         "291761274.0",
         "3.2045500000000002",
         "0.006399999999999739",
         "1"
        ],
        [
         "34",
         "2025-01-23 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1802",
         "3.1868",
         "3.0374",
         "3.1194",
         "305314846.0",
         "3.1121",
         "-0.060799999999999965",
         "0"
        ],
        [
         "35",
         "2025-01-24 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1194",
         "3.2031",
         "3.055",
         "3.1009",
         "232626964.0",
         "3.1290500000000003",
         "-0.01849999999999996",
         "0"
        ],
        [
         "36",
         "2025-01-25 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1008",
         "3.1446",
         "3.0784",
         "3.108",
         "99489857.0",
         "3.1115",
         "0.007200000000000095",
         "1"
        ],
        [
         "37",
         "2025-01-26 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1079",
         "3.1443",
         "3.0115",
         "3.0223",
         "128937813.0",
         "3.0778999999999996",
         "-0.0855999999999999",
         "0"
        ],
        [
         "38",
         "2025-01-27 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0222",
         "3.0587",
         "2.6559",
         "3.0552",
         "660056174.0",
         "2.8573",
         "0.03299999999999992",
         "1"
        ],
        [
         "39",
         "2025-01-28 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0552",
         "3.214",
         "3.0062",
         "3.0572",
         "369470786.0",
         "3.1101",
         "0.0019999999999997797",
         "1"
        ],
        [
         "40",
         "2025-01-29 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0572",
         "3.1363",
         "2.9673",
         "3.0683",
         "254756655.0",
         "3.0518",
         "0.011099999999999888",
         "1"
        ],
        [
         "41",
         "2025-01-30 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0683",
         "3.1544",
         "3.0466",
         "3.1276",
         "173143314.0",
         "3.1005000000000003",
         "0.05930000000000035",
         "1"
        ],
        [
         "42",
         "2025-01-31 01:00:00",
         "BINANCE:XRPUSDT",
         "3.1276",
         "3.1333",
         "3.003",
         "3.0361",
         "162235322.0",
         "3.06815",
         "-0.09150000000000036",
         "0"
        ],
        [
         "43",
         "2025-02-01 01:00:00",
         "BINANCE:XRPUSDT",
         "3.0361",
         "3.0727",
         "2.8281",
         "2.8778",
         "173601404.0",
         "2.9504",
         "-0.15829999999999966",
         "0"
        ],
        [
         "44",
         "2025-02-02 01:00:00",
         "BINANCE:XRPUSDT",
         "2.8779",
         "2.9559",
         "2.4603",
         "2.58",
         "684089012.0",
         "2.7081",
         "-0.29789999999999983",
         "0"
        ],
        [
         "45",
         "2025-02-03 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5801",
         "2.7814",
         "1.7711",
         "2.7001",
         "1866758972.0",
         "2.27625",
         "0.1200000000000001",
         "1"
        ],
        [
         "46",
         "2025-02-04 01:00:00",
         "BINANCE:XRPUSDT",
         "2.7",
         "2.7874",
         "2.4209",
         "2.5274",
         "621552965.0",
         "2.6041499999999997",
         "-0.1726000000000001",
         "0"
        ],
        [
         "47",
         "2025-02-05 01:00:00",
         "BINANCE:XRPUSDT",
         "2.5275",
         "2.5692",
         "2.3384",
         "2.381",
         "338815093.0",
         "2.4538",
         "-0.14650000000000007",
         "0"
        ],
        [
         "48",
         "2025-02-06 01:00:00",
         "BINANCE:XRPUSDT",
         "2.381",
         "2.4699",
         "2.2772",
         "2.325",
         "322896937.0",
         "2.37355",
         "-0.055999999999999606",
         "0"
        ],
        [
         "49",
         "2025-02-07 01:00:00",
         "BINANCE:XRPUSDT",
         "2.3251",
         "2.542",
         "2.2655",
         "2.3968",
         "447487945.0",
         "2.4037499999999996",
         "0.07169999999999987",
         "1"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 66
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-20 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2391</td>\n",
       "      <td>2.3550</td>\n",
       "      <td>1.9601</td>\n",
       "      <td>2.2793</td>\n",
       "      <td>1.110347e+09</td>\n",
       "      <td>2.15755</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-21 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2793</td>\n",
       "      <td>2.3858</td>\n",
       "      <td>2.1915</td>\n",
       "      <td>2.2380</td>\n",
       "      <td>4.515999e+08</td>\n",
       "      <td>2.28865</td>\n",
       "      <td>-0.0413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-22 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2379</td>\n",
       "      <td>2.2938</td>\n",
       "      <td>2.1604</td>\n",
       "      <td>2.2031</td>\n",
       "      <td>3.103185e+08</td>\n",
       "      <td>2.22710</td>\n",
       "      <td>-0.0348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-23 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2032</td>\n",
       "      <td>2.2789</td>\n",
       "      <td>2.1308</td>\n",
       "      <td>2.2617</td>\n",
       "      <td>3.888209e+08</td>\n",
       "      <td>2.20485</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-24 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.2616</td>\n",
       "      <td>2.3507</td>\n",
       "      <td>2.2138</td>\n",
       "      <td>2.3238</td>\n",
       "      <td>2.490211e+08</td>\n",
       "      <td>2.28225</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2025-02-19 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5629</td>\n",
       "      <td>2.7470</td>\n",
       "      <td>2.5121</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.082441e+08</td>\n",
       "      <td>2.62955</td>\n",
       "      <td>0.1749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2025-02-20 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.7490</td>\n",
       "      <td>2.6671</td>\n",
       "      <td>2.6877</td>\n",
       "      <td>1.616046e+08</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>-0.0501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2025-02-21 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6878</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.5076</td>\n",
       "      <td>2.5721</td>\n",
       "      <td>2.577774e+08</td>\n",
       "      <td>2.61180</td>\n",
       "      <td>-0.1157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2025-02-22 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5722</td>\n",
       "      <td>2.6099</td>\n",
       "      <td>2.5505</td>\n",
       "      <td>2.5740</td>\n",
       "      <td>9.267673e+07</td>\n",
       "      <td>2.58020</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2025-02-23 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.5740</td>\n",
       "      <td>2.6016</td>\n",
       "      <td>2.5408</td>\n",
       "      <td>2.5673</td>\n",
       "      <td>4.397890e+07</td>\n",
       "      <td>2.57120</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime           symbol    open    high     low   close  \\\n",
       "0   2024-12-20 01:00:00  BINANCE:XRPUSDT  2.2391  2.3550  1.9601  2.2793   \n",
       "1   2024-12-21 01:00:00  BINANCE:XRPUSDT  2.2793  2.3858  2.1915  2.2380   \n",
       "2   2024-12-22 01:00:00  BINANCE:XRPUSDT  2.2379  2.2938  2.1604  2.2031   \n",
       "3   2024-12-23 01:00:00  BINANCE:XRPUSDT  2.2032  2.2789  2.1308  2.2617   \n",
       "4   2024-12-24 01:00:00  BINANCE:XRPUSDT  2.2616  2.3507  2.2138  2.3238   \n",
       "..                  ...              ...     ...     ...     ...     ...   \n",
       "61  2025-02-19 01:00:00  BINANCE:XRPUSDT  2.5629  2.7470  2.5121  2.7378   \n",
       "62  2025-02-20 01:00:00  BINANCE:XRPUSDT  2.7378  2.7490  2.6671  2.6877   \n",
       "63  2025-02-21 01:00:00  BINANCE:XRPUSDT  2.6878  2.7160  2.5076  2.5721   \n",
       "64  2025-02-22 01:00:00  BINANCE:XRPUSDT  2.5722  2.6099  2.5505  2.5740   \n",
       "65  2025-02-23 01:00:00  BINANCE:XRPUSDT  2.5740  2.6016  2.5408  2.5673   \n",
       "\n",
       "          volume    av_pr    diff  candle  \n",
       "0   1.110347e+09  2.15755  0.0402       1  \n",
       "1   4.515999e+08  2.28865 -0.0413       0  \n",
       "2   3.103185e+08  2.22710 -0.0348       0  \n",
       "3   3.888209e+08  2.20485  0.0585       1  \n",
       "4   2.490211e+08  2.28225  0.0622       1  \n",
       "..           ...      ...     ...     ...  \n",
       "61  2.082441e+08  2.62955  0.1749       1  \n",
       "62  1.616046e+08  2.70805 -0.0501       0  \n",
       "63  2.577774e+08  2.61180 -0.1157       0  \n",
       "64  9.267673e+07  2.58020  0.0018       1  \n",
       "65  4.397890e+07  2.57120 -0.0067       0  \n",
       "\n",
       "[66 rows x 10 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the daily dataset\n",
    "\n",
    "# Moving Averages\n",
    "df_val['7_day_SMA'] = df_val['close'].rolling(window=7).mean()\n",
    "df_val['30_day_SMA'] = df_val['close'].rolling(window=30).mean()\n",
    "df_val['7_day_EMA'] = df_val['close'].ewm(span=7, adjust=False).mean()\n",
    "df_val['30_day_EMA'] = df_val['close'].ewm(span=30, adjust=False).mean()\n",
    "\n",
    "# RSI\n",
    "def calculate_rsi(data, period=14):\n",
    "    delta = data['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "df_val['RSI'] = calculate_rsi(df_val)\n",
    "\n",
    "# MACD\n",
    "df_val['12_day_EMA'] = df_val['close'].ewm(span=12, adjust=False).mean()\n",
    "df_val['26_day_EMA'] = df_val['close'].ewm(span=26, adjust=False).mean()\n",
    "df_val['MACD'] = df_val['12_day_EMA'] - df_val['26_day_EMA']\n",
    "df_val['Signal_Line'] = df_val['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# Bollinger Bands\n",
    "window = 20\n",
    "df_val['20_day_SMA'] = df_val['close'].rolling(window=window).mean()\n",
    "df_val['20_day_STD'] = df_val['close'].rolling(window=window).std()\n",
    "df_val['Upper_Band'] = df_val['20_day_SMA'] + (df_val['20_day_STD'] * 2)\n",
    "df_val['Lower_Band'] = df_val['20_day_SMA'] - (df_val['20_day_STD'] * 2)\n",
    "\n",
    "# Lag Features\n",
    "df_val['lag_1'] = df_val['close'].shift(1)\n",
    "df_val['lag_2'] = df_val['close'].shift(2)\n",
    "df_val['lag_3'] = df_val['close'].shift(3)\n",
    "\n",
    "# Drop rows with NaN values (created by rolling windows and shifts)\n",
    "df_val.dropna(inplace=True)\n",
    "\n",
    "# Save the updated dataset\n",
    "df_val.to_csv('xrpusdt_daily_dataset_with_features_val.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(\"xrpusdt_daily_dataset_with_features_val.csv\", parse_dates=[\"datetime\"])  # Replace with actual column name\n",
    "df_val = df_val.set_index(\"datetime\").sort_index()  # Ensure chronological order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val.drop(columns='symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7b315766-141f-416f-b9eb-032a55ebaf41",
       "rows": [
        [
         "2025-01-18 01:00:00",
         "3.2923",
         "3.2996",
         "3.058",
         "3.2697",
         "458088944.0",
         "3.1788",
         "-0.0226000000000001",
         "0",
         "2.9492857142857143",
         "2.4411733333333334",
         "3.0141094592779685",
         "2.5637328040426266",
         "76.90310322989234",
         "2.8347321610675134",
         "2.599338377693888",
         "0.2353937833736257",
         "0.133276149300667",
         "2.55255",
         "0.3800097997351346",
         "3.3125695994702693",
         "1.792530400529731",
         "3.2922",
         "3.2451",
         "3.1429"
        ],
        [
         "2025-01-19 01:00:00",
         "3.2697",
         "3.2929",
         "2.8277",
         "2.9587",
         "663328805.0",
         "3.0603",
         "-0.3109999999999999",
         "0",
         "3.014157142857143",
         "2.46382",
         "3.0002570944584765",
         "2.589214558620521",
         "64.96014550901407",
         "2.853804136287896",
         "2.6259577571239703",
         "0.2278463791639255",
         "0.1521901952733187",
         "2.59755",
         "0.3716472230772792",
         "3.3408444461545583",
         "1.8542555538454413",
         "3.2697",
         "3.2922",
         "3.2451"
        ],
        [
         "2025-01-20 01:00:00",
         "2.9586",
         "3.3695",
         "2.909",
         "3.1053",
         "838761258.0",
         "3.13925",
         "0.1467",
         "1",
         "3.097314285714286",
         "2.49273",
         "3.026517820843857",
         "2.62251039354823",
         "67.17285621209844",
         "2.89249580762822",
         "2.661464589929602",
         "0.2310312176986175",
         "0.1679583997583785",
         "2.648635",
         "0.3674795680320922",
         "3.3835941360641844",
         "1.913675863935816",
         "2.9587",
         "3.2697",
         "3.2922"
        ],
        [
         "2025-01-21 01:00:00",
         "3.1053",
         "3.246",
         "3.0124",
         "3.1738",
         "376423502.0",
         "3.1292",
         "0.0684999999999997",
         "1",
         "3.1696714285714287",
         "2.5250866666666667",
         "3.063338365632893",
         "2.6580774649322154",
         "73.56657963446476",
         "2.9357733756854167",
         "2.699415361045928",
         "0.2363580146394888",
         "0.1816383227346006",
         "2.690685",
         "0.3774196258459339",
         "3.445524251691868",
         "1.935845748308132",
         "3.1053",
         "2.9587",
         "3.2697"
        ],
        [
         "2025-01-22 01:00:00",
         "3.1739",
         "3.2854",
         "3.1237",
         "3.1803",
         "291761274.0",
         "3.20455",
         "0.0063999999999997",
         "1",
         "3.1750142857142856",
         "2.5557066666666666",
         "3.0925787742246698",
         "2.6917692413882017",
         "72.18069905473732",
         "2.9733928563491987",
         "2.7350364454128964",
         "0.2383564109363023",
         "0.1929819403749409",
         "2.72958",
         "0.3861295182216789",
         "3.501839036443358",
         "1.957320963556642",
         "3.1738",
         "3.1053",
         "2.9587"
        ],
        [
         "2025-01-23 01:00:00",
         "3.1802",
         "3.1868",
         "3.0374",
         "3.1194",
         "305314846.0",
         "3.1121",
         "-0.0607999999999999",
         "0",
         "3.1570571428571426",
         "2.5822266666666667",
         "3.0992840806685025",
         "2.7193583225889637",
         "73.80310182063386",
         "2.995855493833937",
         "2.763507819826756",
         "0.2323476740071814",
         "0.200855087101389",
         "2.762815",
         "0.3898132755091322",
         "3.5424415510182645",
         "1.983188448981736",
         "3.1803",
         "3.1738",
         "3.1053"
        ],
        [
         "2025-01-24 01:00:00",
         "3.1194",
         "3.2031",
         "3.055",
         "3.1009",
         "232626964.0",
         "3.1290500000000003",
         "-0.0184999999999999",
         "0",
         "3.129728571428572",
         "2.609013333333333",
         "3.099688060501377",
         "2.7439739146799984",
         "71.96483313089249",
         "3.012016187090255",
         "2.7884998331729225",
         "0.2235163539173323",
         "0.2053873404645777",
         "2.796855",
         "0.3880319350327547",
         "3.572918870065509",
         "2.0207911299344907",
         "3.1194",
         "3.1803",
         "3.1738"
        ],
        [
         "2025-01-25 01:00:00",
         "3.1008",
         "3.1446",
         "3.0784",
         "3.108",
         "99489857.0",
         "3.1115",
         "0.0072",
         "1",
         "3.106628571428572",
         "2.64075",
         "3.1017660453760327",
         "2.767459468571612",
         "67.70819453697536",
         "3.026782927537908",
         "2.8121665121971504",
         "0.2146164153407577",
         "0.2072331554398137",
         "2.832285",
         "0.3821367835502179",
         "3.596558567100436",
         "2.068011432899564",
         "3.1009",
         "3.1194",
         "3.1803"
        ],
        [
         "2025-01-26 01:00:00",
         "3.1079",
         "3.1443",
         "3.0115",
         "3.0223",
         "128937813.0",
         "3.0779",
         "-0.0855999999999999",
         "0",
         "3.115714285714286",
         "2.66994",
         "3.0818995340320243",
         "2.7839007931798947",
         "67.08693643144763",
         "3.0260932463782297",
         "2.827731955738102",
         "0.1983612906401277",
         "0.2054587824798765",
         "2.8624",
         "0.3715210853264",
         "3.6054421706528",
         "2.1193578293472",
         "3.108",
         "3.1009",
         "3.1194"
        ],
        [
         "2025-01-27 01:00:00",
         "3.0222",
         "3.0587",
         "2.6559",
         "3.0552",
         "660056174.0",
         "2.8573",
         "0.0329999999999999",
         "1",
         "3.1085571428571432",
         "2.69897",
         "3.075224650524018",
         "2.8014039678134504",
         "67.39471619147267",
         "3.0305712084738867",
         "2.8445814404982426",
         "0.1859897679756441",
         "0.2015649795790301",
         "2.9016",
         "0.3463685305384561",
         "3.5943370610769123",
         "2.208862938923088",
         "3.0223",
         "3.108",
         "3.1009"
        ],
        [
         "2025-01-28 01:00:00",
         "3.0552",
         "3.214",
         "3.0062",
         "3.0572",
         "369470786.0",
         "3.1101",
         "0.0019999999999997",
         "1",
         "3.0919",
         "2.73107",
         "3.070718487893014",
         "2.8179069376319377",
         "64.0545021988321",
         "3.0346679456317505",
         "2.8603309634242984",
         "0.174336982207452",
         "0.1961193801047145",
         "2.935805",
         "0.324520009074132",
         "3.5848450181482643",
         "2.286764981851736",
         "3.0552",
         "3.0223",
         "3.108"
        ],
        [
         "2025-01-29 01:00:00",
         "3.0572",
         "3.1363",
         "2.9673",
         "3.0683",
         "254756655.0",
         "3.0518",
         "0.0110999999999998",
         "1",
         "3.0759000000000003",
         "2.7647233333333334",
         "3.07011386591976",
         "2.834061328752458",
         "45.95707782354214",
         "3.0398421078422504",
         "2.8757360772447207",
         "0.1641060305975297",
         "0.1897167102032775",
         "2.97561",
         "0.2852926528837973",
         "3.5461953057675943",
         "2.405024694232405",
         "3.0572",
         "3.0552",
         "3.0223"
        ],
        [
         "2025-01-30 01:00:00",
         "3.0683",
         "3.1544",
         "3.0466",
         "3.1276",
         "173143314.0",
         "3.1005000000000003",
         "0.0593000000000003",
         "1",
         "3.0770714285714287",
         "2.7995233333333336",
         "3.08448539943982",
         "2.852999307542622",
         "43.32158690462659",
         "3.053343322020366",
         "2.894392664115482",
         "0.1589506579048838",
         "0.1835634997435988",
         "3.01492",
         "0.2445639698901339",
         "3.504047939780268",
         "2.5257920602197323",
         "3.0683",
         "3.0572",
         "3.0552"
        ],
        [
         "2025-01-31 01:00:00",
         "3.1276",
         "3.1333",
         "3.003",
         "3.0361",
         "162235322.0",
         "3.06815",
         "-0.0915000000000003",
         "0",
         "3.0678142857142854",
         "2.8229666666666664",
         "3.0723890495798645",
         "2.8648122554430984",
         "36.14327453738773",
         "3.050690503248002",
         "2.9048895038106317",
         "0.1458009994373705",
         "0.1760109996823532",
         "3.037905",
         "0.2217160072444531",
         "3.481337014488906",
         "2.5944729855110937",
         "3.1276",
         "3.0683",
         "3.0572"
        ],
        [
         "2025-02-01 01:00:00",
         "3.0361",
         "3.0727",
         "2.8281",
         "2.8778",
         "173601404.0",
         "2.9504",
         "-0.1582999999999996",
         "0",
         "3.0349285714285714",
         "2.8388133333333334",
         "3.0237417871848984",
         "2.86565017444677",
         "31.512406830833115",
         "3.0240919642867707",
         "2.9028828738987325",
         "0.1212090903880382",
         "0.1650506178234902",
         "3.056565",
         "0.1875404862254698",
         "3.4316459724509394",
         "2.681484027549061",
         "3.0361",
         "3.1276",
         "3.0683"
        ],
        [
         "2025-02-02 01:00:00",
         "2.8779",
         "2.9559",
         "2.4603",
         "2.58",
         "684089012.0",
         "2.7081",
         "-0.2978999999999998",
         "0",
         "2.971742857142857",
         "2.84299",
         "2.912806340388674",
         "2.847221130934076",
         "31.909811789433466",
         "2.9557701236272678",
         "2.878965623980308",
         "0.0768044996469594",
         "0.147401394188184",
         "3.059405",
         "0.1792868782441362",
         "3.4179787564882727",
         "2.700831243511727",
         "2.8778",
         "3.0361",
         "3.1276"
        ],
        [
         "2025-02-03 01:00:00",
         "2.5801",
         "2.7814",
         "1.7711",
         "2.7001",
         "1866758972.0",
         "2.27625",
         "0.1200000000000001",
         "1",
         "2.9210142857142856",
         "2.852323333333333",
         "2.8596297552915058",
         "2.8377294450673607",
         "30.141148794354024",
         "2.916436258453841",
         "2.8657163185002847",
         "0.0507199399535567",
         "0.1280651033412586",
         "3.061045",
         "0.1756239807237741",
         "3.412292961447548",
         "2.709797038552452",
         "2.58",
         "2.8778",
         "3.0361"
        ],
        [
         "2025-02-04 01:00:00",
         "2.7",
         "2.7874",
         "2.4209",
         "2.5274",
         "621552965.0",
         "2.60415",
         "-0.1726000000000001",
         "0",
         "2.8453285714285714",
         "2.85659",
         "2.7765723164686293",
         "2.8177081905468864",
         "21.2557808609036",
         "2.85658452638402",
         "2.8406558504632264",
         "0.0159286759207932",
         "0.1056378178571655",
         "3.03027",
         "0.2109086359939854",
         "3.4520872719879714",
         "2.608452728012029",
         "2.7001",
         "2.58",
         "2.8778"
        ],
        [
         "2025-02-05 01:00:00",
         "2.5275",
         "2.5692",
         "2.3384",
         "2.381",
         "338815093.0",
         "2.4538",
         "-0.1465",
         "0",
         "2.7471428571428573",
         "2.85529",
         "2.677679237351472",
         "2.78953346857612",
         "18.38962271612749",
         "2.783417676171094",
         "2.806607268947432",
         "-0.0231895927763381",
         "0.0798723357304648",
         "2.9870650000000003",
         "0.2495504131644097",
         "3.48616582632882",
         "2.487964173671181",
         "2.5274",
         "2.7001",
         "2.58"
        ],
        [
         "2025-02-06 01:00:00",
         "2.381",
         "2.4699",
         "2.2772",
         "2.325",
         "322896937.0",
         "2.37355",
         "-0.0559999999999996",
         "0",
         "2.632485714285714",
         "2.857083333333333",
         "2.589509428013604",
         "2.7595635673776604",
         "18.461171986660304",
         "2.71289187983708",
         "2.7709326564328074",
         "-0.0580407765957278",
         "0.0522897132652262",
         "2.938705",
         "0.2792548043689831",
         "3.4972146087379663",
         "2.380195391262034",
         "2.381",
         "2.5274",
         "2.7001"
        ],
        [
         "2025-02-07 01:00:00",
         "2.3251",
         "2.542",
         "2.2655",
         "2.3968",
         "447487945.0",
         "2.40375",
         "0.0716999999999998",
         "1",
         "2.5411571428571427",
         "2.857873333333333",
         "2.5413320710102028",
         "2.736159466256521",
         "23.1812295269292",
         "2.6642623598621444",
         "2.7432191263266734",
         "-0.0789567664645289",
         "0.0260404173192752",
         "2.89506",
         "0.2926905396489628",
         "3.480441079297925",
         "2.3096789207020745",
         "2.325",
         "2.381",
         "2.5274"
        ],
        [
         "2025-02-08 01:00:00",
         "2.3969",
         "2.4372",
         "2.3506",
         "2.419",
         "154717204.0",
         "2.3939",
         "0.0221",
         "1",
         "2.4756142857142858",
         "2.862766666666667",
         "2.510749053257652",
         "2.715697565207713",
         "24.054827534267204",
         "2.626529689114122",
         "2.71920289474692",
         "-0.0926732056327979",
         "0.0022976927288606",
         "2.868075",
         "0.3108313603954146",
         "3.4897377207908296",
         "2.2464122792091707",
         "2.3968",
         "2.325",
         "2.381"
        ],
        [
         "2025-02-09 01:00:00",
         "2.419",
         "2.5079",
         "2.3113",
         "2.3928",
         "204205603.0",
         "2.4096",
         "-0.0262000000000002",
         "0",
         "2.4488714285714286",
         "2.86448",
         "2.481261789943239",
         "2.6948654642265706",
         "25.18331625009856",
         "2.590571275404257",
         "2.695024902543444",
         "-0.1044536271391871",
         "-0.0190525712447489",
         "2.83245",
         "0.3228112019513326",
         "3.4780724039026656",
         "2.1868275960973347",
         "2.419",
         "2.3968",
         "2.325"
        ],
        [
         "2025-02-10 01:00:00",
         "2.3928",
         "2.4733",
         "2.3235",
         "2.4237",
         "207257933.0",
         "2.3984",
         "0.0309000000000003",
         "1",
         "2.4093857142857145",
         "2.85939",
         "2.4668713424574293",
         "2.677370918147437",
         "25.06515043828477",
         "2.5648987714959097",
         "2.6749267616143",
         "-0.1100279901183904",
         "-0.0372476550194772",
         "2.794945",
         "0.3246340943844977",
         "3.4442131887689955",
         "2.145676811231004",
         "2.3928",
         "2.419",
         "2.3968"
        ],
        [
         "2025-02-11 01:00:00",
         "2.4238",
         "2.529",
         "2.3708",
         "2.4131",
         "248182176.0",
         "2.4499",
         "-0.0106999999999999",
         "0",
         "2.3930571428571428",
         "2.85634",
         "2.453428506843072",
         "2.6603211814927645",
         "24.739195230998533",
         "2.541545114342693",
         "2.6555321866799075",
         "-0.1139870723372147",
         "-0.0525955384830247",
         "2.756585",
         "0.3220196092018731",
         "3.4006242184037463",
         "2.1125457815962534",
         "2.4237",
         "2.3928",
         "2.419"
        ],
        [
         "2025-02-12 01:00:00",
         "2.413",
         "2.4962",
         "2.3323",
         "2.4734",
         "227957636.0",
         "2.41425",
         "0.0604",
         "1",
         "2.4062571428571427",
         "2.85468",
         "2.458421380132304",
         "2.648261750428716",
         "27.53568461596558",
         "2.5310612505976637",
         "2.6420409135925067",
         "-0.1109796629948434",
         "-0.0642723633853885",
         "2.724285",
         "0.3160553886750343",
         "3.3563957773500688",
         "2.092174222649932",
         "2.4131",
         "2.4237",
         "2.3928"
        ],
        [
         "2025-02-13 01:00:00",
         "2.4734",
         "2.6061",
         "2.4154",
         "2.5599",
         "212478703.0",
         "2.51075",
         "0.0865",
         "1",
         "2.4398142857142857",
         "2.8511",
         "2.483791035099228",
         "2.6425609923365405",
         "28.99430178346776",
         "2.5354979812749456",
         "2.635956401474544",
         "-0.1004584201995979",
         "-0.0715095747482303",
         "2.697235",
         "0.3050865869759472",
         "3.3074081739518943",
         "2.0870618260481058",
         "2.4734",
         "2.4131",
         "2.4237"
        ],
        [
         "2025-02-14 01:00:00",
         "2.56",
         "2.8356",
         "2.53",
         "2.7384",
         "407541122.0",
         "2.6828",
         "0.1783999999999999",
         "1",
         "2.488614285714285",
         "2.837616666666667",
         "2.5474432763244206",
         "2.64874415412128",
         "39.65097684766739",
         "2.5667136764634155",
         "2.643544816180133",
         "-0.0768311397167176",
         "-0.0725738877419278",
         "2.678755",
         "0.2897017658413209",
         "3.258158531682642",
         "2.0993514683173577",
         "2.5599",
         "2.4734",
         "2.4131"
        ],
        [
         "2025-02-15 01:00:00",
         "2.7384",
         "2.8335",
         "2.713",
         "2.7619",
         "184181907.0",
         "2.77325",
         "0.0234999999999998",
         "1",
         "2.5376",
         "2.8215100000000004",
         "2.601057457243315",
         "2.6560445312747456",
         "45.554276946682",
         "2.59674234162289",
         "2.6523118668334567",
         "-0.0555695252105667",
         "-0.0691730152356556",
         "2.665735",
         "0.2791070974884401",
         "3.22394919497688",
         "2.10752080502312",
         "2.7384",
         "2.5599",
         "2.4734"
        ],
        [
         "2025-02-16 01:00:00",
         "2.7619",
         "2.8054",
         "2.6879",
         "2.7283",
         "132387997.0",
         "2.74665",
         "-0.0335999999999998",
         "0",
         "2.585528571428572",
         "2.8027133333333327",
         "2.6328680929324864",
         "2.6607061744183107",
         "57.1346098335418",
         "2.6169819813732142",
         "2.657940617438386",
         "-0.0409586360651719",
         "-0.0635301394015588",
         "2.64939",
         "0.2642768562262739",
         "3.177943712452548",
         "2.120836287547452",
         "2.7619",
         "2.7384",
         "2.5599"
        ],
        [
         "2025-02-17 01:00:00",
         "2.7283",
         "2.7648",
         "2.6075",
         "2.6599",
         "212813356.0",
         "2.68615",
         "-0.0684",
         "0",
         "2.619271428571428",
         "2.7823866666666666",
         "2.6396260696993648",
         "2.6606541631655167",
         "47.964763061968405",
         "2.623584753469643",
         "2.6580857568873943",
         "-0.0345010034177515",
         "-0.0577243122047974",
         "2.629525",
         "0.2463322507573021",
         "3.1221895015146046",
         "2.136860498485396",
         "2.7283",
         "2.7619",
         "2.7384"
        ],
        [
         "2025-02-18 01:00:00",
         "2.6599",
         "2.6699",
         "2.4693",
         "2.5628",
         "227170019.0",
         "2.5696000000000003",
         "-0.0970999999999997",
         "0",
         "2.640657142857143",
         "2.76919",
         "2.620419552274524",
         "2.654340991348387",
         "51.94078947368422",
         "2.6142332529358514",
         "2.6510275526735136",
         "-0.0367942997376622",
         "-0.0535383097113703",
         "2.6042499999999995",
         "0.22384959588739",
         "3.05194919177478",
         "2.1565508082252194",
         "2.6599",
         "2.7283",
         "2.7619"
        ],
        [
         "2025-02-19 01:00:00",
         "2.5629",
         "2.747",
         "2.5121",
         "2.7378",
         "208244059.0",
         "2.62955",
         "0.1749",
         "1",
         "2.678428571428572",
         "2.75694",
         "2.649764664205893",
         "2.659725443519459",
         "68.96661705294495",
         "2.6332435217149515",
         "2.6574551413643643",
         "-0.0242116196494128",
         "-0.0476729716989788",
         "2.58476",
         "0.1903469640862247",
         "2.9654539281724497",
         "2.2040660718275507",
         "2.5628",
         "2.6599",
         "2.7283"
        ],
        [
         "2025-02-20 01:00:00",
         "2.7378",
         "2.749",
         "2.6671",
         "2.6877",
         "161604635.0",
         "2.70805",
         "-0.0501",
         "0",
         "2.696685714285714",
         "2.7407366666666664",
         "2.65924849815442",
         "2.661530253614978",
         "69.4019471488178",
         "2.6416214414511128",
         "2.6596955012633003",
         "-0.0180740598121875",
         "-0.0417531893216206",
         "2.56734",
         "0.1604643078857835",
         "2.888268615771567",
         "2.2464113842284323",
         "2.7378",
         "2.5628",
         "2.6599"
        ],
        [
         "2025-02-21 01:00:00",
         "2.6878",
         "2.716",
         "2.5076",
         "2.5721",
         "257777373.0",
         "2.6118",
         "-0.1157000000000003",
         "0",
         "2.6729285714285718",
         "2.720463333333333",
         "2.637461373615815",
         "2.6557605598333667",
         "58.95758814512008",
         "2.6309258350740183",
         "2.653206945614167",
         "-0.0222811105401485",
         "-0.0378587735653262",
         "2.552055",
         "0.1429375479195844",
         "2.837930095839169",
         "2.2661799041608317",
         "2.6877",
         "2.7378",
         "2.5628"
        ],
        [
         "2025-02-22 01:00:00",
         "2.5722",
         "2.6099",
         "2.5505",
         "2.574",
         "92676731.0",
         "2.5802",
         "0.0017999999999998",
         "1",
         "2.646085714285714",
         "2.7022833333333334",
         "2.621596030211861",
         "2.650485685005408",
         "58.0880818200793",
         "2.6221680142934",
         "2.647339764457562",
         "-0.0251717501641617",
         "-0.0353213688850933",
         "2.551755",
         "0.1428820952099292",
         "2.8375191904198585",
         "2.265990809580141",
         "2.5721",
         "2.6877",
         "2.7378"
        ],
        [
         "2025-02-23 01:00:00",
         "2.574",
         "2.6016",
         "2.5408",
         "2.5673",
         "43978905.0",
         "2.5712",
         "-0.0066999999999999",
         "0",
         "2.6230857142857142",
         "2.684496666666667",
         "2.608022022658896",
         "2.645118866617962",
         "59.29476936188346",
         "2.6137267813251848",
         "2.641410893016261",
         "-0.0276841116910762",
         "-0.0337939174462899",
         "2.545115",
         "0.138648397697957",
         "2.8224117953959142",
         "2.267818204604086",
         "2.574",
         "2.5721",
         "2.6877"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 37
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>30_day_SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>26_day_EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-18 01:00:00</th>\n",
       "      <td>3.2923</td>\n",
       "      <td>3.2996</td>\n",
       "      <td>3.0580</td>\n",
       "      <td>3.2697</td>\n",
       "      <td>4.580889e+08</td>\n",
       "      <td>3.17880</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>0</td>\n",
       "      <td>2.949286</td>\n",
       "      <td>2.441173</td>\n",
       "      <td>...</td>\n",
       "      <td>2.599338</td>\n",
       "      <td>0.235394</td>\n",
       "      <td>0.133276</td>\n",
       "      <td>2.552550</td>\n",
       "      <td>0.380010</td>\n",
       "      <td>3.312570</td>\n",
       "      <td>1.792530</td>\n",
       "      <td>3.2922</td>\n",
       "      <td>3.2451</td>\n",
       "      <td>3.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-19 01:00:00</th>\n",
       "      <td>3.2697</td>\n",
       "      <td>3.2929</td>\n",
       "      <td>2.8277</td>\n",
       "      <td>2.9587</td>\n",
       "      <td>6.633288e+08</td>\n",
       "      <td>3.06030</td>\n",
       "      <td>-0.3110</td>\n",
       "      <td>0</td>\n",
       "      <td>3.014157</td>\n",
       "      <td>2.463820</td>\n",
       "      <td>...</td>\n",
       "      <td>2.625958</td>\n",
       "      <td>0.227846</td>\n",
       "      <td>0.152190</td>\n",
       "      <td>2.597550</td>\n",
       "      <td>0.371647</td>\n",
       "      <td>3.340844</td>\n",
       "      <td>1.854256</td>\n",
       "      <td>3.2697</td>\n",
       "      <td>3.2922</td>\n",
       "      <td>3.2451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-20 01:00:00</th>\n",
       "      <td>2.9586</td>\n",
       "      <td>3.3695</td>\n",
       "      <td>2.9090</td>\n",
       "      <td>3.1053</td>\n",
       "      <td>8.387613e+08</td>\n",
       "      <td>3.13925</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>1</td>\n",
       "      <td>3.097314</td>\n",
       "      <td>2.492730</td>\n",
       "      <td>...</td>\n",
       "      <td>2.661465</td>\n",
       "      <td>0.231031</td>\n",
       "      <td>0.167958</td>\n",
       "      <td>2.648635</td>\n",
       "      <td>0.367480</td>\n",
       "      <td>3.383594</td>\n",
       "      <td>1.913676</td>\n",
       "      <td>2.9587</td>\n",
       "      <td>3.2697</td>\n",
       "      <td>3.2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 01:00:00</th>\n",
       "      <td>3.1053</td>\n",
       "      <td>3.2460</td>\n",
       "      <td>3.0124</td>\n",
       "      <td>3.1738</td>\n",
       "      <td>3.764235e+08</td>\n",
       "      <td>3.12920</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>1</td>\n",
       "      <td>3.169671</td>\n",
       "      <td>2.525087</td>\n",
       "      <td>...</td>\n",
       "      <td>2.699415</td>\n",
       "      <td>0.236358</td>\n",
       "      <td>0.181638</td>\n",
       "      <td>2.690685</td>\n",
       "      <td>0.377420</td>\n",
       "      <td>3.445524</td>\n",
       "      <td>1.935846</td>\n",
       "      <td>3.1053</td>\n",
       "      <td>2.9587</td>\n",
       "      <td>3.2697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 01:00:00</th>\n",
       "      <td>3.1739</td>\n",
       "      <td>3.2854</td>\n",
       "      <td>3.1237</td>\n",
       "      <td>3.1803</td>\n",
       "      <td>2.917613e+08</td>\n",
       "      <td>3.20455</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>1</td>\n",
       "      <td>3.175014</td>\n",
       "      <td>2.555707</td>\n",
       "      <td>...</td>\n",
       "      <td>2.735036</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>2.729580</td>\n",
       "      <td>0.386130</td>\n",
       "      <td>3.501839</td>\n",
       "      <td>1.957321</td>\n",
       "      <td>3.1738</td>\n",
       "      <td>3.1053</td>\n",
       "      <td>2.9587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23 01:00:00</th>\n",
       "      <td>3.1802</td>\n",
       "      <td>3.1868</td>\n",
       "      <td>3.0374</td>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.053148e+08</td>\n",
       "      <td>3.11210</td>\n",
       "      <td>-0.0608</td>\n",
       "      <td>0</td>\n",
       "      <td>3.157057</td>\n",
       "      <td>2.582227</td>\n",
       "      <td>...</td>\n",
       "      <td>2.763508</td>\n",
       "      <td>0.232348</td>\n",
       "      <td>0.200855</td>\n",
       "      <td>2.762815</td>\n",
       "      <td>0.389813</td>\n",
       "      <td>3.542442</td>\n",
       "      <td>1.983188</td>\n",
       "      <td>3.1803</td>\n",
       "      <td>3.1738</td>\n",
       "      <td>3.1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-24 01:00:00</th>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.2031</td>\n",
       "      <td>3.0550</td>\n",
       "      <td>3.1009</td>\n",
       "      <td>2.326270e+08</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>0</td>\n",
       "      <td>3.129729</td>\n",
       "      <td>2.609013</td>\n",
       "      <td>...</td>\n",
       "      <td>2.788500</td>\n",
       "      <td>0.223516</td>\n",
       "      <td>0.205387</td>\n",
       "      <td>2.796855</td>\n",
       "      <td>0.388032</td>\n",
       "      <td>3.572919</td>\n",
       "      <td>2.020791</td>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.1803</td>\n",
       "      <td>3.1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-25 01:00:00</th>\n",
       "      <td>3.1008</td>\n",
       "      <td>3.1446</td>\n",
       "      <td>3.0784</td>\n",
       "      <td>3.1080</td>\n",
       "      <td>9.948986e+07</td>\n",
       "      <td>3.11150</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>1</td>\n",
       "      <td>3.106629</td>\n",
       "      <td>2.640750</td>\n",
       "      <td>...</td>\n",
       "      <td>2.812167</td>\n",
       "      <td>0.214616</td>\n",
       "      <td>0.207233</td>\n",
       "      <td>2.832285</td>\n",
       "      <td>0.382137</td>\n",
       "      <td>3.596559</td>\n",
       "      <td>2.068011</td>\n",
       "      <td>3.1009</td>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.1803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-26 01:00:00</th>\n",
       "      <td>3.1079</td>\n",
       "      <td>3.1443</td>\n",
       "      <td>3.0115</td>\n",
       "      <td>3.0223</td>\n",
       "      <td>1.289378e+08</td>\n",
       "      <td>3.07790</td>\n",
       "      <td>-0.0856</td>\n",
       "      <td>0</td>\n",
       "      <td>3.115714</td>\n",
       "      <td>2.669940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.827732</td>\n",
       "      <td>0.198361</td>\n",
       "      <td>0.205459</td>\n",
       "      <td>2.862400</td>\n",
       "      <td>0.371521</td>\n",
       "      <td>3.605442</td>\n",
       "      <td>2.119358</td>\n",
       "      <td>3.1080</td>\n",
       "      <td>3.1009</td>\n",
       "      <td>3.1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-27 01:00:00</th>\n",
       "      <td>3.0222</td>\n",
       "      <td>3.0587</td>\n",
       "      <td>2.6559</td>\n",
       "      <td>3.0552</td>\n",
       "      <td>6.600562e+08</td>\n",
       "      <td>2.85730</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>1</td>\n",
       "      <td>3.108557</td>\n",
       "      <td>2.698970</td>\n",
       "      <td>...</td>\n",
       "      <td>2.844581</td>\n",
       "      <td>0.185990</td>\n",
       "      <td>0.201565</td>\n",
       "      <td>2.901600</td>\n",
       "      <td>0.346369</td>\n",
       "      <td>3.594337</td>\n",
       "      <td>2.208863</td>\n",
       "      <td>3.0223</td>\n",
       "      <td>3.1080</td>\n",
       "      <td>3.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-28 01:00:00</th>\n",
       "      <td>3.0552</td>\n",
       "      <td>3.2140</td>\n",
       "      <td>3.0062</td>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.694708e+08</td>\n",
       "      <td>3.11010</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1</td>\n",
       "      <td>3.091900</td>\n",
       "      <td>2.731070</td>\n",
       "      <td>...</td>\n",
       "      <td>2.860331</td>\n",
       "      <td>0.174337</td>\n",
       "      <td>0.196119</td>\n",
       "      <td>2.935805</td>\n",
       "      <td>0.324520</td>\n",
       "      <td>3.584845</td>\n",
       "      <td>2.286765</td>\n",
       "      <td>3.0552</td>\n",
       "      <td>3.0223</td>\n",
       "      <td>3.1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-29 01:00:00</th>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.1363</td>\n",
       "      <td>2.9673</td>\n",
       "      <td>3.0683</td>\n",
       "      <td>2.547567e+08</td>\n",
       "      <td>3.05180</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>1</td>\n",
       "      <td>3.075900</td>\n",
       "      <td>2.764723</td>\n",
       "      <td>...</td>\n",
       "      <td>2.875736</td>\n",
       "      <td>0.164106</td>\n",
       "      <td>0.189717</td>\n",
       "      <td>2.975610</td>\n",
       "      <td>0.285293</td>\n",
       "      <td>3.546195</td>\n",
       "      <td>2.405025</td>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.0552</td>\n",
       "      <td>3.0223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-30 01:00:00</th>\n",
       "      <td>3.0683</td>\n",
       "      <td>3.1544</td>\n",
       "      <td>3.0466</td>\n",
       "      <td>3.1276</td>\n",
       "      <td>1.731433e+08</td>\n",
       "      <td>3.10050</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>1</td>\n",
       "      <td>3.077071</td>\n",
       "      <td>2.799523</td>\n",
       "      <td>...</td>\n",
       "      <td>2.894393</td>\n",
       "      <td>0.158951</td>\n",
       "      <td>0.183563</td>\n",
       "      <td>3.014920</td>\n",
       "      <td>0.244564</td>\n",
       "      <td>3.504048</td>\n",
       "      <td>2.525792</td>\n",
       "      <td>3.0683</td>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-31 01:00:00</th>\n",
       "      <td>3.1276</td>\n",
       "      <td>3.1333</td>\n",
       "      <td>3.0030</td>\n",
       "      <td>3.0361</td>\n",
       "      <td>1.622353e+08</td>\n",
       "      <td>3.06815</td>\n",
       "      <td>-0.0915</td>\n",
       "      <td>0</td>\n",
       "      <td>3.067814</td>\n",
       "      <td>2.822967</td>\n",
       "      <td>...</td>\n",
       "      <td>2.904890</td>\n",
       "      <td>0.145801</td>\n",
       "      <td>0.176011</td>\n",
       "      <td>3.037905</td>\n",
       "      <td>0.221716</td>\n",
       "      <td>3.481337</td>\n",
       "      <td>2.594473</td>\n",
       "      <td>3.1276</td>\n",
       "      <td>3.0683</td>\n",
       "      <td>3.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01 01:00:00</th>\n",
       "      <td>3.0361</td>\n",
       "      <td>3.0727</td>\n",
       "      <td>2.8281</td>\n",
       "      <td>2.8778</td>\n",
       "      <td>1.736014e+08</td>\n",
       "      <td>2.95040</td>\n",
       "      <td>-0.1583</td>\n",
       "      <td>0</td>\n",
       "      <td>3.034929</td>\n",
       "      <td>2.838813</td>\n",
       "      <td>...</td>\n",
       "      <td>2.902883</td>\n",
       "      <td>0.121209</td>\n",
       "      <td>0.165051</td>\n",
       "      <td>3.056565</td>\n",
       "      <td>0.187540</td>\n",
       "      <td>3.431646</td>\n",
       "      <td>2.681484</td>\n",
       "      <td>3.0361</td>\n",
       "      <td>3.1276</td>\n",
       "      <td>3.0683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-02 01:00:00</th>\n",
       "      <td>2.8779</td>\n",
       "      <td>2.9559</td>\n",
       "      <td>2.4603</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>6.840890e+08</td>\n",
       "      <td>2.70810</td>\n",
       "      <td>-0.2979</td>\n",
       "      <td>0</td>\n",
       "      <td>2.971743</td>\n",
       "      <td>2.842990</td>\n",
       "      <td>...</td>\n",
       "      <td>2.878966</td>\n",
       "      <td>0.076804</td>\n",
       "      <td>0.147401</td>\n",
       "      <td>3.059405</td>\n",
       "      <td>0.179287</td>\n",
       "      <td>3.417979</td>\n",
       "      <td>2.700831</td>\n",
       "      <td>2.8778</td>\n",
       "      <td>3.0361</td>\n",
       "      <td>3.1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-03 01:00:00</th>\n",
       "      <td>2.5801</td>\n",
       "      <td>2.7814</td>\n",
       "      <td>1.7711</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>1.866759e+09</td>\n",
       "      <td>2.27625</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921014</td>\n",
       "      <td>2.852323</td>\n",
       "      <td>...</td>\n",
       "      <td>2.865716</td>\n",
       "      <td>0.050720</td>\n",
       "      <td>0.128065</td>\n",
       "      <td>3.061045</td>\n",
       "      <td>0.175624</td>\n",
       "      <td>3.412293</td>\n",
       "      <td>2.709797</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>2.8778</td>\n",
       "      <td>3.0361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-04 01:00:00</th>\n",
       "      <td>2.7000</td>\n",
       "      <td>2.7874</td>\n",
       "      <td>2.4209</td>\n",
       "      <td>2.5274</td>\n",
       "      <td>6.215530e+08</td>\n",
       "      <td>2.60415</td>\n",
       "      <td>-0.1726</td>\n",
       "      <td>0</td>\n",
       "      <td>2.845329</td>\n",
       "      <td>2.856590</td>\n",
       "      <td>...</td>\n",
       "      <td>2.840656</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>0.105638</td>\n",
       "      <td>3.030270</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>3.452087</td>\n",
       "      <td>2.608453</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>2.8778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-05 01:00:00</th>\n",
       "      <td>2.5275</td>\n",
       "      <td>2.5692</td>\n",
       "      <td>2.3384</td>\n",
       "      <td>2.3810</td>\n",
       "      <td>3.388151e+08</td>\n",
       "      <td>2.45380</td>\n",
       "      <td>-0.1465</td>\n",
       "      <td>0</td>\n",
       "      <td>2.747143</td>\n",
       "      <td>2.855290</td>\n",
       "      <td>...</td>\n",
       "      <td>2.806607</td>\n",
       "      <td>-0.023190</td>\n",
       "      <td>0.079872</td>\n",
       "      <td>2.987065</td>\n",
       "      <td>0.249550</td>\n",
       "      <td>3.486166</td>\n",
       "      <td>2.487964</td>\n",
       "      <td>2.5274</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>2.5800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-06 01:00:00</th>\n",
       "      <td>2.3810</td>\n",
       "      <td>2.4699</td>\n",
       "      <td>2.2772</td>\n",
       "      <td>2.3250</td>\n",
       "      <td>3.228969e+08</td>\n",
       "      <td>2.37355</td>\n",
       "      <td>-0.0560</td>\n",
       "      <td>0</td>\n",
       "      <td>2.632486</td>\n",
       "      <td>2.857083</td>\n",
       "      <td>...</td>\n",
       "      <td>2.770933</td>\n",
       "      <td>-0.058041</td>\n",
       "      <td>0.052290</td>\n",
       "      <td>2.938705</td>\n",
       "      <td>0.279255</td>\n",
       "      <td>3.497215</td>\n",
       "      <td>2.380195</td>\n",
       "      <td>2.3810</td>\n",
       "      <td>2.5274</td>\n",
       "      <td>2.7001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-07 01:00:00</th>\n",
       "      <td>2.3251</td>\n",
       "      <td>2.5420</td>\n",
       "      <td>2.2655</td>\n",
       "      <td>2.3968</td>\n",
       "      <td>4.474879e+08</td>\n",
       "      <td>2.40375</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>2.541157</td>\n",
       "      <td>2.857873</td>\n",
       "      <td>...</td>\n",
       "      <td>2.743219</td>\n",
       "      <td>-0.078957</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>2.895060</td>\n",
       "      <td>0.292691</td>\n",
       "      <td>3.480441</td>\n",
       "      <td>2.309679</td>\n",
       "      <td>2.3250</td>\n",
       "      <td>2.3810</td>\n",
       "      <td>2.5274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-08 01:00:00</th>\n",
       "      <td>2.3969</td>\n",
       "      <td>2.4372</td>\n",
       "      <td>2.3506</td>\n",
       "      <td>2.4190</td>\n",
       "      <td>1.547172e+08</td>\n",
       "      <td>2.39390</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>1</td>\n",
       "      <td>2.475614</td>\n",
       "      <td>2.862767</td>\n",
       "      <td>...</td>\n",
       "      <td>2.719203</td>\n",
       "      <td>-0.092673</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>2.868075</td>\n",
       "      <td>0.310831</td>\n",
       "      <td>3.489738</td>\n",
       "      <td>2.246412</td>\n",
       "      <td>2.3968</td>\n",
       "      <td>2.3250</td>\n",
       "      <td>2.3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-09 01:00:00</th>\n",
       "      <td>2.4190</td>\n",
       "      <td>2.5079</td>\n",
       "      <td>2.3113</td>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.042056e+08</td>\n",
       "      <td>2.40960</td>\n",
       "      <td>-0.0262</td>\n",
       "      <td>0</td>\n",
       "      <td>2.448871</td>\n",
       "      <td>2.864480</td>\n",
       "      <td>...</td>\n",
       "      <td>2.695025</td>\n",
       "      <td>-0.104454</td>\n",
       "      <td>-0.019053</td>\n",
       "      <td>2.832450</td>\n",
       "      <td>0.322811</td>\n",
       "      <td>3.478072</td>\n",
       "      <td>2.186828</td>\n",
       "      <td>2.4190</td>\n",
       "      <td>2.3968</td>\n",
       "      <td>2.3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-10 01:00:00</th>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.4733</td>\n",
       "      <td>2.3235</td>\n",
       "      <td>2.4237</td>\n",
       "      <td>2.072579e+08</td>\n",
       "      <td>2.39840</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>1</td>\n",
       "      <td>2.409386</td>\n",
       "      <td>2.859390</td>\n",
       "      <td>...</td>\n",
       "      <td>2.674927</td>\n",
       "      <td>-0.110028</td>\n",
       "      <td>-0.037248</td>\n",
       "      <td>2.794945</td>\n",
       "      <td>0.324634</td>\n",
       "      <td>3.444213</td>\n",
       "      <td>2.145677</td>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.4190</td>\n",
       "      <td>2.3968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 01:00:00</th>\n",
       "      <td>2.4238</td>\n",
       "      <td>2.5290</td>\n",
       "      <td>2.3708</td>\n",
       "      <td>2.4131</td>\n",
       "      <td>2.481822e+08</td>\n",
       "      <td>2.44990</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>0</td>\n",
       "      <td>2.393057</td>\n",
       "      <td>2.856340</td>\n",
       "      <td>...</td>\n",
       "      <td>2.655532</td>\n",
       "      <td>-0.113987</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>2.756585</td>\n",
       "      <td>0.322020</td>\n",
       "      <td>3.400624</td>\n",
       "      <td>2.112546</td>\n",
       "      <td>2.4237</td>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-12 01:00:00</th>\n",
       "      <td>2.4130</td>\n",
       "      <td>2.4962</td>\n",
       "      <td>2.3323</td>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.279576e+08</td>\n",
       "      <td>2.41425</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1</td>\n",
       "      <td>2.406257</td>\n",
       "      <td>2.854680</td>\n",
       "      <td>...</td>\n",
       "      <td>2.642041</td>\n",
       "      <td>-0.110980</td>\n",
       "      <td>-0.064272</td>\n",
       "      <td>2.724285</td>\n",
       "      <td>0.316055</td>\n",
       "      <td>3.356396</td>\n",
       "      <td>2.092174</td>\n",
       "      <td>2.4131</td>\n",
       "      <td>2.4237</td>\n",
       "      <td>2.3928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-13 01:00:00</th>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.6061</td>\n",
       "      <td>2.4154</td>\n",
       "      <td>2.5599</td>\n",
       "      <td>2.124787e+08</td>\n",
       "      <td>2.51075</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>1</td>\n",
       "      <td>2.439814</td>\n",
       "      <td>2.851100</td>\n",
       "      <td>...</td>\n",
       "      <td>2.635956</td>\n",
       "      <td>-0.100458</td>\n",
       "      <td>-0.071510</td>\n",
       "      <td>2.697235</td>\n",
       "      <td>0.305087</td>\n",
       "      <td>3.307408</td>\n",
       "      <td>2.087062</td>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.4131</td>\n",
       "      <td>2.4237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 01:00:00</th>\n",
       "      <td>2.5600</td>\n",
       "      <td>2.8356</td>\n",
       "      <td>2.5300</td>\n",
       "      <td>2.7384</td>\n",
       "      <td>4.075411e+08</td>\n",
       "      <td>2.68280</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>1</td>\n",
       "      <td>2.488614</td>\n",
       "      <td>2.837617</td>\n",
       "      <td>...</td>\n",
       "      <td>2.643545</td>\n",
       "      <td>-0.076831</td>\n",
       "      <td>-0.072574</td>\n",
       "      <td>2.678755</td>\n",
       "      <td>0.289702</td>\n",
       "      <td>3.258159</td>\n",
       "      <td>2.099351</td>\n",
       "      <td>2.5599</td>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.4131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-15 01:00:00</th>\n",
       "      <td>2.7384</td>\n",
       "      <td>2.8335</td>\n",
       "      <td>2.7130</td>\n",
       "      <td>2.7619</td>\n",
       "      <td>1.841819e+08</td>\n",
       "      <td>2.77325</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>1</td>\n",
       "      <td>2.537600</td>\n",
       "      <td>2.821510</td>\n",
       "      <td>...</td>\n",
       "      <td>2.652312</td>\n",
       "      <td>-0.055570</td>\n",
       "      <td>-0.069173</td>\n",
       "      <td>2.665735</td>\n",
       "      <td>0.279107</td>\n",
       "      <td>3.223949</td>\n",
       "      <td>2.107521</td>\n",
       "      <td>2.7384</td>\n",
       "      <td>2.5599</td>\n",
       "      <td>2.4734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-16 01:00:00</th>\n",
       "      <td>2.7619</td>\n",
       "      <td>2.8054</td>\n",
       "      <td>2.6879</td>\n",
       "      <td>2.7283</td>\n",
       "      <td>1.323880e+08</td>\n",
       "      <td>2.74665</td>\n",
       "      <td>-0.0336</td>\n",
       "      <td>0</td>\n",
       "      <td>2.585529</td>\n",
       "      <td>2.802713</td>\n",
       "      <td>...</td>\n",
       "      <td>2.657941</td>\n",
       "      <td>-0.040959</td>\n",
       "      <td>-0.063530</td>\n",
       "      <td>2.649390</td>\n",
       "      <td>0.264277</td>\n",
       "      <td>3.177944</td>\n",
       "      <td>2.120836</td>\n",
       "      <td>2.7619</td>\n",
       "      <td>2.7384</td>\n",
       "      <td>2.5599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-17 01:00:00</th>\n",
       "      <td>2.7283</td>\n",
       "      <td>2.7648</td>\n",
       "      <td>2.6075</td>\n",
       "      <td>2.6599</td>\n",
       "      <td>2.128134e+08</td>\n",
       "      <td>2.68615</td>\n",
       "      <td>-0.0684</td>\n",
       "      <td>0</td>\n",
       "      <td>2.619271</td>\n",
       "      <td>2.782387</td>\n",
       "      <td>...</td>\n",
       "      <td>2.658086</td>\n",
       "      <td>-0.034501</td>\n",
       "      <td>-0.057724</td>\n",
       "      <td>2.629525</td>\n",
       "      <td>0.246332</td>\n",
       "      <td>3.122190</td>\n",
       "      <td>2.136860</td>\n",
       "      <td>2.7283</td>\n",
       "      <td>2.7619</td>\n",
       "      <td>2.7384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-18 01:00:00</th>\n",
       "      <td>2.6599</td>\n",
       "      <td>2.6699</td>\n",
       "      <td>2.4693</td>\n",
       "      <td>2.5628</td>\n",
       "      <td>2.271700e+08</td>\n",
       "      <td>2.56960</td>\n",
       "      <td>-0.0971</td>\n",
       "      <td>0</td>\n",
       "      <td>2.640657</td>\n",
       "      <td>2.769190</td>\n",
       "      <td>...</td>\n",
       "      <td>2.651028</td>\n",
       "      <td>-0.036794</td>\n",
       "      <td>-0.053538</td>\n",
       "      <td>2.604250</td>\n",
       "      <td>0.223850</td>\n",
       "      <td>3.051949</td>\n",
       "      <td>2.156551</td>\n",
       "      <td>2.6599</td>\n",
       "      <td>2.7283</td>\n",
       "      <td>2.7619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 01:00:00</th>\n",
       "      <td>2.5629</td>\n",
       "      <td>2.7470</td>\n",
       "      <td>2.5121</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.082441e+08</td>\n",
       "      <td>2.62955</td>\n",
       "      <td>0.1749</td>\n",
       "      <td>1</td>\n",
       "      <td>2.678429</td>\n",
       "      <td>2.756940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.657455</td>\n",
       "      <td>-0.024212</td>\n",
       "      <td>-0.047673</td>\n",
       "      <td>2.584760</td>\n",
       "      <td>0.190347</td>\n",
       "      <td>2.965454</td>\n",
       "      <td>2.204066</td>\n",
       "      <td>2.5628</td>\n",
       "      <td>2.6599</td>\n",
       "      <td>2.7283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-20 01:00:00</th>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.7490</td>\n",
       "      <td>2.6671</td>\n",
       "      <td>2.6877</td>\n",
       "      <td>1.616046e+08</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>-0.0501</td>\n",
       "      <td>0</td>\n",
       "      <td>2.696686</td>\n",
       "      <td>2.740737</td>\n",
       "      <td>...</td>\n",
       "      <td>2.659696</td>\n",
       "      <td>-0.018074</td>\n",
       "      <td>-0.041753</td>\n",
       "      <td>2.567340</td>\n",
       "      <td>0.160464</td>\n",
       "      <td>2.888269</td>\n",
       "      <td>2.246411</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.5628</td>\n",
       "      <td>2.6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 01:00:00</th>\n",
       "      <td>2.6878</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.5076</td>\n",
       "      <td>2.5721</td>\n",
       "      <td>2.577774e+08</td>\n",
       "      <td>2.61180</td>\n",
       "      <td>-0.1157</td>\n",
       "      <td>0</td>\n",
       "      <td>2.672929</td>\n",
       "      <td>2.720463</td>\n",
       "      <td>...</td>\n",
       "      <td>2.653207</td>\n",
       "      <td>-0.022281</td>\n",
       "      <td>-0.037859</td>\n",
       "      <td>2.552055</td>\n",
       "      <td>0.142938</td>\n",
       "      <td>2.837930</td>\n",
       "      <td>2.266180</td>\n",
       "      <td>2.6877</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.5628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22 01:00:00</th>\n",
       "      <td>2.5722</td>\n",
       "      <td>2.6099</td>\n",
       "      <td>2.5505</td>\n",
       "      <td>2.5740</td>\n",
       "      <td>9.267673e+07</td>\n",
       "      <td>2.58020</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>1</td>\n",
       "      <td>2.646086</td>\n",
       "      <td>2.702283</td>\n",
       "      <td>...</td>\n",
       "      <td>2.647340</td>\n",
       "      <td>-0.025172</td>\n",
       "      <td>-0.035321</td>\n",
       "      <td>2.551755</td>\n",
       "      <td>0.142882</td>\n",
       "      <td>2.837519</td>\n",
       "      <td>2.265991</td>\n",
       "      <td>2.5721</td>\n",
       "      <td>2.6877</td>\n",
       "      <td>2.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-23 01:00:00</th>\n",
       "      <td>2.5740</td>\n",
       "      <td>2.6016</td>\n",
       "      <td>2.5408</td>\n",
       "      <td>2.5673</td>\n",
       "      <td>4.397890e+07</td>\n",
       "      <td>2.57120</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0</td>\n",
       "      <td>2.623086</td>\n",
       "      <td>2.684497</td>\n",
       "      <td>...</td>\n",
       "      <td>2.641411</td>\n",
       "      <td>-0.027684</td>\n",
       "      <td>-0.033794</td>\n",
       "      <td>2.545115</td>\n",
       "      <td>0.138648</td>\n",
       "      <td>2.822412</td>\n",
       "      <td>2.267818</td>\n",
       "      <td>2.5740</td>\n",
       "      <td>2.5721</td>\n",
       "      <td>2.6877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close        volume    av_pr  \\\n",
       "datetime                                                                     \n",
       "2025-01-18 01:00:00  3.2923  3.2996  3.0580  3.2697  4.580889e+08  3.17880   \n",
       "2025-01-19 01:00:00  3.2697  3.2929  2.8277  2.9587  6.633288e+08  3.06030   \n",
       "2025-01-20 01:00:00  2.9586  3.3695  2.9090  3.1053  8.387613e+08  3.13925   \n",
       "2025-01-21 01:00:00  3.1053  3.2460  3.0124  3.1738  3.764235e+08  3.12920   \n",
       "2025-01-22 01:00:00  3.1739  3.2854  3.1237  3.1803  2.917613e+08  3.20455   \n",
       "2025-01-23 01:00:00  3.1802  3.1868  3.0374  3.1194  3.053148e+08  3.11210   \n",
       "2025-01-24 01:00:00  3.1194  3.2031  3.0550  3.1009  2.326270e+08  3.12905   \n",
       "2025-01-25 01:00:00  3.1008  3.1446  3.0784  3.1080  9.948986e+07  3.11150   \n",
       "2025-01-26 01:00:00  3.1079  3.1443  3.0115  3.0223  1.289378e+08  3.07790   \n",
       "2025-01-27 01:00:00  3.0222  3.0587  2.6559  3.0552  6.600562e+08  2.85730   \n",
       "2025-01-28 01:00:00  3.0552  3.2140  3.0062  3.0572  3.694708e+08  3.11010   \n",
       "2025-01-29 01:00:00  3.0572  3.1363  2.9673  3.0683  2.547567e+08  3.05180   \n",
       "2025-01-30 01:00:00  3.0683  3.1544  3.0466  3.1276  1.731433e+08  3.10050   \n",
       "2025-01-31 01:00:00  3.1276  3.1333  3.0030  3.0361  1.622353e+08  3.06815   \n",
       "2025-02-01 01:00:00  3.0361  3.0727  2.8281  2.8778  1.736014e+08  2.95040   \n",
       "2025-02-02 01:00:00  2.8779  2.9559  2.4603  2.5800  6.840890e+08  2.70810   \n",
       "2025-02-03 01:00:00  2.5801  2.7814  1.7711  2.7001  1.866759e+09  2.27625   \n",
       "2025-02-04 01:00:00  2.7000  2.7874  2.4209  2.5274  6.215530e+08  2.60415   \n",
       "2025-02-05 01:00:00  2.5275  2.5692  2.3384  2.3810  3.388151e+08  2.45380   \n",
       "2025-02-06 01:00:00  2.3810  2.4699  2.2772  2.3250  3.228969e+08  2.37355   \n",
       "2025-02-07 01:00:00  2.3251  2.5420  2.2655  2.3968  4.474879e+08  2.40375   \n",
       "2025-02-08 01:00:00  2.3969  2.4372  2.3506  2.4190  1.547172e+08  2.39390   \n",
       "2025-02-09 01:00:00  2.4190  2.5079  2.3113  2.3928  2.042056e+08  2.40960   \n",
       "2025-02-10 01:00:00  2.3928  2.4733  2.3235  2.4237  2.072579e+08  2.39840   \n",
       "2025-02-11 01:00:00  2.4238  2.5290  2.3708  2.4131  2.481822e+08  2.44990   \n",
       "2025-02-12 01:00:00  2.4130  2.4962  2.3323  2.4734  2.279576e+08  2.41425   \n",
       "2025-02-13 01:00:00  2.4734  2.6061  2.4154  2.5599  2.124787e+08  2.51075   \n",
       "2025-02-14 01:00:00  2.5600  2.8356  2.5300  2.7384  4.075411e+08  2.68280   \n",
       "2025-02-15 01:00:00  2.7384  2.8335  2.7130  2.7619  1.841819e+08  2.77325   \n",
       "2025-02-16 01:00:00  2.7619  2.8054  2.6879  2.7283  1.323880e+08  2.74665   \n",
       "2025-02-17 01:00:00  2.7283  2.7648  2.6075  2.6599  2.128134e+08  2.68615   \n",
       "2025-02-18 01:00:00  2.6599  2.6699  2.4693  2.5628  2.271700e+08  2.56960   \n",
       "2025-02-19 01:00:00  2.5629  2.7470  2.5121  2.7378  2.082441e+08  2.62955   \n",
       "2025-02-20 01:00:00  2.7378  2.7490  2.6671  2.6877  1.616046e+08  2.70805   \n",
       "2025-02-21 01:00:00  2.6878  2.7160  2.5076  2.5721  2.577774e+08  2.61180   \n",
       "2025-02-22 01:00:00  2.5722  2.6099  2.5505  2.5740  9.267673e+07  2.58020   \n",
       "2025-02-23 01:00:00  2.5740  2.6016  2.5408  2.5673  4.397890e+07  2.57120   \n",
       "\n",
       "                       diff  candle  7_day_SMA  30_day_SMA  ...  26_day_EMA  \\\n",
       "datetime                                                    ...               \n",
       "2025-01-18 01:00:00 -0.0226       0   2.949286    2.441173  ...    2.599338   \n",
       "2025-01-19 01:00:00 -0.3110       0   3.014157    2.463820  ...    2.625958   \n",
       "2025-01-20 01:00:00  0.1467       1   3.097314    2.492730  ...    2.661465   \n",
       "2025-01-21 01:00:00  0.0685       1   3.169671    2.525087  ...    2.699415   \n",
       "2025-01-22 01:00:00  0.0064       1   3.175014    2.555707  ...    2.735036   \n",
       "2025-01-23 01:00:00 -0.0608       0   3.157057    2.582227  ...    2.763508   \n",
       "2025-01-24 01:00:00 -0.0185       0   3.129729    2.609013  ...    2.788500   \n",
       "2025-01-25 01:00:00  0.0072       1   3.106629    2.640750  ...    2.812167   \n",
       "2025-01-26 01:00:00 -0.0856       0   3.115714    2.669940  ...    2.827732   \n",
       "2025-01-27 01:00:00  0.0330       1   3.108557    2.698970  ...    2.844581   \n",
       "2025-01-28 01:00:00  0.0020       1   3.091900    2.731070  ...    2.860331   \n",
       "2025-01-29 01:00:00  0.0111       1   3.075900    2.764723  ...    2.875736   \n",
       "2025-01-30 01:00:00  0.0593       1   3.077071    2.799523  ...    2.894393   \n",
       "2025-01-31 01:00:00 -0.0915       0   3.067814    2.822967  ...    2.904890   \n",
       "2025-02-01 01:00:00 -0.1583       0   3.034929    2.838813  ...    2.902883   \n",
       "2025-02-02 01:00:00 -0.2979       0   2.971743    2.842990  ...    2.878966   \n",
       "2025-02-03 01:00:00  0.1200       1   2.921014    2.852323  ...    2.865716   \n",
       "2025-02-04 01:00:00 -0.1726       0   2.845329    2.856590  ...    2.840656   \n",
       "2025-02-05 01:00:00 -0.1465       0   2.747143    2.855290  ...    2.806607   \n",
       "2025-02-06 01:00:00 -0.0560       0   2.632486    2.857083  ...    2.770933   \n",
       "2025-02-07 01:00:00  0.0717       1   2.541157    2.857873  ...    2.743219   \n",
       "2025-02-08 01:00:00  0.0221       1   2.475614    2.862767  ...    2.719203   \n",
       "2025-02-09 01:00:00 -0.0262       0   2.448871    2.864480  ...    2.695025   \n",
       "2025-02-10 01:00:00  0.0309       1   2.409386    2.859390  ...    2.674927   \n",
       "2025-02-11 01:00:00 -0.0107       0   2.393057    2.856340  ...    2.655532   \n",
       "2025-02-12 01:00:00  0.0604       1   2.406257    2.854680  ...    2.642041   \n",
       "2025-02-13 01:00:00  0.0865       1   2.439814    2.851100  ...    2.635956   \n",
       "2025-02-14 01:00:00  0.1784       1   2.488614    2.837617  ...    2.643545   \n",
       "2025-02-15 01:00:00  0.0235       1   2.537600    2.821510  ...    2.652312   \n",
       "2025-02-16 01:00:00 -0.0336       0   2.585529    2.802713  ...    2.657941   \n",
       "2025-02-17 01:00:00 -0.0684       0   2.619271    2.782387  ...    2.658086   \n",
       "2025-02-18 01:00:00 -0.0971       0   2.640657    2.769190  ...    2.651028   \n",
       "2025-02-19 01:00:00  0.1749       1   2.678429    2.756940  ...    2.657455   \n",
       "2025-02-20 01:00:00 -0.0501       0   2.696686    2.740737  ...    2.659696   \n",
       "2025-02-21 01:00:00 -0.1157       0   2.672929    2.720463  ...    2.653207   \n",
       "2025-02-22 01:00:00  0.0018       1   2.646086    2.702283  ...    2.647340   \n",
       "2025-02-23 01:00:00 -0.0067       0   2.623086    2.684497  ...    2.641411   \n",
       "\n",
       "                         MACD  Signal_Line  20_day_SMA  20_day_STD  \\\n",
       "datetime                                                             \n",
       "2025-01-18 01:00:00  0.235394     0.133276    2.552550    0.380010   \n",
       "2025-01-19 01:00:00  0.227846     0.152190    2.597550    0.371647   \n",
       "2025-01-20 01:00:00  0.231031     0.167958    2.648635    0.367480   \n",
       "2025-01-21 01:00:00  0.236358     0.181638    2.690685    0.377420   \n",
       "2025-01-22 01:00:00  0.238356     0.192982    2.729580    0.386130   \n",
       "2025-01-23 01:00:00  0.232348     0.200855    2.762815    0.389813   \n",
       "2025-01-24 01:00:00  0.223516     0.205387    2.796855    0.388032   \n",
       "2025-01-25 01:00:00  0.214616     0.207233    2.832285    0.382137   \n",
       "2025-01-26 01:00:00  0.198361     0.205459    2.862400    0.371521   \n",
       "2025-01-27 01:00:00  0.185990     0.201565    2.901600    0.346369   \n",
       "2025-01-28 01:00:00  0.174337     0.196119    2.935805    0.324520   \n",
       "2025-01-29 01:00:00  0.164106     0.189717    2.975610    0.285293   \n",
       "2025-01-30 01:00:00  0.158951     0.183563    3.014920    0.244564   \n",
       "2025-01-31 01:00:00  0.145801     0.176011    3.037905    0.221716   \n",
       "2025-02-01 01:00:00  0.121209     0.165051    3.056565    0.187540   \n",
       "2025-02-02 01:00:00  0.076804     0.147401    3.059405    0.179287   \n",
       "2025-02-03 01:00:00  0.050720     0.128065    3.061045    0.175624   \n",
       "2025-02-04 01:00:00  0.015929     0.105638    3.030270    0.210909   \n",
       "2025-02-05 01:00:00 -0.023190     0.079872    2.987065    0.249550   \n",
       "2025-02-06 01:00:00 -0.058041     0.052290    2.938705    0.279255   \n",
       "2025-02-07 01:00:00 -0.078957     0.026040    2.895060    0.292691   \n",
       "2025-02-08 01:00:00 -0.092673     0.002298    2.868075    0.310831   \n",
       "2025-02-09 01:00:00 -0.104454    -0.019053    2.832450    0.322811   \n",
       "2025-02-10 01:00:00 -0.110028    -0.037248    2.794945    0.324634   \n",
       "2025-02-11 01:00:00 -0.113987    -0.052596    2.756585    0.322020   \n",
       "2025-02-12 01:00:00 -0.110980    -0.064272    2.724285    0.316055   \n",
       "2025-02-13 01:00:00 -0.100458    -0.071510    2.697235    0.305087   \n",
       "2025-02-14 01:00:00 -0.076831    -0.072574    2.678755    0.289702   \n",
       "2025-02-15 01:00:00 -0.055570    -0.069173    2.665735    0.279107   \n",
       "2025-02-16 01:00:00 -0.040959    -0.063530    2.649390    0.264277   \n",
       "2025-02-17 01:00:00 -0.034501    -0.057724    2.629525    0.246332   \n",
       "2025-02-18 01:00:00 -0.036794    -0.053538    2.604250    0.223850   \n",
       "2025-02-19 01:00:00 -0.024212    -0.047673    2.584760    0.190347   \n",
       "2025-02-20 01:00:00 -0.018074    -0.041753    2.567340    0.160464   \n",
       "2025-02-21 01:00:00 -0.022281    -0.037859    2.552055    0.142938   \n",
       "2025-02-22 01:00:00 -0.025172    -0.035321    2.551755    0.142882   \n",
       "2025-02-23 01:00:00 -0.027684    -0.033794    2.545115    0.138648   \n",
       "\n",
       "                     Upper_Band  Lower_Band   lag_1   lag_2   lag_3  \n",
       "datetime                                                             \n",
       "2025-01-18 01:00:00    3.312570    1.792530  3.2922  3.2451  3.1429  \n",
       "2025-01-19 01:00:00    3.340844    1.854256  3.2697  3.2922  3.2451  \n",
       "2025-01-20 01:00:00    3.383594    1.913676  2.9587  3.2697  3.2922  \n",
       "2025-01-21 01:00:00    3.445524    1.935846  3.1053  2.9587  3.2697  \n",
       "2025-01-22 01:00:00    3.501839    1.957321  3.1738  3.1053  2.9587  \n",
       "2025-01-23 01:00:00    3.542442    1.983188  3.1803  3.1738  3.1053  \n",
       "2025-01-24 01:00:00    3.572919    2.020791  3.1194  3.1803  3.1738  \n",
       "2025-01-25 01:00:00    3.596559    2.068011  3.1009  3.1194  3.1803  \n",
       "2025-01-26 01:00:00    3.605442    2.119358  3.1080  3.1009  3.1194  \n",
       "2025-01-27 01:00:00    3.594337    2.208863  3.0223  3.1080  3.1009  \n",
       "2025-01-28 01:00:00    3.584845    2.286765  3.0552  3.0223  3.1080  \n",
       "2025-01-29 01:00:00    3.546195    2.405025  3.0572  3.0552  3.0223  \n",
       "2025-01-30 01:00:00    3.504048    2.525792  3.0683  3.0572  3.0552  \n",
       "2025-01-31 01:00:00    3.481337    2.594473  3.1276  3.0683  3.0572  \n",
       "2025-02-01 01:00:00    3.431646    2.681484  3.0361  3.1276  3.0683  \n",
       "2025-02-02 01:00:00    3.417979    2.700831  2.8778  3.0361  3.1276  \n",
       "2025-02-03 01:00:00    3.412293    2.709797  2.5800  2.8778  3.0361  \n",
       "2025-02-04 01:00:00    3.452087    2.608453  2.7001  2.5800  2.8778  \n",
       "2025-02-05 01:00:00    3.486166    2.487964  2.5274  2.7001  2.5800  \n",
       "2025-02-06 01:00:00    3.497215    2.380195  2.3810  2.5274  2.7001  \n",
       "2025-02-07 01:00:00    3.480441    2.309679  2.3250  2.3810  2.5274  \n",
       "2025-02-08 01:00:00    3.489738    2.246412  2.3968  2.3250  2.3810  \n",
       "2025-02-09 01:00:00    3.478072    2.186828  2.4190  2.3968  2.3250  \n",
       "2025-02-10 01:00:00    3.444213    2.145677  2.3928  2.4190  2.3968  \n",
       "2025-02-11 01:00:00    3.400624    2.112546  2.4237  2.3928  2.4190  \n",
       "2025-02-12 01:00:00    3.356396    2.092174  2.4131  2.4237  2.3928  \n",
       "2025-02-13 01:00:00    3.307408    2.087062  2.4734  2.4131  2.4237  \n",
       "2025-02-14 01:00:00    3.258159    2.099351  2.5599  2.4734  2.4131  \n",
       "2025-02-15 01:00:00    3.223949    2.107521  2.7384  2.5599  2.4734  \n",
       "2025-02-16 01:00:00    3.177944    2.120836  2.7619  2.7384  2.5599  \n",
       "2025-02-17 01:00:00    3.122190    2.136860  2.7283  2.7619  2.7384  \n",
       "2025-02-18 01:00:00    3.051949    2.156551  2.6599  2.7283  2.7619  \n",
       "2025-02-19 01:00:00    2.965454    2.204066  2.5628  2.6599  2.7283  \n",
       "2025-02-20 01:00:00    2.888269    2.246411  2.7378  2.5628  2.6599  \n",
       "2025-02-21 01:00:00    2.837930    2.266180  2.6877  2.7378  2.5628  \n",
       "2025-02-22 01:00:00    2.837519    2.265991  2.5721  2.6877  2.7378  \n",
       "2025-02-23 01:00:00    2.822412    2.267818  2.5740  2.5721  2.6877  \n",
       "\n",
       "[37 rows x 24 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3483d9d8-7307-4825-95d4-df92a268eca0",
       "rows": [
        [
         "2018-07-01 02:00:00",
         "0.46797",
         "0.46989",
         "0.45007",
         "0.46222",
         "31676174.10000002",
         "0.45998",
         "-0.0057499999999999",
         "0",
         "0.46192714285714287",
         "0.5532916666666666",
         "0.4672347548515338",
         "0.5316441532839548",
         "35.37081941712037",
         "0.4818625021717392",
         "0.5226332992019683",
         "-0.04077079703022912",
         "-0.03959813504052097",
         "0.5036595",
         "0.03874555247481883",
         "0.5811506049496377",
         "0.42616839505036236",
         "0.46796",
         "0.45321",
         "0.44575"
        ],
        [
         "2018-07-02 02:00:00",
         "0.46222",
         "0.4954",
         "0.452",
         "0.4899",
         "39873781.79999994",
         "0.4737",
         "0.0276799999999999",
         "1",
         "0.46316285714285715",
         "0.5481986666666666",
         "0.47290106613865035",
         "0.5289509821043448",
         "39.56015745336302",
         "0.48309904029916395",
         "0.5202086103721929",
         "-0.03710957007302895",
         "-0.03910042204702257",
         "0.5003744999999999",
         "0.03684878252291445",
         "0.5740720650458289",
         "0.426676934954171",
         "0.46222",
         "0.46796",
         "0.45321"
        ],
        [
         "2018-07-03 02:00:00",
         "0.48913",
         "0.52",
         "0.47801",
         "0.4844",
         "44333181.59999998",
         "0.499005",
         "-0.00473",
         "0",
         "0.46764857142857147",
         "0.541342",
         "0.47577579960398775",
         "0.5260767251943871",
         "36.07457095565815",
         "0.4832991879454464",
         "0.5175561207149935",
         "-0.034256932769547055",
         "-0.038131724191527466",
         "0.4981635",
         "0.036388567214818465",
         "0.5709406344296369",
         "0.425386365570363",
         "0.4899",
         "0.46222",
         "0.46796"
        ],
        [
         "2018-07-04 02:00:00",
         "0.48469",
         "0.508",
         "0.47941",
         "0.49097",
         "26722886.30000002",
         "0.493705",
         "0.00628",
         "1",
         "0.47063",
         "0.535872",
         "0.47957434970299084",
         "0.523811775181846",
         "39.38405956734371",
         "0.4844793128769162",
         "0.5155867784398087",
         "-0.03110746556289251",
         "-0.036726872465800475",
         "0.4948275000000001",
         "0.0335952635876891",
         "0.5620180271753783",
         "0.4276369728246219",
         "0.4844",
         "0.4899",
         "0.46222"
        ],
        [
         "2018-07-05 02:00:00",
         "0.49155",
         "0.50295",
         "0.46887",
         "0.4769",
         "30689285.9",
         "0.48591",
         "-0.0146499999999999",
         "0",
         "0.47508",
         "0.5292806666666666",
         "0.47890576227724313",
         "0.5207852090410817",
         "37.805032776485525",
         "0.483313264742006",
         "0.512721091147971",
         "-0.029407826405965065",
         "-0.035263063253833396",
         "0.49204349999999997",
         "0.03259425510811107",
         "0.5572320102162222",
         "0.42685498978377784",
         "0.49097",
         "0.4844",
         "0.4899"
        ],
        [
         "2018-07-06 02:00:00",
         "0.47772",
         "0.48156",
         "0.45747",
         "0.47698",
         "26805008.70000003",
         "0.469515",
         "-0.0007399999999999",
         "0",
         "0.4784757142857143",
         "0.52271",
         "0.4784243217079323",
         "0.5179590665223023",
         "48.59330871170976",
         "0.4823389163201589",
         "0.510073602914788",
         "-0.027734686594629077",
         "-0.03375738792199254",
         "0.489255",
         "0.03128788154507973",
         "0.5518307630901594",
         "0.42667923690984055",
         "0.4769",
         "0.49097",
         "0.4844"
        ],
        [
         "2018-07-07 02:00:00",
         "0.47644",
         "0.488",
         "0.46381",
         "0.48494",
         "28584029.19999998",
         "0.475905",
         "0.0085",
         "1",
         "0.48090142857142865",
         "0.5162893333333334",
         "0.4800532412809492",
         "0.5158288041660247",
         "48.61284543134806",
         "0.48273908304013446",
         "0.5082118545507296",
         "-0.025472771510595127",
         "-0.032100464639713056",
         "0.48719350000000006",
         "0.03006187080969747",
         "0.547317241619395",
         "0.4270697583806051",
         "0.47698",
         "0.4769",
         "0.49097"
        ],
        [
         "2018-07-08 02:00:00",
         "0.4852",
         "0.48798",
         "0.4751",
         "0.47915",
         "31480979.29999998",
         "0.48154",
         "-0.00605",
         "0",
         "0.48331999999999997",
         "0.5098576666666667",
         "0.4798274309607119",
         "0.5134624297037006",
         "51.68552297390903",
         "0.4821869164185753",
         "0.5060591245840089",
         "-0.023872208165433617",
         "-0.030454813344857168",
         "0.484216",
         "0.02753473756242417",
         "0.5392854751248484",
         "0.42914652487515165",
         "0.48494",
         "0.47698",
         "0.4769"
        ],
        [
         "2018-07-09 02:00:00",
         "0.47872",
         "0.48201",
         "0.47015",
         "0.473",
         "26690553.60000002",
         "0.47608",
         "-0.00572",
         "0",
         "0.4809057142857143",
         "0.503711",
         "0.4781205732205339",
         "0.510851950367978",
         "47.59405074365703",
         "0.4807735446618714",
         "0.5036103005407491",
         "-0.02283675587887768",
         "-0.028931201851661273",
         "0.480449",
         "0.02309611402721004",
         "0.5266412280544202",
         "0.43425677194557993",
         "0.47915",
         "0.48494",
         "0.47698"
        ],
        [
         "2018-07-10 02:00:00",
         "0.4728",
         "0.47338",
         "0.43866",
         "0.44337",
         "30651668.10000005",
         "0.45602",
         "-0.02943",
         "0",
         "0.4750442857142857",
         "0.49908966666666665",
         "0.4694329299154005",
         "0.5064982761506892",
         "47.21402534282241",
         "0.47501915317542964",
         "0.4991480560562491",
         "-0.02412890288081948",
         "-0.027970742057492917",
         "0.4756595",
         "0.020005609338382933",
         "0.5156707186767658",
         "0.43564828132323413",
         "0.473",
         "0.47915",
         "0.48494"
        ],
        [
         "2018-07-11 02:00:00",
         "0.44247",
         "0.45134",
         "0.43957",
         "0.44872",
         "28635928.19999998",
         "0.445455",
         "0.00625",
         "1",
         "0.4690085714285714",
         "0.49405066666666664",
         "0.46425469743655035",
         "0.5027706454312899",
         "43.36354606406754",
         "0.47097312960997895",
         "0.49541264449652694",
         "-0.024439514886547997",
         "-0.027264496623303935",
         "0.471367",
         "0.01537435017026378",
         "0.5021157003405275",
         "0.4406182996594724",
         "0.44337",
         "0.473",
         "0.47915"
        ],
        [
         "2018-07-12 02:00:00",
         "0.449",
         "0.44932",
         "0.4236",
         "0.43675",
         "30380599.49999994",
         "0.4364599999999999",
         "-0.0122499999999999",
         "0",
         "0.46327285714285715",
         "0.490089",
         "0.4573785230774128",
         "0.49851124895185184",
         "46.97377269670479",
         "0.4657080327469053",
         "0.4910672634227101",
         "-0.02535923067580481",
         "-0.026883443433804114",
         "0.4690965",
         "0.016967130227527882",
         "0.5030307604550558",
         "0.43516223954494426",
         "0.44872",
         "0.44337",
         "0.473"
        ],
        [
         "2018-07-13 02:00:00",
         "0.43706",
         "0.44509",
         "0.43001",
         "0.43754",
         "33168644.29999998",
         "0.43755",
         "0.0004799999999999",
         "1",
         "0.4576385714285714",
         "0.487053",
         "0.4524188923080596",
         "0.4945776199872163",
         "44.48355981130746",
         "0.46137448924738145",
         "0.4871022809469538",
         "-0.025727791699572344",
         "-0.02665231308695776",
         "0.466471",
         "0.017604851574136163",
         "0.5016807031482724",
         "0.4312612968517277",
         "0.43675",
         "0.44872",
         "0.44337"
        ],
        [
         "2018-07-14 02:00:00",
         "0.43761",
         "0.4443",
         "0.431",
         "0.43864",
         "27141582.29999995",
         "0.43765",
         "0.0010299999999999",
         "1",
         "0.4510242857142857",
         "0.48308466666666666",
         "0.44897416923104466",
         "0.4909687412783636",
         "38.580775821779085",
         "0.45787687551701506",
         "0.48351248235829053",
         "-0.02563560684127547",
         "-0.026448971837821304",
         "0.4647374999999999",
         "0.018576126975800123",
         "0.5018897539516002",
         "0.42758524604839965",
         "0.43754",
         "0.43675",
         "0.44872"
        ],
        [
         "2018-07-15 02:00:00",
         "0.43864",
         "0.45004",
         "0.43509",
         "0.44681",
         "33882949.8",
         "0.442565",
         "0.00817",
         "1",
         "0.44640428571428575",
         "0.48022566666666666",
         "0.44843312692328346",
         "0.4881197902281466",
         "44.109777539943416",
         "0.4561742792836281",
         "0.4807937799613801",
         "-0.024619500677752038",
         "-0.02608307760580745",
         "0.4630155",
         "0.018561142624480654",
         "0.5001377852489614",
         "0.4258932147510387",
         "0.43864",
         "0.43754",
         "0.43675"
        ],
        [
         "2018-07-16 02:00:00",
         "0.44695",
         "0.4858",
         "0.4435",
         "0.48173",
         "41419524.1",
         "0.46465",
         "0.0347799999999999",
         "1",
         "0.4476514285714286",
         "0.478525",
         "0.4567573451924626",
         "0.48770754569729846",
         "47.04092720028975",
         "0.46010592862460836",
         "0.4808631295938705",
         "-0.020757200969262146",
         "-0.02501790227849839",
         "0.464452",
         "0.018854646111767695",
         "0.5021612922235353",
         "0.4267427077764646",
         "0.44681",
         "0.43864",
         "0.43754"
        ],
        [
         "2018-07-17 02:00:00",
         "0.48173",
         "0.52019",
         "0.4665",
         "0.50728",
         "48166296.2000001",
         "0.493345",
         "0.0255499999999999",
         "1",
         "0.45678142857142856",
         "0.47789533333333334",
         "0.4693880088943469",
         "0.4889702846845696",
         "57.23592662871599",
         "0.4673634780669763",
         "0.4828199348091393",
         "-0.015456456742163005",
         "-0.023105613171231314",
         "0.466311",
         "0.02113574669655768",
         "0.5085824933931153",
         "0.4240395066068846",
         "0.48173",
         "0.44681",
         "0.43864"
        ],
        [
         "2018-07-18 02:00:00",
         "0.50651",
         "0.52525",
         "0.4752",
         "0.48868",
         "48747453.60000002",
         "0.500225",
         "-0.01783",
         "0",
         "0.46248999999999996",
         "0.476228",
         "0.47421100667076016",
         "0.48895155664040385",
         "49.32698524657614",
         "0.4706429429797492",
         "0.48325401371216603",
         "-0.012611070732416851",
         "-0.021006704683468422",
         "0.46845749999999997",
         "0.021117645621113717",
         "0.5106927912422274",
         "0.42622220875777256",
         "0.50728",
         "0.48173",
         "0.44681"
        ],
        [
         "2018-07-19 02:00:00",
         "0.48869",
         "0.495",
         "0.47125",
         "0.47687",
         "36600560.00000002",
         "0.483125",
         "-0.0118199999999999",
         "0",
         "0.4682214285714286",
         "0.47384566666666667",
         "0.4748757550030701",
         "0.48817210137328104",
         "49.99106451420743",
         "0.4716009517520955",
         "0.4827811238075611",
         "-0.01118017205546562",
         "-0.019041398157867862",
         "0.46964049999999996",
         "0.020879905090276228",
         "0.5114003101805524",
         "0.4278806898194475",
         "0.48868",
         "0.50728",
         "0.48173"
        ],
        [
         "2018-07-20 02:00:00",
         "0.47703",
         "0.4773",
         "0.431",
         "0.44439",
         "40745516.20000002",
         "0.45415",
         "-0.03264",
         "0",
         "0.46919999999999995",
         "0.47068666666666664",
         "0.46725431625230257",
         "0.48534744967177906",
         "41.86348429620011",
         "0.4674146514825423",
         "0.47993733685885287",
         "-0.012522685376310572",
         "-0.017737655601556403",
         "0.468462",
         "0.021631391322018835",
         "0.5117247826440376",
         "0.42519921735596233",
         "0.47687",
         "0.48868",
         "0.50728"
        ],
        [
         "2018-07-21 02:00:00",
         "0.4444",
         "0.459",
         "0.4346",
         "0.45506",
         "28483991.39999995",
         "0.4468",
         "0.01066",
         "1",
         "0.4715457142857143",
         "0.4680363333333333",
         "0.4642057371892269",
         "0.48339342066069657",
         "42.639668932899795",
         "0.46551393586984346",
         "0.4780945711656045",
         "-0.012580635295761033",
         "-0.01670625154039733",
         "0.46810399999999996",
         "0.021798735453425207",
         "0.5117014709068504",
         "0.42450652909314956",
         "0.44439",
         "0.47687",
         "0.48868"
        ],
        [
         "2018-07-22 02:00:00",
         "0.45467",
         "0.46409",
         "0.44589",
         "0.44859",
         "32232347.19999996",
         "0.45499",
         "-0.00608",
         "0",
         "0.4718",
         "0.46691733333333335",
         "0.4603018028919202",
         "0.48114803868258715",
         "42.49729942060296",
         "0.4629102534283291",
         "0.4759090473755597",
         "-0.012998793947230636",
         "-0.01596476002176399",
         "0.4660385000000001",
         "0.021580836107650225",
         "0.5092001722153006",
         "0.42287682778469965",
         "0.45506",
         "0.44439",
         "0.47687"
        ],
        [
         "2018-07-23 02:00:00",
         "0.44859",
         "0.46371",
         "0.44212",
         "0.44499",
         "30316389.90000007",
         "0.452915",
         "-0.0035999999999999",
         "0",
         "0.46655142857142856",
         "0.46541533333333335",
         "0.45647385216894015",
         "0.47881526199338803",
         "43.03614937099099",
         "0.4601532913624323",
         "0.4736187475699627",
         "-0.013465456207530369",
         "-0.015464899258917267",
         "0.464068",
         "0.02161524135760148",
         "0.507298482715203",
         "0.420837517284797",
         "0.44859",
         "0.45506",
         "0.44439"
        ],
        [
         "2018-07-24 02:00:00",
         "0.4452",
         "0.4715",
         "0.438",
         "0.45885",
         "43532211.20000008",
         "0.45475",
         "0.0136499999999999",
         "1",
         "0.4596328571428572",
         "0.4649333333333333",
         "0.4570678891267051",
         "0.47752718057445975",
         "54.17610877306572",
         "0.4599527849989812",
         "0.472524766268484",
         "-0.012571981269502819",
         "-0.014886315661034379",
         "0.46246199999999993",
         "0.02068444587250596",
         "0.5038308917450118",
         "0.421093108254988",
         "0.44499",
         "0.44859",
         "0.45506"
        ],
        [
         "2018-07-25 02:00:00",
         "0.45741",
         "0.46878",
         "0.45153",
         "0.4598",
         "42650288.40000004",
         "0.460155",
         "0.00239",
         "1",
         "0.45550714285714283",
         "0.4642183333333333",
         "0.45775091684502883",
         "0.4763834915051398",
         "53.06178843815629",
         "0.4599292796145225",
         "0.471582190989337",
         "-0.0116529113748145",
         "-0.014239634803790405",
         "0.46160700000000005",
         "0.020407802455252966",
         "0.5024226049105059",
         "0.4207913950894941",
         "0.45885",
         "0.44499",
         "0.44859"
        ],
        [
         "2018-07-26 02:00:00",
         "0.45983",
         "0.46887",
         "0.44538",
         "0.44968",
         "38041528.40000003",
         "0.457125",
         "-0.0101499999999999",
         "0",
         "0.4516228571428571",
         "0.4641076666666667",
         "0.45573318763377163",
         "0.4746606856015824",
         "53.60991680160813",
         "0.45835246736613444",
         "0.46995980647160834",
         "-0.011607339105473902",
         "-0.013713175664127105",
         "0.46024199999999993",
         "0.02023773094208459",
         "0.5007174618841691",
         "0.41976653811583076",
         "0.4598",
         "0.45885",
         "0.44499"
        ],
        [
         "2018-07-27 02:00:00",
         "0.44878",
         "0.462",
         "0.444",
         "0.4555",
         "35252979.79999998",
         "0.453",
         "0.00672",
         "1",
         "0.45321",
         "0.463621",
         "0.45567489072532874",
         "0.4734245123369642",
         "54.87725396480557",
         "0.457913626232883",
         "0.46888870969593366",
         "-0.01097508346305065",
         "-0.013165557223911814",
         "0.45877",
         "0.019400093597169706",
         "0.49757018719433943",
         "0.4199698128056606",
         "0.44968",
         "0.4598",
         "0.45885"
        ],
        [
         "2018-07-28 02:00:00",
         "0.4555",
         "0.45887",
         "0.44803",
         "0.45641",
         "27843347.29999995",
         "0.45345",
         "0.0009099999999999",
         "1",
         "0.45340285714285716",
         "0.4639763333333333",
         "0.45585866804399655",
         "0.47232680186361164",
         "54.83064209210026",
         "0.45768229912013175",
         "0.4679643608295682",
         "-0.010282061709436463",
         "-0.012588858121016745",
         "0.45763300000000007",
         "0.018799886365837924",
         "0.49523277273167593",
         "0.4200332272683242",
         "0.4555",
         "0.44968",
         "0.4598"
        ],
        [
         "2018-07-29 02:00:00",
         "0.45643",
         "0.45849",
         "0.45",
         "0.45315",
         "31188705.49999994",
         "0.454245",
         "-0.00328",
         "0",
         "0.4540542857142857",
         "0.4639743333333333",
         "0.45518150103299737",
         "0.47108958884015284",
         "51.770751871299304",
         "0.45698502233241917",
         "0.4668670007681187",
         "-0.009881978435699545",
         "-0.012047482183953306",
         "0.45664049999999995",
         "0.01846694100990079",
         "0.4935743820198015",
         "0.41970661798019837",
         "0.45641",
         "0.4555",
         "0.44968"
        ],
        [
         "2018-07-30 02:00:00",
         "0.45315",
         "0.45621",
         "0.43382",
         "0.44534",
         "32141597.89999998",
         "0.445015",
         "-0.0078099999999999",
         "0",
         "0.4541042857142857",
         "0.4632203333333333",
         "0.45272112577474805",
         "0.46942832504401394",
         "38.022513330261326",
         "0.4551934804351239",
         "0.46527240811862847",
         "-0.010078927683504546",
         "-0.011653771283863554",
         "0.45673899999999995",
         "0.0183975561592179",
         "0.49353411231843575",
         "0.41994388768156415",
         "0.45315",
         "0.45641",
         "0.4555"
        ],
        [
         "2018-07-31 02:00:00",
         "0.44616",
         "0.44641",
         "0.4268",
         "0.4353",
         "31785092.6",
         "0.436605",
         "-0.0108599999999999",
         "0",
         "0.45074000000000003",
         "0.46232299999999993",
         "0.448365844331061",
         "0.46722649762181956",
         "23.61436950146627",
         "0.4521329449835664",
         "0.4630522297394708",
         "-0.010919284755904424",
         "-0.01150687397827173",
         "0.456068",
         "0.018942090308705518",
         "0.49395218061741103",
         "0.4181838193825889",
         "0.44534",
         "0.45315",
         "0.45641"
        ],
        [
         "2018-08-01 02:00:00",
         "0.4353",
         "0.46382",
         "0.42671",
         "0.44642",
         "39833478.29999995",
         "0.445265",
         "0.0111199999999999",
         "1",
         "0.4488285714285714",
         "0.46087366666666674",
         "0.4478793832482958",
         "0.4658841429365409",
         "33.60999069190193",
         "0.45125403037071005",
         "0.4618202127217322",
         "-0.010566182351022135",
         "-0.01131873565282181",
         "0.45655150000000005",
         "0.018542236643318943",
         "0.49363597328663794",
         "0.41946702671336217",
         "0.4353",
         "0.44534",
         "0.45315"
        ],
        [
         "2018-08-02 02:00:00",
         "0.44673",
         "0.44888",
         "0.42849",
         "0.42975",
         "33396468.10000001",
         "0.438685",
         "-0.0169799999999999",
         "0",
         "0.44598142857142864",
         "0.45905199999999996",
         "0.4433470374362219",
         "0.463552907908377",
         "32.38899686051725",
         "0.4479457180059854",
         "0.45944464140901126",
         "-0.01149892340302583",
         "-0.011354773202862614",
         "0.45616199999999996",
         "0.019037809084472918",
         "0.4942376181689458",
         "0.4180863818310541",
         "0.44642",
         "0.4353",
         "0.44534"
        ],
        [
         "2018-08-03 02:00:00",
         "0.43021",
         "0.44619",
         "0.4253",
         "0.44033",
         "44748261.19999998",
         "0.435745",
         "0.01012",
         "1",
         "0.4438142857142857",
         "0.457364",
         "0.44259277807716646",
         "0.4620546557852559",
         "48.185555952806574",
         "0.4467740690819877",
         "0.4580287420453808",
         "-0.011254672963393109",
         "-0.011334753154968714",
         "0.45624650000000005",
         "0.01895953343724186",
         "0.49416556687448376",
         "0.41832743312551635",
         "0.42975",
         "0.44642",
         "0.4353"
        ],
        [
         "2018-08-04 02:00:00",
         "0.44097",
         "0.445",
         "0.42741",
         "0.42985",
         "35095397.49999999",
         "0.436205",
         "-0.0111199999999999",
         "0",
         "0.44002",
         "0.4557956666666667",
         "0.43940708355787483",
         "0.4599769360571749",
         "38.71429850479002",
         "0.44417036614629724",
         "0.455941427819797",
         "-0.011771061673499783",
         "-0.01142201485867493",
         "0.4553985",
         "0.019765946067602378",
         "0.49493039213520473",
         "0.41586660786479523",
         "0.44033",
         "0.42975",
         "0.44642"
        ],
        [
         "2018-08-05 02:00:00",
         "0.42984",
         "0.43705",
         "0.42705",
         "0.4345",
         "34962084.2",
         "0.43205",
         "0.0046599999999999",
         "1",
         "0.4373557142857143",
         "0.4543796666666667",
         "0.43818031266840607",
         "0.45833326276316366",
         "43.58787658141439",
         "0.4426826175084053",
         "0.45435317390721947",
         "-0.011670556398814147",
         "-0.011471723166702773",
         "0.453037",
         "0.01926959101524301",
         "0.49157618203048603",
         "0.414497817969514",
         "0.42985",
         "0.44033",
         "0.42975"
        ],
        [
         "2018-08-06 02:00:00",
         "0.43437",
         "0.43699",
         "0.40127",
         "0.4129",
         "40578992.90000006",
         "0.41913",
         "-0.0214699999999999",
         "0",
         "0.4327214285714286",
         "0.45197833333333326",
         "0.43186023450130456",
         "0.4554020845203789",
         "37.45209978884802",
         "0.438100676353266",
         "0.4512825684326106",
         "-0.013181892079344615",
         "-0.011813756949231142",
         "0.448318",
         "0.01666752613222546",
         "0.48165305226445093",
         "0.41498294773554906",
         "0.4345",
         "0.42985",
         "0.44033"
        ],
        [
         "2018-08-07 02:00:00",
         "0.41328",
         "0.41567",
         "0.37387",
         "0.37863",
         "41157252.55999998",
         "0.3947699999999999",
         "-0.0346499999999999",
         "0",
         "0.4246257142857143",
         "0.4486276666666667",
         "0.41855267587597844",
         "0.45044904680938674",
         "22.94982465605608",
         "0.4289513415296866",
         "0.44590089669686167",
         "-0.016949555167175057",
         "-0.012840916592819926",
         "0.44281550000000003",
         "0.020391043305953236",
         "0.4835975866119065",
         "0.40203341338809356",
         "0.4129",
         "0.4345",
         "0.42985"
        ],
        [
         "2018-08-08 02:00:00",
         "0.37863",
         "0.37863",
         "0.31928",
         "0.33171",
         "72393008.14999995",
         "0.348955",
         "-0.04692",
         "0",
         "0.40823857142857145",
         "0.443918",
         "0.39684200690698385",
         "0.442788463144265",
         "17.029601029600997",
         "0.41399113514050406",
         "0.4374423117563534",
         "-0.023451176615849334",
         "-0.014962968597425809",
         "0.4355575",
         "0.03080605731191936",
         "0.4971696146238387",
         "0.3739453853761613",
         "0.37863",
         "0.4129",
         "0.4345"
        ],
        [
         "2018-08-09 02:00:00",
         "0.33197",
         "0.35799",
         "0.328",
         "0.3441",
         "51832840.70000008",
         "0.342995",
         "0.01213",
         "1",
         "0.39600285714285716",
         "0.44060900000000003",
         "0.3836565051802379",
         "0.4364214655220544",
         "23.13759413800119",
         "0.40323865281119575",
         "0.43052806644106795",
         "-0.027289413629872195",
         "-0.017428257603915087",
         "0.430543",
         "0.03686019620417833",
         "0.5042633924083567",
         "0.35682260759164336",
         "0.33171",
         "0.37863",
         "0.4129"
        ],
        [
         "2018-08-10 02:00:00",
         "0.3441",
         "0.34689",
         "0.31236",
         "0.31897",
         "39269097.20000007",
         "0.329625",
         "-0.02513",
         "0",
         "0.37866571428571427",
         "0.436284",
         "0.36748487888517845",
         "0.4288439516174058",
         "18.370940091738845",
         "0.3902742446863964",
         "0.4222645059639518",
         "-0.03199026127755544",
         "-0.02034065833864316",
         "0.4237385000000001",
         "0.04397142245104674",
         "0.5116813449020936",
         "0.3357956550979066",
         "0.3441",
         "0.33171",
         "0.37863"
        ],
        [
         "2018-08-11 02:00:00",
         "0.31897",
         "0.32008",
         "0.2874",
         "0.29784",
         "48724318.70000006",
         "0.30374",
         "-0.0211299999999999",
         "0",
         "0.3598071428571429",
         "0.43165366666666666",
         "0.3500736591638838",
         "0.4203920837711215",
         "16.411777165854673",
         "0.37605359165772",
         "0.413047875892548",
         "-0.03699428423482798",
         "-0.023671383517880125",
         "0.41620099999999993",
         "0.051724366130276964",
         "0.5196497322605539",
         "0.312752267739446",
         "0.31897",
         "0.3441",
         "0.33171"
        ],
        [
         "2018-08-12 02:00:00",
         "0.29708",
         "0.30938",
         "0.29401",
         "0.29547",
         "35382260.6",
         "0.301695",
         "-0.00161",
         "0",
         "0.3399457142857143",
         "0.42691799999999996",
         "0.33642274437291286",
         "0.41233259449556536",
         "16.473890117366892",
         "0.36365611601807074",
         "0.4043384036042111",
         "-0.04068228758614034",
         "-0.02707356433153217",
         "0.408725",
         "0.0577937108670958",
         "0.5243124217341916",
         "0.2931375782658084",
         "0.29784",
         "0.31897",
         "0.3441"
        ],
        [
         "2018-08-13 02:00:00",
         "0.29575",
         "0.309",
         "0.27127",
         "0.2743",
         "43767335.33999998",
         "0.290135",
         "-0.02145",
         "0",
         "0.32014571428571426",
         "0.42144",
         "0.32089205827968464",
         "0.40342726581843213",
         "15.588282633188456",
         "0.3499090212460599",
         "0.3947059292631584",
         "-0.04479690801709851",
         "-0.030618233068645445",
         "0.3994975",
         "0.06379109704215861",
         "0.5270796940843172",
         "0.2719153059156828",
         "0.29547",
         "0.29784",
         "0.31897"
        ],
        [
         "2018-08-14 02:00:00",
         "0.2743",
         "0.27732",
         "0.24672",
         "0.2725",
         "56101898.99999996",
         "0.26202",
         "-0.0017999999999999",
         "0",
         "0.3049842857142857",
         "0.4156296666666667",
         "0.3087940437097635",
         "0.39498034544304944",
         "16.122856667221555",
         "0.3379999410543584",
         "0.3856536382066282",
         "-0.0476536971522698",
         "-0.034025325885370314",
         "0.3901325",
         "0.06807684751150903",
         "0.526286195023018",
         "0.25397880497698194",
         "0.2743",
         "0.29547",
         "0.29784"
        ],
        [
         "2018-08-15 02:00:00",
         "0.2728",
         "0.30234",
         "0.2728",
         "0.28039",
         "72676585.19999997",
         "0.28757",
         "0.0075899999999999",
         "1",
         "0.2976528571428571",
         "0.40891833333333333",
         "0.3016930327823226",
         "0.3875874199305947",
         "14.979962033326288",
         "0.3291368731998417",
         "0.37785633167280386",
         "-0.04871945847296216",
         "-0.03696415240288868",
         "0.381668",
         "0.07075504167269814",
         "0.5231780833453963",
         "0.24015791665460373",
         "0.2725",
         "0.2743",
         "0.29547"
        ],
        [
         "2018-08-16 02:00:00",
         "0.28",
         "0.30184",
         "0.2755",
         "0.29142",
         "46325561.50000004",
         "0.28867",
         "0.0114199999999999",
         "1",
         "0.29012714285714286",
         "0.401723",
         "0.29912477458674197",
         "0.3813830702576531",
         "20.111490428244224",
         "0.323334277322943",
         "0.37145364043778134",
         "-0.04811936311483833",
         "-0.03919519454527862",
         "0.373464",
         "0.07125442460130559",
         "0.5159728492026112",
         "0.23095515079738885",
         "0.28039",
         "0.2725",
         "0.2743"
        ],
        [
         "2018-08-17 02:00:00",
         "0.29161",
         "0.37506",
         "0.29085",
         "0.3672",
         "84683658.1",
         "0.332955",
         "0.07559",
         "1",
         "0.29701714285714287",
         "0.3976736666666667",
         "0.31614358094005646",
         "0.38046803346683683",
         "37.67236438420823",
         "0.3300828500424903",
         "0.37113855596090867",
         "-0.041055705918418395",
         "-0.039567296819906575",
         "0.36900350000000004",
         "0.06852888175414559",
         "0.5060612635082913",
         "0.23194573649170885",
         "0.29142",
         "0.28039",
         "0.2725"
        ],
        [
         "2018-08-18 02:00:00",
         "0.36721",
         "0.37",
         "0.31039",
         "0.32829",
         "80106581.6000001",
         "0.340195",
         "-0.0389199999999999",
         "0",
         "0.3013671428571429",
         "0.392721",
         "0.31918018570504236",
         "0.3771017087270409",
         "34.377307408318984",
         "0.32980702695903025",
         "0.36796458885269323",
         "-0.03815756189366298",
         "-0.039285349834657854",
         "0.36276050000000004",
         "0.06610414418691306",
         "0.4949687883738262",
         "0.23055221162617393",
         "0.3672",
         "0.29142",
         "0.28039"
        ],
        [
         "2018-08-19 02:00:00",
         "0.32848",
         "0.35281",
         "0.316",
         "0.34201",
         "63806323.29999998",
         "0.334405",
         "0.0135299999999999",
         "1",
         "0.3080157142857143",
         "0.3893083333333333",
         "0.3248876392787818",
         "0.37483772751884475",
         "36.15875011223848",
         "0.3316844074268717",
         "0.3660420267154567",
         "-0.034357619288584995",
         "-0.03829980372544328",
         "0.357594",
         "0.06328829387060936",
         "0.48417058774121874",
         "0.2310174122587813",
         "0.32829",
         "0.3672",
         "0.29142"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 2428
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>30_day_SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>26_day_EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-01 02:00:00</th>\n",
       "      <td>0.46797</td>\n",
       "      <td>0.46989</td>\n",
       "      <td>0.45007</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>31676174.1</td>\n",
       "      <td>0.459980</td>\n",
       "      <td>-0.00575</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461927</td>\n",
       "      <td>0.553292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522633</td>\n",
       "      <td>-0.040771</td>\n",
       "      <td>-0.039598</td>\n",
       "      <td>0.503660</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.581151</td>\n",
       "      <td>0.426168</td>\n",
       "      <td>0.46796</td>\n",
       "      <td>0.45321</td>\n",
       "      <td>0.44575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-02 02:00:00</th>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.49540</td>\n",
       "      <td>0.45200</td>\n",
       "      <td>0.48990</td>\n",
       "      <td>39873781.8</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>0.02768</td>\n",
       "      <td>1</td>\n",
       "      <td>0.463163</td>\n",
       "      <td>0.548199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520209</td>\n",
       "      <td>-0.037110</td>\n",
       "      <td>-0.039100</td>\n",
       "      <td>0.500374</td>\n",
       "      <td>0.036849</td>\n",
       "      <td>0.574072</td>\n",
       "      <td>0.426677</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.46796</td>\n",
       "      <td>0.45321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-03 02:00:00</th>\n",
       "      <td>0.48913</td>\n",
       "      <td>0.52000</td>\n",
       "      <td>0.47801</td>\n",
       "      <td>0.48440</td>\n",
       "      <td>44333181.6</td>\n",
       "      <td>0.499005</td>\n",
       "      <td>-0.00473</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467649</td>\n",
       "      <td>0.541342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517556</td>\n",
       "      <td>-0.034257</td>\n",
       "      <td>-0.038132</td>\n",
       "      <td>0.498163</td>\n",
       "      <td>0.036389</td>\n",
       "      <td>0.570941</td>\n",
       "      <td>0.425386</td>\n",
       "      <td>0.48990</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.46796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04 02:00:00</th>\n",
       "      <td>0.48469</td>\n",
       "      <td>0.50800</td>\n",
       "      <td>0.47941</td>\n",
       "      <td>0.49097</td>\n",
       "      <td>26722886.3</td>\n",
       "      <td>0.493705</td>\n",
       "      <td>0.00628</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470630</td>\n",
       "      <td>0.535872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515587</td>\n",
       "      <td>-0.031107</td>\n",
       "      <td>-0.036727</td>\n",
       "      <td>0.494828</td>\n",
       "      <td>0.033595</td>\n",
       "      <td>0.562018</td>\n",
       "      <td>0.427637</td>\n",
       "      <td>0.48440</td>\n",
       "      <td>0.48990</td>\n",
       "      <td>0.46222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05 02:00:00</th>\n",
       "      <td>0.49155</td>\n",
       "      <td>0.50295</td>\n",
       "      <td>0.46887</td>\n",
       "      <td>0.47690</td>\n",
       "      <td>30689285.9</td>\n",
       "      <td>0.485910</td>\n",
       "      <td>-0.01465</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475080</td>\n",
       "      <td>0.529281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512721</td>\n",
       "      <td>-0.029408</td>\n",
       "      <td>-0.035263</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.032594</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.426855</td>\n",
       "      <td>0.49097</td>\n",
       "      <td>0.48440</td>\n",
       "      <td>0.48990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-17 01:00:00</th>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76480</td>\n",
       "      <td>2.60750</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>212813356.0</td>\n",
       "      <td>2.686150</td>\n",
       "      <td>-0.06840</td>\n",
       "      <td>0</td>\n",
       "      <td>2.619271</td>\n",
       "      <td>2.782387</td>\n",
       "      <td>...</td>\n",
       "      <td>2.656563</td>\n",
       "      <td>-0.032975</td>\n",
       "      <td>-0.055473</td>\n",
       "      <td>2.629525</td>\n",
       "      <td>0.246332</td>\n",
       "      <td>3.122190</td>\n",
       "      <td>2.136860</td>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76190</td>\n",
       "      <td>2.73840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-18 01:00:00</th>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.66990</td>\n",
       "      <td>2.46930</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>227170019.0</td>\n",
       "      <td>2.569600</td>\n",
       "      <td>-0.09710</td>\n",
       "      <td>0</td>\n",
       "      <td>2.640657</td>\n",
       "      <td>2.769190</td>\n",
       "      <td>...</td>\n",
       "      <td>2.649618</td>\n",
       "      <td>-0.035382</td>\n",
       "      <td>-0.051455</td>\n",
       "      <td>2.604250</td>\n",
       "      <td>0.223850</td>\n",
       "      <td>3.051949</td>\n",
       "      <td>2.156551</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 01:00:00</th>\n",
       "      <td>2.56290</td>\n",
       "      <td>2.74700</td>\n",
       "      <td>2.51210</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>208577133.0</td>\n",
       "      <td>2.629550</td>\n",
       "      <td>0.17490</td>\n",
       "      <td>1</td>\n",
       "      <td>2.678429</td>\n",
       "      <td>2.756940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.656150</td>\n",
       "      <td>-0.022904</td>\n",
       "      <td>-0.045745</td>\n",
       "      <td>2.584760</td>\n",
       "      <td>0.190347</td>\n",
       "      <td>2.965454</td>\n",
       "      <td>2.204066</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.72830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-20 01:00:00</th>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.74900</td>\n",
       "      <td>2.66710</td>\n",
       "      <td>2.68770</td>\n",
       "      <td>161604635.0</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>-0.05010</td>\n",
       "      <td>0</td>\n",
       "      <td>2.696686</td>\n",
       "      <td>2.740737</td>\n",
       "      <td>...</td>\n",
       "      <td>2.658487</td>\n",
       "      <td>-0.016864</td>\n",
       "      <td>-0.039969</td>\n",
       "      <td>2.567340</td>\n",
       "      <td>0.160464</td>\n",
       "      <td>2.888269</td>\n",
       "      <td>2.246411</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>2.65990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 01:00:00</th>\n",
       "      <td>2.68780</td>\n",
       "      <td>2.71600</td>\n",
       "      <td>2.50760</td>\n",
       "      <td>2.54120</td>\n",
       "      <td>227097007.0</td>\n",
       "      <td>2.611800</td>\n",
       "      <td>-0.14660</td>\n",
       "      <td>0</td>\n",
       "      <td>2.668514</td>\n",
       "      <td>2.719433</td>\n",
       "      <td>...</td>\n",
       "      <td>2.649799</td>\n",
       "      <td>-0.023625</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>2.550510</td>\n",
       "      <td>0.142876</td>\n",
       "      <td>2.836263</td>\n",
       "      <td>2.264757</td>\n",
       "      <td>2.68770</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.56280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2428 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close       volume  \\\n",
       "datetime                                                               \n",
       "2018-07-01 02:00:00  0.46797  0.46989  0.45007  0.46222   31676174.1   \n",
       "2018-07-02 02:00:00  0.46222  0.49540  0.45200  0.48990   39873781.8   \n",
       "2018-07-03 02:00:00  0.48913  0.52000  0.47801  0.48440   44333181.6   \n",
       "2018-07-04 02:00:00  0.48469  0.50800  0.47941  0.49097   26722886.3   \n",
       "2018-07-05 02:00:00  0.49155  0.50295  0.46887  0.47690   30689285.9   \n",
       "...                      ...      ...      ...      ...          ...   \n",
       "2025-02-17 01:00:00  2.72830  2.76480  2.60750  2.65990  212813356.0   \n",
       "2025-02-18 01:00:00  2.65990  2.66990  2.46930  2.56280  227170019.0   \n",
       "2025-02-19 01:00:00  2.56290  2.74700  2.51210  2.73780  208577133.0   \n",
       "2025-02-20 01:00:00  2.73780  2.74900  2.66710  2.68770  161604635.0   \n",
       "2025-02-21 01:00:00  2.68780  2.71600  2.50760  2.54120  227097007.0   \n",
       "\n",
       "                        av_pr     diff  candle  7_day_SMA  30_day_SMA  ...  \\\n",
       "datetime                                                               ...   \n",
       "2018-07-01 02:00:00  0.459980 -0.00575       0   0.461927    0.553292  ...   \n",
       "2018-07-02 02:00:00  0.473700  0.02768       1   0.463163    0.548199  ...   \n",
       "2018-07-03 02:00:00  0.499005 -0.00473       0   0.467649    0.541342  ...   \n",
       "2018-07-04 02:00:00  0.493705  0.00628       1   0.470630    0.535872  ...   \n",
       "2018-07-05 02:00:00  0.485910 -0.01465       0   0.475080    0.529281  ...   \n",
       "...                       ...      ...     ...        ...         ...  ...   \n",
       "2025-02-17 01:00:00  2.686150 -0.06840       0   2.619271    2.782387  ...   \n",
       "2025-02-18 01:00:00  2.569600 -0.09710       0   2.640657    2.769190  ...   \n",
       "2025-02-19 01:00:00  2.629550  0.17490       1   2.678429    2.756940  ...   \n",
       "2025-02-20 01:00:00  2.708050 -0.05010       0   2.696686    2.740737  ...   \n",
       "2025-02-21 01:00:00  2.611800 -0.14660       0   2.668514    2.719433  ...   \n",
       "\n",
       "                     26_day_EMA      MACD  Signal_Line  20_day_SMA  \\\n",
       "datetime                                                             \n",
       "2018-07-01 02:00:00    0.522633 -0.040771    -0.039598    0.503660   \n",
       "2018-07-02 02:00:00    0.520209 -0.037110    -0.039100    0.500374   \n",
       "2018-07-03 02:00:00    0.517556 -0.034257    -0.038132    0.498163   \n",
       "2018-07-04 02:00:00    0.515587 -0.031107    -0.036727    0.494828   \n",
       "2018-07-05 02:00:00    0.512721 -0.029408    -0.035263    0.492043   \n",
       "...                         ...       ...          ...         ...   \n",
       "2025-02-17 01:00:00    2.656563 -0.032975    -0.055473    2.629525   \n",
       "2025-02-18 01:00:00    2.649618 -0.035382    -0.051455    2.604250   \n",
       "2025-02-19 01:00:00    2.656150 -0.022904    -0.045745    2.584760   \n",
       "2025-02-20 01:00:00    2.658487 -0.016864    -0.039969    2.567340   \n",
       "2025-02-21 01:00:00    2.649799 -0.023625    -0.036700    2.550510   \n",
       "\n",
       "                     20_day_STD  Upper_Band  Lower_Band    lag_1    lag_2  \\\n",
       "datetime                                                                    \n",
       "2018-07-01 02:00:00    0.038746    0.581151    0.426168  0.46796  0.45321   \n",
       "2018-07-02 02:00:00    0.036849    0.574072    0.426677  0.46222  0.46796   \n",
       "2018-07-03 02:00:00    0.036389    0.570941    0.425386  0.48990  0.46222   \n",
       "2018-07-04 02:00:00    0.033595    0.562018    0.427637  0.48440  0.48990   \n",
       "2018-07-05 02:00:00    0.032594    0.557232    0.426855  0.49097  0.48440   \n",
       "...                         ...         ...         ...      ...      ...   \n",
       "2025-02-17 01:00:00    0.246332    3.122190    2.136860  2.72830  2.76190   \n",
       "2025-02-18 01:00:00    0.223850    3.051949    2.156551  2.65990  2.72830   \n",
       "2025-02-19 01:00:00    0.190347    2.965454    2.204066  2.56280  2.65990   \n",
       "2025-02-20 01:00:00    0.160464    2.888269    2.246411  2.73780  2.56280   \n",
       "2025-02-21 01:00:00    0.142876    2.836263    2.264757  2.68770  2.73780   \n",
       "\n",
       "                       lag_3  \n",
       "datetime                      \n",
       "2018-07-01 02:00:00  0.44575  \n",
       "2018-07-02 02:00:00  0.45321  \n",
       "2018-07-03 02:00:00  0.46796  \n",
       "2018-07-04 02:00:00  0.46222  \n",
       "2018-07-05 02:00:00  0.48990  \n",
       "...                      ...  \n",
       "2025-02-17 01:00:00  2.73840  \n",
       "2025-02-18 01:00:00  2.76190  \n",
       "2025-02-19 01:00:00  2.72830  \n",
       "2025-02-20 01:00:00  2.65990  \n",
       "2025-02-21 01:00:00  2.56280  \n",
       "\n",
       "[2428 rows x 24 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_time_series(data, target_column, window_size=30):\n",
    "    \"\"\"\n",
    "    Preprocesses time series data for XGBoost by creating rolling windows.\n",
    "\n",
    "    Parameters:\n",
    "    - data: Pandas DataFrame containing the time series features.\n",
    "    - target_column: String, the column name of the target variable.\n",
    "    - window_size: Number of past days to use as input features.\n",
    "\n",
    "    Returns:\n",
    "    - X: Numpy array of shape (num_samples, window_size * num_features)\n",
    "    - y: Numpy array of target values\n",
    "    - scaler: StandardScaler fitted on features\n",
    "    \"\"\"\n",
    "\n",
    "    data = data.copy()  # Avoid modifying the original dataframe\n",
    "\n",
    "    # Drop non-numeric columns (e.g., DateTime)\n",
    "    non_numeric_cols = data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    if non_numeric_cols:\n",
    "        print(f\"Dropping non-numeric columns: {non_numeric_cols}\")\n",
    "        data = data.drop(columns=non_numeric_cols)\n",
    "\n",
    "    # Ensure target column is numeric\n",
    "    data[target_column] = pd.to_numeric(data[target_column], errors='coerce')\n",
    "\n",
    "    # Drop rows with missing values after conversion\n",
    "    data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Extract target and features\n",
    "    target = data[target_column].values\n",
    "    features = data.drop(columns=[target_column]).values\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    # Create rolling window dataset\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(features[i:i+window_size].flatten())  # Flatten 2D window into 1D\n",
    "        y.append(target[i+window_size])  # Next day's target\n",
    "\n",
    "    return np.array(X), np.array(y), scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_feature_matrix, your_target_values, scaler = preprocess_time_series(df, 'close', window_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboostNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from xgboost) (1.15.2)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.6/124.9 MB 7.6 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 3.1/124.9 MB 8.0 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 5.0/124.9 MB 8.1 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 6.3/124.9 MB 7.3 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 7.9/124.9 MB 7.5 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 10.0/124.9 MB 7.9 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 11.8/124.9 MB 7.9 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 13.4/124.9 MB 7.9 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 15.2/124.9 MB 8.0 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 16.8/124.9 MB 8.0 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 18.6/124.9 MB 8.0 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 20.4/124.9 MB 8.1 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 22.3/124.9 MB 8.1 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 23.6/124.9 MB 8.0 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 25.4/124.9 MB 8.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 27.5/124.9 MB 8.2 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 29.1/124.9 MB 8.2 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 30.9/124.9 MB 8.1 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 32.5/124.9 MB 8.1 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 33.6/124.9 MB 7.9 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 34.6/124.9 MB 7.9 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 7.8 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 37.5/124.9 MB 7.7 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 38.8/124.9 MB 7.7 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 40.6/124.9 MB 7.7 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 42.5/124.9 MB 7.7 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 44.0/124.9 MB 7.7 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 45.9/124.9 MB 7.7 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 47.7/124.9 MB 7.8 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 49.3/124.9 MB 7.7 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 51.4/124.9 MB 7.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 52.7/124.9 MB 7.8 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 54.8/124.9 MB 7.8 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 56.6/124.9 MB 7.8 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 58.7/124.9 MB 7.9 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 60.6/124.9 MB 7.9 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 62.4/124.9 MB 7.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 64.2/124.9 MB 8.0 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 66.3/124.9 MB 8.0 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 68.2/124.9 MB 8.0 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 70.3/124.9 MB 8.0 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 71.8/124.9 MB 8.1 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 73.7/124.9 MB 8.0 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 75.5/124.9 MB 8.1 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 76.5/124.9 MB 8.1 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 77.6/124.9 MB 7.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 79.2/124.9 MB 7.9 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 81.3/124.9 MB 8.0 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 82.6/124.9 MB 8.0 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 83.9/124.9 MB 7.9 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 86.2/124.9 MB 8.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 88.3/124.9 MB 8.0 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 90.7/124.9 MB 8.0 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 92.3/124.9 MB 8.1 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 94.1/124.9 MB 8.1 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 95.9/124.9 MB 8.1 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 98.0/124.9 MB 8.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 100.4/124.9 MB 8.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 102.0/124.9 MB 8.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 103.8/124.9 MB 8.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 105.9/124.9 MB 8.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 107.7/124.9 MB 8.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 109.3/124.9 MB 8.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 110.6/124.9 MB 8.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 111.9/124.9 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 113.2/124.9 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 114.6/124.9 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 116.1/124.9 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 118.0/124.9 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 119.5/124.9 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 121.4/124.9 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  122.9/124.9 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.8/124.9 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.8/124.9 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 124.9/124.9 MB 7.9 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MAE: 0.32080237106266335\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load your time series dataset (assume X and y are preprocessed)\n",
    "X, y = your_feature_matrix, your_target_values  # X shape: (num_samples, 30 * num_features)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Define XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "\n",
    "# Train model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'XGBoost MAE: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">148,992</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_21 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m10,304\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_12 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   │         \u001b[38;5;34m148,992\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    │          \u001b[38;5;34m16,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_48 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)                    │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,481</span> (705.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m180,481\u001b[0m (705.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,289</span> (704.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m180,289\u001b[0m (704.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, BatchNormalization, ReLU, MaxPooling1D, \n",
    "    Bidirectional, GRU, Dropout, Dense\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define model parameters\n",
    "num_features = 23  # Adjusted to 26 features (OHLC, volume, indicators, etc.)\n",
    "seq_length = 30    # 30 days input\n",
    "batch_size = 32    # Fixed batch size for stateful RNN\n",
    "rnn_units = 128\n",
    "cnn_filters = [32, 64]\n",
    "kernel_sizes = [3, 5]\n",
    "dropout_rate = 0.3\n",
    "recurrent_dropout_rate = 0.2  # Prevents overfitting in GRU\n",
    "\n",
    "def build_rnn_cnn_hybrid_model():\n",
    "    inputs = Input(batch_shape=(batch_size, seq_length, num_features))  # Fixed batch size for stateful=True\n",
    "\n",
    "    # CNN Feature Extraction\n",
    "    x = Conv1D(filters=cnn_filters[0], kernel_size=kernel_sizes[0], padding=\"same\", activation=None)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv1D(filters=cnn_filters[1], kernel_size=kernel_sizes[1], padding=\"valid\", activation=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = MaxPooling1D(pool_size=2, strides=2)(x)  # Adjusted pooling for better feature reduction\n",
    "\n",
    "    # Bidirectional GRU Layer\n",
    "    x = Bidirectional(GRU(rnn_units, return_sequences=False, stateful=True, recurrent_dropout=recurrent_dropout_rate))(x)\n",
    "    x = Dropout(dropout_rate)(x)  # Dropout for regularization\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    output = Dense(1, activation='linear')(x)  # Regression output\n",
    "\n",
    "    # Define model\n",
    "    model = Model(inputs, output)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.001, decay_steps=1000, decay_rate=0.96, staircase=True\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=tf.keras.losses.Huber(delta=1.0),\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_rnn_cnn_hybrid_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_time_series(df, target_column, seq_length=30, batch_size=32):\n",
    "    \"\"\"\n",
    "    Prepares time series data for the stateful RNN-CNN model.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataset containing time series data.\n",
    "        target_column (str): Name of the target column.\n",
    "        seq_length (int): Number of past days to use as input.\n",
    "        batch_size (int): Ensures data is aligned for stateful training.\n",
    "    \n",
    "    Returns:\n",
    "        X (np.array): Feature sequences of shape (num_samples, seq_length, num_features).\n",
    "        y (np.array): Target values of shape (num_samples, 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure datetime index\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df = df.copy()\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "        df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "    # Sort by datetime (just in case)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Handle missing values\n",
    "    df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")  # Forward then backward fill\n",
    "    \n",
    "    # Select features (exclude target temporarily)\n",
    "    feature_columns = [col for col in df.columns if col != target_column]\n",
    "    features = df[feature_columns].values\n",
    "    target = df[target_column].values\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    # Create rolling window sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - seq_length):\n",
    "        X.append(features[i : i + seq_length])  # 30-day window\n",
    "        y.append(target[i + seq_length])  # Prediction for next day\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "\n",
    "    # Ensure batch size compatibility by removing excess rows from the beginning\n",
    "    num_samples = (X.shape[0] // batch_size) * batch_size\n",
    "    X, y = X[-num_samples:], y[-num_samples:]  # Keep the last `num_samples` rows\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Example Usage\n",
    "# df = pd.read_csv(\"your_data.csv\")  # Load dataset\n",
    "# X_train, y_train = preprocess_time_series(df, \"close\", seq_length=30, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chidi\\AppData\\Local\\Temp\\ipykernel_115876\\4209493190.py:30: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")  # Forward then backward fill\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = preprocess_time_series(df, \"close\", seq_length=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45315, 0.44534, 0.4353 , ..., 2.7378 , 2.6877 , 2.5412 ])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 6.1323e-04 - mae: 0.0182\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 5.8059e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 6.1580e-04 - mae: 0.0183\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 5.8153e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - loss: 5.9023e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 5.9606e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 6.0495e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 5.9772e-04 - mae: 0.0176\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 6.0227e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 6.3225e-04 - mae: 0.0185\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 5.9121e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 6.3280e-04 - mae: 0.0183\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 5.7832e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 5.8510e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 5.6284e-04 - mae: 0.0173\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 5.7428e-04 - mae: 0.0176\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 5.9967e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 6.1915e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 6.0158e-04 - mae: 0.0183\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 6.1093e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 6.0127e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 6.0773e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 5.7809e-04 - mae: 0.0175\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 6.1210e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 5.9350e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 5.6056e-04 - mae: 0.0173\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 5.9448e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 5.9521e-04 - mae: 0.0177\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 6.3459e-04 - mae: 0.0186\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 5.7296e-04 - mae: 0.0175\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 6.1364e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 5.8364e-04 - mae: 0.0176\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 5.7698e-04 - mae: 0.0178\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 5.9716e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 6.1562e-04 - mae: 0.0182\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 6.3187e-04 - mae: 0.0184\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 5.3371e-04 - mae: 0.0173\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 5.9435e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 5.8624e-04 - mae: 0.0182\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 6.2150e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 5.9712e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 5.6482e-04 - mae: 0.0178\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.6348e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 5.9683e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.8869e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 6.0556e-04 - mae: 0.0182\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.7693e-04 - mae: 0.0175\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.7171e-04 - mae: 0.0174\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 6.3990e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.7806e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.9445e-04 - mae: 0.0177\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 5.9127e-04 - mae: 0.0183\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 6.0380e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.6259e-04 - mae: 0.0173\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 6.0341e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.9285e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 6.1463e-04 - mae: 0.0182\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.8246e-04 - mae: 0.0178\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.8513e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.6363e-04 - mae: 0.0174\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.7018e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.8582e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 6.0981e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.9072e-04 - mae: 0.0177\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 5.9425e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 6.1419e-04 - mae: 0.0182\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.8546e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.9242e-04 - mae: 0.0176\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 6.5848e-04 - mae: 0.0182\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 5.9015e-04 - mae: 0.0177\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.7728e-04 - mae: 0.0176\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 6.0379e-04 - mae: 0.0182\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.9469e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 6.3045e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 5.9223e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 5.7786e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 5.6225e-04 - mae: 0.0173\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 5.8163e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.8841e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.6157e-04 - mae: 0.0174\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 6.0431e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.9726e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.8392e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 5.7034e-04 - mae: 0.0176\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.8484e-04 - mae: 0.0176\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.8461e-04 - mae: 0.0179\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 6.1232e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 6.1700e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 5.8555e-04 - mae: 0.0178\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 5.9628e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 5.8840e-04 - mae: 0.0177\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 5.9937e-04 - mae: 0.0178\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 6.7618e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 6.2215e-04 - mae: 0.0182\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.6678e-04 - mae: 0.0174\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 6.0435e-04 - mae: 0.0181\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 5.7695e-04 - mae: 0.0174\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 5.9564e-04 - mae: 0.0180\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 5.8371e-04 - mae: 0.0176\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 6.2040e-04 - mae: 0.0184\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=1, shuffle=False)\n",
    "    \n",
    "    # Reset states for each GRU layer\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'reset_states'):\n",
    "            layer.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the entire model (architecture + weights + optimizer state)\n",
    "model.save(\"rnn_cnn_hybrid_model_xrpusdt_daily_ovft_2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"rnn_cnn_hybrid_model_xrpusdt_daily_ovft_2.keras\")  # Saves in TensorFlow SavedModel format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"rnn_cnn_hybrid_weights_ovft_2.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make prediction using the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_last_30_days(df, target_column, scaler):\n",
    "    \"\"\"\n",
    "    Extracts the last 30 days of features for prediction.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataset containing time series data.\n",
    "        target_column (str): Name of the target column.\n",
    "        scaler (StandardScaler): The same scaler used during training.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Reshaped input of shape (1, 30, num_features) ready for prediction.\n",
    "    \"\"\"\n",
    "    # Ensure datetime index\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df = df.copy()\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "        df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "    # Sort by datetime\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Select features (exclude target temporarily)\n",
    "    feature_columns = [col for col in df.columns if col != target_column]\n",
    "    features = df[feature_columns].values\n",
    "\n",
    "    # Normalize features using the same scaler\n",
    "    features = scaler.transform(features)\n",
    "\n",
    "    # Extract last 30 days\n",
    "    last_30_days = features[-30:]\n",
    "\n",
    "    # Reshape to match model input (batch_size=1, seq_length=30, num_features)\n",
    "    return np.expand_dims(last_30_days, axis=0)\n",
    "\n",
    "# Example Usage\n",
    "# df = pd.read_csv(\"your_new_data.csv\")  # Load dataset\n",
    "# scaler = StandardScaler().fit(df[feature_columns])  # Load the same scaler used during training\n",
    "# X_input = prepare_last_30_days(df, \"close\", scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_1 = df_val.iloc[:30]\n",
    "df_val_2 = df_val.iloc[4:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9b333b62-867a-44ed-8b80-58d319e4383a",
       "rows": [
        [
         "2025-01-22 01:00:00",
         "3.1739",
         "3.2854",
         "3.1237",
         "3.1803",
         "291761274.0",
         "3.20455",
         "0.0063999999999997",
         "1",
         "3.1750142857142856",
         "2.5557066666666666",
         "3.0925787742246698",
         "2.6917692413882017",
         "72.18069905473732",
         "2.9733928563491987",
         "2.7350364454128964",
         "0.2383564109363023",
         "0.1929819403749409",
         "2.72958",
         "0.3861295182216789",
         "3.501839036443358",
         "1.957320963556642",
         "3.1738",
         "3.1053",
         "2.9587"
        ],
        [
         "2025-01-23 01:00:00",
         "3.1802",
         "3.1868",
         "3.0374",
         "3.1194",
         "305314846.0",
         "3.1121",
         "-0.0607999999999999",
         "0",
         "3.1570571428571426",
         "2.5822266666666667",
         "3.0992840806685025",
         "2.7193583225889637",
         "73.80310182063386",
         "2.995855493833937",
         "2.763507819826756",
         "0.2323476740071814",
         "0.200855087101389",
         "2.762815",
         "0.3898132755091322",
         "3.5424415510182645",
         "1.983188448981736",
         "3.1803",
         "3.1738",
         "3.1053"
        ],
        [
         "2025-01-24 01:00:00",
         "3.1194",
         "3.2031",
         "3.055",
         "3.1009",
         "232626964.0",
         "3.1290500000000003",
         "-0.0184999999999999",
         "0",
         "3.129728571428572",
         "2.609013333333333",
         "3.099688060501377",
         "2.7439739146799984",
         "71.96483313089249",
         "3.012016187090255",
         "2.7884998331729225",
         "0.2235163539173323",
         "0.2053873404645777",
         "2.796855",
         "0.3880319350327547",
         "3.572918870065509",
         "2.0207911299344907",
         "3.1194",
         "3.1803",
         "3.1738"
        ],
        [
         "2025-01-25 01:00:00",
         "3.1008",
         "3.1446",
         "3.0784",
         "3.108",
         "99489857.0",
         "3.1115",
         "0.0072",
         "1",
         "3.106628571428572",
         "2.64075",
         "3.1017660453760327",
         "2.767459468571612",
         "67.70819453697536",
         "3.026782927537908",
         "2.8121665121971504",
         "0.2146164153407577",
         "0.2072331554398137",
         "2.832285",
         "0.3821367835502179",
         "3.596558567100436",
         "2.068011432899564",
         "3.1009",
         "3.1194",
         "3.1803"
        ],
        [
         "2025-01-26 01:00:00",
         "3.1079",
         "3.1443",
         "3.0115",
         "3.0223",
         "128937813.0",
         "3.0779",
         "-0.0855999999999999",
         "0",
         "3.115714285714286",
         "2.66994",
         "3.0818995340320243",
         "2.7839007931798947",
         "67.08693643144763",
         "3.0260932463782297",
         "2.827731955738102",
         "0.1983612906401277",
         "0.2054587824798765",
         "2.8624",
         "0.3715210853264",
         "3.6054421706528",
         "2.1193578293472",
         "3.108",
         "3.1009",
         "3.1194"
        ],
        [
         "2025-01-27 01:00:00",
         "3.0222",
         "3.0587",
         "2.6559",
         "3.0552",
         "660056174.0",
         "2.8573",
         "0.0329999999999999",
         "1",
         "3.1085571428571432",
         "2.69897",
         "3.075224650524018",
         "2.8014039678134504",
         "67.39471619147267",
         "3.0305712084738867",
         "2.8445814404982426",
         "0.1859897679756441",
         "0.2015649795790301",
         "2.9016",
         "0.3463685305384561",
         "3.5943370610769123",
         "2.208862938923088",
         "3.0223",
         "3.108",
         "3.1009"
        ],
        [
         "2025-01-28 01:00:00",
         "3.0552",
         "3.214",
         "3.0062",
         "3.0572",
         "369470786.0",
         "3.1101",
         "0.0019999999999997",
         "1",
         "3.0919",
         "2.73107",
         "3.070718487893014",
         "2.8179069376319377",
         "64.0545021988321",
         "3.0346679456317505",
         "2.8603309634242984",
         "0.174336982207452",
         "0.1961193801047145",
         "2.935805",
         "0.324520009074132",
         "3.5848450181482643",
         "2.286764981851736",
         "3.0552",
         "3.0223",
         "3.108"
        ],
        [
         "2025-01-29 01:00:00",
         "3.0572",
         "3.1363",
         "2.9673",
         "3.0683",
         "254756655.0",
         "3.0518",
         "0.0110999999999998",
         "1",
         "3.0759000000000003",
         "2.7647233333333334",
         "3.07011386591976",
         "2.834061328752458",
         "45.95707782354214",
         "3.0398421078422504",
         "2.8757360772447207",
         "0.1641060305975297",
         "0.1897167102032775",
         "2.97561",
         "0.2852926528837973",
         "3.5461953057675943",
         "2.405024694232405",
         "3.0572",
         "3.0552",
         "3.0223"
        ],
        [
         "2025-01-30 01:00:00",
         "3.0683",
         "3.1544",
         "3.0466",
         "3.1276",
         "173143314.0",
         "3.1005000000000003",
         "0.0593000000000003",
         "1",
         "3.0770714285714287",
         "2.7995233333333336",
         "3.08448539943982",
         "2.852999307542622",
         "43.32158690462659",
         "3.053343322020366",
         "2.894392664115482",
         "0.1589506579048838",
         "0.1835634997435988",
         "3.01492",
         "0.2445639698901339",
         "3.504047939780268",
         "2.5257920602197323",
         "3.0683",
         "3.0572",
         "3.0552"
        ],
        [
         "2025-01-31 01:00:00",
         "3.1276",
         "3.1333",
         "3.003",
         "3.0361",
         "162235322.0",
         "3.06815",
         "-0.0915000000000003",
         "0",
         "3.0678142857142854",
         "2.8229666666666664",
         "3.0723890495798645",
         "2.8648122554430984",
         "36.14327453738773",
         "3.050690503248002",
         "2.9048895038106317",
         "0.1458009994373705",
         "0.1760109996823532",
         "3.037905",
         "0.2217160072444531",
         "3.481337014488906",
         "2.5944729855110937",
         "3.1276",
         "3.0683",
         "3.0572"
        ],
        [
         "2025-02-01 01:00:00",
         "3.0361",
         "3.0727",
         "2.8281",
         "2.8778",
         "173601404.0",
         "2.9504",
         "-0.1582999999999996",
         "0",
         "3.0349285714285714",
         "2.8388133333333334",
         "3.0237417871848984",
         "2.86565017444677",
         "31.512406830833115",
         "3.0240919642867707",
         "2.9028828738987325",
         "0.1212090903880382",
         "0.1650506178234902",
         "3.056565",
         "0.1875404862254698",
         "3.4316459724509394",
         "2.681484027549061",
         "3.0361",
         "3.1276",
         "3.0683"
        ],
        [
         "2025-02-02 01:00:00",
         "2.8779",
         "2.9559",
         "2.4603",
         "2.58",
         "684089012.0",
         "2.7081",
         "-0.2978999999999998",
         "0",
         "2.971742857142857",
         "2.84299",
         "2.912806340388674",
         "2.847221130934076",
         "31.909811789433466",
         "2.9557701236272678",
         "2.878965623980308",
         "0.0768044996469594",
         "0.147401394188184",
         "3.059405",
         "0.1792868782441362",
         "3.4179787564882727",
         "2.700831243511727",
         "2.8778",
         "3.0361",
         "3.1276"
        ],
        [
         "2025-02-03 01:00:00",
         "2.5801",
         "2.7814",
         "1.7711",
         "2.7001",
         "1866758972.0",
         "2.27625",
         "0.1200000000000001",
         "1",
         "2.9210142857142856",
         "2.852323333333333",
         "2.8596297552915058",
         "2.8377294450673607",
         "30.141148794354024",
         "2.916436258453841",
         "2.8657163185002847",
         "0.0507199399535567",
         "0.1280651033412586",
         "3.061045",
         "0.1756239807237741",
         "3.412292961447548",
         "2.709797038552452",
         "2.58",
         "2.8778",
         "3.0361"
        ],
        [
         "2025-02-04 01:00:00",
         "2.7",
         "2.7874",
         "2.4209",
         "2.5274",
         "621552965.0",
         "2.60415",
         "-0.1726000000000001",
         "0",
         "2.8453285714285714",
         "2.85659",
         "2.7765723164686293",
         "2.8177081905468864",
         "21.2557808609036",
         "2.85658452638402",
         "2.8406558504632264",
         "0.0159286759207932",
         "0.1056378178571655",
         "3.03027",
         "0.2109086359939854",
         "3.4520872719879714",
         "2.608452728012029",
         "2.7001",
         "2.58",
         "2.8778"
        ],
        [
         "2025-02-05 01:00:00",
         "2.5275",
         "2.5692",
         "2.3384",
         "2.381",
         "338815093.0",
         "2.4538",
         "-0.1465",
         "0",
         "2.7471428571428573",
         "2.85529",
         "2.677679237351472",
         "2.78953346857612",
         "18.38962271612749",
         "2.783417676171094",
         "2.806607268947432",
         "-0.0231895927763381",
         "0.0798723357304648",
         "2.9870650000000003",
         "0.2495504131644097",
         "3.48616582632882",
         "2.487964173671181",
         "2.5274",
         "2.7001",
         "2.58"
        ],
        [
         "2025-02-06 01:00:00",
         "2.381",
         "2.4699",
         "2.2772",
         "2.325",
         "322896937.0",
         "2.37355",
         "-0.0559999999999996",
         "0",
         "2.632485714285714",
         "2.857083333333333",
         "2.589509428013604",
         "2.7595635673776604",
         "18.461171986660304",
         "2.71289187983708",
         "2.7709326564328074",
         "-0.0580407765957278",
         "0.0522897132652262",
         "2.938705",
         "0.2792548043689831",
         "3.4972146087379663",
         "2.380195391262034",
         "2.381",
         "2.5274",
         "2.7001"
        ],
        [
         "2025-02-07 01:00:00",
         "2.3251",
         "2.542",
         "2.2655",
         "2.3968",
         "447487945.0",
         "2.40375",
         "0.0716999999999998",
         "1",
         "2.5411571428571427",
         "2.857873333333333",
         "2.5413320710102028",
         "2.736159466256521",
         "23.1812295269292",
         "2.6642623598621444",
         "2.7432191263266734",
         "-0.0789567664645289",
         "0.0260404173192752",
         "2.89506",
         "0.2926905396489628",
         "3.480441079297925",
         "2.3096789207020745",
         "2.325",
         "2.381",
         "2.5274"
        ],
        [
         "2025-02-08 01:00:00",
         "2.3969",
         "2.4372",
         "2.3506",
         "2.419",
         "154717204.0",
         "2.3939",
         "0.0221",
         "1",
         "2.4756142857142858",
         "2.862766666666667",
         "2.510749053257652",
         "2.715697565207713",
         "24.054827534267204",
         "2.626529689114122",
         "2.71920289474692",
         "-0.0926732056327979",
         "0.0022976927288606",
         "2.868075",
         "0.3108313603954146",
         "3.4897377207908296",
         "2.2464122792091707",
         "2.3968",
         "2.325",
         "2.381"
        ],
        [
         "2025-02-09 01:00:00",
         "2.419",
         "2.5079",
         "2.3113",
         "2.3928",
         "204205603.0",
         "2.4096",
         "-0.0262000000000002",
         "0",
         "2.4488714285714286",
         "2.86448",
         "2.481261789943239",
         "2.6948654642265706",
         "25.18331625009856",
         "2.590571275404257",
         "2.695024902543444",
         "-0.1044536271391871",
         "-0.0190525712447489",
         "2.83245",
         "0.3228112019513326",
         "3.4780724039026656",
         "2.1868275960973347",
         "2.419",
         "2.3968",
         "2.325"
        ],
        [
         "2025-02-10 01:00:00",
         "2.3928",
         "2.4733",
         "2.3235",
         "2.4237",
         "207257933.0",
         "2.3984",
         "0.0309000000000003",
         "1",
         "2.4093857142857145",
         "2.85939",
         "2.4668713424574293",
         "2.677370918147437",
         "25.06515043828477",
         "2.5648987714959097",
         "2.6749267616143",
         "-0.1100279901183904",
         "-0.0372476550194772",
         "2.794945",
         "0.3246340943844977",
         "3.4442131887689955",
         "2.145676811231004",
         "2.3928",
         "2.419",
         "2.3968"
        ],
        [
         "2025-02-11 01:00:00",
         "2.4238",
         "2.529",
         "2.3708",
         "2.4131",
         "248182176.0",
         "2.4499",
         "-0.0106999999999999",
         "0",
         "2.3930571428571428",
         "2.85634",
         "2.453428506843072",
         "2.6603211814927645",
         "24.739195230998533",
         "2.541545114342693",
         "2.6555321866799075",
         "-0.1139870723372147",
         "-0.0525955384830247",
         "2.756585",
         "0.3220196092018731",
         "3.4006242184037463",
         "2.1125457815962534",
         "2.4237",
         "2.3928",
         "2.419"
        ],
        [
         "2025-02-12 01:00:00",
         "2.413",
         "2.4962",
         "2.3323",
         "2.4734",
         "227957636.0",
         "2.41425",
         "0.0604",
         "1",
         "2.4062571428571427",
         "2.85468",
         "2.458421380132304",
         "2.648261750428716",
         "27.53568461596558",
         "2.5310612505976637",
         "2.6420409135925067",
         "-0.1109796629948434",
         "-0.0642723633853885",
         "2.724285",
         "0.3160553886750343",
         "3.3563957773500688",
         "2.092174222649932",
         "2.4131",
         "2.4237",
         "2.3928"
        ],
        [
         "2025-02-13 01:00:00",
         "2.4734",
         "2.6061",
         "2.4154",
         "2.5599",
         "212478703.0",
         "2.51075",
         "0.0865",
         "1",
         "2.4398142857142857",
         "2.8511",
         "2.483791035099228",
         "2.6425609923365405",
         "28.99430178346776",
         "2.5354979812749456",
         "2.635956401474544",
         "-0.1004584201995979",
         "-0.0715095747482303",
         "2.697235",
         "0.3050865869759472",
         "3.3074081739518943",
         "2.0870618260481058",
         "2.4734",
         "2.4131",
         "2.4237"
        ],
        [
         "2025-02-14 01:00:00",
         "2.56",
         "2.8356",
         "2.53",
         "2.7384",
         "407541122.0",
         "2.6828",
         "0.1783999999999999",
         "1",
         "2.488614285714285",
         "2.837616666666667",
         "2.5474432763244206",
         "2.64874415412128",
         "39.65097684766739",
         "2.5667136764634155",
         "2.643544816180133",
         "-0.0768311397167176",
         "-0.0725738877419278",
         "2.678755",
         "0.2897017658413209",
         "3.258158531682642",
         "2.0993514683173577",
         "2.5599",
         "2.4734",
         "2.4131"
        ],
        [
         "2025-02-15 01:00:00",
         "2.7384",
         "2.8335",
         "2.713",
         "2.7619",
         "184181907.0",
         "2.77325",
         "0.0234999999999998",
         "1",
         "2.5376",
         "2.8215100000000004",
         "2.601057457243315",
         "2.6560445312747456",
         "45.554276946682",
         "2.59674234162289",
         "2.6523118668334567",
         "-0.0555695252105667",
         "-0.0691730152356556",
         "2.665735",
         "0.2791070974884401",
         "3.22394919497688",
         "2.10752080502312",
         "2.7384",
         "2.5599",
         "2.4734"
        ],
        [
         "2025-02-16 01:00:00",
         "2.7619",
         "2.8054",
         "2.6879",
         "2.7283",
         "132387997.0",
         "2.74665",
         "-0.0335999999999998",
         "0",
         "2.585528571428572",
         "2.8027133333333327",
         "2.6328680929324864",
         "2.6607061744183107",
         "57.1346098335418",
         "2.6169819813732142",
         "2.657940617438386",
         "-0.0409586360651719",
         "-0.0635301394015588",
         "2.64939",
         "0.2642768562262739",
         "3.177943712452548",
         "2.120836287547452",
         "2.7619",
         "2.7384",
         "2.5599"
        ],
        [
         "2025-02-17 01:00:00",
         "2.7283",
         "2.7648",
         "2.6075",
         "2.6599",
         "212813356.0",
         "2.68615",
         "-0.0684",
         "0",
         "2.619271428571428",
         "2.7823866666666666",
         "2.6396260696993648",
         "2.6606541631655167",
         "47.964763061968405",
         "2.623584753469643",
         "2.6580857568873943",
         "-0.0345010034177515",
         "-0.0577243122047974",
         "2.629525",
         "0.2463322507573021",
         "3.1221895015146046",
         "2.136860498485396",
         "2.7283",
         "2.7619",
         "2.7384"
        ],
        [
         "2025-02-18 01:00:00",
         "2.6599",
         "2.6699",
         "2.4693",
         "2.5628",
         "227170019.0",
         "2.5696000000000003",
         "-0.0970999999999997",
         "0",
         "2.640657142857143",
         "2.76919",
         "2.620419552274524",
         "2.654340991348387",
         "51.94078947368422",
         "2.6142332529358514",
         "2.6510275526735136",
         "-0.0367942997376622",
         "-0.0535383097113703",
         "2.6042499999999995",
         "0.22384959588739",
         "3.05194919177478",
         "2.1565508082252194",
         "2.6599",
         "2.7283",
         "2.7619"
        ],
        [
         "2025-02-19 01:00:00",
         "2.5629",
         "2.747",
         "2.5121",
         "2.7378",
         "208244059.0",
         "2.62955",
         "0.1749",
         "1",
         "2.678428571428572",
         "2.75694",
         "2.649764664205893",
         "2.659725443519459",
         "68.96661705294495",
         "2.6332435217149515",
         "2.6574551413643643",
         "-0.0242116196494128",
         "-0.0476729716989788",
         "2.58476",
         "0.1903469640862247",
         "2.9654539281724497",
         "2.2040660718275507",
         "2.5628",
         "2.6599",
         "2.7283"
        ],
        [
         "2025-02-20 01:00:00",
         "2.7378",
         "2.749",
         "2.6671",
         "2.6877",
         "161604635.0",
         "2.70805",
         "-0.0501",
         "0",
         "2.696685714285714",
         "2.7407366666666664",
         "2.65924849815442",
         "2.661530253614978",
         "69.4019471488178",
         "2.6416214414511128",
         "2.6596955012633003",
         "-0.0180740598121875",
         "-0.0417531893216206",
         "2.56734",
         "0.1604643078857835",
         "2.888268615771567",
         "2.2464113842284323",
         "2.7378",
         "2.5628",
         "2.6599"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 30
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>30_day_SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>26_day_EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-22 01:00:00</th>\n",
       "      <td>3.1739</td>\n",
       "      <td>3.2854</td>\n",
       "      <td>3.1237</td>\n",
       "      <td>3.1803</td>\n",
       "      <td>2.917613e+08</td>\n",
       "      <td>3.20455</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>1</td>\n",
       "      <td>3.175014</td>\n",
       "      <td>2.555707</td>\n",
       "      <td>...</td>\n",
       "      <td>2.735036</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>2.729580</td>\n",
       "      <td>0.386130</td>\n",
       "      <td>3.501839</td>\n",
       "      <td>1.957321</td>\n",
       "      <td>3.1738</td>\n",
       "      <td>3.1053</td>\n",
       "      <td>2.9587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23 01:00:00</th>\n",
       "      <td>3.1802</td>\n",
       "      <td>3.1868</td>\n",
       "      <td>3.0374</td>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.053148e+08</td>\n",
       "      <td>3.11210</td>\n",
       "      <td>-0.0608</td>\n",
       "      <td>0</td>\n",
       "      <td>3.157057</td>\n",
       "      <td>2.582227</td>\n",
       "      <td>...</td>\n",
       "      <td>2.763508</td>\n",
       "      <td>0.232348</td>\n",
       "      <td>0.200855</td>\n",
       "      <td>2.762815</td>\n",
       "      <td>0.389813</td>\n",
       "      <td>3.542442</td>\n",
       "      <td>1.983188</td>\n",
       "      <td>3.1803</td>\n",
       "      <td>3.1738</td>\n",
       "      <td>3.1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-24 01:00:00</th>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.2031</td>\n",
       "      <td>3.0550</td>\n",
       "      <td>3.1009</td>\n",
       "      <td>2.326270e+08</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>0</td>\n",
       "      <td>3.129729</td>\n",
       "      <td>2.609013</td>\n",
       "      <td>...</td>\n",
       "      <td>2.788500</td>\n",
       "      <td>0.223516</td>\n",
       "      <td>0.205387</td>\n",
       "      <td>2.796855</td>\n",
       "      <td>0.388032</td>\n",
       "      <td>3.572919</td>\n",
       "      <td>2.020791</td>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.1803</td>\n",
       "      <td>3.1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-25 01:00:00</th>\n",
       "      <td>3.1008</td>\n",
       "      <td>3.1446</td>\n",
       "      <td>3.0784</td>\n",
       "      <td>3.1080</td>\n",
       "      <td>9.948986e+07</td>\n",
       "      <td>3.11150</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>1</td>\n",
       "      <td>3.106629</td>\n",
       "      <td>2.640750</td>\n",
       "      <td>...</td>\n",
       "      <td>2.812167</td>\n",
       "      <td>0.214616</td>\n",
       "      <td>0.207233</td>\n",
       "      <td>2.832285</td>\n",
       "      <td>0.382137</td>\n",
       "      <td>3.596559</td>\n",
       "      <td>2.068011</td>\n",
       "      <td>3.1009</td>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.1803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-26 01:00:00</th>\n",
       "      <td>3.1079</td>\n",
       "      <td>3.1443</td>\n",
       "      <td>3.0115</td>\n",
       "      <td>3.0223</td>\n",
       "      <td>1.289378e+08</td>\n",
       "      <td>3.07790</td>\n",
       "      <td>-0.0856</td>\n",
       "      <td>0</td>\n",
       "      <td>3.115714</td>\n",
       "      <td>2.669940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.827732</td>\n",
       "      <td>0.198361</td>\n",
       "      <td>0.205459</td>\n",
       "      <td>2.862400</td>\n",
       "      <td>0.371521</td>\n",
       "      <td>3.605442</td>\n",
       "      <td>2.119358</td>\n",
       "      <td>3.1080</td>\n",
       "      <td>3.1009</td>\n",
       "      <td>3.1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-27 01:00:00</th>\n",
       "      <td>3.0222</td>\n",
       "      <td>3.0587</td>\n",
       "      <td>2.6559</td>\n",
       "      <td>3.0552</td>\n",
       "      <td>6.600562e+08</td>\n",
       "      <td>2.85730</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>1</td>\n",
       "      <td>3.108557</td>\n",
       "      <td>2.698970</td>\n",
       "      <td>...</td>\n",
       "      <td>2.844581</td>\n",
       "      <td>0.185990</td>\n",
       "      <td>0.201565</td>\n",
       "      <td>2.901600</td>\n",
       "      <td>0.346369</td>\n",
       "      <td>3.594337</td>\n",
       "      <td>2.208863</td>\n",
       "      <td>3.0223</td>\n",
       "      <td>3.1080</td>\n",
       "      <td>3.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-28 01:00:00</th>\n",
       "      <td>3.0552</td>\n",
       "      <td>3.2140</td>\n",
       "      <td>3.0062</td>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.694708e+08</td>\n",
       "      <td>3.11010</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1</td>\n",
       "      <td>3.091900</td>\n",
       "      <td>2.731070</td>\n",
       "      <td>...</td>\n",
       "      <td>2.860331</td>\n",
       "      <td>0.174337</td>\n",
       "      <td>0.196119</td>\n",
       "      <td>2.935805</td>\n",
       "      <td>0.324520</td>\n",
       "      <td>3.584845</td>\n",
       "      <td>2.286765</td>\n",
       "      <td>3.0552</td>\n",
       "      <td>3.0223</td>\n",
       "      <td>3.1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-29 01:00:00</th>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.1363</td>\n",
       "      <td>2.9673</td>\n",
       "      <td>3.0683</td>\n",
       "      <td>2.547567e+08</td>\n",
       "      <td>3.05180</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>1</td>\n",
       "      <td>3.075900</td>\n",
       "      <td>2.764723</td>\n",
       "      <td>...</td>\n",
       "      <td>2.875736</td>\n",
       "      <td>0.164106</td>\n",
       "      <td>0.189717</td>\n",
       "      <td>2.975610</td>\n",
       "      <td>0.285293</td>\n",
       "      <td>3.546195</td>\n",
       "      <td>2.405025</td>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.0552</td>\n",
       "      <td>3.0223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-30 01:00:00</th>\n",
       "      <td>3.0683</td>\n",
       "      <td>3.1544</td>\n",
       "      <td>3.0466</td>\n",
       "      <td>3.1276</td>\n",
       "      <td>1.731433e+08</td>\n",
       "      <td>3.10050</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>1</td>\n",
       "      <td>3.077071</td>\n",
       "      <td>2.799523</td>\n",
       "      <td>...</td>\n",
       "      <td>2.894393</td>\n",
       "      <td>0.158951</td>\n",
       "      <td>0.183563</td>\n",
       "      <td>3.014920</td>\n",
       "      <td>0.244564</td>\n",
       "      <td>3.504048</td>\n",
       "      <td>2.525792</td>\n",
       "      <td>3.0683</td>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-31 01:00:00</th>\n",
       "      <td>3.1276</td>\n",
       "      <td>3.1333</td>\n",
       "      <td>3.0030</td>\n",
       "      <td>3.0361</td>\n",
       "      <td>1.622353e+08</td>\n",
       "      <td>3.06815</td>\n",
       "      <td>-0.0915</td>\n",
       "      <td>0</td>\n",
       "      <td>3.067814</td>\n",
       "      <td>2.822967</td>\n",
       "      <td>...</td>\n",
       "      <td>2.904890</td>\n",
       "      <td>0.145801</td>\n",
       "      <td>0.176011</td>\n",
       "      <td>3.037905</td>\n",
       "      <td>0.221716</td>\n",
       "      <td>3.481337</td>\n",
       "      <td>2.594473</td>\n",
       "      <td>3.1276</td>\n",
       "      <td>3.0683</td>\n",
       "      <td>3.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01 01:00:00</th>\n",
       "      <td>3.0361</td>\n",
       "      <td>3.0727</td>\n",
       "      <td>2.8281</td>\n",
       "      <td>2.8778</td>\n",
       "      <td>1.736014e+08</td>\n",
       "      <td>2.95040</td>\n",
       "      <td>-0.1583</td>\n",
       "      <td>0</td>\n",
       "      <td>3.034929</td>\n",
       "      <td>2.838813</td>\n",
       "      <td>...</td>\n",
       "      <td>2.902883</td>\n",
       "      <td>0.121209</td>\n",
       "      <td>0.165051</td>\n",
       "      <td>3.056565</td>\n",
       "      <td>0.187540</td>\n",
       "      <td>3.431646</td>\n",
       "      <td>2.681484</td>\n",
       "      <td>3.0361</td>\n",
       "      <td>3.1276</td>\n",
       "      <td>3.0683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-02 01:00:00</th>\n",
       "      <td>2.8779</td>\n",
       "      <td>2.9559</td>\n",
       "      <td>2.4603</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>6.840890e+08</td>\n",
       "      <td>2.70810</td>\n",
       "      <td>-0.2979</td>\n",
       "      <td>0</td>\n",
       "      <td>2.971743</td>\n",
       "      <td>2.842990</td>\n",
       "      <td>...</td>\n",
       "      <td>2.878966</td>\n",
       "      <td>0.076804</td>\n",
       "      <td>0.147401</td>\n",
       "      <td>3.059405</td>\n",
       "      <td>0.179287</td>\n",
       "      <td>3.417979</td>\n",
       "      <td>2.700831</td>\n",
       "      <td>2.8778</td>\n",
       "      <td>3.0361</td>\n",
       "      <td>3.1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-03 01:00:00</th>\n",
       "      <td>2.5801</td>\n",
       "      <td>2.7814</td>\n",
       "      <td>1.7711</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>1.866759e+09</td>\n",
       "      <td>2.27625</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921014</td>\n",
       "      <td>2.852323</td>\n",
       "      <td>...</td>\n",
       "      <td>2.865716</td>\n",
       "      <td>0.050720</td>\n",
       "      <td>0.128065</td>\n",
       "      <td>3.061045</td>\n",
       "      <td>0.175624</td>\n",
       "      <td>3.412293</td>\n",
       "      <td>2.709797</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>2.8778</td>\n",
       "      <td>3.0361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-04 01:00:00</th>\n",
       "      <td>2.7000</td>\n",
       "      <td>2.7874</td>\n",
       "      <td>2.4209</td>\n",
       "      <td>2.5274</td>\n",
       "      <td>6.215530e+08</td>\n",
       "      <td>2.60415</td>\n",
       "      <td>-0.1726</td>\n",
       "      <td>0</td>\n",
       "      <td>2.845329</td>\n",
       "      <td>2.856590</td>\n",
       "      <td>...</td>\n",
       "      <td>2.840656</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>0.105638</td>\n",
       "      <td>3.030270</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>3.452087</td>\n",
       "      <td>2.608453</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>2.8778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-05 01:00:00</th>\n",
       "      <td>2.5275</td>\n",
       "      <td>2.5692</td>\n",
       "      <td>2.3384</td>\n",
       "      <td>2.3810</td>\n",
       "      <td>3.388151e+08</td>\n",
       "      <td>2.45380</td>\n",
       "      <td>-0.1465</td>\n",
       "      <td>0</td>\n",
       "      <td>2.747143</td>\n",
       "      <td>2.855290</td>\n",
       "      <td>...</td>\n",
       "      <td>2.806607</td>\n",
       "      <td>-0.023190</td>\n",
       "      <td>0.079872</td>\n",
       "      <td>2.987065</td>\n",
       "      <td>0.249550</td>\n",
       "      <td>3.486166</td>\n",
       "      <td>2.487964</td>\n",
       "      <td>2.5274</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>2.5800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-06 01:00:00</th>\n",
       "      <td>2.3810</td>\n",
       "      <td>2.4699</td>\n",
       "      <td>2.2772</td>\n",
       "      <td>2.3250</td>\n",
       "      <td>3.228969e+08</td>\n",
       "      <td>2.37355</td>\n",
       "      <td>-0.0560</td>\n",
       "      <td>0</td>\n",
       "      <td>2.632486</td>\n",
       "      <td>2.857083</td>\n",
       "      <td>...</td>\n",
       "      <td>2.770933</td>\n",
       "      <td>-0.058041</td>\n",
       "      <td>0.052290</td>\n",
       "      <td>2.938705</td>\n",
       "      <td>0.279255</td>\n",
       "      <td>3.497215</td>\n",
       "      <td>2.380195</td>\n",
       "      <td>2.3810</td>\n",
       "      <td>2.5274</td>\n",
       "      <td>2.7001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-07 01:00:00</th>\n",
       "      <td>2.3251</td>\n",
       "      <td>2.5420</td>\n",
       "      <td>2.2655</td>\n",
       "      <td>2.3968</td>\n",
       "      <td>4.474879e+08</td>\n",
       "      <td>2.40375</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>2.541157</td>\n",
       "      <td>2.857873</td>\n",
       "      <td>...</td>\n",
       "      <td>2.743219</td>\n",
       "      <td>-0.078957</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>2.895060</td>\n",
       "      <td>0.292691</td>\n",
       "      <td>3.480441</td>\n",
       "      <td>2.309679</td>\n",
       "      <td>2.3250</td>\n",
       "      <td>2.3810</td>\n",
       "      <td>2.5274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-08 01:00:00</th>\n",
       "      <td>2.3969</td>\n",
       "      <td>2.4372</td>\n",
       "      <td>2.3506</td>\n",
       "      <td>2.4190</td>\n",
       "      <td>1.547172e+08</td>\n",
       "      <td>2.39390</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>1</td>\n",
       "      <td>2.475614</td>\n",
       "      <td>2.862767</td>\n",
       "      <td>...</td>\n",
       "      <td>2.719203</td>\n",
       "      <td>-0.092673</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>2.868075</td>\n",
       "      <td>0.310831</td>\n",
       "      <td>3.489738</td>\n",
       "      <td>2.246412</td>\n",
       "      <td>2.3968</td>\n",
       "      <td>2.3250</td>\n",
       "      <td>2.3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-09 01:00:00</th>\n",
       "      <td>2.4190</td>\n",
       "      <td>2.5079</td>\n",
       "      <td>2.3113</td>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.042056e+08</td>\n",
       "      <td>2.40960</td>\n",
       "      <td>-0.0262</td>\n",
       "      <td>0</td>\n",
       "      <td>2.448871</td>\n",
       "      <td>2.864480</td>\n",
       "      <td>...</td>\n",
       "      <td>2.695025</td>\n",
       "      <td>-0.104454</td>\n",
       "      <td>-0.019053</td>\n",
       "      <td>2.832450</td>\n",
       "      <td>0.322811</td>\n",
       "      <td>3.478072</td>\n",
       "      <td>2.186828</td>\n",
       "      <td>2.4190</td>\n",
       "      <td>2.3968</td>\n",
       "      <td>2.3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-10 01:00:00</th>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.4733</td>\n",
       "      <td>2.3235</td>\n",
       "      <td>2.4237</td>\n",
       "      <td>2.072579e+08</td>\n",
       "      <td>2.39840</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>1</td>\n",
       "      <td>2.409386</td>\n",
       "      <td>2.859390</td>\n",
       "      <td>...</td>\n",
       "      <td>2.674927</td>\n",
       "      <td>-0.110028</td>\n",
       "      <td>-0.037248</td>\n",
       "      <td>2.794945</td>\n",
       "      <td>0.324634</td>\n",
       "      <td>3.444213</td>\n",
       "      <td>2.145677</td>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.4190</td>\n",
       "      <td>2.3968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 01:00:00</th>\n",
       "      <td>2.4238</td>\n",
       "      <td>2.5290</td>\n",
       "      <td>2.3708</td>\n",
       "      <td>2.4131</td>\n",
       "      <td>2.481822e+08</td>\n",
       "      <td>2.44990</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>0</td>\n",
       "      <td>2.393057</td>\n",
       "      <td>2.856340</td>\n",
       "      <td>...</td>\n",
       "      <td>2.655532</td>\n",
       "      <td>-0.113987</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>2.756585</td>\n",
       "      <td>0.322020</td>\n",
       "      <td>3.400624</td>\n",
       "      <td>2.112546</td>\n",
       "      <td>2.4237</td>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-12 01:00:00</th>\n",
       "      <td>2.4130</td>\n",
       "      <td>2.4962</td>\n",
       "      <td>2.3323</td>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.279576e+08</td>\n",
       "      <td>2.41425</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1</td>\n",
       "      <td>2.406257</td>\n",
       "      <td>2.854680</td>\n",
       "      <td>...</td>\n",
       "      <td>2.642041</td>\n",
       "      <td>-0.110980</td>\n",
       "      <td>-0.064272</td>\n",
       "      <td>2.724285</td>\n",
       "      <td>0.316055</td>\n",
       "      <td>3.356396</td>\n",
       "      <td>2.092174</td>\n",
       "      <td>2.4131</td>\n",
       "      <td>2.4237</td>\n",
       "      <td>2.3928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-13 01:00:00</th>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.6061</td>\n",
       "      <td>2.4154</td>\n",
       "      <td>2.5599</td>\n",
       "      <td>2.124787e+08</td>\n",
       "      <td>2.51075</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>1</td>\n",
       "      <td>2.439814</td>\n",
       "      <td>2.851100</td>\n",
       "      <td>...</td>\n",
       "      <td>2.635956</td>\n",
       "      <td>-0.100458</td>\n",
       "      <td>-0.071510</td>\n",
       "      <td>2.697235</td>\n",
       "      <td>0.305087</td>\n",
       "      <td>3.307408</td>\n",
       "      <td>2.087062</td>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.4131</td>\n",
       "      <td>2.4237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 01:00:00</th>\n",
       "      <td>2.5600</td>\n",
       "      <td>2.8356</td>\n",
       "      <td>2.5300</td>\n",
       "      <td>2.7384</td>\n",
       "      <td>4.075411e+08</td>\n",
       "      <td>2.68280</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>1</td>\n",
       "      <td>2.488614</td>\n",
       "      <td>2.837617</td>\n",
       "      <td>...</td>\n",
       "      <td>2.643545</td>\n",
       "      <td>-0.076831</td>\n",
       "      <td>-0.072574</td>\n",
       "      <td>2.678755</td>\n",
       "      <td>0.289702</td>\n",
       "      <td>3.258159</td>\n",
       "      <td>2.099351</td>\n",
       "      <td>2.5599</td>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.4131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-15 01:00:00</th>\n",
       "      <td>2.7384</td>\n",
       "      <td>2.8335</td>\n",
       "      <td>2.7130</td>\n",
       "      <td>2.7619</td>\n",
       "      <td>1.841819e+08</td>\n",
       "      <td>2.77325</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>1</td>\n",
       "      <td>2.537600</td>\n",
       "      <td>2.821510</td>\n",
       "      <td>...</td>\n",
       "      <td>2.652312</td>\n",
       "      <td>-0.055570</td>\n",
       "      <td>-0.069173</td>\n",
       "      <td>2.665735</td>\n",
       "      <td>0.279107</td>\n",
       "      <td>3.223949</td>\n",
       "      <td>2.107521</td>\n",
       "      <td>2.7384</td>\n",
       "      <td>2.5599</td>\n",
       "      <td>2.4734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-16 01:00:00</th>\n",
       "      <td>2.7619</td>\n",
       "      <td>2.8054</td>\n",
       "      <td>2.6879</td>\n",
       "      <td>2.7283</td>\n",
       "      <td>1.323880e+08</td>\n",
       "      <td>2.74665</td>\n",
       "      <td>-0.0336</td>\n",
       "      <td>0</td>\n",
       "      <td>2.585529</td>\n",
       "      <td>2.802713</td>\n",
       "      <td>...</td>\n",
       "      <td>2.657941</td>\n",
       "      <td>-0.040959</td>\n",
       "      <td>-0.063530</td>\n",
       "      <td>2.649390</td>\n",
       "      <td>0.264277</td>\n",
       "      <td>3.177944</td>\n",
       "      <td>2.120836</td>\n",
       "      <td>2.7619</td>\n",
       "      <td>2.7384</td>\n",
       "      <td>2.5599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-17 01:00:00</th>\n",
       "      <td>2.7283</td>\n",
       "      <td>2.7648</td>\n",
       "      <td>2.6075</td>\n",
       "      <td>2.6599</td>\n",
       "      <td>2.128134e+08</td>\n",
       "      <td>2.68615</td>\n",
       "      <td>-0.0684</td>\n",
       "      <td>0</td>\n",
       "      <td>2.619271</td>\n",
       "      <td>2.782387</td>\n",
       "      <td>...</td>\n",
       "      <td>2.658086</td>\n",
       "      <td>-0.034501</td>\n",
       "      <td>-0.057724</td>\n",
       "      <td>2.629525</td>\n",
       "      <td>0.246332</td>\n",
       "      <td>3.122190</td>\n",
       "      <td>2.136860</td>\n",
       "      <td>2.7283</td>\n",
       "      <td>2.7619</td>\n",
       "      <td>2.7384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-18 01:00:00</th>\n",
       "      <td>2.6599</td>\n",
       "      <td>2.6699</td>\n",
       "      <td>2.4693</td>\n",
       "      <td>2.5628</td>\n",
       "      <td>2.271700e+08</td>\n",
       "      <td>2.56960</td>\n",
       "      <td>-0.0971</td>\n",
       "      <td>0</td>\n",
       "      <td>2.640657</td>\n",
       "      <td>2.769190</td>\n",
       "      <td>...</td>\n",
       "      <td>2.651028</td>\n",
       "      <td>-0.036794</td>\n",
       "      <td>-0.053538</td>\n",
       "      <td>2.604250</td>\n",
       "      <td>0.223850</td>\n",
       "      <td>3.051949</td>\n",
       "      <td>2.156551</td>\n",
       "      <td>2.6599</td>\n",
       "      <td>2.7283</td>\n",
       "      <td>2.7619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 01:00:00</th>\n",
       "      <td>2.5629</td>\n",
       "      <td>2.7470</td>\n",
       "      <td>2.5121</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.082441e+08</td>\n",
       "      <td>2.62955</td>\n",
       "      <td>0.1749</td>\n",
       "      <td>1</td>\n",
       "      <td>2.678429</td>\n",
       "      <td>2.756940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.657455</td>\n",
       "      <td>-0.024212</td>\n",
       "      <td>-0.047673</td>\n",
       "      <td>2.584760</td>\n",
       "      <td>0.190347</td>\n",
       "      <td>2.965454</td>\n",
       "      <td>2.204066</td>\n",
       "      <td>2.5628</td>\n",
       "      <td>2.6599</td>\n",
       "      <td>2.7283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-20 01:00:00</th>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.7490</td>\n",
       "      <td>2.6671</td>\n",
       "      <td>2.6877</td>\n",
       "      <td>1.616046e+08</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>-0.0501</td>\n",
       "      <td>0</td>\n",
       "      <td>2.696686</td>\n",
       "      <td>2.740737</td>\n",
       "      <td>...</td>\n",
       "      <td>2.659696</td>\n",
       "      <td>-0.018074</td>\n",
       "      <td>-0.041753</td>\n",
       "      <td>2.567340</td>\n",
       "      <td>0.160464</td>\n",
       "      <td>2.888269</td>\n",
       "      <td>2.246411</td>\n",
       "      <td>2.7378</td>\n",
       "      <td>2.5628</td>\n",
       "      <td>2.6599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close        volume    av_pr  \\\n",
       "datetime                                                                     \n",
       "2025-01-22 01:00:00  3.1739  3.2854  3.1237  3.1803  2.917613e+08  3.20455   \n",
       "2025-01-23 01:00:00  3.1802  3.1868  3.0374  3.1194  3.053148e+08  3.11210   \n",
       "2025-01-24 01:00:00  3.1194  3.2031  3.0550  3.1009  2.326270e+08  3.12905   \n",
       "2025-01-25 01:00:00  3.1008  3.1446  3.0784  3.1080  9.948986e+07  3.11150   \n",
       "2025-01-26 01:00:00  3.1079  3.1443  3.0115  3.0223  1.289378e+08  3.07790   \n",
       "2025-01-27 01:00:00  3.0222  3.0587  2.6559  3.0552  6.600562e+08  2.85730   \n",
       "2025-01-28 01:00:00  3.0552  3.2140  3.0062  3.0572  3.694708e+08  3.11010   \n",
       "2025-01-29 01:00:00  3.0572  3.1363  2.9673  3.0683  2.547567e+08  3.05180   \n",
       "2025-01-30 01:00:00  3.0683  3.1544  3.0466  3.1276  1.731433e+08  3.10050   \n",
       "2025-01-31 01:00:00  3.1276  3.1333  3.0030  3.0361  1.622353e+08  3.06815   \n",
       "2025-02-01 01:00:00  3.0361  3.0727  2.8281  2.8778  1.736014e+08  2.95040   \n",
       "2025-02-02 01:00:00  2.8779  2.9559  2.4603  2.5800  6.840890e+08  2.70810   \n",
       "2025-02-03 01:00:00  2.5801  2.7814  1.7711  2.7001  1.866759e+09  2.27625   \n",
       "2025-02-04 01:00:00  2.7000  2.7874  2.4209  2.5274  6.215530e+08  2.60415   \n",
       "2025-02-05 01:00:00  2.5275  2.5692  2.3384  2.3810  3.388151e+08  2.45380   \n",
       "2025-02-06 01:00:00  2.3810  2.4699  2.2772  2.3250  3.228969e+08  2.37355   \n",
       "2025-02-07 01:00:00  2.3251  2.5420  2.2655  2.3968  4.474879e+08  2.40375   \n",
       "2025-02-08 01:00:00  2.3969  2.4372  2.3506  2.4190  1.547172e+08  2.39390   \n",
       "2025-02-09 01:00:00  2.4190  2.5079  2.3113  2.3928  2.042056e+08  2.40960   \n",
       "2025-02-10 01:00:00  2.3928  2.4733  2.3235  2.4237  2.072579e+08  2.39840   \n",
       "2025-02-11 01:00:00  2.4238  2.5290  2.3708  2.4131  2.481822e+08  2.44990   \n",
       "2025-02-12 01:00:00  2.4130  2.4962  2.3323  2.4734  2.279576e+08  2.41425   \n",
       "2025-02-13 01:00:00  2.4734  2.6061  2.4154  2.5599  2.124787e+08  2.51075   \n",
       "2025-02-14 01:00:00  2.5600  2.8356  2.5300  2.7384  4.075411e+08  2.68280   \n",
       "2025-02-15 01:00:00  2.7384  2.8335  2.7130  2.7619  1.841819e+08  2.77325   \n",
       "2025-02-16 01:00:00  2.7619  2.8054  2.6879  2.7283  1.323880e+08  2.74665   \n",
       "2025-02-17 01:00:00  2.7283  2.7648  2.6075  2.6599  2.128134e+08  2.68615   \n",
       "2025-02-18 01:00:00  2.6599  2.6699  2.4693  2.5628  2.271700e+08  2.56960   \n",
       "2025-02-19 01:00:00  2.5629  2.7470  2.5121  2.7378  2.082441e+08  2.62955   \n",
       "2025-02-20 01:00:00  2.7378  2.7490  2.6671  2.6877  1.616046e+08  2.70805   \n",
       "\n",
       "                       diff  candle  7_day_SMA  30_day_SMA  ...  26_day_EMA  \\\n",
       "datetime                                                    ...               \n",
       "2025-01-22 01:00:00  0.0064       1   3.175014    2.555707  ...    2.735036   \n",
       "2025-01-23 01:00:00 -0.0608       0   3.157057    2.582227  ...    2.763508   \n",
       "2025-01-24 01:00:00 -0.0185       0   3.129729    2.609013  ...    2.788500   \n",
       "2025-01-25 01:00:00  0.0072       1   3.106629    2.640750  ...    2.812167   \n",
       "2025-01-26 01:00:00 -0.0856       0   3.115714    2.669940  ...    2.827732   \n",
       "2025-01-27 01:00:00  0.0330       1   3.108557    2.698970  ...    2.844581   \n",
       "2025-01-28 01:00:00  0.0020       1   3.091900    2.731070  ...    2.860331   \n",
       "2025-01-29 01:00:00  0.0111       1   3.075900    2.764723  ...    2.875736   \n",
       "2025-01-30 01:00:00  0.0593       1   3.077071    2.799523  ...    2.894393   \n",
       "2025-01-31 01:00:00 -0.0915       0   3.067814    2.822967  ...    2.904890   \n",
       "2025-02-01 01:00:00 -0.1583       0   3.034929    2.838813  ...    2.902883   \n",
       "2025-02-02 01:00:00 -0.2979       0   2.971743    2.842990  ...    2.878966   \n",
       "2025-02-03 01:00:00  0.1200       1   2.921014    2.852323  ...    2.865716   \n",
       "2025-02-04 01:00:00 -0.1726       0   2.845329    2.856590  ...    2.840656   \n",
       "2025-02-05 01:00:00 -0.1465       0   2.747143    2.855290  ...    2.806607   \n",
       "2025-02-06 01:00:00 -0.0560       0   2.632486    2.857083  ...    2.770933   \n",
       "2025-02-07 01:00:00  0.0717       1   2.541157    2.857873  ...    2.743219   \n",
       "2025-02-08 01:00:00  0.0221       1   2.475614    2.862767  ...    2.719203   \n",
       "2025-02-09 01:00:00 -0.0262       0   2.448871    2.864480  ...    2.695025   \n",
       "2025-02-10 01:00:00  0.0309       1   2.409386    2.859390  ...    2.674927   \n",
       "2025-02-11 01:00:00 -0.0107       0   2.393057    2.856340  ...    2.655532   \n",
       "2025-02-12 01:00:00  0.0604       1   2.406257    2.854680  ...    2.642041   \n",
       "2025-02-13 01:00:00  0.0865       1   2.439814    2.851100  ...    2.635956   \n",
       "2025-02-14 01:00:00  0.1784       1   2.488614    2.837617  ...    2.643545   \n",
       "2025-02-15 01:00:00  0.0235       1   2.537600    2.821510  ...    2.652312   \n",
       "2025-02-16 01:00:00 -0.0336       0   2.585529    2.802713  ...    2.657941   \n",
       "2025-02-17 01:00:00 -0.0684       0   2.619271    2.782387  ...    2.658086   \n",
       "2025-02-18 01:00:00 -0.0971       0   2.640657    2.769190  ...    2.651028   \n",
       "2025-02-19 01:00:00  0.1749       1   2.678429    2.756940  ...    2.657455   \n",
       "2025-02-20 01:00:00 -0.0501       0   2.696686    2.740737  ...    2.659696   \n",
       "\n",
       "                         MACD  Signal_Line  20_day_SMA  20_day_STD  \\\n",
       "datetime                                                             \n",
       "2025-01-22 01:00:00  0.238356     0.192982    2.729580    0.386130   \n",
       "2025-01-23 01:00:00  0.232348     0.200855    2.762815    0.389813   \n",
       "2025-01-24 01:00:00  0.223516     0.205387    2.796855    0.388032   \n",
       "2025-01-25 01:00:00  0.214616     0.207233    2.832285    0.382137   \n",
       "2025-01-26 01:00:00  0.198361     0.205459    2.862400    0.371521   \n",
       "2025-01-27 01:00:00  0.185990     0.201565    2.901600    0.346369   \n",
       "2025-01-28 01:00:00  0.174337     0.196119    2.935805    0.324520   \n",
       "2025-01-29 01:00:00  0.164106     0.189717    2.975610    0.285293   \n",
       "2025-01-30 01:00:00  0.158951     0.183563    3.014920    0.244564   \n",
       "2025-01-31 01:00:00  0.145801     0.176011    3.037905    0.221716   \n",
       "2025-02-01 01:00:00  0.121209     0.165051    3.056565    0.187540   \n",
       "2025-02-02 01:00:00  0.076804     0.147401    3.059405    0.179287   \n",
       "2025-02-03 01:00:00  0.050720     0.128065    3.061045    0.175624   \n",
       "2025-02-04 01:00:00  0.015929     0.105638    3.030270    0.210909   \n",
       "2025-02-05 01:00:00 -0.023190     0.079872    2.987065    0.249550   \n",
       "2025-02-06 01:00:00 -0.058041     0.052290    2.938705    0.279255   \n",
       "2025-02-07 01:00:00 -0.078957     0.026040    2.895060    0.292691   \n",
       "2025-02-08 01:00:00 -0.092673     0.002298    2.868075    0.310831   \n",
       "2025-02-09 01:00:00 -0.104454    -0.019053    2.832450    0.322811   \n",
       "2025-02-10 01:00:00 -0.110028    -0.037248    2.794945    0.324634   \n",
       "2025-02-11 01:00:00 -0.113987    -0.052596    2.756585    0.322020   \n",
       "2025-02-12 01:00:00 -0.110980    -0.064272    2.724285    0.316055   \n",
       "2025-02-13 01:00:00 -0.100458    -0.071510    2.697235    0.305087   \n",
       "2025-02-14 01:00:00 -0.076831    -0.072574    2.678755    0.289702   \n",
       "2025-02-15 01:00:00 -0.055570    -0.069173    2.665735    0.279107   \n",
       "2025-02-16 01:00:00 -0.040959    -0.063530    2.649390    0.264277   \n",
       "2025-02-17 01:00:00 -0.034501    -0.057724    2.629525    0.246332   \n",
       "2025-02-18 01:00:00 -0.036794    -0.053538    2.604250    0.223850   \n",
       "2025-02-19 01:00:00 -0.024212    -0.047673    2.584760    0.190347   \n",
       "2025-02-20 01:00:00 -0.018074    -0.041753    2.567340    0.160464   \n",
       "\n",
       "                     Upper_Band  Lower_Band   lag_1   lag_2   lag_3  \n",
       "datetime                                                             \n",
       "2025-01-22 01:00:00    3.501839    1.957321  3.1738  3.1053  2.9587  \n",
       "2025-01-23 01:00:00    3.542442    1.983188  3.1803  3.1738  3.1053  \n",
       "2025-01-24 01:00:00    3.572919    2.020791  3.1194  3.1803  3.1738  \n",
       "2025-01-25 01:00:00    3.596559    2.068011  3.1009  3.1194  3.1803  \n",
       "2025-01-26 01:00:00    3.605442    2.119358  3.1080  3.1009  3.1194  \n",
       "2025-01-27 01:00:00    3.594337    2.208863  3.0223  3.1080  3.1009  \n",
       "2025-01-28 01:00:00    3.584845    2.286765  3.0552  3.0223  3.1080  \n",
       "2025-01-29 01:00:00    3.546195    2.405025  3.0572  3.0552  3.0223  \n",
       "2025-01-30 01:00:00    3.504048    2.525792  3.0683  3.0572  3.0552  \n",
       "2025-01-31 01:00:00    3.481337    2.594473  3.1276  3.0683  3.0572  \n",
       "2025-02-01 01:00:00    3.431646    2.681484  3.0361  3.1276  3.0683  \n",
       "2025-02-02 01:00:00    3.417979    2.700831  2.8778  3.0361  3.1276  \n",
       "2025-02-03 01:00:00    3.412293    2.709797  2.5800  2.8778  3.0361  \n",
       "2025-02-04 01:00:00    3.452087    2.608453  2.7001  2.5800  2.8778  \n",
       "2025-02-05 01:00:00    3.486166    2.487964  2.5274  2.7001  2.5800  \n",
       "2025-02-06 01:00:00    3.497215    2.380195  2.3810  2.5274  2.7001  \n",
       "2025-02-07 01:00:00    3.480441    2.309679  2.3250  2.3810  2.5274  \n",
       "2025-02-08 01:00:00    3.489738    2.246412  2.3968  2.3250  2.3810  \n",
       "2025-02-09 01:00:00    3.478072    2.186828  2.4190  2.3968  2.3250  \n",
       "2025-02-10 01:00:00    3.444213    2.145677  2.3928  2.4190  2.3968  \n",
       "2025-02-11 01:00:00    3.400624    2.112546  2.4237  2.3928  2.4190  \n",
       "2025-02-12 01:00:00    3.356396    2.092174  2.4131  2.4237  2.3928  \n",
       "2025-02-13 01:00:00    3.307408    2.087062  2.4734  2.4131  2.4237  \n",
       "2025-02-14 01:00:00    3.258159    2.099351  2.5599  2.4734  2.4131  \n",
       "2025-02-15 01:00:00    3.223949    2.107521  2.7384  2.5599  2.4734  \n",
       "2025-02-16 01:00:00    3.177944    2.120836  2.7619  2.7384  2.5599  \n",
       "2025-02-17 01:00:00    3.122190    2.136860  2.7283  2.7619  2.7384  \n",
       "2025-02-18 01:00:00    3.051949    2.156551  2.6599  2.7283  2.7619  \n",
       "2025-02-19 01:00:00    2.965454    2.204066  2.5628  2.6599  2.7283  \n",
       "2025-02-20 01:00:00    2.888269    2.246411  2.7378  2.5628  2.6599  \n",
       "\n",
       "[30 rows x 24 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "afe320ae-16a5-4f67-9d19-23f668d70c74",
       "rows": [
        [
         "2025-01-18 01:00:00",
         "3.2923",
         "3.2996",
         "3.058",
         "3.2697",
         "458088944.0",
         "3.1788",
         "-0.0226000000000001",
         "0",
         "2.9492857142857143",
         "2.4411733333333334",
         "3.0141094592779685",
         "2.5637328040426266",
         "76.90310322989234",
         "2.8347321610675134",
         "2.599338377693888",
         "0.2353937833736257",
         "0.133276149300667",
         "2.55255",
         "0.3800097997351346",
         "3.3125695994702693",
         "1.792530400529731",
         "3.2922",
         "3.2451",
         "3.1429"
        ],
        [
         "2025-01-19 01:00:00",
         "3.2697",
         "3.2929",
         "2.8277",
         "2.9587",
         "663328805.0",
         "3.0603",
         "-0.3109999999999999",
         "0",
         "3.014157142857143",
         "2.46382",
         "3.0002570944584765",
         "2.589214558620521",
         "64.96014550901407",
         "2.853804136287896",
         "2.6259577571239703",
         "0.2278463791639255",
         "0.1521901952733187",
         "2.59755",
         "0.3716472230772792",
         "3.3408444461545583",
         "1.8542555538454413",
         "3.2697",
         "3.2922",
         "3.2451"
        ],
        [
         "2025-01-20 01:00:00",
         "2.9586",
         "3.3695",
         "2.909",
         "3.1053",
         "838761258.0",
         "3.13925",
         "0.1467",
         "1",
         "3.097314285714286",
         "2.49273",
         "3.026517820843857",
         "2.62251039354823",
         "67.17285621209844",
         "2.89249580762822",
         "2.661464589929602",
         "0.2310312176986175",
         "0.1679583997583785",
         "2.648635",
         "0.3674795680320922",
         "3.3835941360641844",
         "1.913675863935816",
         "2.9587",
         "3.2697",
         "3.2922"
        ],
        [
         "2025-01-21 01:00:00",
         "3.1053",
         "3.246",
         "3.0124",
         "3.1738",
         "376423502.0",
         "3.1292",
         "0.0684999999999997",
         "1",
         "3.1696714285714287",
         "2.5250866666666667",
         "3.063338365632893",
         "2.6580774649322154",
         "73.56657963446476",
         "2.9357733756854167",
         "2.699415361045928",
         "0.2363580146394888",
         "0.1816383227346006",
         "2.690685",
         "0.3774196258459339",
         "3.445524251691868",
         "1.935845748308132",
         "3.1053",
         "2.9587",
         "3.2697"
        ],
        [
         "2025-01-22 01:00:00",
         "3.1739",
         "3.2854",
         "3.1237",
         "3.1803",
         "291761274.0",
         "3.20455",
         "0.0063999999999997",
         "1",
         "3.1750142857142856",
         "2.5557066666666666",
         "3.0925787742246698",
         "2.6917692413882017",
         "72.18069905473732",
         "2.9733928563491987",
         "2.7350364454128964",
         "0.2383564109363023",
         "0.1929819403749409",
         "2.72958",
         "0.3861295182216789",
         "3.501839036443358",
         "1.957320963556642",
         "3.1738",
         "3.1053",
         "2.9587"
        ],
        [
         "2025-01-23 01:00:00",
         "3.1802",
         "3.1868",
         "3.0374",
         "3.1194",
         "305314846.0",
         "3.1121",
         "-0.0607999999999999",
         "0",
         "3.1570571428571426",
         "2.5822266666666667",
         "3.0992840806685025",
         "2.7193583225889637",
         "73.80310182063386",
         "2.995855493833937",
         "2.763507819826756",
         "0.2323476740071814",
         "0.200855087101389",
         "2.762815",
         "0.3898132755091322",
         "3.5424415510182645",
         "1.983188448981736",
         "3.1803",
         "3.1738",
         "3.1053"
        ],
        [
         "2025-01-24 01:00:00",
         "3.1194",
         "3.2031",
         "3.055",
         "3.1009",
         "232626964.0",
         "3.1290500000000003",
         "-0.0184999999999999",
         "0",
         "3.129728571428572",
         "2.609013333333333",
         "3.099688060501377",
         "2.7439739146799984",
         "71.96483313089249",
         "3.012016187090255",
         "2.7884998331729225",
         "0.2235163539173323",
         "0.2053873404645777",
         "2.796855",
         "0.3880319350327547",
         "3.572918870065509",
         "2.0207911299344907",
         "3.1194",
         "3.1803",
         "3.1738"
        ],
        [
         "2025-01-25 01:00:00",
         "3.1008",
         "3.1446",
         "3.0784",
         "3.108",
         "99489857.0",
         "3.1115",
         "0.0072",
         "1",
         "3.106628571428572",
         "2.64075",
         "3.1017660453760327",
         "2.767459468571612",
         "67.70819453697536",
         "3.026782927537908",
         "2.8121665121971504",
         "0.2146164153407577",
         "0.2072331554398137",
         "2.832285",
         "0.3821367835502179",
         "3.596558567100436",
         "2.068011432899564",
         "3.1009",
         "3.1194",
         "3.1803"
        ],
        [
         "2025-01-26 01:00:00",
         "3.1079",
         "3.1443",
         "3.0115",
         "3.0223",
         "128937813.0",
         "3.0779",
         "-0.0855999999999999",
         "0",
         "3.115714285714286",
         "2.66994",
         "3.0818995340320243",
         "2.7839007931798947",
         "67.08693643144763",
         "3.0260932463782297",
         "2.827731955738102",
         "0.1983612906401277",
         "0.2054587824798765",
         "2.8624",
         "0.3715210853264",
         "3.6054421706528",
         "2.1193578293472",
         "3.108",
         "3.1009",
         "3.1194"
        ],
        [
         "2025-01-27 01:00:00",
         "3.0222",
         "3.0587",
         "2.6559",
         "3.0552",
         "660056174.0",
         "2.8573",
         "0.0329999999999999",
         "1",
         "3.1085571428571432",
         "2.69897",
         "3.075224650524018",
         "2.8014039678134504",
         "67.39471619147267",
         "3.0305712084738867",
         "2.8445814404982426",
         "0.1859897679756441",
         "0.2015649795790301",
         "2.9016",
         "0.3463685305384561",
         "3.5943370610769123",
         "2.208862938923088",
         "3.0223",
         "3.108",
         "3.1009"
        ],
        [
         "2025-01-28 01:00:00",
         "3.0552",
         "3.214",
         "3.0062",
         "3.0572",
         "369470786.0",
         "3.1101",
         "0.0019999999999997",
         "1",
         "3.0919",
         "2.73107",
         "3.070718487893014",
         "2.8179069376319377",
         "64.0545021988321",
         "3.0346679456317505",
         "2.8603309634242984",
         "0.174336982207452",
         "0.1961193801047145",
         "2.935805",
         "0.324520009074132",
         "3.5848450181482643",
         "2.286764981851736",
         "3.0552",
         "3.0223",
         "3.108"
        ],
        [
         "2025-01-29 01:00:00",
         "3.0572",
         "3.1363",
         "2.9673",
         "3.0683",
         "254756655.0",
         "3.0518",
         "0.0110999999999998",
         "1",
         "3.0759000000000003",
         "2.7647233333333334",
         "3.07011386591976",
         "2.834061328752458",
         "45.95707782354214",
         "3.0398421078422504",
         "2.8757360772447207",
         "0.1641060305975297",
         "0.1897167102032775",
         "2.97561",
         "0.2852926528837973",
         "3.5461953057675943",
         "2.405024694232405",
         "3.0572",
         "3.0552",
         "3.0223"
        ],
        [
         "2025-01-30 01:00:00",
         "3.0683",
         "3.1544",
         "3.0466",
         "3.1276",
         "173143314.0",
         "3.1005000000000003",
         "0.0593000000000003",
         "1",
         "3.0770714285714287",
         "2.7995233333333336",
         "3.08448539943982",
         "2.852999307542622",
         "43.32158690462659",
         "3.053343322020366",
         "2.894392664115482",
         "0.1589506579048838",
         "0.1835634997435988",
         "3.01492",
         "0.2445639698901339",
         "3.504047939780268",
         "2.5257920602197323",
         "3.0683",
         "3.0572",
         "3.0552"
        ],
        [
         "2025-01-31 01:00:00",
         "3.1276",
         "3.1333",
         "3.003",
         "3.0361",
         "162235322.0",
         "3.06815",
         "-0.0915000000000003",
         "0",
         "3.0678142857142854",
         "2.8229666666666664",
         "3.0723890495798645",
         "2.8648122554430984",
         "36.14327453738773",
         "3.050690503248002",
         "2.9048895038106317",
         "0.1458009994373705",
         "0.1760109996823532",
         "3.037905",
         "0.2217160072444531",
         "3.481337014488906",
         "2.5944729855110937",
         "3.1276",
         "3.0683",
         "3.0572"
        ],
        [
         "2025-02-01 01:00:00",
         "3.0361",
         "3.0727",
         "2.8281",
         "2.8778",
         "173601404.0",
         "2.9504",
         "-0.1582999999999996",
         "0",
         "3.0349285714285714",
         "2.8388133333333334",
         "3.0237417871848984",
         "2.86565017444677",
         "31.512406830833115",
         "3.0240919642867707",
         "2.9028828738987325",
         "0.1212090903880382",
         "0.1650506178234902",
         "3.056565",
         "0.1875404862254698",
         "3.4316459724509394",
         "2.681484027549061",
         "3.0361",
         "3.1276",
         "3.0683"
        ],
        [
         "2025-02-02 01:00:00",
         "2.8779",
         "2.9559",
         "2.4603",
         "2.58",
         "684089012.0",
         "2.7081",
         "-0.2978999999999998",
         "0",
         "2.971742857142857",
         "2.84299",
         "2.912806340388674",
         "2.847221130934076",
         "31.909811789433466",
         "2.9557701236272678",
         "2.878965623980308",
         "0.0768044996469594",
         "0.147401394188184",
         "3.059405",
         "0.1792868782441362",
         "3.4179787564882727",
         "2.700831243511727",
         "2.8778",
         "3.0361",
         "3.1276"
        ],
        [
         "2025-02-03 01:00:00",
         "2.5801",
         "2.7814",
         "1.7711",
         "2.7001",
         "1866758972.0",
         "2.27625",
         "0.1200000000000001",
         "1",
         "2.9210142857142856",
         "2.852323333333333",
         "2.8596297552915058",
         "2.8377294450673607",
         "30.141148794354024",
         "2.916436258453841",
         "2.8657163185002847",
         "0.0507199399535567",
         "0.1280651033412586",
         "3.061045",
         "0.1756239807237741",
         "3.412292961447548",
         "2.709797038552452",
         "2.58",
         "2.8778",
         "3.0361"
        ],
        [
         "2025-02-04 01:00:00",
         "2.7",
         "2.7874",
         "2.4209",
         "2.5274",
         "621552965.0",
         "2.60415",
         "-0.1726000000000001",
         "0",
         "2.8453285714285714",
         "2.85659",
         "2.7765723164686293",
         "2.8177081905468864",
         "21.2557808609036",
         "2.85658452638402",
         "2.8406558504632264",
         "0.0159286759207932",
         "0.1056378178571655",
         "3.03027",
         "0.2109086359939854",
         "3.4520872719879714",
         "2.608452728012029",
         "2.7001",
         "2.58",
         "2.8778"
        ],
        [
         "2025-02-05 01:00:00",
         "2.5275",
         "2.5692",
         "2.3384",
         "2.381",
         "338815093.0",
         "2.4538",
         "-0.1465",
         "0",
         "2.7471428571428573",
         "2.85529",
         "2.677679237351472",
         "2.78953346857612",
         "18.38962271612749",
         "2.783417676171094",
         "2.806607268947432",
         "-0.0231895927763381",
         "0.0798723357304648",
         "2.9870650000000003",
         "0.2495504131644097",
         "3.48616582632882",
         "2.487964173671181",
         "2.5274",
         "2.7001",
         "2.58"
        ],
        [
         "2025-02-06 01:00:00",
         "2.381",
         "2.4699",
         "2.2772",
         "2.325",
         "322896937.0",
         "2.37355",
         "-0.0559999999999996",
         "0",
         "2.632485714285714",
         "2.857083333333333",
         "2.589509428013604",
         "2.7595635673776604",
         "18.461171986660304",
         "2.71289187983708",
         "2.7709326564328074",
         "-0.0580407765957278",
         "0.0522897132652262",
         "2.938705",
         "0.2792548043689831",
         "3.4972146087379663",
         "2.380195391262034",
         "2.381",
         "2.5274",
         "2.7001"
        ],
        [
         "2025-02-07 01:00:00",
         "2.3251",
         "2.542",
         "2.2655",
         "2.3968",
         "447487945.0",
         "2.40375",
         "0.0716999999999998",
         "1",
         "2.5411571428571427",
         "2.857873333333333",
         "2.5413320710102028",
         "2.736159466256521",
         "23.1812295269292",
         "2.6642623598621444",
         "2.7432191263266734",
         "-0.0789567664645289",
         "0.0260404173192752",
         "2.89506",
         "0.2926905396489628",
         "3.480441079297925",
         "2.3096789207020745",
         "2.325",
         "2.381",
         "2.5274"
        ],
        [
         "2025-02-08 01:00:00",
         "2.3969",
         "2.4372",
         "2.3506",
         "2.419",
         "154717204.0",
         "2.3939",
         "0.0221",
         "1",
         "2.4756142857142858",
         "2.862766666666667",
         "2.510749053257652",
         "2.715697565207713",
         "24.054827534267204",
         "2.626529689114122",
         "2.71920289474692",
         "-0.0926732056327979",
         "0.0022976927288606",
         "2.868075",
         "0.3108313603954146",
         "3.4897377207908296",
         "2.2464122792091707",
         "2.3968",
         "2.325",
         "2.381"
        ],
        [
         "2025-02-09 01:00:00",
         "2.419",
         "2.5079",
         "2.3113",
         "2.3928",
         "204205603.0",
         "2.4096",
         "-0.0262000000000002",
         "0",
         "2.4488714285714286",
         "2.86448",
         "2.481261789943239",
         "2.6948654642265706",
         "25.18331625009856",
         "2.590571275404257",
         "2.695024902543444",
         "-0.1044536271391871",
         "-0.0190525712447489",
         "2.83245",
         "0.3228112019513326",
         "3.4780724039026656",
         "2.1868275960973347",
         "2.419",
         "2.3968",
         "2.325"
        ],
        [
         "2025-02-10 01:00:00",
         "2.3928",
         "2.4733",
         "2.3235",
         "2.4237",
         "207257933.0",
         "2.3984",
         "0.0309000000000003",
         "1",
         "2.4093857142857145",
         "2.85939",
         "2.4668713424574293",
         "2.677370918147437",
         "25.06515043828477",
         "2.5648987714959097",
         "2.6749267616143",
         "-0.1100279901183904",
         "-0.0372476550194772",
         "2.794945",
         "0.3246340943844977",
         "3.4442131887689955",
         "2.145676811231004",
         "2.3928",
         "2.419",
         "2.3968"
        ],
        [
         "2025-02-11 01:00:00",
         "2.4238",
         "2.529",
         "2.3708",
         "2.4131",
         "248182176.0",
         "2.4499",
         "-0.0106999999999999",
         "0",
         "2.3930571428571428",
         "2.85634",
         "2.453428506843072",
         "2.6603211814927645",
         "24.739195230998533",
         "2.541545114342693",
         "2.6555321866799075",
         "-0.1139870723372147",
         "-0.0525955384830247",
         "2.756585",
         "0.3220196092018731",
         "3.4006242184037463",
         "2.1125457815962534",
         "2.4237",
         "2.3928",
         "2.419"
        ],
        [
         "2025-02-12 01:00:00",
         "2.413",
         "2.4962",
         "2.3323",
         "2.4734",
         "227957636.0",
         "2.41425",
         "0.0604",
         "1",
         "2.4062571428571427",
         "2.85468",
         "2.458421380132304",
         "2.648261750428716",
         "27.53568461596558",
         "2.5310612505976637",
         "2.6420409135925067",
         "-0.1109796629948434",
         "-0.0642723633853885",
         "2.724285",
         "0.3160553886750343",
         "3.3563957773500688",
         "2.092174222649932",
         "2.4131",
         "2.4237",
         "2.3928"
        ],
        [
         "2025-02-13 01:00:00",
         "2.4734",
         "2.6061",
         "2.4154",
         "2.5599",
         "212478703.0",
         "2.51075",
         "0.0865",
         "1",
         "2.4398142857142857",
         "2.8511",
         "2.483791035099228",
         "2.6425609923365405",
         "28.99430178346776",
         "2.5354979812749456",
         "2.635956401474544",
         "-0.1004584201995979",
         "-0.0715095747482303",
         "2.697235",
         "0.3050865869759472",
         "3.3074081739518943",
         "2.0870618260481058",
         "2.4734",
         "2.4131",
         "2.4237"
        ],
        [
         "2025-02-14 01:00:00",
         "2.56",
         "2.8356",
         "2.53",
         "2.7384",
         "407541122.0",
         "2.6828",
         "0.1783999999999999",
         "1",
         "2.488614285714285",
         "2.837616666666667",
         "2.5474432763244206",
         "2.64874415412128",
         "39.65097684766739",
         "2.5667136764634155",
         "2.643544816180133",
         "-0.0768311397167176",
         "-0.0725738877419278",
         "2.678755",
         "0.2897017658413209",
         "3.258158531682642",
         "2.0993514683173577",
         "2.5599",
         "2.4734",
         "2.4131"
        ],
        [
         "2025-02-15 01:00:00",
         "2.7384",
         "2.8335",
         "2.713",
         "2.7619",
         "184181907.0",
         "2.77325",
         "0.0234999999999998",
         "1",
         "2.5376",
         "2.8215100000000004",
         "2.601057457243315",
         "2.6560445312747456",
         "45.554276946682",
         "2.59674234162289",
         "2.6523118668334567",
         "-0.0555695252105667",
         "-0.0691730152356556",
         "2.665735",
         "0.2791070974884401",
         "3.22394919497688",
         "2.10752080502312",
         "2.7384",
         "2.5599",
         "2.4734"
        ],
        [
         "2025-02-16 01:00:00",
         "2.7619",
         "2.8054",
         "2.6879",
         "2.7283",
         "132387997.0",
         "2.74665",
         "-0.0335999999999998",
         "0",
         "2.585528571428572",
         "2.8027133333333327",
         "2.6328680929324864",
         "2.6607061744183107",
         "57.1346098335418",
         "2.6169819813732142",
         "2.657940617438386",
         "-0.0409586360651719",
         "-0.0635301394015588",
         "2.64939",
         "0.2642768562262739",
         "3.177943712452548",
         "2.120836287547452",
         "2.7619",
         "2.7384",
         "2.5599"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 30
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>30_day_SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>26_day_EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-18 01:00:00</th>\n",
       "      <td>3.2923</td>\n",
       "      <td>3.2996</td>\n",
       "      <td>3.0580</td>\n",
       "      <td>3.2697</td>\n",
       "      <td>4.580889e+08</td>\n",
       "      <td>3.17880</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>0</td>\n",
       "      <td>2.949286</td>\n",
       "      <td>2.441173</td>\n",
       "      <td>...</td>\n",
       "      <td>2.599338</td>\n",
       "      <td>0.235394</td>\n",
       "      <td>0.133276</td>\n",
       "      <td>2.552550</td>\n",
       "      <td>0.380010</td>\n",
       "      <td>3.312570</td>\n",
       "      <td>1.792530</td>\n",
       "      <td>3.2922</td>\n",
       "      <td>3.2451</td>\n",
       "      <td>3.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-19 01:00:00</th>\n",
       "      <td>3.2697</td>\n",
       "      <td>3.2929</td>\n",
       "      <td>2.8277</td>\n",
       "      <td>2.9587</td>\n",
       "      <td>6.633288e+08</td>\n",
       "      <td>3.06030</td>\n",
       "      <td>-0.3110</td>\n",
       "      <td>0</td>\n",
       "      <td>3.014157</td>\n",
       "      <td>2.463820</td>\n",
       "      <td>...</td>\n",
       "      <td>2.625958</td>\n",
       "      <td>0.227846</td>\n",
       "      <td>0.152190</td>\n",
       "      <td>2.597550</td>\n",
       "      <td>0.371647</td>\n",
       "      <td>3.340844</td>\n",
       "      <td>1.854256</td>\n",
       "      <td>3.2697</td>\n",
       "      <td>3.2922</td>\n",
       "      <td>3.2451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-20 01:00:00</th>\n",
       "      <td>2.9586</td>\n",
       "      <td>3.3695</td>\n",
       "      <td>2.9090</td>\n",
       "      <td>3.1053</td>\n",
       "      <td>8.387613e+08</td>\n",
       "      <td>3.13925</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>1</td>\n",
       "      <td>3.097314</td>\n",
       "      <td>2.492730</td>\n",
       "      <td>...</td>\n",
       "      <td>2.661465</td>\n",
       "      <td>0.231031</td>\n",
       "      <td>0.167958</td>\n",
       "      <td>2.648635</td>\n",
       "      <td>0.367480</td>\n",
       "      <td>3.383594</td>\n",
       "      <td>1.913676</td>\n",
       "      <td>2.9587</td>\n",
       "      <td>3.2697</td>\n",
       "      <td>3.2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 01:00:00</th>\n",
       "      <td>3.1053</td>\n",
       "      <td>3.2460</td>\n",
       "      <td>3.0124</td>\n",
       "      <td>3.1738</td>\n",
       "      <td>3.764235e+08</td>\n",
       "      <td>3.12920</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>1</td>\n",
       "      <td>3.169671</td>\n",
       "      <td>2.525087</td>\n",
       "      <td>...</td>\n",
       "      <td>2.699415</td>\n",
       "      <td>0.236358</td>\n",
       "      <td>0.181638</td>\n",
       "      <td>2.690685</td>\n",
       "      <td>0.377420</td>\n",
       "      <td>3.445524</td>\n",
       "      <td>1.935846</td>\n",
       "      <td>3.1053</td>\n",
       "      <td>2.9587</td>\n",
       "      <td>3.2697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 01:00:00</th>\n",
       "      <td>3.1739</td>\n",
       "      <td>3.2854</td>\n",
       "      <td>3.1237</td>\n",
       "      <td>3.1803</td>\n",
       "      <td>2.917613e+08</td>\n",
       "      <td>3.20455</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>1</td>\n",
       "      <td>3.175014</td>\n",
       "      <td>2.555707</td>\n",
       "      <td>...</td>\n",
       "      <td>2.735036</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>2.729580</td>\n",
       "      <td>0.386130</td>\n",
       "      <td>3.501839</td>\n",
       "      <td>1.957321</td>\n",
       "      <td>3.1738</td>\n",
       "      <td>3.1053</td>\n",
       "      <td>2.9587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23 01:00:00</th>\n",
       "      <td>3.1802</td>\n",
       "      <td>3.1868</td>\n",
       "      <td>3.0374</td>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.053148e+08</td>\n",
       "      <td>3.11210</td>\n",
       "      <td>-0.0608</td>\n",
       "      <td>0</td>\n",
       "      <td>3.157057</td>\n",
       "      <td>2.582227</td>\n",
       "      <td>...</td>\n",
       "      <td>2.763508</td>\n",
       "      <td>0.232348</td>\n",
       "      <td>0.200855</td>\n",
       "      <td>2.762815</td>\n",
       "      <td>0.389813</td>\n",
       "      <td>3.542442</td>\n",
       "      <td>1.983188</td>\n",
       "      <td>3.1803</td>\n",
       "      <td>3.1738</td>\n",
       "      <td>3.1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-24 01:00:00</th>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.2031</td>\n",
       "      <td>3.0550</td>\n",
       "      <td>3.1009</td>\n",
       "      <td>2.326270e+08</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>0</td>\n",
       "      <td>3.129729</td>\n",
       "      <td>2.609013</td>\n",
       "      <td>...</td>\n",
       "      <td>2.788500</td>\n",
       "      <td>0.223516</td>\n",
       "      <td>0.205387</td>\n",
       "      <td>2.796855</td>\n",
       "      <td>0.388032</td>\n",
       "      <td>3.572919</td>\n",
       "      <td>2.020791</td>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.1803</td>\n",
       "      <td>3.1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-25 01:00:00</th>\n",
       "      <td>3.1008</td>\n",
       "      <td>3.1446</td>\n",
       "      <td>3.0784</td>\n",
       "      <td>3.1080</td>\n",
       "      <td>9.948986e+07</td>\n",
       "      <td>3.11150</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>1</td>\n",
       "      <td>3.106629</td>\n",
       "      <td>2.640750</td>\n",
       "      <td>...</td>\n",
       "      <td>2.812167</td>\n",
       "      <td>0.214616</td>\n",
       "      <td>0.207233</td>\n",
       "      <td>2.832285</td>\n",
       "      <td>0.382137</td>\n",
       "      <td>3.596559</td>\n",
       "      <td>2.068011</td>\n",
       "      <td>3.1009</td>\n",
       "      <td>3.1194</td>\n",
       "      <td>3.1803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-26 01:00:00</th>\n",
       "      <td>3.1079</td>\n",
       "      <td>3.1443</td>\n",
       "      <td>3.0115</td>\n",
       "      <td>3.0223</td>\n",
       "      <td>1.289378e+08</td>\n",
       "      <td>3.07790</td>\n",
       "      <td>-0.0856</td>\n",
       "      <td>0</td>\n",
       "      <td>3.115714</td>\n",
       "      <td>2.669940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.827732</td>\n",
       "      <td>0.198361</td>\n",
       "      <td>0.205459</td>\n",
       "      <td>2.862400</td>\n",
       "      <td>0.371521</td>\n",
       "      <td>3.605442</td>\n",
       "      <td>2.119358</td>\n",
       "      <td>3.1080</td>\n",
       "      <td>3.1009</td>\n",
       "      <td>3.1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-27 01:00:00</th>\n",
       "      <td>3.0222</td>\n",
       "      <td>3.0587</td>\n",
       "      <td>2.6559</td>\n",
       "      <td>3.0552</td>\n",
       "      <td>6.600562e+08</td>\n",
       "      <td>2.85730</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>1</td>\n",
       "      <td>3.108557</td>\n",
       "      <td>2.698970</td>\n",
       "      <td>...</td>\n",
       "      <td>2.844581</td>\n",
       "      <td>0.185990</td>\n",
       "      <td>0.201565</td>\n",
       "      <td>2.901600</td>\n",
       "      <td>0.346369</td>\n",
       "      <td>3.594337</td>\n",
       "      <td>2.208863</td>\n",
       "      <td>3.0223</td>\n",
       "      <td>3.1080</td>\n",
       "      <td>3.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-28 01:00:00</th>\n",
       "      <td>3.0552</td>\n",
       "      <td>3.2140</td>\n",
       "      <td>3.0062</td>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.694708e+08</td>\n",
       "      <td>3.11010</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1</td>\n",
       "      <td>3.091900</td>\n",
       "      <td>2.731070</td>\n",
       "      <td>...</td>\n",
       "      <td>2.860331</td>\n",
       "      <td>0.174337</td>\n",
       "      <td>0.196119</td>\n",
       "      <td>2.935805</td>\n",
       "      <td>0.324520</td>\n",
       "      <td>3.584845</td>\n",
       "      <td>2.286765</td>\n",
       "      <td>3.0552</td>\n",
       "      <td>3.0223</td>\n",
       "      <td>3.1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-29 01:00:00</th>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.1363</td>\n",
       "      <td>2.9673</td>\n",
       "      <td>3.0683</td>\n",
       "      <td>2.547567e+08</td>\n",
       "      <td>3.05180</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>1</td>\n",
       "      <td>3.075900</td>\n",
       "      <td>2.764723</td>\n",
       "      <td>...</td>\n",
       "      <td>2.875736</td>\n",
       "      <td>0.164106</td>\n",
       "      <td>0.189717</td>\n",
       "      <td>2.975610</td>\n",
       "      <td>0.285293</td>\n",
       "      <td>3.546195</td>\n",
       "      <td>2.405025</td>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.0552</td>\n",
       "      <td>3.0223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-30 01:00:00</th>\n",
       "      <td>3.0683</td>\n",
       "      <td>3.1544</td>\n",
       "      <td>3.0466</td>\n",
       "      <td>3.1276</td>\n",
       "      <td>1.731433e+08</td>\n",
       "      <td>3.10050</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>1</td>\n",
       "      <td>3.077071</td>\n",
       "      <td>2.799523</td>\n",
       "      <td>...</td>\n",
       "      <td>2.894393</td>\n",
       "      <td>0.158951</td>\n",
       "      <td>0.183563</td>\n",
       "      <td>3.014920</td>\n",
       "      <td>0.244564</td>\n",
       "      <td>3.504048</td>\n",
       "      <td>2.525792</td>\n",
       "      <td>3.0683</td>\n",
       "      <td>3.0572</td>\n",
       "      <td>3.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-31 01:00:00</th>\n",
       "      <td>3.1276</td>\n",
       "      <td>3.1333</td>\n",
       "      <td>3.0030</td>\n",
       "      <td>3.0361</td>\n",
       "      <td>1.622353e+08</td>\n",
       "      <td>3.06815</td>\n",
       "      <td>-0.0915</td>\n",
       "      <td>0</td>\n",
       "      <td>3.067814</td>\n",
       "      <td>2.822967</td>\n",
       "      <td>...</td>\n",
       "      <td>2.904890</td>\n",
       "      <td>0.145801</td>\n",
       "      <td>0.176011</td>\n",
       "      <td>3.037905</td>\n",
       "      <td>0.221716</td>\n",
       "      <td>3.481337</td>\n",
       "      <td>2.594473</td>\n",
       "      <td>3.1276</td>\n",
       "      <td>3.0683</td>\n",
       "      <td>3.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01 01:00:00</th>\n",
       "      <td>3.0361</td>\n",
       "      <td>3.0727</td>\n",
       "      <td>2.8281</td>\n",
       "      <td>2.8778</td>\n",
       "      <td>1.736014e+08</td>\n",
       "      <td>2.95040</td>\n",
       "      <td>-0.1583</td>\n",
       "      <td>0</td>\n",
       "      <td>3.034929</td>\n",
       "      <td>2.838813</td>\n",
       "      <td>...</td>\n",
       "      <td>2.902883</td>\n",
       "      <td>0.121209</td>\n",
       "      <td>0.165051</td>\n",
       "      <td>3.056565</td>\n",
       "      <td>0.187540</td>\n",
       "      <td>3.431646</td>\n",
       "      <td>2.681484</td>\n",
       "      <td>3.0361</td>\n",
       "      <td>3.1276</td>\n",
       "      <td>3.0683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-02 01:00:00</th>\n",
       "      <td>2.8779</td>\n",
       "      <td>2.9559</td>\n",
       "      <td>2.4603</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>6.840890e+08</td>\n",
       "      <td>2.70810</td>\n",
       "      <td>-0.2979</td>\n",
       "      <td>0</td>\n",
       "      <td>2.971743</td>\n",
       "      <td>2.842990</td>\n",
       "      <td>...</td>\n",
       "      <td>2.878966</td>\n",
       "      <td>0.076804</td>\n",
       "      <td>0.147401</td>\n",
       "      <td>3.059405</td>\n",
       "      <td>0.179287</td>\n",
       "      <td>3.417979</td>\n",
       "      <td>2.700831</td>\n",
       "      <td>2.8778</td>\n",
       "      <td>3.0361</td>\n",
       "      <td>3.1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-03 01:00:00</th>\n",
       "      <td>2.5801</td>\n",
       "      <td>2.7814</td>\n",
       "      <td>1.7711</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>1.866759e+09</td>\n",
       "      <td>2.27625</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921014</td>\n",
       "      <td>2.852323</td>\n",
       "      <td>...</td>\n",
       "      <td>2.865716</td>\n",
       "      <td>0.050720</td>\n",
       "      <td>0.128065</td>\n",
       "      <td>3.061045</td>\n",
       "      <td>0.175624</td>\n",
       "      <td>3.412293</td>\n",
       "      <td>2.709797</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>2.8778</td>\n",
       "      <td>3.0361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-04 01:00:00</th>\n",
       "      <td>2.7000</td>\n",
       "      <td>2.7874</td>\n",
       "      <td>2.4209</td>\n",
       "      <td>2.5274</td>\n",
       "      <td>6.215530e+08</td>\n",
       "      <td>2.60415</td>\n",
       "      <td>-0.1726</td>\n",
       "      <td>0</td>\n",
       "      <td>2.845329</td>\n",
       "      <td>2.856590</td>\n",
       "      <td>...</td>\n",
       "      <td>2.840656</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>0.105638</td>\n",
       "      <td>3.030270</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>3.452087</td>\n",
       "      <td>2.608453</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>2.8778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-05 01:00:00</th>\n",
       "      <td>2.5275</td>\n",
       "      <td>2.5692</td>\n",
       "      <td>2.3384</td>\n",
       "      <td>2.3810</td>\n",
       "      <td>3.388151e+08</td>\n",
       "      <td>2.45380</td>\n",
       "      <td>-0.1465</td>\n",
       "      <td>0</td>\n",
       "      <td>2.747143</td>\n",
       "      <td>2.855290</td>\n",
       "      <td>...</td>\n",
       "      <td>2.806607</td>\n",
       "      <td>-0.023190</td>\n",
       "      <td>0.079872</td>\n",
       "      <td>2.987065</td>\n",
       "      <td>0.249550</td>\n",
       "      <td>3.486166</td>\n",
       "      <td>2.487964</td>\n",
       "      <td>2.5274</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>2.5800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-06 01:00:00</th>\n",
       "      <td>2.3810</td>\n",
       "      <td>2.4699</td>\n",
       "      <td>2.2772</td>\n",
       "      <td>2.3250</td>\n",
       "      <td>3.228969e+08</td>\n",
       "      <td>2.37355</td>\n",
       "      <td>-0.0560</td>\n",
       "      <td>0</td>\n",
       "      <td>2.632486</td>\n",
       "      <td>2.857083</td>\n",
       "      <td>...</td>\n",
       "      <td>2.770933</td>\n",
       "      <td>-0.058041</td>\n",
       "      <td>0.052290</td>\n",
       "      <td>2.938705</td>\n",
       "      <td>0.279255</td>\n",
       "      <td>3.497215</td>\n",
       "      <td>2.380195</td>\n",
       "      <td>2.3810</td>\n",
       "      <td>2.5274</td>\n",
       "      <td>2.7001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-07 01:00:00</th>\n",
       "      <td>2.3251</td>\n",
       "      <td>2.5420</td>\n",
       "      <td>2.2655</td>\n",
       "      <td>2.3968</td>\n",
       "      <td>4.474879e+08</td>\n",
       "      <td>2.40375</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>2.541157</td>\n",
       "      <td>2.857873</td>\n",
       "      <td>...</td>\n",
       "      <td>2.743219</td>\n",
       "      <td>-0.078957</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>2.895060</td>\n",
       "      <td>0.292691</td>\n",
       "      <td>3.480441</td>\n",
       "      <td>2.309679</td>\n",
       "      <td>2.3250</td>\n",
       "      <td>2.3810</td>\n",
       "      <td>2.5274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-08 01:00:00</th>\n",
       "      <td>2.3969</td>\n",
       "      <td>2.4372</td>\n",
       "      <td>2.3506</td>\n",
       "      <td>2.4190</td>\n",
       "      <td>1.547172e+08</td>\n",
       "      <td>2.39390</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>1</td>\n",
       "      <td>2.475614</td>\n",
       "      <td>2.862767</td>\n",
       "      <td>...</td>\n",
       "      <td>2.719203</td>\n",
       "      <td>-0.092673</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>2.868075</td>\n",
       "      <td>0.310831</td>\n",
       "      <td>3.489738</td>\n",
       "      <td>2.246412</td>\n",
       "      <td>2.3968</td>\n",
       "      <td>2.3250</td>\n",
       "      <td>2.3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-09 01:00:00</th>\n",
       "      <td>2.4190</td>\n",
       "      <td>2.5079</td>\n",
       "      <td>2.3113</td>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.042056e+08</td>\n",
       "      <td>2.40960</td>\n",
       "      <td>-0.0262</td>\n",
       "      <td>0</td>\n",
       "      <td>2.448871</td>\n",
       "      <td>2.864480</td>\n",
       "      <td>...</td>\n",
       "      <td>2.695025</td>\n",
       "      <td>-0.104454</td>\n",
       "      <td>-0.019053</td>\n",
       "      <td>2.832450</td>\n",
       "      <td>0.322811</td>\n",
       "      <td>3.478072</td>\n",
       "      <td>2.186828</td>\n",
       "      <td>2.4190</td>\n",
       "      <td>2.3968</td>\n",
       "      <td>2.3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-10 01:00:00</th>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.4733</td>\n",
       "      <td>2.3235</td>\n",
       "      <td>2.4237</td>\n",
       "      <td>2.072579e+08</td>\n",
       "      <td>2.39840</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>1</td>\n",
       "      <td>2.409386</td>\n",
       "      <td>2.859390</td>\n",
       "      <td>...</td>\n",
       "      <td>2.674927</td>\n",
       "      <td>-0.110028</td>\n",
       "      <td>-0.037248</td>\n",
       "      <td>2.794945</td>\n",
       "      <td>0.324634</td>\n",
       "      <td>3.444213</td>\n",
       "      <td>2.145677</td>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.4190</td>\n",
       "      <td>2.3968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 01:00:00</th>\n",
       "      <td>2.4238</td>\n",
       "      <td>2.5290</td>\n",
       "      <td>2.3708</td>\n",
       "      <td>2.4131</td>\n",
       "      <td>2.481822e+08</td>\n",
       "      <td>2.44990</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>0</td>\n",
       "      <td>2.393057</td>\n",
       "      <td>2.856340</td>\n",
       "      <td>...</td>\n",
       "      <td>2.655532</td>\n",
       "      <td>-0.113987</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>2.756585</td>\n",
       "      <td>0.322020</td>\n",
       "      <td>3.400624</td>\n",
       "      <td>2.112546</td>\n",
       "      <td>2.4237</td>\n",
       "      <td>2.3928</td>\n",
       "      <td>2.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-12 01:00:00</th>\n",
       "      <td>2.4130</td>\n",
       "      <td>2.4962</td>\n",
       "      <td>2.3323</td>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.279576e+08</td>\n",
       "      <td>2.41425</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1</td>\n",
       "      <td>2.406257</td>\n",
       "      <td>2.854680</td>\n",
       "      <td>...</td>\n",
       "      <td>2.642041</td>\n",
       "      <td>-0.110980</td>\n",
       "      <td>-0.064272</td>\n",
       "      <td>2.724285</td>\n",
       "      <td>0.316055</td>\n",
       "      <td>3.356396</td>\n",
       "      <td>2.092174</td>\n",
       "      <td>2.4131</td>\n",
       "      <td>2.4237</td>\n",
       "      <td>2.3928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-13 01:00:00</th>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.6061</td>\n",
       "      <td>2.4154</td>\n",
       "      <td>2.5599</td>\n",
       "      <td>2.124787e+08</td>\n",
       "      <td>2.51075</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>1</td>\n",
       "      <td>2.439814</td>\n",
       "      <td>2.851100</td>\n",
       "      <td>...</td>\n",
       "      <td>2.635956</td>\n",
       "      <td>-0.100458</td>\n",
       "      <td>-0.071510</td>\n",
       "      <td>2.697235</td>\n",
       "      <td>0.305087</td>\n",
       "      <td>3.307408</td>\n",
       "      <td>2.087062</td>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.4131</td>\n",
       "      <td>2.4237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 01:00:00</th>\n",
       "      <td>2.5600</td>\n",
       "      <td>2.8356</td>\n",
       "      <td>2.5300</td>\n",
       "      <td>2.7384</td>\n",
       "      <td>4.075411e+08</td>\n",
       "      <td>2.68280</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>1</td>\n",
       "      <td>2.488614</td>\n",
       "      <td>2.837617</td>\n",
       "      <td>...</td>\n",
       "      <td>2.643545</td>\n",
       "      <td>-0.076831</td>\n",
       "      <td>-0.072574</td>\n",
       "      <td>2.678755</td>\n",
       "      <td>0.289702</td>\n",
       "      <td>3.258159</td>\n",
       "      <td>2.099351</td>\n",
       "      <td>2.5599</td>\n",
       "      <td>2.4734</td>\n",
       "      <td>2.4131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-15 01:00:00</th>\n",
       "      <td>2.7384</td>\n",
       "      <td>2.8335</td>\n",
       "      <td>2.7130</td>\n",
       "      <td>2.7619</td>\n",
       "      <td>1.841819e+08</td>\n",
       "      <td>2.77325</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>1</td>\n",
       "      <td>2.537600</td>\n",
       "      <td>2.821510</td>\n",
       "      <td>...</td>\n",
       "      <td>2.652312</td>\n",
       "      <td>-0.055570</td>\n",
       "      <td>-0.069173</td>\n",
       "      <td>2.665735</td>\n",
       "      <td>0.279107</td>\n",
       "      <td>3.223949</td>\n",
       "      <td>2.107521</td>\n",
       "      <td>2.7384</td>\n",
       "      <td>2.5599</td>\n",
       "      <td>2.4734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-16 01:00:00</th>\n",
       "      <td>2.7619</td>\n",
       "      <td>2.8054</td>\n",
       "      <td>2.6879</td>\n",
       "      <td>2.7283</td>\n",
       "      <td>1.323880e+08</td>\n",
       "      <td>2.74665</td>\n",
       "      <td>-0.0336</td>\n",
       "      <td>0</td>\n",
       "      <td>2.585529</td>\n",
       "      <td>2.802713</td>\n",
       "      <td>...</td>\n",
       "      <td>2.657941</td>\n",
       "      <td>-0.040959</td>\n",
       "      <td>-0.063530</td>\n",
       "      <td>2.649390</td>\n",
       "      <td>0.264277</td>\n",
       "      <td>3.177944</td>\n",
       "      <td>2.120836</td>\n",
       "      <td>2.7619</td>\n",
       "      <td>2.7384</td>\n",
       "      <td>2.5599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close        volume    av_pr  \\\n",
       "datetime                                                                     \n",
       "2025-01-18 01:00:00  3.2923  3.2996  3.0580  3.2697  4.580889e+08  3.17880   \n",
       "2025-01-19 01:00:00  3.2697  3.2929  2.8277  2.9587  6.633288e+08  3.06030   \n",
       "2025-01-20 01:00:00  2.9586  3.3695  2.9090  3.1053  8.387613e+08  3.13925   \n",
       "2025-01-21 01:00:00  3.1053  3.2460  3.0124  3.1738  3.764235e+08  3.12920   \n",
       "2025-01-22 01:00:00  3.1739  3.2854  3.1237  3.1803  2.917613e+08  3.20455   \n",
       "2025-01-23 01:00:00  3.1802  3.1868  3.0374  3.1194  3.053148e+08  3.11210   \n",
       "2025-01-24 01:00:00  3.1194  3.2031  3.0550  3.1009  2.326270e+08  3.12905   \n",
       "2025-01-25 01:00:00  3.1008  3.1446  3.0784  3.1080  9.948986e+07  3.11150   \n",
       "2025-01-26 01:00:00  3.1079  3.1443  3.0115  3.0223  1.289378e+08  3.07790   \n",
       "2025-01-27 01:00:00  3.0222  3.0587  2.6559  3.0552  6.600562e+08  2.85730   \n",
       "2025-01-28 01:00:00  3.0552  3.2140  3.0062  3.0572  3.694708e+08  3.11010   \n",
       "2025-01-29 01:00:00  3.0572  3.1363  2.9673  3.0683  2.547567e+08  3.05180   \n",
       "2025-01-30 01:00:00  3.0683  3.1544  3.0466  3.1276  1.731433e+08  3.10050   \n",
       "2025-01-31 01:00:00  3.1276  3.1333  3.0030  3.0361  1.622353e+08  3.06815   \n",
       "2025-02-01 01:00:00  3.0361  3.0727  2.8281  2.8778  1.736014e+08  2.95040   \n",
       "2025-02-02 01:00:00  2.8779  2.9559  2.4603  2.5800  6.840890e+08  2.70810   \n",
       "2025-02-03 01:00:00  2.5801  2.7814  1.7711  2.7001  1.866759e+09  2.27625   \n",
       "2025-02-04 01:00:00  2.7000  2.7874  2.4209  2.5274  6.215530e+08  2.60415   \n",
       "2025-02-05 01:00:00  2.5275  2.5692  2.3384  2.3810  3.388151e+08  2.45380   \n",
       "2025-02-06 01:00:00  2.3810  2.4699  2.2772  2.3250  3.228969e+08  2.37355   \n",
       "2025-02-07 01:00:00  2.3251  2.5420  2.2655  2.3968  4.474879e+08  2.40375   \n",
       "2025-02-08 01:00:00  2.3969  2.4372  2.3506  2.4190  1.547172e+08  2.39390   \n",
       "2025-02-09 01:00:00  2.4190  2.5079  2.3113  2.3928  2.042056e+08  2.40960   \n",
       "2025-02-10 01:00:00  2.3928  2.4733  2.3235  2.4237  2.072579e+08  2.39840   \n",
       "2025-02-11 01:00:00  2.4238  2.5290  2.3708  2.4131  2.481822e+08  2.44990   \n",
       "2025-02-12 01:00:00  2.4130  2.4962  2.3323  2.4734  2.279576e+08  2.41425   \n",
       "2025-02-13 01:00:00  2.4734  2.6061  2.4154  2.5599  2.124787e+08  2.51075   \n",
       "2025-02-14 01:00:00  2.5600  2.8356  2.5300  2.7384  4.075411e+08  2.68280   \n",
       "2025-02-15 01:00:00  2.7384  2.8335  2.7130  2.7619  1.841819e+08  2.77325   \n",
       "2025-02-16 01:00:00  2.7619  2.8054  2.6879  2.7283  1.323880e+08  2.74665   \n",
       "\n",
       "                       diff  candle  7_day_SMA  30_day_SMA  ...  26_day_EMA  \\\n",
       "datetime                                                    ...               \n",
       "2025-01-18 01:00:00 -0.0226       0   2.949286    2.441173  ...    2.599338   \n",
       "2025-01-19 01:00:00 -0.3110       0   3.014157    2.463820  ...    2.625958   \n",
       "2025-01-20 01:00:00  0.1467       1   3.097314    2.492730  ...    2.661465   \n",
       "2025-01-21 01:00:00  0.0685       1   3.169671    2.525087  ...    2.699415   \n",
       "2025-01-22 01:00:00  0.0064       1   3.175014    2.555707  ...    2.735036   \n",
       "2025-01-23 01:00:00 -0.0608       0   3.157057    2.582227  ...    2.763508   \n",
       "2025-01-24 01:00:00 -0.0185       0   3.129729    2.609013  ...    2.788500   \n",
       "2025-01-25 01:00:00  0.0072       1   3.106629    2.640750  ...    2.812167   \n",
       "2025-01-26 01:00:00 -0.0856       0   3.115714    2.669940  ...    2.827732   \n",
       "2025-01-27 01:00:00  0.0330       1   3.108557    2.698970  ...    2.844581   \n",
       "2025-01-28 01:00:00  0.0020       1   3.091900    2.731070  ...    2.860331   \n",
       "2025-01-29 01:00:00  0.0111       1   3.075900    2.764723  ...    2.875736   \n",
       "2025-01-30 01:00:00  0.0593       1   3.077071    2.799523  ...    2.894393   \n",
       "2025-01-31 01:00:00 -0.0915       0   3.067814    2.822967  ...    2.904890   \n",
       "2025-02-01 01:00:00 -0.1583       0   3.034929    2.838813  ...    2.902883   \n",
       "2025-02-02 01:00:00 -0.2979       0   2.971743    2.842990  ...    2.878966   \n",
       "2025-02-03 01:00:00  0.1200       1   2.921014    2.852323  ...    2.865716   \n",
       "2025-02-04 01:00:00 -0.1726       0   2.845329    2.856590  ...    2.840656   \n",
       "2025-02-05 01:00:00 -0.1465       0   2.747143    2.855290  ...    2.806607   \n",
       "2025-02-06 01:00:00 -0.0560       0   2.632486    2.857083  ...    2.770933   \n",
       "2025-02-07 01:00:00  0.0717       1   2.541157    2.857873  ...    2.743219   \n",
       "2025-02-08 01:00:00  0.0221       1   2.475614    2.862767  ...    2.719203   \n",
       "2025-02-09 01:00:00 -0.0262       0   2.448871    2.864480  ...    2.695025   \n",
       "2025-02-10 01:00:00  0.0309       1   2.409386    2.859390  ...    2.674927   \n",
       "2025-02-11 01:00:00 -0.0107       0   2.393057    2.856340  ...    2.655532   \n",
       "2025-02-12 01:00:00  0.0604       1   2.406257    2.854680  ...    2.642041   \n",
       "2025-02-13 01:00:00  0.0865       1   2.439814    2.851100  ...    2.635956   \n",
       "2025-02-14 01:00:00  0.1784       1   2.488614    2.837617  ...    2.643545   \n",
       "2025-02-15 01:00:00  0.0235       1   2.537600    2.821510  ...    2.652312   \n",
       "2025-02-16 01:00:00 -0.0336       0   2.585529    2.802713  ...    2.657941   \n",
       "\n",
       "                         MACD  Signal_Line  20_day_SMA  20_day_STD  \\\n",
       "datetime                                                             \n",
       "2025-01-18 01:00:00  0.235394     0.133276    2.552550    0.380010   \n",
       "2025-01-19 01:00:00  0.227846     0.152190    2.597550    0.371647   \n",
       "2025-01-20 01:00:00  0.231031     0.167958    2.648635    0.367480   \n",
       "2025-01-21 01:00:00  0.236358     0.181638    2.690685    0.377420   \n",
       "2025-01-22 01:00:00  0.238356     0.192982    2.729580    0.386130   \n",
       "2025-01-23 01:00:00  0.232348     0.200855    2.762815    0.389813   \n",
       "2025-01-24 01:00:00  0.223516     0.205387    2.796855    0.388032   \n",
       "2025-01-25 01:00:00  0.214616     0.207233    2.832285    0.382137   \n",
       "2025-01-26 01:00:00  0.198361     0.205459    2.862400    0.371521   \n",
       "2025-01-27 01:00:00  0.185990     0.201565    2.901600    0.346369   \n",
       "2025-01-28 01:00:00  0.174337     0.196119    2.935805    0.324520   \n",
       "2025-01-29 01:00:00  0.164106     0.189717    2.975610    0.285293   \n",
       "2025-01-30 01:00:00  0.158951     0.183563    3.014920    0.244564   \n",
       "2025-01-31 01:00:00  0.145801     0.176011    3.037905    0.221716   \n",
       "2025-02-01 01:00:00  0.121209     0.165051    3.056565    0.187540   \n",
       "2025-02-02 01:00:00  0.076804     0.147401    3.059405    0.179287   \n",
       "2025-02-03 01:00:00  0.050720     0.128065    3.061045    0.175624   \n",
       "2025-02-04 01:00:00  0.015929     0.105638    3.030270    0.210909   \n",
       "2025-02-05 01:00:00 -0.023190     0.079872    2.987065    0.249550   \n",
       "2025-02-06 01:00:00 -0.058041     0.052290    2.938705    0.279255   \n",
       "2025-02-07 01:00:00 -0.078957     0.026040    2.895060    0.292691   \n",
       "2025-02-08 01:00:00 -0.092673     0.002298    2.868075    0.310831   \n",
       "2025-02-09 01:00:00 -0.104454    -0.019053    2.832450    0.322811   \n",
       "2025-02-10 01:00:00 -0.110028    -0.037248    2.794945    0.324634   \n",
       "2025-02-11 01:00:00 -0.113987    -0.052596    2.756585    0.322020   \n",
       "2025-02-12 01:00:00 -0.110980    -0.064272    2.724285    0.316055   \n",
       "2025-02-13 01:00:00 -0.100458    -0.071510    2.697235    0.305087   \n",
       "2025-02-14 01:00:00 -0.076831    -0.072574    2.678755    0.289702   \n",
       "2025-02-15 01:00:00 -0.055570    -0.069173    2.665735    0.279107   \n",
       "2025-02-16 01:00:00 -0.040959    -0.063530    2.649390    0.264277   \n",
       "\n",
       "                     Upper_Band  Lower_Band   lag_1   lag_2   lag_3  \n",
       "datetime                                                             \n",
       "2025-01-18 01:00:00    3.312570    1.792530  3.2922  3.2451  3.1429  \n",
       "2025-01-19 01:00:00    3.340844    1.854256  3.2697  3.2922  3.2451  \n",
       "2025-01-20 01:00:00    3.383594    1.913676  2.9587  3.2697  3.2922  \n",
       "2025-01-21 01:00:00    3.445524    1.935846  3.1053  2.9587  3.2697  \n",
       "2025-01-22 01:00:00    3.501839    1.957321  3.1738  3.1053  2.9587  \n",
       "2025-01-23 01:00:00    3.542442    1.983188  3.1803  3.1738  3.1053  \n",
       "2025-01-24 01:00:00    3.572919    2.020791  3.1194  3.1803  3.1738  \n",
       "2025-01-25 01:00:00    3.596559    2.068011  3.1009  3.1194  3.1803  \n",
       "2025-01-26 01:00:00    3.605442    2.119358  3.1080  3.1009  3.1194  \n",
       "2025-01-27 01:00:00    3.594337    2.208863  3.0223  3.1080  3.1009  \n",
       "2025-01-28 01:00:00    3.584845    2.286765  3.0552  3.0223  3.1080  \n",
       "2025-01-29 01:00:00    3.546195    2.405025  3.0572  3.0552  3.0223  \n",
       "2025-01-30 01:00:00    3.504048    2.525792  3.0683  3.0572  3.0552  \n",
       "2025-01-31 01:00:00    3.481337    2.594473  3.1276  3.0683  3.0572  \n",
       "2025-02-01 01:00:00    3.431646    2.681484  3.0361  3.1276  3.0683  \n",
       "2025-02-02 01:00:00    3.417979    2.700831  2.8778  3.0361  3.1276  \n",
       "2025-02-03 01:00:00    3.412293    2.709797  2.5800  2.8778  3.0361  \n",
       "2025-02-04 01:00:00    3.452087    2.608453  2.7001  2.5800  2.8778  \n",
       "2025-02-05 01:00:00    3.486166    2.487964  2.5274  2.7001  2.5800  \n",
       "2025-02-06 01:00:00    3.497215    2.380195  2.3810  2.5274  2.7001  \n",
       "2025-02-07 01:00:00    3.480441    2.309679  2.3250  2.3810  2.5274  \n",
       "2025-02-08 01:00:00    3.489738    2.246412  2.3968  2.3250  2.3810  \n",
       "2025-02-09 01:00:00    3.478072    2.186828  2.4190  2.3968  2.3250  \n",
       "2025-02-10 01:00:00    3.444213    2.145677  2.3928  2.4190  2.3968  \n",
       "2025-02-11 01:00:00    3.400624    2.112546  2.4237  2.3928  2.4190  \n",
       "2025-02-12 01:00:00    3.356396    2.092174  2.4131  2.4237  2.3928  \n",
       "2025-02-13 01:00:00    3.307408    2.087062  2.4734  2.4131  2.4237  \n",
       "2025-02-14 01:00:00    3.258159    2.099351  2.5599  2.4734  2.4131  \n",
       "2025-02-15 01:00:00    3.223949    2.107521  2.7384  2.5599  2.4734  \n",
       "2025-02-16 01:00:00    3.177944    2.120836  2.7619  2.7384  2.5599  \n",
       "\n",
       "[30 rows x 24 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_input = prepare_last_30_days(df_val_1, \"close\", scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chidi\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 22 variables whereas the saved optimizer has 41 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model_sv_1 = load_model(\"rnn_cnn_hybrid_model_xrpusdt_daily_ovft.keras\")  # Change \"your_model.h5\" to your actual model filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted value for the next day: 1.3928344249725342\n"
     ]
    }
   ],
   "source": [
    "# Predict the next day's value\n",
    "next_day_prediction = model_sv_1.predict(X_input)\n",
    "\n",
    "print(f\"Predicted value for the next day: {next_day_prediction[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted value for the next day: 0.43444517254829407\n"
     ]
    }
   ],
   "source": [
    "# Predict the next day's value\n",
    "next_day_prediction = model_sv_1.predict(X_input)\n",
    "\n",
    "print(f\"Predicted value for the next day: {next_day_prediction[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">148,992</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m10,304\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_13 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   │         \u001b[38;5;34m148,992\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    │          \u001b[38;5;34m16,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)                    │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,481</span> (705.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m180,481\u001b[0m (705.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,289</span> (704.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m180,289\u001b[0m (704.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the model\n",
    "model_2 = build_rnn_cnn_hybrid_model()\n",
    "model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0162 - mae: 0.1195\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0100 - mae: 0.1073\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0181 - mae: 0.1184\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0093 - mae: 0.1055\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0081 - mae: 0.1016\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0147 - mae: 0.1147\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0081 - mae: 0.0986\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0158 - mae: 0.1156\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0073 - mae: 0.0933\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0140 - mae: 0.1086\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model_2.fit(X_train, y_train, batch_size=batch_size, epochs=1, shuffle=False)\n",
    "    \n",
    "    # Reset states for each GRU layer\n",
    "    for layer in model_2.layers:\n",
    "        if hasattr(layer, 'reset_states'):\n",
    "            layer.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save(\"rnn_cnn_hybrid_model_xrpusdt_daily_2.keras\")  # Saves in TensorFlow SavedModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Predicted value for the next day: 1.3755455017089844\n"
     ]
    }
   ],
   "source": [
    "# Predict the next day's value\n",
    "next_day_prediction = model_2.predict(X_input)\n",
    "\n",
    "print(f\"Predicted value for the next day: {next_day_prediction[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (32,1) doesn't match the broadcast shape (32,23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[280], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_day_prediction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1125\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[1;32m-> 1125\u001b[0m         \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_\u001b[49m\n\u001b[0;32m   1126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[0;32m   1127\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (32,1) doesn't match the broadcast shape (32,23)"
     ]
    }
   ],
   "source": [
    "y_pred = scaler.inverse_transform(next_day_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = next_day_prediction.reshape(-1, 1)  # Ensure it's 2D\n",
    "\n",
    "# Apply inverse transformation only to the relevant column\n",
    "y_pred_original = scaler.inverse_transform(np.hstack([np.zeros((y_pred.shape[0], 22)), y_pred]))[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.19135862, 1.19135862, 1.19135862, 1.19135862, 1.19135862,\n",
       "       1.19135862, 1.19135862, 1.19135862, 1.19135862, 1.19135862,\n",
       "       1.19135862, 1.19135862, 1.19135862, 1.19135862, 1.19135862,\n",
       "       1.19135862, 1.19135862, 1.19135862, 1.19135862, 1.19135862,\n",
       "       1.19135862, 1.19135862, 1.19135862, 1.19135862, 1.19135862,\n",
       "       1.19135862, 1.19135862, 1.19135862, 1.19135862, 1.19135862,\n",
       "       1.19135857, 1.19135857])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,120</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_8                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,592</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_9                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">37,632</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │           \u001b[38;5;34m1,120\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_8                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,592\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_9                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_14 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   │          \u001b[38;5;34m37,632\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)                    │           \u001b[38;5;34m4,128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)                    │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │              \u001b[38;5;34m17\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,209</span> (180.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,209\u001b[0m (180.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,113</span> (180.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,113\u001b[0m (180.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, BatchNormalization, ReLU, MaxPooling1D,\n",
    "    Bidirectional, GRU, Dropout, Dense\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Updated parameters for smaller dataset\n",
    "num_features = 23    # Corrected number of features (OHLC, volume, indicators)\n",
    "seq_length = 30       # 30-day window\n",
    "batch_size = 32       # Keep stateful RNN compatibility\n",
    "cnn_filters = [16, 32]  # Reduced filters for smaller dataset\n",
    "kernel_sizes = [3, 5]\n",
    "rnn_units = 64        # Reduced GRU units\n",
    "dropout_rate = 0.5     # Increased dropout\n",
    "recurrent_dropout_rate = 0.3  # Increased recurrent dropout\n",
    "\n",
    "def build_optimized_model():\n",
    "    inputs = Input(batch_shape=(batch_size, seq_length, num_features))\n",
    "\n",
    "    # Simplified CNN Architecture\n",
    "    x = Conv1D(filters=cnn_filters[0], kernel_size=kernel_sizes[0], \n",
    "               padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv1D(filters=cnn_filters[1], kernel_size=kernel_sizes[1],\n",
    "               padding=\"valid\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Reduced GRU Capacity with increased dropout\n",
    "    x = Bidirectional(GRU(rnn_units, return_sequences=False, stateful=True,\n",
    "                        recurrent_dropout=recurrent_dropout_rate))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Simplified Dense Layers with aggressive dropout\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    \n",
    "    # Adjusted learning rate schedule for smaller dataset\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.0005,  # Reduced initial rate\n",
    "        decay_steps=500,               # More frequent adjustments\n",
    "        decay_rate=0.9, \n",
    "        staircase=True\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=tf.keras.losses.Huber(delta=1.0),\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and verify the model\n",
    "model = build_optimized_model()\n",
    "model.summary()\n",
    "\n",
    "# Early stopping callback (to be used during training)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,          # Increased patience for small dataset\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - loss: 0.0987 - mae: 0.3399 - val_loss: 0.3211 - val_mae: 0.7017\n",
      "Epoch 2/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0483 - mae: 0.2168 - val_loss: 0.2660 - val_mae: 0.6208\n",
      "Epoch 3/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0443 - mae: 0.2118 - val_loss: 0.2508 - val_mae: 0.5728\n",
      "Epoch 4/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0415 - mae: 0.2066 - val_loss: 0.2225 - val_mae: 0.5217\n",
      "Epoch 5/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0369 - mae: 0.1844 - val_loss: 0.1693 - val_mae: 0.4204\n",
      "Epoch 6/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0367 - mae: 0.1862 - val_loss: 0.2362 - val_mae: 0.4878\n",
      "Epoch 7/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0333 - mae: 0.1778 - val_loss: 0.2167 - val_mae: 0.4507\n",
      "Epoch 8/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0274 - mae: 0.1602 - val_loss: 0.2342 - val_mae: 0.4426\n",
      "Epoch 9/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0240 - mae: 0.1505 - val_loss: 0.1987 - val_mae: 0.3904\n",
      "Epoch 10/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0216 - mae: 0.1437 - val_loss: 0.2028 - val_mae: 0.4005\n",
      "Epoch 11/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0185 - mae: 0.1287 - val_loss: 0.1856 - val_mae: 0.3743\n",
      "Epoch 12/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0176 - mae: 0.1209 - val_loss: 0.1944 - val_mae: 0.3935\n",
      "Epoch 13/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0129 - mae: 0.1102 - val_loss: 0.1805 - val_mae: 0.3974\n",
      "Epoch 14/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0125 - mae: 0.1077 - val_loss: 0.1833 - val_mae: 0.3800\n",
      "Epoch 15/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0111 - mae: 0.1016 - val_loss: 0.1999 - val_mae: 0.4068\n",
      "Epoch 16/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0107 - mae: 0.0999 - val_loss: 0.1861 - val_mae: 0.3900\n",
      "Epoch 17/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0095 - mae: 0.0960 - val_loss: 0.1938 - val_mae: 0.3925\n",
      "Epoch 18/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0101 - mae: 0.0991 - val_loss: 0.1866 - val_mae: 0.3730\n",
      "Epoch 19/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0085 - mae: 0.0929 - val_loss: 0.2201 - val_mae: 0.4188\n",
      "Epoch 20/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0089 - mae: 0.0945 - val_loss: 0.2080 - val_mae: 0.3983\n"
     ]
    }
   ],
   "source": [
    "# Example training implementation\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    shuffle=False  # Important for stateful RNNs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Predicted value for the next day: 1.419382095336914\n"
     ]
    }
   ],
   "source": [
    "# Predict the next day's value\n",
    "next_day_prediction = model.predict(X_input)\n",
    "\n",
    "print(f\"Predicted value for the next day: {next_day_prediction[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"rnn_cnn_hybrid_model_xrpusdt_daily_21.keras\")  # Saves in TensorFlow SavedModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "hourly_finetune_daily_model = clone_model(model)  # Copy architecture\n",
    "hourly_finetune_daily_model.set_weights(model.get_weights())  # Copy weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in hourly_finetune_daily_model.layers[:-1]:  # Freeze all layers except the last one\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hourly_finetune_daily_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),  # Small LR for stability\n",
    "    loss=tf.keras.losses.Huber(delta=1.0),\n",
    "    metrics=[\"mae\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr = pd.read_csv('xrpusdt_hourly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f1925746-3204-491f-b14c-24bcbc0b39c1",
       "rows": [
        [
         "0",
         "2024-01-01 01:00:00",
         "BINANCE:XRPUSDT",
         "0.6155",
         "0.6172",
         "0.6146",
         "0.6162",
         "14498728.0",
         "0.6159",
         "0.0006999999999999",
         "1"
        ],
        [
         "1",
         "2024-01-01 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6161",
         "0.619",
         "0.615",
         "0.6185",
         "9029149.0",
         "0.617",
         "0.0024",
         "1"
        ],
        [
         "2",
         "2024-01-01 03:00:00",
         "BINANCE:XRPUSDT",
         "0.6184",
         "0.6186",
         "0.6149",
         "0.6154",
         "6553752.0",
         "0.61675",
         "-0.003",
         "0"
        ],
        [
         "3",
         "2024-01-01 04:00:00",
         "BINANCE:XRPUSDT",
         "0.6154",
         "0.6157",
         "0.6112",
         "0.613",
         "8001610.0",
         "0.61345",
         "-0.0023999999999999",
         "0"
        ],
        [
         "4",
         "2024-01-01 05:00:00",
         "BINANCE:XRPUSDT",
         "0.6129",
         "0.6134",
         "0.6093",
         "0.6116",
         "10514620.0",
         "0.61135",
         "-0.0012999999999999",
         "0"
        ],
        [
         "5",
         "2024-01-01 06:00:00",
         "BINANCE:XRPUSDT",
         "0.6116",
         "0.6124",
         "0.6083",
         "0.6087",
         "7622323.0",
         "0.61035",
         "-0.0029",
         "0"
        ],
        [
         "6",
         "2024-01-01 07:00:00",
         "BINANCE:XRPUSDT",
         "0.6087",
         "0.6129",
         "0.6084",
         "0.6127",
         "5515748.0",
         "0.61065",
         "0.004",
         "1"
        ],
        [
         "7",
         "2024-01-01 08:00:00",
         "BINANCE:XRPUSDT",
         "0.6127",
         "0.6153",
         "0.6127",
         "0.615",
         "3607686.0",
         "0.614",
         "0.0022999999999999",
         "1"
        ],
        [
         "8",
         "2024-01-01 09:00:00",
         "BINANCE:XRPUSDT",
         "0.615",
         "0.6163",
         "0.6143",
         "0.6161",
         "4436880.0",
         "0.6153",
         "0.0010999999999999",
         "1"
        ],
        [
         "9",
         "2024-01-01 10:00:00",
         "BINANCE:XRPUSDT",
         "0.6161",
         "0.6177",
         "0.6152",
         "0.6175",
         "4422313.0",
         "0.6164499999999999",
         "0.0014",
         "1"
        ],
        [
         "10",
         "2024-01-01 11:00:00",
         "BINANCE:XRPUSDT",
         "0.6175",
         "0.619",
         "0.6173",
         "0.6188",
         "4925516.0",
         "0.61815",
         "0.0012999999999999",
         "1"
        ],
        [
         "11",
         "2024-01-01 12:00:00",
         "BINANCE:XRPUSDT",
         "0.6188",
         "0.6207",
         "0.6177",
         "0.6205",
         "6067891.0",
         "0.6192",
         "0.0017",
         "1"
        ],
        [
         "12",
         "2024-01-01 13:00:00",
         "BINANCE:XRPUSDT",
         "0.6205",
         "0.6213",
         "0.6191",
         "0.6196",
         "5869164.0",
         "0.6202",
         "-0.0009",
         "0"
        ],
        [
         "13",
         "2024-01-01 14:00:00",
         "BINANCE:XRPUSDT",
         "0.6197",
         "0.6216",
         "0.619",
         "0.621",
         "5679263.0",
         "0.6203000000000001",
         "0.0012999999999999",
         "1"
        ],
        [
         "14",
         "2024-01-01 15:00:00",
         "BINANCE:XRPUSDT",
         "0.6209",
         "0.621",
         "0.6183",
         "0.6193",
         "6224809.0",
         "0.61965",
         "-0.0016",
         "0"
        ],
        [
         "15",
         "2024-01-01 16:00:00",
         "BINANCE:XRPUSDT",
         "0.6193",
         "0.6219",
         "0.619",
         "0.6213",
         "5328702.0",
         "0.62045",
         "0.002",
         "1"
        ],
        [
         "16",
         "2024-01-01 17:00:00",
         "BINANCE:XRPUSDT",
         "0.6213",
         "0.622",
         "0.6198",
         "0.6209",
         "6248474.0",
         "0.6209",
         "-0.0003999999999999",
         "0"
        ],
        [
         "17",
         "2024-01-01 18:00:00",
         "BINANCE:XRPUSDT",
         "0.6208",
         "0.6237",
         "0.6206",
         "0.6232",
         "4728255.0",
         "0.62215",
         "0.0023999999999999",
         "1"
        ],
        [
         "18",
         "2024-01-01 19:00:00",
         "BINANCE:XRPUSDT",
         "0.6233",
         "0.6254",
         "0.6231",
         "0.6237",
         "7106348.0",
         "0.62425",
         "0.0004",
         "1"
        ],
        [
         "19",
         "2024-01-01 20:00:00",
         "BINANCE:XRPUSDT",
         "0.6238",
         "0.626",
         "0.6237",
         "0.6258",
         "6658451.0",
         "0.62485",
         "0.002",
         "1"
        ],
        [
         "20",
         "2024-01-01 21:00:00",
         "BINANCE:XRPUSDT",
         "0.6258",
         "0.6289",
         "0.6255",
         "0.6276",
         "11038195.0",
         "0.6272",
         "0.0018",
         "1"
        ],
        [
         "21",
         "2024-01-01 22:00:00",
         "BINANCE:XRPUSDT",
         "0.6277",
         "0.6283",
         "0.6266",
         "0.6282",
         "6331827.0",
         "0.6274500000000001",
         "0.0004999999999999",
         "1"
        ],
        [
         "22",
         "2024-01-01 23:00:00",
         "BINANCE:XRPUSDT",
         "0.6281",
         "0.6286",
         "0.6257",
         "0.6269",
         "5483173.0",
         "0.6271500000000001",
         "-0.0011999999999999",
         "0"
        ],
        [
         "23",
         "2024-01-02 00:00:00",
         "BINANCE:XRPUSDT",
         "0.6269",
         "0.6309",
         "0.6269",
         "0.6294",
         "9976523.0",
         "0.6289",
         "0.0024999999999999",
         "1"
        ],
        [
         "24",
         "2024-01-02 01:00:00",
         "BINANCE:XRPUSDT",
         "0.6295",
         "0.6327",
         "0.6287",
         "0.6314",
         "27514701.0",
         "0.6307",
         "0.0019",
         "1"
        ],
        [
         "25",
         "2024-01-02 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6314",
         "0.6344",
         "0.631",
         "0.6323",
         "14919889.0",
         "0.6327",
         "0.0009",
         "1"
        ],
        [
         "26",
         "2024-01-02 03:00:00",
         "BINANCE:XRPUSDT",
         "0.6323",
         "0.6354",
         "0.6317",
         "0.634",
         "11160952.0",
         "0.6335500000000001",
         "0.0017",
         "1"
        ],
        [
         "27",
         "2024-01-02 04:00:00",
         "BINANCE:XRPUSDT",
         "0.634",
         "0.6348",
         "0.6317",
         "0.6339",
         "9683658.0",
         "0.6332500000000001",
         "-9.9999999999989e-05",
         "0"
        ],
        [
         "28",
         "2024-01-02 05:00:00",
         "BINANCE:XRPUSDT",
         "0.6339",
         "0.6343",
         "0.6327",
         "0.6334",
         "8161331.0",
         "0.6335",
         "-0.0005",
         "0"
        ],
        [
         "29",
         "2024-01-02 06:00:00",
         "BINANCE:XRPUSDT",
         "0.6333",
         "0.6343",
         "0.6289",
         "0.6301",
         "11923852.0",
         "0.6315999999999999",
         "-0.0031999999999999",
         "0"
        ],
        [
         "30",
         "2024-01-02 07:00:00",
         "BINANCE:XRPUSDT",
         "0.6301",
         "0.6306",
         "0.6277",
         "0.6282",
         "23775317.0",
         "0.6291500000000001",
         "-0.0019",
         "0"
        ],
        [
         "31",
         "2024-01-02 08:00:00",
         "BINANCE:XRPUSDT",
         "0.6282",
         "0.6321",
         "0.6281",
         "0.6307",
         "17415828.0",
         "0.6301",
         "0.0025",
         "1"
        ],
        [
         "32",
         "2024-01-02 09:00:00",
         "BINANCE:XRPUSDT",
         "0.6307",
         "0.6334",
         "0.6291",
         "0.6329",
         "24496588.0",
         "0.63125",
         "0.0021999999999999",
         "1"
        ],
        [
         "33",
         "2024-01-02 10:00:00",
         "BINANCE:XRPUSDT",
         "0.6328",
         "0.6405",
         "0.6313",
         "0.6377",
         "25115367.0",
         "0.6358999999999999",
         "0.0049",
         "1"
        ],
        [
         "34",
         "2024-01-02 11:00:00",
         "BINANCE:XRPUSDT",
         "0.6377",
         "0.6381",
         "0.634",
         "0.6366",
         "21126103.0",
         "0.63605",
         "-0.0010999999999999",
         "0"
        ],
        [
         "35",
         "2024-01-02 12:00:00",
         "BINANCE:XRPUSDT",
         "0.6366",
         "0.6367",
         "0.63",
         "0.632",
         "22137767.0",
         "0.6333500000000001",
         "-0.0046",
         "0"
        ],
        [
         "36",
         "2024-01-02 13:00:00",
         "BINANCE:XRPUSDT",
         "0.632",
         "0.634",
         "0.6278",
         "0.6298",
         "18026227.0",
         "0.6309",
         "-0.0021999999999999",
         "0"
        ],
        [
         "37",
         "2024-01-02 14:00:00",
         "BINANCE:XRPUSDT",
         "0.6297",
         "0.6329",
         "0.6288",
         "0.6317",
         "10862122.0",
         "0.63085",
         "0.002",
         "1"
        ],
        [
         "38",
         "2024-01-02 15:00:00",
         "BINANCE:XRPUSDT",
         "0.6316",
         "0.6324",
         "0.623",
         "0.6254",
         "27806283.0",
         "0.6276999999999999",
         "-0.0062",
         "0"
        ],
        [
         "39",
         "2024-01-02 16:00:00",
         "BINANCE:XRPUSDT",
         "0.6253",
         "0.6282",
         "0.6218",
         "0.6256",
         "16160486.0",
         "0.625",
         "0.0003",
         "1"
        ],
        [
         "40",
         "2024-01-02 17:00:00",
         "BINANCE:XRPUSDT",
         "0.6255",
         "0.6272",
         "0.6224",
         "0.6272",
         "12275659.0",
         "0.6248",
         "0.0017",
         "1"
        ],
        [
         "41",
         "2024-01-02 18:00:00",
         "BINANCE:XRPUSDT",
         "0.6271",
         "0.6272",
         "0.6213",
         "0.6228",
         "11171014.0",
         "0.62425",
         "-0.0042999999999999",
         "0"
        ],
        [
         "42",
         "2024-01-02 19:00:00",
         "BINANCE:XRPUSDT",
         "0.6229",
         "0.6264",
         "0.6226",
         "0.6256",
         "11738872.0",
         "0.6245",
         "0.0027",
         "1"
        ],
        [
         "43",
         "2024-01-02 20:00:00",
         "BINANCE:XRPUSDT",
         "0.6256",
         "0.6292",
         "0.625",
         "0.6276",
         "11702497.0",
         "0.6271",
         "0.002",
         "1"
        ],
        [
         "44",
         "2024-01-02 21:00:00",
         "BINANCE:XRPUSDT",
         "0.6276",
         "0.629",
         "0.6253",
         "0.6259",
         "9379802.0",
         "0.62715",
         "-0.0017",
         "0"
        ],
        [
         "45",
         "2024-01-02 22:00:00",
         "BINANCE:XRPUSDT",
         "0.6259",
         "0.628",
         "0.6237",
         "0.6272",
         "8102154.0",
         "0.62585",
         "0.0012999999999999",
         "1"
        ],
        [
         "46",
         "2024-01-02 23:00:00",
         "BINANCE:XRPUSDT",
         "0.6272",
         "0.6283",
         "0.6248",
         "0.6273",
         "7594774.0",
         "0.6265499999999999",
         "9.9999999999989e-05",
         "1"
        ],
        [
         "47",
         "2024-01-03 00:00:00",
         "BINANCE:XRPUSDT",
         "0.6273",
         "0.628",
         "0.624",
         "0.6246",
         "8818251.0",
         "0.626",
         "-0.0026999999999999",
         "0"
        ],
        [
         "48",
         "2024-01-03 01:00:00",
         "BINANCE:XRPUSDT",
         "0.6245",
         "0.6273",
         "0.6226",
         "0.6266",
         "18827999.0",
         "0.62495",
         "0.0020999999999999",
         "1"
        ],
        [
         "49",
         "2024-01-03 02:00:00",
         "BINANCE:XRPUSDT",
         "0.6265",
         "0.6279",
         "0.6264",
         "0.6274",
         "6271377.0",
         "0.62715",
         "0.0009",
         "1"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 10023
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6155</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.6146</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>14498728.0</td>\n",
       "      <td>0.61590</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>9029149.0</td>\n",
       "      <td>0.61700</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.6186</td>\n",
       "      <td>0.6149</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>6553752.0</td>\n",
       "      <td>0.61675</td>\n",
       "      <td>-0.0030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.6157</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>8001610.0</td>\n",
       "      <td>0.61345</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 05:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.6129</td>\n",
       "      <td>0.6134</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>10514620.0</td>\n",
       "      <td>0.61135</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10018</th>\n",
       "      <td>2025-02-21 11:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6787</td>\n",
       "      <td>2.6601</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>4420326.0</td>\n",
       "      <td>2.66940</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>2025-02-21 12:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6758</td>\n",
       "      <td>2.6773</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>6597897.0</td>\n",
       "      <td>2.66400</td>\n",
       "      <td>-0.0251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>2025-02-21 13:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6508</td>\n",
       "      <td>2.6661</td>\n",
       "      <td>2.6454</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>4207626.0</td>\n",
       "      <td>2.65575</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10021</th>\n",
       "      <td>2025-02-21 14:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.6655</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>16416120.0</td>\n",
       "      <td>2.69075</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>2025-02-21 15:00:00</td>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.7012</td>\n",
       "      <td>2.6793</td>\n",
       "      <td>2.6851</td>\n",
       "      <td>3973640.0</td>\n",
       "      <td>2.69025</td>\n",
       "      <td>-0.0136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10023 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime           symbol    open    high     low   close  \\\n",
       "0      2024-01-01 01:00:00  BINANCE:XRPUSDT  0.6155  0.6172  0.6146  0.6162   \n",
       "1      2024-01-01 02:00:00  BINANCE:XRPUSDT  0.6161  0.6190  0.6150  0.6185   \n",
       "2      2024-01-01 03:00:00  BINANCE:XRPUSDT  0.6184  0.6186  0.6149  0.6154   \n",
       "3      2024-01-01 04:00:00  BINANCE:XRPUSDT  0.6154  0.6157  0.6112  0.6130   \n",
       "4      2024-01-01 05:00:00  BINANCE:XRPUSDT  0.6129  0.6134  0.6093  0.6116   \n",
       "...                    ...              ...     ...     ...     ...     ...   \n",
       "10018  2025-02-21 11:00:00  BINANCE:XRPUSDT  2.6670  2.6787  2.6601  2.6757   \n",
       "10019  2025-02-21 12:00:00  BINANCE:XRPUSDT  2.6758  2.6773  2.6507  2.6507   \n",
       "10020  2025-02-21 13:00:00  BINANCE:XRPUSDT  2.6508  2.6661  2.6454  2.6656   \n",
       "10021  2025-02-21 14:00:00  BINANCE:XRPUSDT  2.6656  2.7160  2.6655  2.6987   \n",
       "10022  2025-02-21 15:00:00  BINANCE:XRPUSDT  2.6987  2.7012  2.6793  2.6851   \n",
       "\n",
       "           volume    av_pr    diff  candle  \n",
       "0      14498728.0  0.61590  0.0007       1  \n",
       "1       9029149.0  0.61700  0.0024       1  \n",
       "2       6553752.0  0.61675 -0.0030       0  \n",
       "3       8001610.0  0.61345 -0.0024       0  \n",
       "4      10514620.0  0.61135 -0.0013       0  \n",
       "...           ...      ...     ...     ...  \n",
       "10018   4420326.0  2.66940  0.0087       1  \n",
       "10019   6597897.0  2.66400 -0.0251       0  \n",
       "10020   4207626.0  2.65575  0.0148       1  \n",
       "10021  16416120.0  2.69075  0.0331       1  \n",
       "10022   3973640.0  2.69025 -0.0136       0  \n",
       "\n",
       "[10023 rows x 10 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the daily dataset\n",
    "\n",
    "# Moving Averages\n",
    "df_hr['7_hour_SMA'] = df_hr['close'].rolling(window=7).mean()\n",
    "df_hr['30_hour_SMA'] = df_hr['close'].rolling(window=30).mean()\n",
    "df_hr['7_hour_EMA'] = df_hr['close'].ewm(span=7, adjust=False).mean()\n",
    "df_hr['30_hour_EMA'] = df_hr['close'].ewm(span=30, adjust=False).mean()\n",
    "\n",
    "# RSI\n",
    "def calculate_rsi(data, period=14):\n",
    "    delta = data['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "df_hr['RSI'] = calculate_rsi(df_hr)\n",
    "\n",
    "# MACD\n",
    "df_hr['12_hour_EMA'] = df_hr['close'].ewm(span=12, adjust=False).mean()\n",
    "df_hr['26_hour_EMA'] = df_hr['close'].ewm(span=26, adjust=False).mean()\n",
    "df_hr['MACD'] = df_hr['12_hour_EMA'] - df_hr['26_hour_EMA']\n",
    "df_hr['Signal_Line'] = df_hr['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# Bollinger Bands\n",
    "window = 20\n",
    "df_hr['20_hour_SMA'] = df_hr['close'].rolling(window=window).mean()\n",
    "df_hr['20_hour_STD'] = df_hr['close'].rolling(window=window).std()\n",
    "df_hr['Upper_Band'] = df_hr['20_hour_SMA'] + (df_hr['20_hour_STD'] * 2)\n",
    "df_hr['Lower_Band'] = df_hr['20_hour_SMA'] - (df_hr['20_hour_STD'] * 2)\n",
    "\n",
    "# Lag Features\n",
    "df_hr['lag_1'] = df_hr['close'].shift(1)\n",
    "df_hr['lag_2'] = df_hr['close'].shift(2)\n",
    "df_hr['lag_3'] = df_hr['close'].shift(3)\n",
    "\n",
    "# Drop rows with NaN values (created by rolling windows and shifts)\n",
    "df_hr.dropna(inplace=True)\n",
    "\n",
    "# Save the updated dataset\n",
    "df_hr.to_csv('xrpusdt_hourly_dataset_with_features_val.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr.to_csv('xrpusdt_hourly_dataset_with_features_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       open    high     low   close      volume    av_pr  \\\n",
      "datetime                                                                   \n",
      "2024-01-02 06:00:00  0.6333  0.6343  0.6289  0.6301  11923852.0  0.63160   \n",
      "2024-01-02 07:00:00  0.6301  0.6306  0.6277  0.6282  23775317.0  0.62915   \n",
      "2024-01-02 08:00:00  0.6282  0.6321  0.6281  0.6307  17415828.0  0.63010   \n",
      "2024-01-02 09:00:00  0.6307  0.6334  0.6291  0.6329  24496588.0  0.63125   \n",
      "2024-01-02 10:00:00  0.6328  0.6405  0.6313  0.6377  25115367.0  0.63590   \n",
      "\n",
      "                       diff  candle  7_hour_SMA  30_hour_SMA  ...  \\\n",
      "datetime                                                      ...   \n",
      "2024-01-02 06:00:00 -0.0032       0    0.632071     0.622200  ...   \n",
      "2024-01-02 07:00:00 -0.0019       0    0.631900     0.622600  ...   \n",
      "2024-01-02 08:00:00  0.0025       1    0.631800     0.623007  ...   \n",
      "2024-01-02 09:00:00  0.0022       1    0.631886     0.623590  ...   \n",
      "2024-01-02 10:00:00  0.0049       1    0.632414     0.624413  ...   \n",
      "\n",
      "                     26_hour_EMA      MACD  Signal_Line  20_hour_SMA  \\\n",
      "datetime                                                               \n",
      "2024-01-02 06:00:00     0.625405  0.004086     0.003606     0.626065   \n",
      "2024-01-02 07:00:00     0.625612  0.003680     0.003621     0.626535   \n",
      "2024-01-02 08:00:00     0.625989  0.003520     0.003601     0.627045   \n",
      "2024-01-02 09:00:00     0.626501  0.003530     0.003587     0.627710   \n",
      "2024-01-02 10:00:00     0.627330  0.003880     0.003646     0.628545   \n",
      "\n",
      "                     20_hour_STD  Upper_Band  Lower_Band   lag_1   lag_2  \\\n",
      "datetime                                                                   \n",
      "2024-01-02 06:00:00     0.005335    0.636734    0.615396  0.6334  0.6339   \n",
      "2024-01-02 07:00:00     0.005068    0.636672    0.616398  0.6301  0.6334   \n",
      "2024-01-02 08:00:00     0.004941    0.636927    0.617163  0.6282  0.6301   \n",
      "2024-01-02 09:00:00     0.004778    0.637267    0.618153  0.6307  0.6282   \n",
      "2024-01-02 10:00:00     0.004998    0.638541    0.618549  0.6329  0.6307   \n",
      "\n",
      "                      lag_3  \n",
      "datetime                     \n",
      "2024-01-02 06:00:00  0.6340  \n",
      "2024-01-02 07:00:00  0.6339  \n",
      "2024-01-02 08:00:00  0.6334  \n",
      "2024-01-02 09:00:00  0.6301  \n",
      "2024-01-02 10:00:00  0.6282  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df_hr = pd.read_csv(\"xrpusdt_hourly_dataset_with_features_val.csv\", parse_dates=[\"datetime\"])\n",
    "\n",
    "# Set datetime as index\n",
    "df_hr.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "# Ensure the index is sorted (important for time series modeling)\n",
    "df_hr.sort_index(inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7_hour_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_hour_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_hour_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_hour_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_hour_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_hour_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_hour_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_hour_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ff7f4324-8a51-4f8c-85ee-664369c0b818",
       "rows": [
        [
         "2024-01-02 06:00:00",
         "0.6333",
         "0.6343",
         "0.6289",
         "0.6301",
         "11923852.0",
         "0.6315999999999999",
         "-0.0031999999999999",
         "0",
         "0.6320714285714286",
         "0.6222",
         "0.6312545845409113",
         "0.6246032198379134",
         "72.00000000000017",
         "0.6294907180053422",
         "0.6254046292085815",
         "0.0040860887967606",
         "0.0036064719040772",
         "0.626065",
         "0.0053347199403628",
         "0.6367344398807256",
         "0.6153955601192743",
         "0.6334",
         "0.6339",
         "0.634"
        ],
        [
         "2024-01-02 07:00:00",
         "0.6301",
         "0.6306",
         "0.6277",
         "0.6282",
         "23775317.0",
         "0.6291500000000001",
         "-0.0019",
         "0",
         "0.6318999999999999",
         "0.6226",
         "0.6304909384056835",
         "0.6248352701709513",
         "66.97674418604647",
         "0.6292921460045203",
         "0.6256116937116496",
         "0.0036804522928707",
         "0.0036212679818359",
         "0.626535",
         "0.0050684031534907",
         "0.6366718063069815",
         "0.6163981936930184",
         "0.6301",
         "0.6334",
         "0.6339"
        ],
        [
         "2024-01-02 08:00:00",
         "0.6282",
         "0.6321",
         "0.6281",
         "0.6307",
         "17415828.0",
         "0.6301",
         "0.0025",
         "1",
         "0.6318",
         "0.6230066666666667",
         "0.6305432038042627",
         "0.6252136398373416",
         "67.28110599078352",
         "0.6295087389269018",
         "0.6259886052885644",
         "0.0035201336383374",
         "0.0036010411131362",
         "0.6270450000000001",
         "0.0049407515942201",
         "0.6369265031884404",
         "0.6171634968115598",
         "0.6282",
         "0.6301",
         "0.6334"
        ],
        [
         "2024-01-02 09:00:00",
         "0.6307",
         "0.6334",
         "0.6291",
         "0.6329",
         "24496588.0",
         "0.63125",
         "0.0021999999999999",
         "1",
         "0.6318857142857144",
         "0.62359",
         "0.631132402853197",
         "0.6257095340413842",
         "69.65811965811965",
         "0.6300304713996862",
         "0.6265005604523745",
         "0.0035299109473116",
         "0.0035868150799713",
         "0.62771",
         "0.0047783392842899",
         "0.63726667856858",
         "0.61815332143142",
         "0.6307",
         "0.6282",
         "0.6301"
        ],
        [
         "2024-01-02 10:00:00",
         "0.6328",
         "0.6405",
         "0.6313",
         "0.6377",
         "25115367.0",
         "0.6358999999999999",
         "0.0049",
         "1",
         "0.6324142857142857",
         "0.6244133333333333",
         "0.6327743021398978",
         "0.6264831124903272",
         "72.79693486590041",
         "0.6312103988766575",
         "0.6273301485670134",
         "0.0038802503096441",
         "0.0036455021259058",
         "0.628545",
         "0.0049981549227268",
         "0.6385413098454537",
         "0.6185486901545464",
         "0.6329",
         "0.6307",
         "0.6282"
        ],
        [
         "2024-01-02 11:00:00",
         "0.6377",
         "0.6381",
         "0.634",
         "0.6366",
         "21126103.0",
         "0.63605",
         "-0.0010999999999999",
         "0",
         "0.6328000000000001",
         "0.6252466666666667",
         "0.6337307266049234",
         "0.6271358149103061",
         "67.7165354330709",
         "0.6320395682802487",
         "0.6280168042287161",
         "0.0040227640515325",
         "0.0037209545110312",
         "0.62941",
         "0.0048073299296627",
         "0.6390246598593254",
         "0.6197953401406746",
         "0.6377",
         "0.6329",
         "0.6307"
        ],
        [
         "2024-01-02 12:00:00",
         "0.6366",
         "0.6367",
         "0.63",
         "0.632",
         "22137767.0",
         "0.6333500000000001",
         "-0.0046",
         "0",
         "0.6326",
         "0.6260233333333335",
         "0.6332980449536926",
         "0.6274496333031896",
         "56.46258503401363",
         "0.6320334808525181",
         "0.6283118557673297",
         "0.0037216250851883",
         "0.0037210886258626",
         "0.629945",
         "0.0044385245296156",
         "0.6388220490592312",
         "0.6210679509407687",
         "0.6366",
         "0.6377",
         "0.6329"
        ],
        [
         "2024-01-02 13:00:00",
         "0.632",
         "0.634",
         "0.6278",
         "0.6298",
         "18026227.0",
         "0.6309",
         "-0.0021999999999999",
         "0",
         "0.6325571428571429",
         "0.6265933333333334",
         "0.6324235337152694",
         "0.6276012698642741",
         "54.7854785478548",
         "0.6316898684136691",
         "0.6284220886734534",
         "0.0032677797402157",
         "0.0036304268487332",
         "0.63039",
         "0.0038970839300551",
         "0.6381841678601103",
         "0.6225958321398897",
         "0.632",
         "0.6366",
         "0.6377"
        ],
        [
         "2024-01-02 14:00:00",
         "0.6297",
         "0.6329",
         "0.6288",
         "0.6317",
         "10862122.0",
         "0.63085",
         "0.002",
         "1",
         "0.6330571428571429",
         "0.62715",
         "0.632242650286452",
         "0.627865704066579",
         "53.872053872054",
         "0.6316914271192585",
         "0.6286648969198643",
         "0.0030265301993942",
         "0.0035096475188654",
         "0.630815",
         "0.0035166184415084",
         "0.637848236883017",
         "0.6237817631169831",
         "0.6298",
         "0.632",
         "0.6366"
        ],
        [
         "2024-01-02 15:00:00",
         "0.6316",
         "0.6324",
         "0.623",
         "0.6254",
         "27806283.0",
         "0.6276999999999999",
         "-0.0062",
         "0",
         "0.6323",
         "0.6274599999999999",
         "0.630531987714839",
         "0.6277066263848643",
         "41.17647058823536",
         "0.6307235152547572",
         "0.628423052703578",
         "0.0023004625511792",
         "0.0032678105253282",
         "0.6309",
         "0.0033522969344677",
         "0.6376045938689355",
         "0.6241954061310645",
         "0.6317",
         "0.6298",
         "0.632"
        ],
        [
         "2024-01-02 16:00:00",
         "0.6253",
         "0.6282",
         "0.6218",
         "0.6256",
         "16160486.0",
         "0.625",
         "0.0003",
         "1",
         "0.6312571428571429",
         "0.62773",
         "0.6292989907861293",
         "0.6275707150051957",
         "39.93993993994015",
         "0.6299352821386407",
         "0.6282139376884982",
         "0.0017213444501424",
         "0.002958517310291",
         "0.63089",
         "0.0033685698980271",
         "0.6376271397960542",
         "0.6241528602039457",
         "0.6254",
         "0.6317",
         "0.6298"
        ],
        [
         "2024-01-02 17:00:00",
         "0.6255",
         "0.6272",
         "0.6224",
         "0.6272",
         "12275659.0",
         "0.6248",
         "0.0017",
         "1",
         "0.6297571428571429",
         "0.62801",
         "0.628774243089597",
         "0.6275467979080863",
         "39.759036144578346",
         "0.6295144695019267",
         "0.6281388311930538",
         "0.0013756383088728",
         "0.0026419415100074",
         "0.63087",
         "0.0033902491757515",
         "0.6376504983515031",
         "0.624089501648497",
         "0.6256",
         "0.6254",
         "0.6317"
        ],
        [
         "2024-01-02 18:00:00",
         "0.6271",
         "0.6272",
         "0.6213",
         "0.6228",
         "11171014.0",
         "0.62425",
         "-0.0042999999999999",
         "0",
         "0.6277857142857143",
         "0.6280866666666667",
         "0.6272806823171977",
         "0.6272405528817582",
         "35.20000000000009",
         "0.628481474193938",
         "0.6277433622157906",
         "0.0007381119781473",
         "0.0022611756036354",
         "0.6306",
         "0.0038038761394412",
         "0.6382077522788825",
         "0.6229922477211176",
         "0.6272",
         "0.6256",
         "0.6254"
        ],
        [
         "2024-01-02 19:00:00",
         "0.6229",
         "0.6264",
         "0.6226",
         "0.6256",
         "11738872.0",
         "0.6245",
         "0.0027",
         "1",
         "0.6268714285714285",
         "0.6282866666666667",
         "0.6268605117378983",
         "0.6271347107603544",
         "40.201005025125774",
         "0.6280381704717937",
         "0.6275845946442506",
         "0.000453575827543",
         "0.0018996556484169",
         "0.630535",
         "0.0038807588785808",
         "0.6382965177571616",
         "0.6227734822428383",
         "0.6228",
         "0.6272",
         "0.6256"
        ],
        [
         "2024-01-02 20:00:00",
         "0.6256",
         "0.6292",
         "0.625",
         "0.6276",
         "11702497.0",
         "0.6271",
         "0.002",
         "1",
         "0.6265571428571429",
         "0.6285066666666667",
         "0.6270453838034237",
         "0.6271647294209768",
         "46.75324675324684",
         "0.6279707596299793",
         "0.6275857357817136",
         "0.0003850238482656",
         "0.0015967292883866",
         "0.630445",
         "0.0039290383181209",
         "0.638303076636242",
         "0.6225869233637581",
         "0.6256",
         "0.6228",
         "0.6272"
        ],
        [
         "2024-01-02 21:00:00",
         "0.6276",
         "0.629",
         "0.6253",
         "0.6259",
         "9379802.0",
         "0.62715",
         "-0.0017",
         "0",
         "0.6257285714285714",
         "0.6287266666666667",
         "0.6267590378525678",
         "0.6270831339744622",
         "46.99738903394262",
         "0.627652181225367",
         "0.6274608664645496",
         "0.0001913147608174",
         "0.0013156463828728",
         "0.63017",
         "0.0040493144319033",
         "0.6382686288638066",
         "0.6220713711361934",
         "0.6276",
         "0.6256",
         "0.6228"
        ],
        [
         "2024-01-02 22:00:00",
         "0.6259",
         "0.628",
         "0.6237",
         "0.6272",
         "8102154.0",
         "0.62585",
         "0.0012999999999999",
         "1",
         "0.6259857142857143",
         "0.6289233333333333",
         "0.6268692783894259",
         "0.6270906737180454",
         "45.28301886792447",
         "0.6275826148830028",
         "0.6274415430227311",
         "0.0001410718602716",
         "0.0010807314783526",
         "0.629915",
         "0.0040686574793425",
         "0.6380523149586851",
         "0.6217776850413149",
         "0.6259",
         "0.6276",
         "0.6256"
        ],
        [
         "2024-01-02 23:00:00",
         "0.6272",
         "0.6283",
         "0.6248",
         "0.6273",
         "7594774.0",
         "0.6265499999999999",
         "9.9999999999989e-05",
         "1",
         "0.6262285714285714",
         "0.6291366666666666",
         "0.6269769587920694",
         "0.6271041786394619",
         "41.999999999999964",
         "0.6275391356702331",
         "0.6274310583543807",
         "0.0001080773158523",
         "0.0008862006458525",
         "0.62958",
         "0.0039896708741712",
         "0.6375593417483425",
         "0.6216006582516576",
         "0.6272",
         "0.6259",
         "0.6276"
        ],
        [
         "2024-01-03 00:00:00",
         "0.6273",
         "0.628",
         "0.624",
         "0.6246",
         "8818251.0",
         "0.626",
         "-0.0026999999999999",
         "0",
         "0.6258571428571429",
         "0.6291833333333333",
         "0.6263827190940521",
         "0.6269426187272386",
         "30.09118541033436",
         "0.6270869609517357",
         "0.6272213503281303",
         "-0.0001343893763946",
         "0.0006820826414031",
         "0.629115",
         "0.0040016148056292",
         "0.6371182296112584",
         "0.6211117703887415",
         "0.6273",
         "0.6272",
         "0.6259"
        ],
        [
         "2024-01-03 01:00:00",
         "0.6245",
         "0.6273",
         "0.6226",
         "0.6266",
         "18827999.0",
         "0.62495",
         "0.0020999999999999",
         "1",
         "0.6264000000000001",
         "0.62928",
         "0.6264370393205391",
         "0.6269205142932232",
         "35.207100591715985",
         "0.6270120438822379",
         "0.6271753243778985",
         "-0.0001632804956606",
         "0.0005130100139903",
         "0.628775",
         "0.0039061186820031",
         "0.6365872373640064",
         "0.6209627626359936",
         "0.6246",
         "0.6273",
         "0.6272"
        ],
        [
         "2024-01-03 02:00:00",
         "0.6265",
         "0.6279",
         "0.6264",
         "0.6274",
         "6271377.0",
         "0.62715",
         "0.0009",
         "1",
         "0.6266571428571428",
         "0.6293333333333334",
         "0.6266777794904044",
         "0.6269514488549508",
         "42.33333333333323",
         "0.6270717294388166",
         "0.6271919670165726",
         "-0.000120237577756",
         "0.000386360495641",
         "0.6286400000000001",
         "0.0039045722186336",
         "0.6364491444372674",
         "0.6208308555627328",
         "0.6266",
         "0.6246",
         "0.6273"
        ],
        [
         "2024-01-03 03:00:00",
         "0.6275",
         "0.6277",
         "0.626",
         "0.6261",
         "9053381.0",
         "0.62685",
         "-0.0013999999999999",
         "0",
         "0.6264428571428571",
         "0.6292833333333333",
         "0.6265333346178033",
         "0.6268965166707604",
         "43.64261168384871",
         "0.6269222326020756",
         "0.6271110805709006",
         "-0.000188847968825",
         "0.0002713188027478",
         "0.6285350000000001",
         "0.003945053531756",
         "0.6364251070635121",
         "0.6206448929364881",
         "0.6274",
         "0.6266",
         "0.6246"
        ],
        [
         "2024-01-03 04:00:00",
         "0.6261",
         "0.6266",
         "0.6253",
         "0.6261",
         "6870125.0",
         "0.62595",
         "0.0",
         "0",
         "0.6264714285714286",
         "0.6292133333333333",
         "0.6264250009633524",
         "0.6268451284984533",
         "39.705882352941046",
         "0.6267957352786794",
         "0.6270361857137968",
         "-0.0002404504351174",
         "0.0001689649551748",
         "0.628305",
         "0.0039462807273364",
         "0.6361975614546729",
         "0.6204124385453271",
         "0.6261",
         "0.6274",
         "0.6266"
        ],
        [
         "2024-01-03 05:00:00",
         "0.6261",
         "0.6392",
         "0.626",
         "0.6336",
         "33778327.0",
         "0.6326",
         "0.0075",
         "1",
         "0.6273857142857143",
         "0.6294366666666668",
         "0.6282187507225143",
         "0.6272809266598435",
         "64.43661971831008",
         "0.6278425452358056",
         "0.6275223941794416",
         "0.000320151056364",
         "0.0001992021754126",
         "0.62834",
         "0.0039920183524522",
         "0.6363240367049044",
         "0.6203559632950956",
         "0.6261",
         "0.6261",
         "0.6274"
        ],
        [
         "2024-01-03 06:00:00",
         "0.6336",
         "0.6394",
         "0.632",
         "0.6359",
         "26582626.0",
         "0.6356999999999999",
         "0.0022999999999999",
         "1",
         "0.6286142857142857",
         "0.6296533333333334",
         "0.6301390630418857",
         "0.6278369959075956",
         "66.88524590163945",
         "0.6290821536610663",
         "0.6281429575735571",
         "0.0009391960875092",
         "0.0003472009578319",
         "0.62825",
         "0.0037848034086468",
         "0.6358196068172937",
         "0.6206803931827063",
         "0.6336",
         "0.6261",
         "0.6261"
        ],
        [
         "2024-01-03 07:00:00",
         "0.6359",
         "0.6382",
         "0.6312",
         "0.6344",
         "27536252.0",
         "0.6347",
         "-0.0015",
         "0",
         "0.6300142857142857",
         "0.6297533333333333",
         "0.6312042972814143",
         "0.6282604155264604",
         "61.84210526315792",
         "0.6299002838670561",
         "0.6286064421977381",
         "0.001293841669318",
         "0.0005365291001291",
         "0.6281399999999999",
         "0.0035543005826151",
         "0.6352486011652303",
         "0.6210313988347695",
         "0.6359",
         "0.6336",
         "0.6261"
        ],
        [
         "2024-01-03 08:00:00",
         "0.6344",
         "0.6359",
         "0.6306",
         "0.6319",
         "15083136.0",
         "0.6332500000000001",
         "-0.0024999999999999",
         "0",
         "0.6307714285714285",
         "0.6297400000000001",
         "0.6313782229610607",
         "0.628495227427979",
         "65.96491228070184",
         "0.6302079325028936",
         "0.62885040944235",
         "0.0013575230605435",
         "0.000700727892212",
         "0.628135",
         "0.0035486505960197",
         "0.6352323011920394",
         "0.6210376988079606",
         "0.6344",
         "0.6359",
         "0.6336"
        ],
        [
         "2024-01-03 09:00:00",
         "0.6318",
         "0.6332",
         "0.6298",
         "0.6309",
         "17252117.0",
         "0.6315",
         "-0.0009",
         "0",
         "0.6312714285714286",
         "0.6296366666666667",
         "0.6312586672207956",
         "0.6286503740455288",
         "59.92509363295881",
         "0.6303144044255253",
         "0.6290022309651389",
         "0.0013121734603864",
         "0.0008230170058469",
         "0.62819",
         "0.0035841610631102",
         "0.6353583221262205",
         "0.6210216778737796",
         "0.6319",
         "0.6344",
         "0.6359"
        ],
        [
         "2024-01-03 10:00:00",
         "0.631",
         "0.6355",
         "0.6307",
         "0.6352",
         "11798344.0",
         "0.6331",
         "0.0041999999999999",
         "1",
         "0.6325714285714286",
         "0.62968",
         "0.6322440004155967",
         "0.6290729305587205",
         "63.10344827586205",
         "0.6310660345139061",
         "0.6294613249677212",
         "0.0016047095461848",
         "0.0009793555139145",
         "0.628365",
         "0.0038408161139336",
         "0.6360466322278672",
         "0.6206833677721327",
         "0.6309",
         "0.6319",
         "0.6344"
        ],
        [
         "2024-01-03 11:00:00",
         "0.6352",
         "0.6363",
         "0.6325",
         "0.633",
         "13608603.0",
         "0.6344",
         "-0.0021999999999999",
         "0",
         "0.6335571428571428",
         "0.6296666666666667",
         "0.6324330003116976",
         "0.6293262898775127",
         "62.03389830508485",
         "0.6313635676656129",
         "0.6297234490441863",
         "0.0016401186214265",
         "0.0011115081354169",
         "0.628745",
         "0.0039074119850678",
         "0.6365598239701358",
         "0.6209301760298642",
         "0.6352",
         "0.6309",
         "0.6319"
        ],
        [
         "2024-01-03 12:00:00",
         "0.6329",
         "0.6332",
         "0.6115",
         "0.6185",
         "52855571.0",
         "0.62235",
         "-0.0143999999999999",
         "0",
         "0.6314000000000001",
         "0.62928",
         "0.6289497502337732",
         "0.6286278195628345",
         "39.81264637002344",
         "0.6293845572555186",
         "0.6288920824483207",
         "0.0004924748071978",
         "0.0009877014697731",
         "0.6283900000000001",
         "0.0044876321267749",
         "0.63736526425355",
         "0.6194147357464502",
         "0.633",
         "0.6352",
         "0.6309"
        ],
        [
         "2024-01-03 13:00:00",
         "0.6186",
         "0.6187",
         "0.5",
         "0.5623",
         "304657095.0",
         "0.55935",
         "-0.0563",
         "0",
         "0.6208857142857143",
         "0.6270833333333333",
         "0.6122873126753299",
         "0.6243486053974905",
         "17.105263157894683",
         "0.6190638561392849",
         "0.6239593356002969",
         "-0.0048954794610119",
         "-0.0001889347163839",
         "0.6251450000000001",
         "0.0154553848561797",
         "0.6560557697123596",
         "0.5942342302876406",
         "0.6185",
         "0.633",
         "0.6352"
        ],
        [
         "2024-01-03 14:00:00",
         "0.5624",
         "0.5698",
         "0.5452",
         "0.5684",
         "149597826.0",
         "0.5575",
         "0.006",
         "1",
         "0.6114571428571429",
         "0.6250066666666666",
         "0.6013154845064974",
         "0.6207390179524911",
         "22.50489236790601",
         "0.6112694167332411",
         "0.6198438292595343",
         "-0.0085744125262932",
         "-0.0018660302783657",
         "0.622425",
         "0.020006627191482",
         "0.662438254382964",
         "0.582411745617036",
         "0.5623",
         "0.6185",
         "0.633"
        ],
        [
         "2024-01-03 15:00:00",
         "0.5685",
         "0.5699",
         "0.5569",
         "0.5615",
         "84067912.0",
         "0.5633999999999999",
         "-0.007",
         "0",
         "0.6014",
         "0.6226266666666667",
         "0.591361613379873",
         "0.6169171458265239",
         "19.607843137254847",
         "0.6036125833896655",
         "0.6155220641291984",
         "-0.0119094807395329",
         "-0.0038747203705991",
         "0.6192200000000001",
         "0.0241719411062104",
         "0.667563882212421",
         "0.5708761177875792",
         "0.5684",
         "0.5623",
         "0.6185"
        ],
        [
         "2024-01-03 16:00:00",
         "0.5615",
         "0.5774",
         "0.5611",
         "0.5765",
         "61459632.0",
         "0.56925",
         "0.015",
         "1",
         "0.5936285714285715",
         "0.6205866666666667",
         "0.5876462100349047",
         "0.6143095880312643",
         "29.018961253091533",
         "0.5994414167143324",
         "0.6126315408603689",
         "-0.0131901241460364",
         "-0.0057378011256866",
         "0.616665",
         "0.0258798697426153",
         "0.6684247394852307",
         "0.5649052605147693",
         "0.5615",
         "0.5684",
         "0.5623"
        ],
        [
         "2024-01-03 17:00:00",
         "0.5766",
         "0.5798",
         "0.5713",
         "0.5752",
         "58008462.0",
         "0.57555",
         "-0.0013999999999999",
         "0",
         "0.5850571428571428",
         "0.61854",
         "0.5845346575261785",
         "0.6117863888034409",
         "29.018961253091533",
         "0.5957119679890506",
         "0.6098588341299712",
         "-0.0141468661409206",
         "-0.0074196141287334",
         "0.6141300000000001",
         "0.027367981676635",
         "0.6688659633532702",
         "0.5593940366467299",
         "0.5765",
         "0.5615",
         "0.5684"
        ],
        [
         "2024-01-03 18:00:00",
         "0.5751",
         "0.5766",
         "0.5708",
         "0.5749",
         "31726381.0",
         "0.5737",
         "-0.0001999999999999",
         "0",
         "0.5767571428571429",
         "0.6166366666666666",
         "0.5821259931446339",
         "0.6094066217838642",
         "28.94736842105263",
         "0.5925101267599658",
         "0.6072692908610845",
         "-0.0147591641011186",
         "-0.0088875241232104",
         "0.611515",
         "0.0285274802879425",
         "0.6685699605758851",
         "0.5544600394241149",
         "0.5752",
         "0.5765",
         "0.5615"
        ],
        [
         "2024-01-03 19:00:00",
         "0.575",
         "0.5781",
         "0.5662",
         "0.5706",
         "29202441.0",
         "0.5721499999999999",
         "-0.0043999999999999",
         "0",
         "0.5699142857142857",
         "0.6146633333333332",
         "0.5792444948584754",
         "0.6069029687655504",
         "23.395270270270245",
         "0.5891393380276634",
         "0.6045530470935968",
         "-0.0154137090659334",
         "-0.010192761111755",
         "0.60868",
         "0.0296706943845802",
         "0.6680213887691605",
         "0.5493386112308395",
         "0.5749",
         "0.5752",
         "0.5765"
        ],
        [
         "2024-01-03 20:00:00",
         "0.5708",
         "0.5793",
         "0.5695",
         "0.5738",
         "20418032.0",
         "0.5744",
         "0.003",
         "1",
         "0.5715571428571428",
         "0.6127333333333334",
         "0.5778833711438566",
         "0.6047672933613214",
         "23.973176865046085",
         "0.5867794398695613",
         "0.6022750436051822",
         "-0.0154956037356209",
         "-0.0112533296365282",
         "0.60614",
         "0.030401513120238",
         "0.6669430262404761",
         "0.545336973759524",
         "0.5706",
         "0.5749",
         "0.5752"
        ],
        [
         "2024-01-03 21:00:00",
         "0.5738",
         "0.5896",
         "0.5734",
         "0.5883",
         "34819083.0",
         "0.5815",
         "0.0145",
         "1",
         "0.5744",
         "0.6114966666666668",
         "0.5804875283578925",
         "0.6037048873380104",
         "32.57747543461832",
         "0.5870133721973211",
         "0.6012398551899836",
         "-0.0142264829926624",
         "-0.0118479603077551",
         "0.604225",
         "0.0302507916381843",
         "0.6647265832763688",
         "0.5437234167236312",
         "0.5738",
         "0.5706",
         "0.5749"
        ],
        [
         "2024-01-03 22:00:00",
         "0.5882",
         "0.59",
         "0.5838",
         "0.5898",
         "18695093.0",
         "0.5869",
         "0.0016",
         "1",
         "0.5784428571428571",
         "0.6103033333333333",
         "0.5828156462684194",
         "0.6028077978323323",
         "33.96801218583396",
         "0.587442084166964",
         "0.600392458509244",
         "-0.01295037434228",
         "-0.0120684431146601",
         "0.602345",
         "0.0299010732952937",
         "0.6621471465905876",
         "0.5425428534094124",
         "0.5883",
         "0.5738",
         "0.5706"
        ],
        [
         "2024-01-03 23:00:00",
         "0.5899",
         "0.5899",
         "0.5791",
         "0.5831",
         "16854222.0",
         "0.5845",
         "-0.0068",
         "0",
         "0.5793857142857143",
         "0.6088333333333333",
         "0.5828867347013146",
         "0.6015363270044399",
         "32.55474452554742",
         "0.5867740712182002",
         "0.5991115356567074",
         "-0.0123374644385071",
         "-0.0121222473794295",
         "0.600195",
         "0.0296479603452173",
         "0.6594909206904348",
         "0.5408990793095653",
         "0.5898",
         "0.5883",
         "0.5738"
        ],
        [
         "2024-01-04 00:00:00",
         "0.583",
         "0.5832",
         "0.5793",
         "0.5823",
         "14489283.0",
         "0.58125",
         "-0.0006999999999999",
         "0",
         "0.5804",
         "0.6074833333333333",
         "0.5827400510259859",
         "0.6002952736493148",
         "30.18726591760301",
         "0.5860857525692463",
         "0.5978662367191735",
         "-0.0117804841499271",
         "-0.012053894733529",
         "0.598005",
         "0.0292487242186912",
         "0.6565024484373825",
         "0.5395075515626175",
         "0.5831",
         "0.5898",
         "0.5883"
        ],
        [
         "2024-01-04 01:00:00",
         "0.5823",
         "0.5834",
         "0.5795",
         "0.5805",
         "19673870.0",
         "0.58145",
         "-0.0018",
         "0",
         "0.5812",
         "0.6059800000000001",
         "0.5821800382694895",
         "0.5990181592203269",
         "30.277986476333595",
         "0.5852264060201315",
         "0.5965798488140496",
         "-0.011353442793918",
         "-0.0119138043456068",
         "0.59535",
         "0.0282402381829824",
         "0.651830476365965",
         "0.5388695236340351",
         "0.5823",
         "0.5831",
         "0.5898"
        ],
        [
         "2024-01-04 02:00:00",
         "0.5804",
         "0.5813",
         "0.5692",
         "0.5733",
         "26680854.0",
         "0.57525",
         "-0.0070999999999999",
         "0",
         "0.5815857142857144",
         "0.60417",
         "0.5799600287021172",
         "0.5973589231415961",
         "32.034976152623216",
         "0.5833915743247267",
         "0.5948554155685644",
         "-0.0114638412438377",
         "-0.011823811725253",
         "0.59222",
         "0.0269489497891262",
         "0.6461178995782524",
         "0.5383221004217476",
         "0.5805",
         "0.5823",
         "0.5831"
        ],
        [
         "2024-01-04 03:00:00",
         "0.5733",
         "0.5829",
         "0.573",
         "0.5823",
         "10520151.0",
         "0.57795",
         "0.009",
         "1",
         "0.5828",
         "0.6027166666666667",
         "0.5805450215265879",
         "0.5963873797131061",
         "62.72264631043257",
         "0.5832236398132302",
         "0.5939253847857078",
         "-0.0107017449724775",
         "-0.0115993983746979",
         "0.589615",
         "0.0251125943450063",
         "0.6398401886900127",
         "0.5393898113099873",
         "0.5733",
         "0.5805",
         "0.5823"
        ],
        [
         "2024-01-04 04:00:00",
         "0.5824",
         "0.5833",
         "0.5793",
         "0.5814",
         "15516419.0",
         "0.5813",
         "-0.001",
         "0",
         "0.5818142857142857",
         "0.60119",
         "0.5807587661449409",
         "0.59542045198968",
         "58.85558583106268",
         "0.582943079841964",
         "0.592997578505285",
         "-0.0100544986633209",
         "-0.0112904184324225",
         "0.5870900000000001",
         "0.0230949504619973",
         "0.6332799009239948",
         "0.5409000990760054",
         "0.5823",
         "0.5733",
         "0.5805"
        ],
        [
         "2024-01-04 05:00:00",
         "0.5813",
         "0.5836",
         "0.5801",
         "0.5832",
         "12754912.0",
         "0.58185",
         "0.0019",
         "1",
         "0.5808714285714285",
         "0.59972",
         "0.5813690746087057",
         "0.5946320357322813",
         "65.88579795021965",
         "0.5829826060201234",
         "0.592271831949338",
         "-0.0092892259292145",
         "-0.0108901799317809",
         "0.584705",
         "0.0206680652469609",
         "0.6260411304939221",
         "0.543368869506078",
         "0.5814",
         "0.5823",
         "0.5733"
        ],
        [
         "2024-01-04 06:00:00",
         "0.5832",
         "0.5845",
         "0.58",
         "0.5813",
         "11706882.0",
         "0.5822499999999999",
         "-0.0019",
         "0",
         "0.5806142857142857",
         "0.5982766666666667",
         "0.5813518059565292",
         "0.5937719043947148",
         "54.34782608695655",
         "0.5827237435554891",
         "0.5914591036567944",
         "-0.0087353601013053",
         "-0.0104592159656858",
         "0.5820100000000001",
         "0.016909664007369",
         "0.6158293280147382",
         "0.5481906719852621",
         "0.5832",
         "0.5814",
         "0.5823"
        ],
        [
         "2024-01-04 07:00:00",
         "0.5813",
         "0.5826",
         "0.5788",
         "0.5798",
         "17740931.0",
         "0.5807",
         "-0.0015",
         "0",
         "0.5802571428571428",
         "0.5967166666666668",
         "0.580963854467397",
         "0.5928704912079591",
         "54.1516245487364",
         "0.5822739368546446",
         "0.5905954663488838",
         "-0.0083215294942392",
         "-0.0100316786713965",
         "0.57935",
         "0.0119123774638865",
         "0.6031747549277731",
         "0.555525245072227",
         "0.5813",
         "0.5832",
         "0.5814"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 9994
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "      <th>7_hour_SMA</th>\n",
       "      <th>30_hour_SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>26_hour_EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_hour_SMA</th>\n",
       "      <th>20_hour_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-02 06:00:00</th>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.6343</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>11923852.0</td>\n",
       "      <td>0.63160</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>0</td>\n",
       "      <td>0.632071</td>\n",
       "      <td>0.622200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625405</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.626065</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.636734</td>\n",
       "      <td>0.615396</td>\n",
       "      <td>0.6334</td>\n",
       "      <td>0.6339</td>\n",
       "      <td>0.6340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02 07:00:00</th>\n",
       "      <td>0.6301</td>\n",
       "      <td>0.6306</td>\n",
       "      <td>0.6277</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>23775317.0</td>\n",
       "      <td>0.62915</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631900</td>\n",
       "      <td>0.622600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625612</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.626535</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.636672</td>\n",
       "      <td>0.616398</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>0.6334</td>\n",
       "      <td>0.6339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02 08:00:00</th>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.6321</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.6307</td>\n",
       "      <td>17415828.0</td>\n",
       "      <td>0.63010</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.631800</td>\n",
       "      <td>0.623007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625989</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.627045</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.636927</td>\n",
       "      <td>0.617163</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>0.6334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02 09:00:00</th>\n",
       "      <td>0.6307</td>\n",
       "      <td>0.6334</td>\n",
       "      <td>0.6291</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>24496588.0</td>\n",
       "      <td>0.63125</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>1</td>\n",
       "      <td>0.631886</td>\n",
       "      <td>0.623590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626501</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>0.627710</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.637267</td>\n",
       "      <td>0.618153</td>\n",
       "      <td>0.6307</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.6301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02 10:00:00</th>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>0.6313</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>25115367.0</td>\n",
       "      <td>0.63590</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632414</td>\n",
       "      <td>0.624413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627330</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>0.628545</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.638541</td>\n",
       "      <td>0.618549</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6307</td>\n",
       "      <td>0.6282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 11:00:00</th>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6787</td>\n",
       "      <td>2.6601</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>4420326.0</td>\n",
       "      <td>2.66940</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>1</td>\n",
       "      <td>2.663429</td>\n",
       "      <td>2.682510</td>\n",
       "      <td>...</td>\n",
       "      <td>2.671651</td>\n",
       "      <td>-0.002811</td>\n",
       "      <td>-0.001474</td>\n",
       "      <td>2.675855</td>\n",
       "      <td>0.019314</td>\n",
       "      <td>2.714482</td>\n",
       "      <td>2.637228</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6715</td>\n",
       "      <td>2.6596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 12:00:00</th>\n",
       "      <td>2.6758</td>\n",
       "      <td>2.6773</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>6597897.0</td>\n",
       "      <td>2.66400</td>\n",
       "      <td>-0.0251</td>\n",
       "      <td>0</td>\n",
       "      <td>2.662786</td>\n",
       "      <td>2.680247</td>\n",
       "      <td>...</td>\n",
       "      <td>2.670099</td>\n",
       "      <td>-0.004050</td>\n",
       "      <td>-0.001989</td>\n",
       "      <td>2.674750</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>2.714976</td>\n",
       "      <td>2.634524</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 13:00:00</th>\n",
       "      <td>2.6508</td>\n",
       "      <td>2.6661</td>\n",
       "      <td>2.6454</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>4207626.0</td>\n",
       "      <td>2.65575</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>1</td>\n",
       "      <td>2.665229</td>\n",
       "      <td>2.679593</td>\n",
       "      <td>...</td>\n",
       "      <td>2.669766</td>\n",
       "      <td>-0.003786</td>\n",
       "      <td>-0.002348</td>\n",
       "      <td>2.673660</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>2.713624</td>\n",
       "      <td>2.633696</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 14:00:00</th>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.6655</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>16416120.0</td>\n",
       "      <td>2.69075</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>1</td>\n",
       "      <td>2.669829</td>\n",
       "      <td>2.680013</td>\n",
       "      <td>...</td>\n",
       "      <td>2.671909</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>-0.002058</td>\n",
       "      <td>2.673400</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>2.712596</td>\n",
       "      <td>2.634204</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 15:00:00</th>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.7012</td>\n",
       "      <td>2.6793</td>\n",
       "      <td>2.6851</td>\n",
       "      <td>3973640.0</td>\n",
       "      <td>2.69025</td>\n",
       "      <td>-0.0136</td>\n",
       "      <td>0</td>\n",
       "      <td>2.673471</td>\n",
       "      <td>2.679360</td>\n",
       "      <td>...</td>\n",
       "      <td>2.672887</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.001587</td>\n",
       "      <td>2.672050</td>\n",
       "      <td>0.017622</td>\n",
       "      <td>2.707294</td>\n",
       "      <td>2.636806</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.6507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9994 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close      volume    av_pr  \\\n",
       "datetime                                                                   \n",
       "2024-01-02 06:00:00  0.6333  0.6343  0.6289  0.6301  11923852.0  0.63160   \n",
       "2024-01-02 07:00:00  0.6301  0.6306  0.6277  0.6282  23775317.0  0.62915   \n",
       "2024-01-02 08:00:00  0.6282  0.6321  0.6281  0.6307  17415828.0  0.63010   \n",
       "2024-01-02 09:00:00  0.6307  0.6334  0.6291  0.6329  24496588.0  0.63125   \n",
       "2024-01-02 10:00:00  0.6328  0.6405  0.6313  0.6377  25115367.0  0.63590   \n",
       "...                     ...     ...     ...     ...         ...      ...   \n",
       "2025-02-21 11:00:00  2.6670  2.6787  2.6601  2.6757   4420326.0  2.66940   \n",
       "2025-02-21 12:00:00  2.6758  2.6773  2.6507  2.6507   6597897.0  2.66400   \n",
       "2025-02-21 13:00:00  2.6508  2.6661  2.6454  2.6656   4207626.0  2.65575   \n",
       "2025-02-21 14:00:00  2.6656  2.7160  2.6655  2.6987  16416120.0  2.69075   \n",
       "2025-02-21 15:00:00  2.6987  2.7012  2.6793  2.6851   3973640.0  2.69025   \n",
       "\n",
       "                       diff  candle  7_hour_SMA  30_hour_SMA  ...  \\\n",
       "datetime                                                      ...   \n",
       "2024-01-02 06:00:00 -0.0032       0    0.632071     0.622200  ...   \n",
       "2024-01-02 07:00:00 -0.0019       0    0.631900     0.622600  ...   \n",
       "2024-01-02 08:00:00  0.0025       1    0.631800     0.623007  ...   \n",
       "2024-01-02 09:00:00  0.0022       1    0.631886     0.623590  ...   \n",
       "2024-01-02 10:00:00  0.0049       1    0.632414     0.624413  ...   \n",
       "...                     ...     ...         ...          ...  ...   \n",
       "2025-02-21 11:00:00  0.0087       1    2.663429     2.682510  ...   \n",
       "2025-02-21 12:00:00 -0.0251       0    2.662786     2.680247  ...   \n",
       "2025-02-21 13:00:00  0.0148       1    2.665229     2.679593  ...   \n",
       "2025-02-21 14:00:00  0.0331       1    2.669829     2.680013  ...   \n",
       "2025-02-21 15:00:00 -0.0136       0    2.673471     2.679360  ...   \n",
       "\n",
       "                     26_hour_EMA      MACD  Signal_Line  20_hour_SMA  \\\n",
       "datetime                                                               \n",
       "2024-01-02 06:00:00     0.625405  0.004086     0.003606     0.626065   \n",
       "2024-01-02 07:00:00     0.625612  0.003680     0.003621     0.626535   \n",
       "2024-01-02 08:00:00     0.625989  0.003520     0.003601     0.627045   \n",
       "2024-01-02 09:00:00     0.626501  0.003530     0.003587     0.627710   \n",
       "2024-01-02 10:00:00     0.627330  0.003880     0.003646     0.628545   \n",
       "...                          ...       ...          ...          ...   \n",
       "2025-02-21 11:00:00     2.671651 -0.002811    -0.001474     2.675855   \n",
       "2025-02-21 12:00:00     2.670099 -0.004050    -0.001989     2.674750   \n",
       "2025-02-21 13:00:00     2.669766 -0.003786    -0.002348     2.673660   \n",
       "2025-02-21 14:00:00     2.671909 -0.000895    -0.002058     2.673400   \n",
       "2025-02-21 15:00:00     2.672887  0.000295    -0.001587     2.672050   \n",
       "\n",
       "                     20_hour_STD  Upper_Band  Lower_Band   lag_1   lag_2  \\\n",
       "datetime                                                                   \n",
       "2024-01-02 06:00:00     0.005335    0.636734    0.615396  0.6334  0.6339   \n",
       "2024-01-02 07:00:00     0.005068    0.636672    0.616398  0.6301  0.6334   \n",
       "2024-01-02 08:00:00     0.004941    0.636927    0.617163  0.6282  0.6301   \n",
       "2024-01-02 09:00:00     0.004778    0.637267    0.618153  0.6307  0.6282   \n",
       "2024-01-02 10:00:00     0.004998    0.638541    0.618549  0.6329  0.6307   \n",
       "...                          ...         ...         ...     ...     ...   \n",
       "2025-02-21 11:00:00     0.019314    2.714482    2.637228  2.6670  2.6715   \n",
       "2025-02-21 12:00:00     0.020113    2.714976    2.634524  2.6757  2.6670   \n",
       "2025-02-21 13:00:00     0.019982    2.713624    2.633696  2.6507  2.6757   \n",
       "2025-02-21 14:00:00     0.019598    2.712596    2.634204  2.6656  2.6507   \n",
       "2025-02-21 15:00:00     0.017622    2.707294    2.636806  2.6987  2.6656   \n",
       "\n",
       "                      lag_3  \n",
       "datetime                     \n",
       "2024-01-02 06:00:00  0.6340  \n",
       "2024-01-02 07:00:00  0.6339  \n",
       "2024-01-02 08:00:00  0.6334  \n",
       "2024-01-02 09:00:00  0.6301  \n",
       "2024-01-02 10:00:00  0.6282  \n",
       "...                     ...  \n",
       "2025-02-21 11:00:00  2.6596  \n",
       "2025-02-21 12:00:00  2.6715  \n",
       "2025-02-21 13:00:00  2.6670  \n",
       "2025-02-21 14:00:00  2.6757  \n",
       "2025-02-21 15:00:00  2.6507  \n",
       "\n",
       "[9994 rows x 24 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (7995, 24)\n",
      "Test set shape: (1999, 24)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the split point\n",
    "split_point = int(len(df_hr) * 0.8)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train = df_hr.iloc[:split_point]  # First 80% of the data\n",
    "test = df_hr.iloc[split_point:]   # Remaining 20% of the data\n",
    "\n",
    "# Print the shapes of the train and test sets\n",
    "print(f\"Train set shape: {train.shape}\")\n",
    "print(f\"Test set shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chidi\\AppData\\Local\\Temp\\ipykernel_115876\\4209493190.py:30: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")  # Forward then backward fill\n",
      "C:\\Users\\chidi\\AppData\\Local\\Temp\\ipykernel_115876\\4209493190.py:30: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")  # Forward then backward fill\n"
     ]
    }
   ],
   "source": [
    "X_train_hourly, y_train_hourly = preprocess_time_series(train, \"close\", seq_length=30, batch_size=32)\n",
    "X_val_hourly, y_val_hourly = preprocess_time_series(test, \"close\", seq_length=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0796 - mae: 0.2679 - val_loss: 1.4524 - val_mae: 1.9524\n",
      "Epoch 2/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0745 - mae: 0.2585 - val_loss: 1.4531 - val_mae: 1.9531\n",
      "Epoch 3/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0736 - mae: 0.2604 - val_loss: 1.4537 - val_mae: 1.9537\n",
      "Epoch 4/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0777 - mae: 0.2655 - val_loss: 1.4544 - val_mae: 1.9544\n",
      "Epoch 5/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0736 - mae: 0.2602 - val_loss: 1.4551 - val_mae: 1.9551\n",
      "Epoch 6/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0720 - mae: 0.2597 - val_loss: 1.4557 - val_mae: 1.9557\n",
      "Epoch 7/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0735 - mae: 0.2642 - val_loss: 1.4564 - val_mae: 1.9564\n",
      "Epoch 8/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0746 - mae: 0.2617 - val_loss: 1.4571 - val_mae: 1.9571\n",
      "Epoch 9/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0814 - mae: 0.2706 - val_loss: 1.4578 - val_mae: 1.9578\n",
      "Epoch 10/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0712 - mae: 0.2588 - val_loss: 1.4584 - val_mae: 1.9584\n",
      "Epoch 11/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0764 - mae: 0.2699 - val_loss: 1.4591 - val_mae: 1.9591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x206082627b0>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_finetune_daily_model.fit(\n",
    "    X_train_hourly, y_train_hourly,\n",
    "    validation_data=(X_val_hourly, y_val_hourly),\n",
    "    epochs=50, batch_size=32,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977ms/step\n",
      "Predicted value for the next day: 1.3318954706192017\n"
     ]
    }
   ],
   "source": [
    "# Predict the next day's value\n",
    "next_day_prediction = hourly_finetune_daily_model.predict(X_input)\n",
    "\n",
    "print(f\"Predicted value for the next day: {next_day_prediction[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# Get original input shape\n",
    "num_features = hourly_finetune_daily_model.input_shape[-1]\n",
    "\n",
    "# Define new input for 168 hours\n",
    "new_input = Input(batch_shape=(hourly_finetune_daily_model.input_shape[0], 168, num_features))\n",
    "\n",
    "# Use the same feature extractor from the pretrained model\n",
    "x = new_input\n",
    "for layer in hourly_finetune_daily_model.layers[:-1]:  # Exclude the last layer\n",
    "    x = layer(x)\n",
    "\n",
    "# Modify the final output layer to predict 4 values instead of 1\n",
    "new_output = Dense(4, activation='linear')(x)\n",
    "\n",
    "# Create the modified model\n",
    "hourly_finetune_daily_model = Model(new_input, new_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "03b713a7-4586-4987-a327-4b246b796526",
       "rows": [
        [
         "2018-07-01 02:00:00",
         "0.46797",
         "0.46989",
         "0.45007",
         "0.46222",
         "31676174.10000002",
         "0.45998",
         "-0.0057499999999999",
         "0",
         "0.46192714285714287",
         "0.5532916666666666",
         "0.4672347548515338",
         "0.5316441532839548",
         "35.37081941712037",
         "0.4818625021717392",
         "0.5226332992019683",
         "-0.04077079703022912",
         "-0.03959813504052097",
         "0.5036595",
         "0.03874555247481883",
         "0.5811506049496377",
         "0.42616839505036236",
         "0.46796",
         "0.45321",
         "0.44575"
        ],
        [
         "2018-07-02 02:00:00",
         "0.46222",
         "0.4954",
         "0.452",
         "0.4899",
         "39873781.79999994",
         "0.4737",
         "0.0276799999999999",
         "1",
         "0.46316285714285715",
         "0.5481986666666666",
         "0.47290106613865035",
         "0.5289509821043448",
         "39.56015745336302",
         "0.48309904029916395",
         "0.5202086103721929",
         "-0.03710957007302895",
         "-0.03910042204702257",
         "0.5003744999999999",
         "0.03684878252291445",
         "0.5740720650458289",
         "0.426676934954171",
         "0.46222",
         "0.46796",
         "0.45321"
        ],
        [
         "2018-07-03 02:00:00",
         "0.48913",
         "0.52",
         "0.47801",
         "0.4844",
         "44333181.59999998",
         "0.499005",
         "-0.00473",
         "0",
         "0.46764857142857147",
         "0.541342",
         "0.47577579960398775",
         "0.5260767251943871",
         "36.07457095565815",
         "0.4832991879454464",
         "0.5175561207149935",
         "-0.034256932769547055",
         "-0.038131724191527466",
         "0.4981635",
         "0.036388567214818465",
         "0.5709406344296369",
         "0.425386365570363",
         "0.4899",
         "0.46222",
         "0.46796"
        ],
        [
         "2018-07-04 02:00:00",
         "0.48469",
         "0.508",
         "0.47941",
         "0.49097",
         "26722886.30000002",
         "0.493705",
         "0.00628",
         "1",
         "0.47063",
         "0.535872",
         "0.47957434970299084",
         "0.523811775181846",
         "39.38405956734371",
         "0.4844793128769162",
         "0.5155867784398087",
         "-0.03110746556289251",
         "-0.036726872465800475",
         "0.4948275000000001",
         "0.0335952635876891",
         "0.5620180271753783",
         "0.4276369728246219",
         "0.4844",
         "0.4899",
         "0.46222"
        ],
        [
         "2018-07-05 02:00:00",
         "0.49155",
         "0.50295",
         "0.46887",
         "0.4769",
         "30689285.9",
         "0.48591",
         "-0.0146499999999999",
         "0",
         "0.47508",
         "0.5292806666666666",
         "0.47890576227724313",
         "0.5207852090410817",
         "37.805032776485525",
         "0.483313264742006",
         "0.512721091147971",
         "-0.029407826405965065",
         "-0.035263063253833396",
         "0.49204349999999997",
         "0.03259425510811107",
         "0.5572320102162222",
         "0.42685498978377784",
         "0.49097",
         "0.4844",
         "0.4899"
        ],
        [
         "2018-07-06 02:00:00",
         "0.47772",
         "0.48156",
         "0.45747",
         "0.47698",
         "26805008.70000003",
         "0.469515",
         "-0.0007399999999999",
         "0",
         "0.4784757142857143",
         "0.52271",
         "0.4784243217079323",
         "0.5179590665223023",
         "48.59330871170976",
         "0.4823389163201589",
         "0.510073602914788",
         "-0.027734686594629077",
         "-0.03375738792199254",
         "0.489255",
         "0.03128788154507973",
         "0.5518307630901594",
         "0.42667923690984055",
         "0.4769",
         "0.49097",
         "0.4844"
        ],
        [
         "2018-07-07 02:00:00",
         "0.47644",
         "0.488",
         "0.46381",
         "0.48494",
         "28584029.19999998",
         "0.475905",
         "0.0085",
         "1",
         "0.48090142857142865",
         "0.5162893333333334",
         "0.4800532412809492",
         "0.5158288041660247",
         "48.61284543134806",
         "0.48273908304013446",
         "0.5082118545507296",
         "-0.025472771510595127",
         "-0.032100464639713056",
         "0.48719350000000006",
         "0.03006187080969747",
         "0.547317241619395",
         "0.4270697583806051",
         "0.47698",
         "0.4769",
         "0.49097"
        ],
        [
         "2018-07-08 02:00:00",
         "0.4852",
         "0.48798",
         "0.4751",
         "0.47915",
         "31480979.29999998",
         "0.48154",
         "-0.00605",
         "0",
         "0.48331999999999997",
         "0.5098576666666667",
         "0.4798274309607119",
         "0.5134624297037006",
         "51.68552297390903",
         "0.4821869164185753",
         "0.5060591245840089",
         "-0.023872208165433617",
         "-0.030454813344857168",
         "0.484216",
         "0.02753473756242417",
         "0.5392854751248484",
         "0.42914652487515165",
         "0.48494",
         "0.47698",
         "0.4769"
        ],
        [
         "2018-07-09 02:00:00",
         "0.47872",
         "0.48201",
         "0.47015",
         "0.473",
         "26690553.60000002",
         "0.47608",
         "-0.00572",
         "0",
         "0.4809057142857143",
         "0.503711",
         "0.4781205732205339",
         "0.510851950367978",
         "47.59405074365703",
         "0.4807735446618714",
         "0.5036103005407491",
         "-0.02283675587887768",
         "-0.028931201851661273",
         "0.480449",
         "0.02309611402721004",
         "0.5266412280544202",
         "0.43425677194557993",
         "0.47915",
         "0.48494",
         "0.47698"
        ],
        [
         "2018-07-10 02:00:00",
         "0.4728",
         "0.47338",
         "0.43866",
         "0.44337",
         "30651668.10000005",
         "0.45602",
         "-0.02943",
         "0",
         "0.4750442857142857",
         "0.49908966666666665",
         "0.4694329299154005",
         "0.5064982761506892",
         "47.21402534282241",
         "0.47501915317542964",
         "0.4991480560562491",
         "-0.02412890288081948",
         "-0.027970742057492917",
         "0.4756595",
         "0.020005609338382933",
         "0.5156707186767658",
         "0.43564828132323413",
         "0.473",
         "0.47915",
         "0.48494"
        ],
        [
         "2018-07-11 02:00:00",
         "0.44247",
         "0.45134",
         "0.43957",
         "0.44872",
         "28635928.19999998",
         "0.445455",
         "0.00625",
         "1",
         "0.4690085714285714",
         "0.49405066666666664",
         "0.46425469743655035",
         "0.5027706454312899",
         "43.36354606406754",
         "0.47097312960997895",
         "0.49541264449652694",
         "-0.024439514886547997",
         "-0.027264496623303935",
         "0.471367",
         "0.01537435017026378",
         "0.5021157003405275",
         "0.4406182996594724",
         "0.44337",
         "0.473",
         "0.47915"
        ],
        [
         "2018-07-12 02:00:00",
         "0.449",
         "0.44932",
         "0.4236",
         "0.43675",
         "30380599.49999994",
         "0.4364599999999999",
         "-0.0122499999999999",
         "0",
         "0.46327285714285715",
         "0.490089",
         "0.4573785230774128",
         "0.49851124895185184",
         "46.97377269670479",
         "0.4657080327469053",
         "0.4910672634227101",
         "-0.02535923067580481",
         "-0.026883443433804114",
         "0.4690965",
         "0.016967130227527882",
         "0.5030307604550558",
         "0.43516223954494426",
         "0.44872",
         "0.44337",
         "0.473"
        ],
        [
         "2018-07-13 02:00:00",
         "0.43706",
         "0.44509",
         "0.43001",
         "0.43754",
         "33168644.29999998",
         "0.43755",
         "0.0004799999999999",
         "1",
         "0.4576385714285714",
         "0.487053",
         "0.4524188923080596",
         "0.4945776199872163",
         "44.48355981130746",
         "0.46137448924738145",
         "0.4871022809469538",
         "-0.025727791699572344",
         "-0.02665231308695776",
         "0.466471",
         "0.017604851574136163",
         "0.5016807031482724",
         "0.4312612968517277",
         "0.43675",
         "0.44872",
         "0.44337"
        ],
        [
         "2018-07-14 02:00:00",
         "0.43761",
         "0.4443",
         "0.431",
         "0.43864",
         "27141582.29999995",
         "0.43765",
         "0.0010299999999999",
         "1",
         "0.4510242857142857",
         "0.48308466666666666",
         "0.44897416923104466",
         "0.4909687412783636",
         "38.580775821779085",
         "0.45787687551701506",
         "0.48351248235829053",
         "-0.02563560684127547",
         "-0.026448971837821304",
         "0.4647374999999999",
         "0.018576126975800123",
         "0.5018897539516002",
         "0.42758524604839965",
         "0.43754",
         "0.43675",
         "0.44872"
        ],
        [
         "2018-07-15 02:00:00",
         "0.43864",
         "0.45004",
         "0.43509",
         "0.44681",
         "33882949.8",
         "0.442565",
         "0.00817",
         "1",
         "0.44640428571428575",
         "0.48022566666666666",
         "0.44843312692328346",
         "0.4881197902281466",
         "44.109777539943416",
         "0.4561742792836281",
         "0.4807937799613801",
         "-0.024619500677752038",
         "-0.02608307760580745",
         "0.4630155",
         "0.018561142624480654",
         "0.5001377852489614",
         "0.4258932147510387",
         "0.43864",
         "0.43754",
         "0.43675"
        ],
        [
         "2018-07-16 02:00:00",
         "0.44695",
         "0.4858",
         "0.4435",
         "0.48173",
         "41419524.1",
         "0.46465",
         "0.0347799999999999",
         "1",
         "0.4476514285714286",
         "0.478525",
         "0.4567573451924626",
         "0.48770754569729846",
         "47.04092720028975",
         "0.46010592862460836",
         "0.4808631295938705",
         "-0.020757200969262146",
         "-0.02501790227849839",
         "0.464452",
         "0.018854646111767695",
         "0.5021612922235353",
         "0.4267427077764646",
         "0.44681",
         "0.43864",
         "0.43754"
        ],
        [
         "2018-07-17 02:00:00",
         "0.48173",
         "0.52019",
         "0.4665",
         "0.50728",
         "48166296.2000001",
         "0.493345",
         "0.0255499999999999",
         "1",
         "0.45678142857142856",
         "0.47789533333333334",
         "0.4693880088943469",
         "0.4889702846845696",
         "57.23592662871599",
         "0.4673634780669763",
         "0.4828199348091393",
         "-0.015456456742163005",
         "-0.023105613171231314",
         "0.466311",
         "0.02113574669655768",
         "0.5085824933931153",
         "0.4240395066068846",
         "0.48173",
         "0.44681",
         "0.43864"
        ],
        [
         "2018-07-18 02:00:00",
         "0.50651",
         "0.52525",
         "0.4752",
         "0.48868",
         "48747453.60000002",
         "0.500225",
         "-0.01783",
         "0",
         "0.46248999999999996",
         "0.476228",
         "0.47421100667076016",
         "0.48895155664040385",
         "49.32698524657614",
         "0.4706429429797492",
         "0.48325401371216603",
         "-0.012611070732416851",
         "-0.021006704683468422",
         "0.46845749999999997",
         "0.021117645621113717",
         "0.5106927912422274",
         "0.42622220875777256",
         "0.50728",
         "0.48173",
         "0.44681"
        ],
        [
         "2018-07-19 02:00:00",
         "0.48869",
         "0.495",
         "0.47125",
         "0.47687",
         "36600560.00000002",
         "0.483125",
         "-0.0118199999999999",
         "0",
         "0.4682214285714286",
         "0.47384566666666667",
         "0.4748757550030701",
         "0.48817210137328104",
         "49.99106451420743",
         "0.4716009517520955",
         "0.4827811238075611",
         "-0.01118017205546562",
         "-0.019041398157867862",
         "0.46964049999999996",
         "0.020879905090276228",
         "0.5114003101805524",
         "0.4278806898194475",
         "0.48868",
         "0.50728",
         "0.48173"
        ],
        [
         "2018-07-20 02:00:00",
         "0.47703",
         "0.4773",
         "0.431",
         "0.44439",
         "40745516.20000002",
         "0.45415",
         "-0.03264",
         "0",
         "0.46919999999999995",
         "0.47068666666666664",
         "0.46725431625230257",
         "0.48534744967177906",
         "41.86348429620011",
         "0.4674146514825423",
         "0.47993733685885287",
         "-0.012522685376310572",
         "-0.017737655601556403",
         "0.468462",
         "0.021631391322018835",
         "0.5117247826440376",
         "0.42519921735596233",
         "0.47687",
         "0.48868",
         "0.50728"
        ],
        [
         "2018-07-21 02:00:00",
         "0.4444",
         "0.459",
         "0.4346",
         "0.45506",
         "28483991.39999995",
         "0.4468",
         "0.01066",
         "1",
         "0.4715457142857143",
         "0.4680363333333333",
         "0.4642057371892269",
         "0.48339342066069657",
         "42.639668932899795",
         "0.46551393586984346",
         "0.4780945711656045",
         "-0.012580635295761033",
         "-0.01670625154039733",
         "0.46810399999999996",
         "0.021798735453425207",
         "0.5117014709068504",
         "0.42450652909314956",
         "0.44439",
         "0.47687",
         "0.48868"
        ],
        [
         "2018-07-22 02:00:00",
         "0.45467",
         "0.46409",
         "0.44589",
         "0.44859",
         "32232347.19999996",
         "0.45499",
         "-0.00608",
         "0",
         "0.4718",
         "0.46691733333333335",
         "0.4603018028919202",
         "0.48114803868258715",
         "42.49729942060296",
         "0.4629102534283291",
         "0.4759090473755597",
         "-0.012998793947230636",
         "-0.01596476002176399",
         "0.4660385000000001",
         "0.021580836107650225",
         "0.5092001722153006",
         "0.42287682778469965",
         "0.45506",
         "0.44439",
         "0.47687"
        ],
        [
         "2018-07-23 02:00:00",
         "0.44859",
         "0.46371",
         "0.44212",
         "0.44499",
         "30316389.90000007",
         "0.452915",
         "-0.0035999999999999",
         "0",
         "0.46655142857142856",
         "0.46541533333333335",
         "0.45647385216894015",
         "0.47881526199338803",
         "43.03614937099099",
         "0.4601532913624323",
         "0.4736187475699627",
         "-0.013465456207530369",
         "-0.015464899258917267",
         "0.464068",
         "0.02161524135760148",
         "0.507298482715203",
         "0.420837517284797",
         "0.44859",
         "0.45506",
         "0.44439"
        ],
        [
         "2018-07-24 02:00:00",
         "0.4452",
         "0.4715",
         "0.438",
         "0.45885",
         "43532211.20000008",
         "0.45475",
         "0.0136499999999999",
         "1",
         "0.4596328571428572",
         "0.4649333333333333",
         "0.4570678891267051",
         "0.47752718057445975",
         "54.17610877306572",
         "0.4599527849989812",
         "0.472524766268484",
         "-0.012571981269502819",
         "-0.014886315661034379",
         "0.46246199999999993",
         "0.02068444587250596",
         "0.5038308917450118",
         "0.421093108254988",
         "0.44499",
         "0.44859",
         "0.45506"
        ],
        [
         "2018-07-25 02:00:00",
         "0.45741",
         "0.46878",
         "0.45153",
         "0.4598",
         "42650288.40000004",
         "0.460155",
         "0.00239",
         "1",
         "0.45550714285714283",
         "0.4642183333333333",
         "0.45775091684502883",
         "0.4763834915051398",
         "53.06178843815629",
         "0.4599292796145225",
         "0.471582190989337",
         "-0.0116529113748145",
         "-0.014239634803790405",
         "0.46160700000000005",
         "0.020407802455252966",
         "0.5024226049105059",
         "0.4207913950894941",
         "0.45885",
         "0.44499",
         "0.44859"
        ],
        [
         "2018-07-26 02:00:00",
         "0.45983",
         "0.46887",
         "0.44538",
         "0.44968",
         "38041528.40000003",
         "0.457125",
         "-0.0101499999999999",
         "0",
         "0.4516228571428571",
         "0.4641076666666667",
         "0.45573318763377163",
         "0.4746606856015824",
         "53.60991680160813",
         "0.45835246736613444",
         "0.46995980647160834",
         "-0.011607339105473902",
         "-0.013713175664127105",
         "0.46024199999999993",
         "0.02023773094208459",
         "0.5007174618841691",
         "0.41976653811583076",
         "0.4598",
         "0.45885",
         "0.44499"
        ],
        [
         "2018-07-27 02:00:00",
         "0.44878",
         "0.462",
         "0.444",
         "0.4555",
         "35252979.79999998",
         "0.453",
         "0.00672",
         "1",
         "0.45321",
         "0.463621",
         "0.45567489072532874",
         "0.4734245123369642",
         "54.87725396480557",
         "0.457913626232883",
         "0.46888870969593366",
         "-0.01097508346305065",
         "-0.013165557223911814",
         "0.45877",
         "0.019400093597169706",
         "0.49757018719433943",
         "0.4199698128056606",
         "0.44968",
         "0.4598",
         "0.45885"
        ],
        [
         "2018-07-28 02:00:00",
         "0.4555",
         "0.45887",
         "0.44803",
         "0.45641",
         "27843347.29999995",
         "0.45345",
         "0.0009099999999999",
         "1",
         "0.45340285714285716",
         "0.4639763333333333",
         "0.45585866804399655",
         "0.47232680186361164",
         "54.83064209210026",
         "0.45768229912013175",
         "0.4679643608295682",
         "-0.010282061709436463",
         "-0.012588858121016745",
         "0.45763300000000007",
         "0.018799886365837924",
         "0.49523277273167593",
         "0.4200332272683242",
         "0.4555",
         "0.44968",
         "0.4598"
        ],
        [
         "2018-07-29 02:00:00",
         "0.45643",
         "0.45849",
         "0.45",
         "0.45315",
         "31188705.49999994",
         "0.454245",
         "-0.00328",
         "0",
         "0.4540542857142857",
         "0.4639743333333333",
         "0.45518150103299737",
         "0.47108958884015284",
         "51.770751871299304",
         "0.45698502233241917",
         "0.4668670007681187",
         "-0.009881978435699545",
         "-0.012047482183953306",
         "0.45664049999999995",
         "0.01846694100990079",
         "0.4935743820198015",
         "0.41970661798019837",
         "0.45641",
         "0.4555",
         "0.44968"
        ],
        [
         "2018-07-30 02:00:00",
         "0.45315",
         "0.45621",
         "0.43382",
         "0.44534",
         "32141597.89999998",
         "0.445015",
         "-0.0078099999999999",
         "0",
         "0.4541042857142857",
         "0.4632203333333333",
         "0.45272112577474805",
         "0.46942832504401394",
         "38.022513330261326",
         "0.4551934804351239",
         "0.46527240811862847",
         "-0.010078927683504546",
         "-0.011653771283863554",
         "0.45673899999999995",
         "0.0183975561592179",
         "0.49353411231843575",
         "0.41994388768156415",
         "0.45315",
         "0.45641",
         "0.4555"
        ],
        [
         "2018-07-31 02:00:00",
         "0.44616",
         "0.44641",
         "0.4268",
         "0.4353",
         "31785092.6",
         "0.436605",
         "-0.0108599999999999",
         "0",
         "0.45074000000000003",
         "0.46232299999999993",
         "0.448365844331061",
         "0.46722649762181956",
         "23.61436950146627",
         "0.4521329449835664",
         "0.4630522297394708",
         "-0.010919284755904424",
         "-0.01150687397827173",
         "0.456068",
         "0.018942090308705518",
         "0.49395218061741103",
         "0.4181838193825889",
         "0.44534",
         "0.45315",
         "0.45641"
        ],
        [
         "2018-08-01 02:00:00",
         "0.4353",
         "0.46382",
         "0.42671",
         "0.44642",
         "39833478.29999995",
         "0.445265",
         "0.0111199999999999",
         "1",
         "0.4488285714285714",
         "0.46087366666666674",
         "0.4478793832482958",
         "0.4658841429365409",
         "33.60999069190193",
         "0.45125403037071005",
         "0.4618202127217322",
         "-0.010566182351022135",
         "-0.01131873565282181",
         "0.45655150000000005",
         "0.018542236643318943",
         "0.49363597328663794",
         "0.41946702671336217",
         "0.4353",
         "0.44534",
         "0.45315"
        ],
        [
         "2018-08-02 02:00:00",
         "0.44673",
         "0.44888",
         "0.42849",
         "0.42975",
         "33396468.10000001",
         "0.438685",
         "-0.0169799999999999",
         "0",
         "0.44598142857142864",
         "0.45905199999999996",
         "0.4433470374362219",
         "0.463552907908377",
         "32.38899686051725",
         "0.4479457180059854",
         "0.45944464140901126",
         "-0.01149892340302583",
         "-0.011354773202862614",
         "0.45616199999999996",
         "0.019037809084472918",
         "0.4942376181689458",
         "0.4180863818310541",
         "0.44642",
         "0.4353",
         "0.44534"
        ],
        [
         "2018-08-03 02:00:00",
         "0.43021",
         "0.44619",
         "0.4253",
         "0.44033",
         "44748261.19999998",
         "0.435745",
         "0.01012",
         "1",
         "0.4438142857142857",
         "0.457364",
         "0.44259277807716646",
         "0.4620546557852559",
         "48.185555952806574",
         "0.4467740690819877",
         "0.4580287420453808",
         "-0.011254672963393109",
         "-0.011334753154968714",
         "0.45624650000000005",
         "0.01895953343724186",
         "0.49416556687448376",
         "0.41832743312551635",
         "0.42975",
         "0.44642",
         "0.4353"
        ],
        [
         "2018-08-04 02:00:00",
         "0.44097",
         "0.445",
         "0.42741",
         "0.42985",
         "35095397.49999999",
         "0.436205",
         "-0.0111199999999999",
         "0",
         "0.44002",
         "0.4557956666666667",
         "0.43940708355787483",
         "0.4599769360571749",
         "38.71429850479002",
         "0.44417036614629724",
         "0.455941427819797",
         "-0.011771061673499783",
         "-0.01142201485867493",
         "0.4553985",
         "0.019765946067602378",
         "0.49493039213520473",
         "0.41586660786479523",
         "0.44033",
         "0.42975",
         "0.44642"
        ],
        [
         "2018-08-05 02:00:00",
         "0.42984",
         "0.43705",
         "0.42705",
         "0.4345",
         "34962084.2",
         "0.43205",
         "0.0046599999999999",
         "1",
         "0.4373557142857143",
         "0.4543796666666667",
         "0.43818031266840607",
         "0.45833326276316366",
         "43.58787658141439",
         "0.4426826175084053",
         "0.45435317390721947",
         "-0.011670556398814147",
         "-0.011471723166702773",
         "0.453037",
         "0.01926959101524301",
         "0.49157618203048603",
         "0.414497817969514",
         "0.42985",
         "0.44033",
         "0.42975"
        ],
        [
         "2018-08-06 02:00:00",
         "0.43437",
         "0.43699",
         "0.40127",
         "0.4129",
         "40578992.90000006",
         "0.41913",
         "-0.0214699999999999",
         "0",
         "0.4327214285714286",
         "0.45197833333333326",
         "0.43186023450130456",
         "0.4554020845203789",
         "37.45209978884802",
         "0.438100676353266",
         "0.4512825684326106",
         "-0.013181892079344615",
         "-0.011813756949231142",
         "0.448318",
         "0.01666752613222546",
         "0.48165305226445093",
         "0.41498294773554906",
         "0.4345",
         "0.42985",
         "0.44033"
        ],
        [
         "2018-08-07 02:00:00",
         "0.41328",
         "0.41567",
         "0.37387",
         "0.37863",
         "41157252.55999998",
         "0.3947699999999999",
         "-0.0346499999999999",
         "0",
         "0.4246257142857143",
         "0.4486276666666667",
         "0.41855267587597844",
         "0.45044904680938674",
         "22.94982465605608",
         "0.4289513415296866",
         "0.44590089669686167",
         "-0.016949555167175057",
         "-0.012840916592819926",
         "0.44281550000000003",
         "0.020391043305953236",
         "0.4835975866119065",
         "0.40203341338809356",
         "0.4129",
         "0.4345",
         "0.42985"
        ],
        [
         "2018-08-08 02:00:00",
         "0.37863",
         "0.37863",
         "0.31928",
         "0.33171",
         "72393008.14999995",
         "0.348955",
         "-0.04692",
         "0",
         "0.40823857142857145",
         "0.443918",
         "0.39684200690698385",
         "0.442788463144265",
         "17.029601029600997",
         "0.41399113514050406",
         "0.4374423117563534",
         "-0.023451176615849334",
         "-0.014962968597425809",
         "0.4355575",
         "0.03080605731191936",
         "0.4971696146238387",
         "0.3739453853761613",
         "0.37863",
         "0.4129",
         "0.4345"
        ],
        [
         "2018-08-09 02:00:00",
         "0.33197",
         "0.35799",
         "0.328",
         "0.3441",
         "51832840.70000008",
         "0.342995",
         "0.01213",
         "1",
         "0.39600285714285716",
         "0.44060900000000003",
         "0.3836565051802379",
         "0.4364214655220544",
         "23.13759413800119",
         "0.40323865281119575",
         "0.43052806644106795",
         "-0.027289413629872195",
         "-0.017428257603915087",
         "0.430543",
         "0.03686019620417833",
         "0.5042633924083567",
         "0.35682260759164336",
         "0.33171",
         "0.37863",
         "0.4129"
        ],
        [
         "2018-08-10 02:00:00",
         "0.3441",
         "0.34689",
         "0.31236",
         "0.31897",
         "39269097.20000007",
         "0.329625",
         "-0.02513",
         "0",
         "0.37866571428571427",
         "0.436284",
         "0.36748487888517845",
         "0.4288439516174058",
         "18.370940091738845",
         "0.3902742446863964",
         "0.4222645059639518",
         "-0.03199026127755544",
         "-0.02034065833864316",
         "0.4237385000000001",
         "0.04397142245104674",
         "0.5116813449020936",
         "0.3357956550979066",
         "0.3441",
         "0.33171",
         "0.37863"
        ],
        [
         "2018-08-11 02:00:00",
         "0.31897",
         "0.32008",
         "0.2874",
         "0.29784",
         "48724318.70000006",
         "0.30374",
         "-0.0211299999999999",
         "0",
         "0.3598071428571429",
         "0.43165366666666666",
         "0.3500736591638838",
         "0.4203920837711215",
         "16.411777165854673",
         "0.37605359165772",
         "0.413047875892548",
         "-0.03699428423482798",
         "-0.023671383517880125",
         "0.41620099999999993",
         "0.051724366130276964",
         "0.5196497322605539",
         "0.312752267739446",
         "0.31897",
         "0.3441",
         "0.33171"
        ],
        [
         "2018-08-12 02:00:00",
         "0.29708",
         "0.30938",
         "0.29401",
         "0.29547",
         "35382260.6",
         "0.301695",
         "-0.00161",
         "0",
         "0.3399457142857143",
         "0.42691799999999996",
         "0.33642274437291286",
         "0.41233259449556536",
         "16.473890117366892",
         "0.36365611601807074",
         "0.4043384036042111",
         "-0.04068228758614034",
         "-0.02707356433153217",
         "0.408725",
         "0.0577937108670958",
         "0.5243124217341916",
         "0.2931375782658084",
         "0.29784",
         "0.31897",
         "0.3441"
        ],
        [
         "2018-08-13 02:00:00",
         "0.29575",
         "0.309",
         "0.27127",
         "0.2743",
         "43767335.33999998",
         "0.290135",
         "-0.02145",
         "0",
         "0.32014571428571426",
         "0.42144",
         "0.32089205827968464",
         "0.40342726581843213",
         "15.588282633188456",
         "0.3499090212460599",
         "0.3947059292631584",
         "-0.04479690801709851",
         "-0.030618233068645445",
         "0.3994975",
         "0.06379109704215861",
         "0.5270796940843172",
         "0.2719153059156828",
         "0.29547",
         "0.29784",
         "0.31897"
        ],
        [
         "2018-08-14 02:00:00",
         "0.2743",
         "0.27732",
         "0.24672",
         "0.2725",
         "56101898.99999996",
         "0.26202",
         "-0.0017999999999999",
         "0",
         "0.3049842857142857",
         "0.4156296666666667",
         "0.3087940437097635",
         "0.39498034544304944",
         "16.122856667221555",
         "0.3379999410543584",
         "0.3856536382066282",
         "-0.0476536971522698",
         "-0.034025325885370314",
         "0.3901325",
         "0.06807684751150903",
         "0.526286195023018",
         "0.25397880497698194",
         "0.2743",
         "0.29547",
         "0.29784"
        ],
        [
         "2018-08-15 02:00:00",
         "0.2728",
         "0.30234",
         "0.2728",
         "0.28039",
         "72676585.19999997",
         "0.28757",
         "0.0075899999999999",
         "1",
         "0.2976528571428571",
         "0.40891833333333333",
         "0.3016930327823226",
         "0.3875874199305947",
         "14.979962033326288",
         "0.3291368731998417",
         "0.37785633167280386",
         "-0.04871945847296216",
         "-0.03696415240288868",
         "0.381668",
         "0.07075504167269814",
         "0.5231780833453963",
         "0.24015791665460373",
         "0.2725",
         "0.2743",
         "0.29547"
        ],
        [
         "2018-08-16 02:00:00",
         "0.28",
         "0.30184",
         "0.2755",
         "0.29142",
         "46325561.50000004",
         "0.28867",
         "0.0114199999999999",
         "1",
         "0.29012714285714286",
         "0.401723",
         "0.29912477458674197",
         "0.3813830702576531",
         "20.111490428244224",
         "0.323334277322943",
         "0.37145364043778134",
         "-0.04811936311483833",
         "-0.03919519454527862",
         "0.373464",
         "0.07125442460130559",
         "0.5159728492026112",
         "0.23095515079738885",
         "0.28039",
         "0.2725",
         "0.2743"
        ],
        [
         "2018-08-17 02:00:00",
         "0.29161",
         "0.37506",
         "0.29085",
         "0.3672",
         "84683658.1",
         "0.332955",
         "0.07559",
         "1",
         "0.29701714285714287",
         "0.3976736666666667",
         "0.31614358094005646",
         "0.38046803346683683",
         "37.67236438420823",
         "0.3300828500424903",
         "0.37113855596090867",
         "-0.041055705918418395",
         "-0.039567296819906575",
         "0.36900350000000004",
         "0.06852888175414559",
         "0.5060612635082913",
         "0.23194573649170885",
         "0.29142",
         "0.28039",
         "0.2725"
        ],
        [
         "2018-08-18 02:00:00",
         "0.36721",
         "0.37",
         "0.31039",
         "0.32829",
         "80106581.6000001",
         "0.340195",
         "-0.0389199999999999",
         "0",
         "0.3013671428571429",
         "0.392721",
         "0.31918018570504236",
         "0.3771017087270409",
         "34.377307408318984",
         "0.32980702695903025",
         "0.36796458885269323",
         "-0.03815756189366298",
         "-0.039285349834657854",
         "0.36276050000000004",
         "0.06610414418691306",
         "0.4949687883738262",
         "0.23055221162617393",
         "0.3672",
         "0.29142",
         "0.28039"
        ],
        [
         "2018-08-19 02:00:00",
         "0.32848",
         "0.35281",
         "0.316",
         "0.34201",
         "63806323.29999998",
         "0.334405",
         "0.0135299999999999",
         "1",
         "0.3080157142857143",
         "0.3893083333333333",
         "0.3248876392787818",
         "0.37483772751884475",
         "36.15875011223848",
         "0.3316844074268717",
         "0.3660420267154567",
         "-0.034357619288584995",
         "-0.03829980372544328",
         "0.357594",
         "0.06328829387060936",
         "0.48417058774121874",
         "0.2310174122587813",
         "0.32829",
         "0.3672",
         "0.29142"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 2428
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>30_day_SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>26_day_EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-01 02:00:00</th>\n",
       "      <td>0.46797</td>\n",
       "      <td>0.46989</td>\n",
       "      <td>0.45007</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>31676174.1</td>\n",
       "      <td>0.459980</td>\n",
       "      <td>-0.00575</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461927</td>\n",
       "      <td>0.553292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522633</td>\n",
       "      <td>-0.040771</td>\n",
       "      <td>-0.039598</td>\n",
       "      <td>0.503660</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.581151</td>\n",
       "      <td>0.426168</td>\n",
       "      <td>0.46796</td>\n",
       "      <td>0.45321</td>\n",
       "      <td>0.44575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-02 02:00:00</th>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.49540</td>\n",
       "      <td>0.45200</td>\n",
       "      <td>0.48990</td>\n",
       "      <td>39873781.8</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>0.02768</td>\n",
       "      <td>1</td>\n",
       "      <td>0.463163</td>\n",
       "      <td>0.548199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520209</td>\n",
       "      <td>-0.037110</td>\n",
       "      <td>-0.039100</td>\n",
       "      <td>0.500374</td>\n",
       "      <td>0.036849</td>\n",
       "      <td>0.574072</td>\n",
       "      <td>0.426677</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.46796</td>\n",
       "      <td>0.45321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-03 02:00:00</th>\n",
       "      <td>0.48913</td>\n",
       "      <td>0.52000</td>\n",
       "      <td>0.47801</td>\n",
       "      <td>0.48440</td>\n",
       "      <td>44333181.6</td>\n",
       "      <td>0.499005</td>\n",
       "      <td>-0.00473</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467649</td>\n",
       "      <td>0.541342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517556</td>\n",
       "      <td>-0.034257</td>\n",
       "      <td>-0.038132</td>\n",
       "      <td>0.498163</td>\n",
       "      <td>0.036389</td>\n",
       "      <td>0.570941</td>\n",
       "      <td>0.425386</td>\n",
       "      <td>0.48990</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.46796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04 02:00:00</th>\n",
       "      <td>0.48469</td>\n",
       "      <td>0.50800</td>\n",
       "      <td>0.47941</td>\n",
       "      <td>0.49097</td>\n",
       "      <td>26722886.3</td>\n",
       "      <td>0.493705</td>\n",
       "      <td>0.00628</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470630</td>\n",
       "      <td>0.535872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515587</td>\n",
       "      <td>-0.031107</td>\n",
       "      <td>-0.036727</td>\n",
       "      <td>0.494828</td>\n",
       "      <td>0.033595</td>\n",
       "      <td>0.562018</td>\n",
       "      <td>0.427637</td>\n",
       "      <td>0.48440</td>\n",
       "      <td>0.48990</td>\n",
       "      <td>0.46222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05 02:00:00</th>\n",
       "      <td>0.49155</td>\n",
       "      <td>0.50295</td>\n",
       "      <td>0.46887</td>\n",
       "      <td>0.47690</td>\n",
       "      <td>30689285.9</td>\n",
       "      <td>0.485910</td>\n",
       "      <td>-0.01465</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475080</td>\n",
       "      <td>0.529281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512721</td>\n",
       "      <td>-0.029408</td>\n",
       "      <td>-0.035263</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.032594</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.426855</td>\n",
       "      <td>0.49097</td>\n",
       "      <td>0.48440</td>\n",
       "      <td>0.48990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-17 01:00:00</th>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76480</td>\n",
       "      <td>2.60750</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>212813356.0</td>\n",
       "      <td>2.686150</td>\n",
       "      <td>-0.06840</td>\n",
       "      <td>0</td>\n",
       "      <td>2.619271</td>\n",
       "      <td>2.782387</td>\n",
       "      <td>...</td>\n",
       "      <td>2.656563</td>\n",
       "      <td>-0.032975</td>\n",
       "      <td>-0.055473</td>\n",
       "      <td>2.629525</td>\n",
       "      <td>0.246332</td>\n",
       "      <td>3.122190</td>\n",
       "      <td>2.136860</td>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76190</td>\n",
       "      <td>2.73840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-18 01:00:00</th>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.66990</td>\n",
       "      <td>2.46930</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>227170019.0</td>\n",
       "      <td>2.569600</td>\n",
       "      <td>-0.09710</td>\n",
       "      <td>0</td>\n",
       "      <td>2.640657</td>\n",
       "      <td>2.769190</td>\n",
       "      <td>...</td>\n",
       "      <td>2.649618</td>\n",
       "      <td>-0.035382</td>\n",
       "      <td>-0.051455</td>\n",
       "      <td>2.604250</td>\n",
       "      <td>0.223850</td>\n",
       "      <td>3.051949</td>\n",
       "      <td>2.156551</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 01:00:00</th>\n",
       "      <td>2.56290</td>\n",
       "      <td>2.74700</td>\n",
       "      <td>2.51210</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>208577133.0</td>\n",
       "      <td>2.629550</td>\n",
       "      <td>0.17490</td>\n",
       "      <td>1</td>\n",
       "      <td>2.678429</td>\n",
       "      <td>2.756940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.656150</td>\n",
       "      <td>-0.022904</td>\n",
       "      <td>-0.045745</td>\n",
       "      <td>2.584760</td>\n",
       "      <td>0.190347</td>\n",
       "      <td>2.965454</td>\n",
       "      <td>2.204066</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.72830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-20 01:00:00</th>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.74900</td>\n",
       "      <td>2.66710</td>\n",
       "      <td>2.68770</td>\n",
       "      <td>161604635.0</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>-0.05010</td>\n",
       "      <td>0</td>\n",
       "      <td>2.696686</td>\n",
       "      <td>2.740737</td>\n",
       "      <td>...</td>\n",
       "      <td>2.658487</td>\n",
       "      <td>-0.016864</td>\n",
       "      <td>-0.039969</td>\n",
       "      <td>2.567340</td>\n",
       "      <td>0.160464</td>\n",
       "      <td>2.888269</td>\n",
       "      <td>2.246411</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>2.65990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 01:00:00</th>\n",
       "      <td>2.68780</td>\n",
       "      <td>2.71600</td>\n",
       "      <td>2.50760</td>\n",
       "      <td>2.54120</td>\n",
       "      <td>227097007.0</td>\n",
       "      <td>2.611800</td>\n",
       "      <td>-0.14660</td>\n",
       "      <td>0</td>\n",
       "      <td>2.668514</td>\n",
       "      <td>2.719433</td>\n",
       "      <td>...</td>\n",
       "      <td>2.649799</td>\n",
       "      <td>-0.023625</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>2.550510</td>\n",
       "      <td>0.142876</td>\n",
       "      <td>2.836263</td>\n",
       "      <td>2.264757</td>\n",
       "      <td>2.68770</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.56280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2428 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close       volume  \\\n",
       "datetime                                                               \n",
       "2018-07-01 02:00:00  0.46797  0.46989  0.45007  0.46222   31676174.1   \n",
       "2018-07-02 02:00:00  0.46222  0.49540  0.45200  0.48990   39873781.8   \n",
       "2018-07-03 02:00:00  0.48913  0.52000  0.47801  0.48440   44333181.6   \n",
       "2018-07-04 02:00:00  0.48469  0.50800  0.47941  0.49097   26722886.3   \n",
       "2018-07-05 02:00:00  0.49155  0.50295  0.46887  0.47690   30689285.9   \n",
       "...                      ...      ...      ...      ...          ...   \n",
       "2025-02-17 01:00:00  2.72830  2.76480  2.60750  2.65990  212813356.0   \n",
       "2025-02-18 01:00:00  2.65990  2.66990  2.46930  2.56280  227170019.0   \n",
       "2025-02-19 01:00:00  2.56290  2.74700  2.51210  2.73780  208577133.0   \n",
       "2025-02-20 01:00:00  2.73780  2.74900  2.66710  2.68770  161604635.0   \n",
       "2025-02-21 01:00:00  2.68780  2.71600  2.50760  2.54120  227097007.0   \n",
       "\n",
       "                        av_pr     diff  candle  7_day_SMA  30_day_SMA  ...  \\\n",
       "datetime                                                               ...   \n",
       "2018-07-01 02:00:00  0.459980 -0.00575       0   0.461927    0.553292  ...   \n",
       "2018-07-02 02:00:00  0.473700  0.02768       1   0.463163    0.548199  ...   \n",
       "2018-07-03 02:00:00  0.499005 -0.00473       0   0.467649    0.541342  ...   \n",
       "2018-07-04 02:00:00  0.493705  0.00628       1   0.470630    0.535872  ...   \n",
       "2018-07-05 02:00:00  0.485910 -0.01465       0   0.475080    0.529281  ...   \n",
       "...                       ...      ...     ...        ...         ...  ...   \n",
       "2025-02-17 01:00:00  2.686150 -0.06840       0   2.619271    2.782387  ...   \n",
       "2025-02-18 01:00:00  2.569600 -0.09710       0   2.640657    2.769190  ...   \n",
       "2025-02-19 01:00:00  2.629550  0.17490       1   2.678429    2.756940  ...   \n",
       "2025-02-20 01:00:00  2.708050 -0.05010       0   2.696686    2.740737  ...   \n",
       "2025-02-21 01:00:00  2.611800 -0.14660       0   2.668514    2.719433  ...   \n",
       "\n",
       "                     26_day_EMA      MACD  Signal_Line  20_day_SMA  \\\n",
       "datetime                                                             \n",
       "2018-07-01 02:00:00    0.522633 -0.040771    -0.039598    0.503660   \n",
       "2018-07-02 02:00:00    0.520209 -0.037110    -0.039100    0.500374   \n",
       "2018-07-03 02:00:00    0.517556 -0.034257    -0.038132    0.498163   \n",
       "2018-07-04 02:00:00    0.515587 -0.031107    -0.036727    0.494828   \n",
       "2018-07-05 02:00:00    0.512721 -0.029408    -0.035263    0.492043   \n",
       "...                         ...       ...          ...         ...   \n",
       "2025-02-17 01:00:00    2.656563 -0.032975    -0.055473    2.629525   \n",
       "2025-02-18 01:00:00    2.649618 -0.035382    -0.051455    2.604250   \n",
       "2025-02-19 01:00:00    2.656150 -0.022904    -0.045745    2.584760   \n",
       "2025-02-20 01:00:00    2.658487 -0.016864    -0.039969    2.567340   \n",
       "2025-02-21 01:00:00    2.649799 -0.023625    -0.036700    2.550510   \n",
       "\n",
       "                     20_day_STD  Upper_Band  Lower_Band    lag_1    lag_2  \\\n",
       "datetime                                                                    \n",
       "2018-07-01 02:00:00    0.038746    0.581151    0.426168  0.46796  0.45321   \n",
       "2018-07-02 02:00:00    0.036849    0.574072    0.426677  0.46222  0.46796   \n",
       "2018-07-03 02:00:00    0.036389    0.570941    0.425386  0.48990  0.46222   \n",
       "2018-07-04 02:00:00    0.033595    0.562018    0.427637  0.48440  0.48990   \n",
       "2018-07-05 02:00:00    0.032594    0.557232    0.426855  0.49097  0.48440   \n",
       "...                         ...         ...         ...      ...      ...   \n",
       "2025-02-17 01:00:00    0.246332    3.122190    2.136860  2.72830  2.76190   \n",
       "2025-02-18 01:00:00    0.223850    3.051949    2.156551  2.65990  2.72830   \n",
       "2025-02-19 01:00:00    0.190347    2.965454    2.204066  2.56280  2.65990   \n",
       "2025-02-20 01:00:00    0.160464    2.888269    2.246411  2.73780  2.56280   \n",
       "2025-02-21 01:00:00    0.142876    2.836263    2.264757  2.68770  2.73780   \n",
       "\n",
       "                       lag_3  \n",
       "datetime                      \n",
       "2018-07-01 02:00:00  0.44575  \n",
       "2018-07-02 02:00:00  0.45321  \n",
       "2018-07-03 02:00:00  0.46796  \n",
       "2018-07-04 02:00:00  0.46222  \n",
       "2018-07-05 02:00:00  0.48990  \n",
       "...                      ...  \n",
       "2025-02-17 01:00:00  2.73840  \n",
       "2025-02-18 01:00:00  2.76190  \n",
       "2025-02-19 01:00:00  2.72830  \n",
       "2025-02-20 01:00:00  2.65990  \n",
       "2025-02-21 01:00:00  2.56280  \n",
       "\n",
       "[2428 rows x 24 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import pickle  # To store scalers for later use\n",
    "\n",
    "# Global dictionary to store scalers\n",
    "scalers = {}\n",
    "\n",
    "def preprocess_data(df, fit_scalers=True, save_scalers=True, scalers_path=\"scalers.pkl\"):\n",
    "    \"\"\"\n",
    "    Preprocesses the input DataFrame by scaling different feature groups.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input data containing all required columns.\n",
    "        fit_scalers (bool): Whether to fit the scalers on this dataset (True for training, False for new data).\n",
    "        save_scalers (bool): Whether to save the scalers for later use.\n",
    "        scalers_path (str): File path to save or load scalers.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Scaled dataset.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    global scalers\n",
    "    \n",
    "    # Define feature groups\n",
    "    price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', '7_day_SMA', \n",
    "                  '30_day_SMA', '7_day_EMA', '30_day_EMA', '12_day_EMA', '26_day_EMA', '20_day_SMA']\n",
    "    volatility_cols = ['20_day_STD', 'Upper_Band', 'Lower_Band']\n",
    "    momentum_cols = ['RSI', 'MACD', 'Signal_Line']\n",
    "    lag_cols = ['lag_1', 'lag_2', 'lag_3']\n",
    "    \n",
    "    # If loading for prediction, load previously saved scalers\n",
    "    if not fit_scalers:\n",
    "        with open(scalers_path, 'rb') as f:\n",
    "            scalers = pickle.load(f)\n",
    "\n",
    "    # Apply RobustScaler to price-based features\n",
    "    if fit_scalers:\n",
    "        scalers['price'] = RobustScaler()\n",
    "        df[price_cols] = scalers['price'].fit_transform(df[price_cols])\n",
    "    else:\n",
    "        df[price_cols] = scalers['price'].transform(df[price_cols])\n",
    "\n",
    "    # Apply Log + RobustScaler to volume\n",
    "    if fit_scalers:\n",
    "        scalers['volume'] = RobustScaler()\n",
    "        df['volume'] = np.log1p(df['volume'])\n",
    "        df['volume'] = scalers['volume'].fit_transform(df[['volume']])\n",
    "    else:\n",
    "        df['volume'] = np.log1p(df['volume'])\n",
    "        df['volume'] = scalers['volume'].transform(df[['volume']])\n",
    "\n",
    "    # Apply StandardScaler to volatility indicators\n",
    "    if fit_scalers:\n",
    "        scalers['volatility'] = StandardScaler()\n",
    "        df[volatility_cols] = scalers['volatility'].fit_transform(df[volatility_cols])\n",
    "    else:\n",
    "        df[volatility_cols] = scalers['volatility'].transform(df[volatility_cols])\n",
    "\n",
    "    # Apply MinMaxScaler to momentum indicators (RSI, MACD, Signal Line)\n",
    "    if fit_scalers:\n",
    "        scalers['momentum'] = MinMaxScaler()\n",
    "        df[momentum_cols] = scalers['momentum'].fit_transform(df[momentum_cols])\n",
    "    else:\n",
    "        df[momentum_cols] = scalers['momentum'].transform(df[momentum_cols])\n",
    "\n",
    "    # Apply RobustScaler to lagged features\n",
    "    if fit_scalers:\n",
    "        scalers['lag'] = RobustScaler()\n",
    "        df[lag_cols] = scalers['lag'].fit_transform(df[lag_cols])\n",
    "    else:\n",
    "        df[lag_cols] = scalers['lag'].transform(df[lag_cols])\n",
    "\n",
    "    # Save the fitted scalers for later use\n",
    "    if fit_scalers and save_scalers:\n",
    "        with open(scalers_path, 'wb') as f:\n",
    "            pickle.dump(scalers, f)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def inverse_transform_predictions(pred_scaled, feature_name, scalers_path=\"scalers.pkl\"):\n",
    "    \"\"\"\n",
    "    Rescales the model's predictions back to their original scale.\n",
    "    \n",
    "    Parameters:\n",
    "        pred_scaled (numpy.ndarray): Scaled predictions from the model.\n",
    "        feature_name (str): The feature for which we are inverting the scale (e.g., 'close').\n",
    "        scalers_path (str): Path to the saved scalers file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Rescaled predictions in the original value range.\n",
    "    \"\"\"\n",
    "    global scalers\n",
    "\n",
    "    # Load scalers if not already loaded\n",
    "    if not scalers:\n",
    "        with open(scalers_path, 'rb') as f:\n",
    "            scalers = pickle.load(f)\n",
    "\n",
    "    # Identify the appropriate scaler\n",
    "    if feature_name in ['open', 'high', 'low', 'close', 'av_pr', 'diff', \n",
    "                        '7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA', \n",
    "                        '12_day_EMA', '26_day_EMA', '20_day_SMA']:\n",
    "        scaler = scalers['price']\n",
    "    elif feature_name in ['20_day_STD', 'Upper_Band', 'Lower_Band']:\n",
    "        scaler = scalers['volatility']\n",
    "    elif feature_name in ['RSI', 'MACD', 'Signal_Line']:\n",
    "        scaler = scalers['momentum']\n",
    "    elif feature_name in ['lag_1', 'lag_2', 'lag_3']:\n",
    "        scaler = scalers['lag']\n",
    "    elif feature_name == 'volume':\n",
    "        scaler = scalers['volume']\n",
    "        return np.expm1(scaler.inverse_transform(pred_scaled.reshape(-1, 1))).flatten()  # Inverse log transform\n",
    "    else:\n",
    "        raise ValueError(f\"Feature {feature_name} not recognized for inverse transformation.\")\n",
    "\n",
    "    # Rescale prediction\n",
    "    return scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"xrpusdt_daily_dataset_with_features.csv\")\n",
    "\n",
    "# Scale and preprocess the dataset (for training)\n",
    "df_scaled = preprocess_data(df, fit_scalers=True)\n",
    "\n",
    "# Split into X, y\n",
    "X_train, y_train = df_scaled.drop(columns=['close']), df_scaled['close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle_target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "48af8c7a-6786-4b09-b321-b62d88e28061",
       "rows": [
        [
         "2018-07-01 02:00:00",
         "0.46797",
         "0.46989",
         "0.45007",
         "0.46222",
         "31676174.10000002",
         "0.45998",
         "-0.0057499999999999",
         "0.46192714285714287",
         "0.5532916666666666",
         "0.4672347548515338",
         "0.5316441532839548",
         "35.37081941712037",
         "0.4818625021717392",
         "0.5226332992019683",
         "-0.04077079703022912",
         "-0.03959813504052097",
         "0.5036595",
         "0.03874555247481883",
         "0.5811506049496377",
         "0.42616839505036236",
         "0.46796",
         "0.45321",
         "0.44575",
         "0"
        ],
        [
         "2018-07-02 02:00:00",
         "0.46222",
         "0.4954",
         "0.452",
         "0.4899",
         "39873781.79999994",
         "0.4737",
         "0.0276799999999999",
         "0.46316285714285715",
         "0.5481986666666666",
         "0.47290106613865035",
         "0.5289509821043448",
         "39.56015745336302",
         "0.48309904029916395",
         "0.5202086103721929",
         "-0.03710957007302895",
         "-0.03910042204702257",
         "0.5003744999999999",
         "0.03684878252291445",
         "0.5740720650458289",
         "0.426676934954171",
         "0.46222",
         "0.46796",
         "0.45321",
         "1"
        ],
        [
         "2018-07-03 02:00:00",
         "0.48913",
         "0.52",
         "0.47801",
         "0.4844",
         "44333181.59999998",
         "0.499005",
         "-0.00473",
         "0.46764857142857147",
         "0.541342",
         "0.47577579960398775",
         "0.5260767251943871",
         "36.07457095565815",
         "0.4832991879454464",
         "0.5175561207149935",
         "-0.034256932769547055",
         "-0.038131724191527466",
         "0.4981635",
         "0.036388567214818465",
         "0.5709406344296369",
         "0.425386365570363",
         "0.4899",
         "0.46222",
         "0.46796",
         "0"
        ],
        [
         "2018-07-04 02:00:00",
         "0.48469",
         "0.508",
         "0.47941",
         "0.49097",
         "26722886.30000002",
         "0.493705",
         "0.00628",
         "0.47063",
         "0.535872",
         "0.47957434970299084",
         "0.523811775181846",
         "39.38405956734371",
         "0.4844793128769162",
         "0.5155867784398087",
         "-0.03110746556289251",
         "-0.036726872465800475",
         "0.4948275000000001",
         "0.0335952635876891",
         "0.5620180271753783",
         "0.4276369728246219",
         "0.4844",
         "0.4899",
         "0.46222",
         "1"
        ],
        [
         "2018-07-05 02:00:00",
         "0.49155",
         "0.50295",
         "0.46887",
         "0.4769",
         "30689285.9",
         "0.48591",
         "-0.0146499999999999",
         "0.47508",
         "0.5292806666666666",
         "0.47890576227724313",
         "0.5207852090410817",
         "37.805032776485525",
         "0.483313264742006",
         "0.512721091147971",
         "-0.029407826405965065",
         "-0.035263063253833396",
         "0.49204349999999997",
         "0.03259425510811107",
         "0.5572320102162222",
         "0.42685498978377784",
         "0.49097",
         "0.4844",
         "0.4899",
         "0"
        ],
        [
         "2018-07-06 02:00:00",
         "0.47772",
         "0.48156",
         "0.45747",
         "0.47698",
         "26805008.70000003",
         "0.469515",
         "-0.0007399999999999",
         "0.4784757142857143",
         "0.52271",
         "0.4784243217079323",
         "0.5179590665223023",
         "48.59330871170976",
         "0.4823389163201589",
         "0.510073602914788",
         "-0.027734686594629077",
         "-0.03375738792199254",
         "0.489255",
         "0.03128788154507973",
         "0.5518307630901594",
         "0.42667923690984055",
         "0.4769",
         "0.49097",
         "0.4844",
         "0"
        ],
        [
         "2018-07-07 02:00:00",
         "0.47644",
         "0.488",
         "0.46381",
         "0.48494",
         "28584029.19999998",
         "0.475905",
         "0.0085",
         "0.48090142857142865",
         "0.5162893333333334",
         "0.4800532412809492",
         "0.5158288041660247",
         "48.61284543134806",
         "0.48273908304013446",
         "0.5082118545507296",
         "-0.025472771510595127",
         "-0.032100464639713056",
         "0.48719350000000006",
         "0.03006187080969747",
         "0.547317241619395",
         "0.4270697583806051",
         "0.47698",
         "0.4769",
         "0.49097",
         "1"
        ],
        [
         "2018-07-08 02:00:00",
         "0.4852",
         "0.48798",
         "0.4751",
         "0.47915",
         "31480979.29999998",
         "0.48154",
         "-0.00605",
         "0.48331999999999997",
         "0.5098576666666667",
         "0.4798274309607119",
         "0.5134624297037006",
         "51.68552297390903",
         "0.4821869164185753",
         "0.5060591245840089",
         "-0.023872208165433617",
         "-0.030454813344857168",
         "0.484216",
         "0.02753473756242417",
         "0.5392854751248484",
         "0.42914652487515165",
         "0.48494",
         "0.47698",
         "0.4769",
         "0"
        ],
        [
         "2018-07-09 02:00:00",
         "0.47872",
         "0.48201",
         "0.47015",
         "0.473",
         "26690553.60000002",
         "0.47608",
         "-0.00572",
         "0.4809057142857143",
         "0.503711",
         "0.4781205732205339",
         "0.510851950367978",
         "47.59405074365703",
         "0.4807735446618714",
         "0.5036103005407491",
         "-0.02283675587887768",
         "-0.028931201851661273",
         "0.480449",
         "0.02309611402721004",
         "0.5266412280544202",
         "0.43425677194557993",
         "0.47915",
         "0.48494",
         "0.47698",
         "0"
        ],
        [
         "2018-07-10 02:00:00",
         "0.4728",
         "0.47338",
         "0.43866",
         "0.44337",
         "30651668.10000005",
         "0.45602",
         "-0.02943",
         "0.4750442857142857",
         "0.49908966666666665",
         "0.4694329299154005",
         "0.5064982761506892",
         "47.21402534282241",
         "0.47501915317542964",
         "0.4991480560562491",
         "-0.02412890288081948",
         "-0.027970742057492917",
         "0.4756595",
         "0.020005609338382933",
         "0.5156707186767658",
         "0.43564828132323413",
         "0.473",
         "0.47915",
         "0.48494",
         "0"
        ],
        [
         "2018-07-11 02:00:00",
         "0.44247",
         "0.45134",
         "0.43957",
         "0.44872",
         "28635928.19999998",
         "0.445455",
         "0.00625",
         "0.4690085714285714",
         "0.49405066666666664",
         "0.46425469743655035",
         "0.5027706454312899",
         "43.36354606406754",
         "0.47097312960997895",
         "0.49541264449652694",
         "-0.024439514886547997",
         "-0.027264496623303935",
         "0.471367",
         "0.01537435017026378",
         "0.5021157003405275",
         "0.4406182996594724",
         "0.44337",
         "0.473",
         "0.47915",
         "1"
        ],
        [
         "2018-07-12 02:00:00",
         "0.449",
         "0.44932",
         "0.4236",
         "0.43675",
         "30380599.49999994",
         "0.4364599999999999",
         "-0.0122499999999999",
         "0.46327285714285715",
         "0.490089",
         "0.4573785230774128",
         "0.49851124895185184",
         "46.97377269670479",
         "0.4657080327469053",
         "0.4910672634227101",
         "-0.02535923067580481",
         "-0.026883443433804114",
         "0.4690965",
         "0.016967130227527882",
         "0.5030307604550558",
         "0.43516223954494426",
         "0.44872",
         "0.44337",
         "0.473",
         "0"
        ],
        [
         "2018-07-13 02:00:00",
         "0.43706",
         "0.44509",
         "0.43001",
         "0.43754",
         "33168644.29999998",
         "0.43755",
         "0.0004799999999999",
         "0.4576385714285714",
         "0.487053",
         "0.4524188923080596",
         "0.4945776199872163",
         "44.48355981130746",
         "0.46137448924738145",
         "0.4871022809469538",
         "-0.025727791699572344",
         "-0.02665231308695776",
         "0.466471",
         "0.017604851574136163",
         "0.5016807031482724",
         "0.4312612968517277",
         "0.43675",
         "0.44872",
         "0.44337",
         "1"
        ],
        [
         "2018-07-14 02:00:00",
         "0.43761",
         "0.4443",
         "0.431",
         "0.43864",
         "27141582.29999995",
         "0.43765",
         "0.0010299999999999",
         "0.4510242857142857",
         "0.48308466666666666",
         "0.44897416923104466",
         "0.4909687412783636",
         "38.580775821779085",
         "0.45787687551701506",
         "0.48351248235829053",
         "-0.02563560684127547",
         "-0.026448971837821304",
         "0.4647374999999999",
         "0.018576126975800123",
         "0.5018897539516002",
         "0.42758524604839965",
         "0.43754",
         "0.43675",
         "0.44872",
         "1"
        ],
        [
         "2018-07-15 02:00:00",
         "0.43864",
         "0.45004",
         "0.43509",
         "0.44681",
         "33882949.8",
         "0.442565",
         "0.00817",
         "0.44640428571428575",
         "0.48022566666666666",
         "0.44843312692328346",
         "0.4881197902281466",
         "44.109777539943416",
         "0.4561742792836281",
         "0.4807937799613801",
         "-0.024619500677752038",
         "-0.02608307760580745",
         "0.4630155",
         "0.018561142624480654",
         "0.5001377852489614",
         "0.4258932147510387",
         "0.43864",
         "0.43754",
         "0.43675",
         "1"
        ],
        [
         "2018-07-16 02:00:00",
         "0.44695",
         "0.4858",
         "0.4435",
         "0.48173",
         "41419524.1",
         "0.46465",
         "0.0347799999999999",
         "0.4476514285714286",
         "0.478525",
         "0.4567573451924626",
         "0.48770754569729846",
         "47.04092720028975",
         "0.46010592862460836",
         "0.4808631295938705",
         "-0.020757200969262146",
         "-0.02501790227849839",
         "0.464452",
         "0.018854646111767695",
         "0.5021612922235353",
         "0.4267427077764646",
         "0.44681",
         "0.43864",
         "0.43754",
         "1"
        ],
        [
         "2018-07-17 02:00:00",
         "0.48173",
         "0.52019",
         "0.4665",
         "0.50728",
         "48166296.2000001",
         "0.493345",
         "0.0255499999999999",
         "0.45678142857142856",
         "0.47789533333333334",
         "0.4693880088943469",
         "0.4889702846845696",
         "57.23592662871599",
         "0.4673634780669763",
         "0.4828199348091393",
         "-0.015456456742163005",
         "-0.023105613171231314",
         "0.466311",
         "0.02113574669655768",
         "0.5085824933931153",
         "0.4240395066068846",
         "0.48173",
         "0.44681",
         "0.43864",
         "1"
        ],
        [
         "2018-07-18 02:00:00",
         "0.50651",
         "0.52525",
         "0.4752",
         "0.48868",
         "48747453.60000002",
         "0.500225",
         "-0.01783",
         "0.46248999999999996",
         "0.476228",
         "0.47421100667076016",
         "0.48895155664040385",
         "49.32698524657614",
         "0.4706429429797492",
         "0.48325401371216603",
         "-0.012611070732416851",
         "-0.021006704683468422",
         "0.46845749999999997",
         "0.021117645621113717",
         "0.5106927912422274",
         "0.42622220875777256",
         "0.50728",
         "0.48173",
         "0.44681",
         "0"
        ],
        [
         "2018-07-19 02:00:00",
         "0.48869",
         "0.495",
         "0.47125",
         "0.47687",
         "36600560.00000002",
         "0.483125",
         "-0.0118199999999999",
         "0.4682214285714286",
         "0.47384566666666667",
         "0.4748757550030701",
         "0.48817210137328104",
         "49.99106451420743",
         "0.4716009517520955",
         "0.4827811238075611",
         "-0.01118017205546562",
         "-0.019041398157867862",
         "0.46964049999999996",
         "0.020879905090276228",
         "0.5114003101805524",
         "0.4278806898194475",
         "0.48868",
         "0.50728",
         "0.48173",
         "0"
        ],
        [
         "2018-07-20 02:00:00",
         "0.47703",
         "0.4773",
         "0.431",
         "0.44439",
         "40745516.20000002",
         "0.45415",
         "-0.03264",
         "0.46919999999999995",
         "0.47068666666666664",
         "0.46725431625230257",
         "0.48534744967177906",
         "41.86348429620011",
         "0.4674146514825423",
         "0.47993733685885287",
         "-0.012522685376310572",
         "-0.017737655601556403",
         "0.468462",
         "0.021631391322018835",
         "0.5117247826440376",
         "0.42519921735596233",
         "0.47687",
         "0.48868",
         "0.50728",
         "0"
        ],
        [
         "2018-07-21 02:00:00",
         "0.4444",
         "0.459",
         "0.4346",
         "0.45506",
         "28483991.39999995",
         "0.4468",
         "0.01066",
         "0.4715457142857143",
         "0.4680363333333333",
         "0.4642057371892269",
         "0.48339342066069657",
         "42.639668932899795",
         "0.46551393586984346",
         "0.4780945711656045",
         "-0.012580635295761033",
         "-0.01670625154039733",
         "0.46810399999999996",
         "0.021798735453425207",
         "0.5117014709068504",
         "0.42450652909314956",
         "0.44439",
         "0.47687",
         "0.48868",
         "1"
        ],
        [
         "2018-07-22 02:00:00",
         "0.45467",
         "0.46409",
         "0.44589",
         "0.44859",
         "32232347.19999996",
         "0.45499",
         "-0.00608",
         "0.4718",
         "0.46691733333333335",
         "0.4603018028919202",
         "0.48114803868258715",
         "42.49729942060296",
         "0.4629102534283291",
         "0.4759090473755597",
         "-0.012998793947230636",
         "-0.01596476002176399",
         "0.4660385000000001",
         "0.021580836107650225",
         "0.5092001722153006",
         "0.42287682778469965",
         "0.45506",
         "0.44439",
         "0.47687",
         "0"
        ],
        [
         "2018-07-23 02:00:00",
         "0.44859",
         "0.46371",
         "0.44212",
         "0.44499",
         "30316389.90000007",
         "0.452915",
         "-0.0035999999999999",
         "0.46655142857142856",
         "0.46541533333333335",
         "0.45647385216894015",
         "0.47881526199338803",
         "43.03614937099099",
         "0.4601532913624323",
         "0.4736187475699627",
         "-0.013465456207530369",
         "-0.015464899258917267",
         "0.464068",
         "0.02161524135760148",
         "0.507298482715203",
         "0.420837517284797",
         "0.44859",
         "0.45506",
         "0.44439",
         "0"
        ],
        [
         "2018-07-24 02:00:00",
         "0.4452",
         "0.4715",
         "0.438",
         "0.45885",
         "43532211.20000008",
         "0.45475",
         "0.0136499999999999",
         "0.4596328571428572",
         "0.4649333333333333",
         "0.4570678891267051",
         "0.47752718057445975",
         "54.17610877306572",
         "0.4599527849989812",
         "0.472524766268484",
         "-0.012571981269502819",
         "-0.014886315661034379",
         "0.46246199999999993",
         "0.02068444587250596",
         "0.5038308917450118",
         "0.421093108254988",
         "0.44499",
         "0.44859",
         "0.45506",
         "1"
        ],
        [
         "2018-07-25 02:00:00",
         "0.45741",
         "0.46878",
         "0.45153",
         "0.4598",
         "42650288.40000004",
         "0.460155",
         "0.00239",
         "0.45550714285714283",
         "0.4642183333333333",
         "0.45775091684502883",
         "0.4763834915051398",
         "53.06178843815629",
         "0.4599292796145225",
         "0.471582190989337",
         "-0.0116529113748145",
         "-0.014239634803790405",
         "0.46160700000000005",
         "0.020407802455252966",
         "0.5024226049105059",
         "0.4207913950894941",
         "0.45885",
         "0.44499",
         "0.44859",
         "1"
        ],
        [
         "2018-07-26 02:00:00",
         "0.45983",
         "0.46887",
         "0.44538",
         "0.44968",
         "38041528.40000003",
         "0.457125",
         "-0.0101499999999999",
         "0.4516228571428571",
         "0.4641076666666667",
         "0.45573318763377163",
         "0.4746606856015824",
         "53.60991680160813",
         "0.45835246736613444",
         "0.46995980647160834",
         "-0.011607339105473902",
         "-0.013713175664127105",
         "0.46024199999999993",
         "0.02023773094208459",
         "0.5007174618841691",
         "0.41976653811583076",
         "0.4598",
         "0.45885",
         "0.44499",
         "0"
        ],
        [
         "2018-07-27 02:00:00",
         "0.44878",
         "0.462",
         "0.444",
         "0.4555",
         "35252979.79999998",
         "0.453",
         "0.00672",
         "0.45321",
         "0.463621",
         "0.45567489072532874",
         "0.4734245123369642",
         "54.87725396480557",
         "0.457913626232883",
         "0.46888870969593366",
         "-0.01097508346305065",
         "-0.013165557223911814",
         "0.45877",
         "0.019400093597169706",
         "0.49757018719433943",
         "0.4199698128056606",
         "0.44968",
         "0.4598",
         "0.45885",
         "1"
        ],
        [
         "2018-07-28 02:00:00",
         "0.4555",
         "0.45887",
         "0.44803",
         "0.45641",
         "27843347.29999995",
         "0.45345",
         "0.0009099999999999",
         "0.45340285714285716",
         "0.4639763333333333",
         "0.45585866804399655",
         "0.47232680186361164",
         "54.83064209210026",
         "0.45768229912013175",
         "0.4679643608295682",
         "-0.010282061709436463",
         "-0.012588858121016745",
         "0.45763300000000007",
         "0.018799886365837924",
         "0.49523277273167593",
         "0.4200332272683242",
         "0.4555",
         "0.44968",
         "0.4598",
         "1"
        ],
        [
         "2018-07-29 02:00:00",
         "0.45643",
         "0.45849",
         "0.45",
         "0.45315",
         "31188705.49999994",
         "0.454245",
         "-0.00328",
         "0.4540542857142857",
         "0.4639743333333333",
         "0.45518150103299737",
         "0.47108958884015284",
         "51.770751871299304",
         "0.45698502233241917",
         "0.4668670007681187",
         "-0.009881978435699545",
         "-0.012047482183953306",
         "0.45664049999999995",
         "0.01846694100990079",
         "0.4935743820198015",
         "0.41970661798019837",
         "0.45641",
         "0.4555",
         "0.44968",
         "0"
        ],
        [
         "2018-07-30 02:00:00",
         "0.45315",
         "0.45621",
         "0.43382",
         "0.44534",
         "32141597.89999998",
         "0.445015",
         "-0.0078099999999999",
         "0.4541042857142857",
         "0.4632203333333333",
         "0.45272112577474805",
         "0.46942832504401394",
         "38.022513330261326",
         "0.4551934804351239",
         "0.46527240811862847",
         "-0.010078927683504546",
         "-0.011653771283863554",
         "0.45673899999999995",
         "0.0183975561592179",
         "0.49353411231843575",
         "0.41994388768156415",
         "0.45315",
         "0.45641",
         "0.4555",
         "0"
        ],
        [
         "2018-07-31 02:00:00",
         "0.44616",
         "0.44641",
         "0.4268",
         "0.4353",
         "31785092.6",
         "0.436605",
         "-0.0108599999999999",
         "0.45074000000000003",
         "0.46232299999999993",
         "0.448365844331061",
         "0.46722649762181956",
         "23.61436950146627",
         "0.4521329449835664",
         "0.4630522297394708",
         "-0.010919284755904424",
         "-0.01150687397827173",
         "0.456068",
         "0.018942090308705518",
         "0.49395218061741103",
         "0.4181838193825889",
         "0.44534",
         "0.45315",
         "0.45641",
         "0"
        ],
        [
         "2018-08-01 02:00:00",
         "0.4353",
         "0.46382",
         "0.42671",
         "0.44642",
         "39833478.29999995",
         "0.445265",
         "0.0111199999999999",
         "0.4488285714285714",
         "0.46087366666666674",
         "0.4478793832482958",
         "0.4658841429365409",
         "33.60999069190193",
         "0.45125403037071005",
         "0.4618202127217322",
         "-0.010566182351022135",
         "-0.01131873565282181",
         "0.45655150000000005",
         "0.018542236643318943",
         "0.49363597328663794",
         "0.41946702671336217",
         "0.4353",
         "0.44534",
         "0.45315",
         "1"
        ],
        [
         "2018-08-02 02:00:00",
         "0.44673",
         "0.44888",
         "0.42849",
         "0.42975",
         "33396468.10000001",
         "0.438685",
         "-0.0169799999999999",
         "0.44598142857142864",
         "0.45905199999999996",
         "0.4433470374362219",
         "0.463552907908377",
         "32.38899686051725",
         "0.4479457180059854",
         "0.45944464140901126",
         "-0.01149892340302583",
         "-0.011354773202862614",
         "0.45616199999999996",
         "0.019037809084472918",
         "0.4942376181689458",
         "0.4180863818310541",
         "0.44642",
         "0.4353",
         "0.44534",
         "0"
        ],
        [
         "2018-08-03 02:00:00",
         "0.43021",
         "0.44619",
         "0.4253",
         "0.44033",
         "44748261.19999998",
         "0.435745",
         "0.01012",
         "0.4438142857142857",
         "0.457364",
         "0.44259277807716646",
         "0.4620546557852559",
         "48.185555952806574",
         "0.4467740690819877",
         "0.4580287420453808",
         "-0.011254672963393109",
         "-0.011334753154968714",
         "0.45624650000000005",
         "0.01895953343724186",
         "0.49416556687448376",
         "0.41832743312551635",
         "0.42975",
         "0.44642",
         "0.4353",
         "1"
        ],
        [
         "2018-08-04 02:00:00",
         "0.44097",
         "0.445",
         "0.42741",
         "0.42985",
         "35095397.49999999",
         "0.436205",
         "-0.0111199999999999",
         "0.44002",
         "0.4557956666666667",
         "0.43940708355787483",
         "0.4599769360571749",
         "38.71429850479002",
         "0.44417036614629724",
         "0.455941427819797",
         "-0.011771061673499783",
         "-0.01142201485867493",
         "0.4553985",
         "0.019765946067602378",
         "0.49493039213520473",
         "0.41586660786479523",
         "0.44033",
         "0.42975",
         "0.44642",
         "0"
        ],
        [
         "2018-08-05 02:00:00",
         "0.42984",
         "0.43705",
         "0.42705",
         "0.4345",
         "34962084.2",
         "0.43205",
         "0.0046599999999999",
         "0.4373557142857143",
         "0.4543796666666667",
         "0.43818031266840607",
         "0.45833326276316366",
         "43.58787658141439",
         "0.4426826175084053",
         "0.45435317390721947",
         "-0.011670556398814147",
         "-0.011471723166702773",
         "0.453037",
         "0.01926959101524301",
         "0.49157618203048603",
         "0.414497817969514",
         "0.42985",
         "0.44033",
         "0.42975",
         "1"
        ],
        [
         "2018-08-06 02:00:00",
         "0.43437",
         "0.43699",
         "0.40127",
         "0.4129",
         "40578992.90000006",
         "0.41913",
         "-0.0214699999999999",
         "0.4327214285714286",
         "0.45197833333333326",
         "0.43186023450130456",
         "0.4554020845203789",
         "37.45209978884802",
         "0.438100676353266",
         "0.4512825684326106",
         "-0.013181892079344615",
         "-0.011813756949231142",
         "0.448318",
         "0.01666752613222546",
         "0.48165305226445093",
         "0.41498294773554906",
         "0.4345",
         "0.42985",
         "0.44033",
         "0"
        ],
        [
         "2018-08-07 02:00:00",
         "0.41328",
         "0.41567",
         "0.37387",
         "0.37863",
         "41157252.55999998",
         "0.3947699999999999",
         "-0.0346499999999999",
         "0.4246257142857143",
         "0.4486276666666667",
         "0.41855267587597844",
         "0.45044904680938674",
         "22.94982465605608",
         "0.4289513415296866",
         "0.44590089669686167",
         "-0.016949555167175057",
         "-0.012840916592819926",
         "0.44281550000000003",
         "0.020391043305953236",
         "0.4835975866119065",
         "0.40203341338809356",
         "0.4129",
         "0.4345",
         "0.42985",
         "0"
        ],
        [
         "2018-08-08 02:00:00",
         "0.37863",
         "0.37863",
         "0.31928",
         "0.33171",
         "72393008.14999995",
         "0.348955",
         "-0.04692",
         "0.40823857142857145",
         "0.443918",
         "0.39684200690698385",
         "0.442788463144265",
         "17.029601029600997",
         "0.41399113514050406",
         "0.4374423117563534",
         "-0.023451176615849334",
         "-0.014962968597425809",
         "0.4355575",
         "0.03080605731191936",
         "0.4971696146238387",
         "0.3739453853761613",
         "0.37863",
         "0.4129",
         "0.4345",
         "0"
        ],
        [
         "2018-08-09 02:00:00",
         "0.33197",
         "0.35799",
         "0.328",
         "0.3441",
         "51832840.70000008",
         "0.342995",
         "0.01213",
         "0.39600285714285716",
         "0.44060900000000003",
         "0.3836565051802379",
         "0.4364214655220544",
         "23.13759413800119",
         "0.40323865281119575",
         "0.43052806644106795",
         "-0.027289413629872195",
         "-0.017428257603915087",
         "0.430543",
         "0.03686019620417833",
         "0.5042633924083567",
         "0.35682260759164336",
         "0.33171",
         "0.37863",
         "0.4129",
         "1"
        ],
        [
         "2018-08-10 02:00:00",
         "0.3441",
         "0.34689",
         "0.31236",
         "0.31897",
         "39269097.20000007",
         "0.329625",
         "-0.02513",
         "0.37866571428571427",
         "0.436284",
         "0.36748487888517845",
         "0.4288439516174058",
         "18.370940091738845",
         "0.3902742446863964",
         "0.4222645059639518",
         "-0.03199026127755544",
         "-0.02034065833864316",
         "0.4237385000000001",
         "0.04397142245104674",
         "0.5116813449020936",
         "0.3357956550979066",
         "0.3441",
         "0.33171",
         "0.37863",
         "0"
        ],
        [
         "2018-08-11 02:00:00",
         "0.31897",
         "0.32008",
         "0.2874",
         "0.29784",
         "48724318.70000006",
         "0.30374",
         "-0.0211299999999999",
         "0.3598071428571429",
         "0.43165366666666666",
         "0.3500736591638838",
         "0.4203920837711215",
         "16.411777165854673",
         "0.37605359165772",
         "0.413047875892548",
         "-0.03699428423482798",
         "-0.023671383517880125",
         "0.41620099999999993",
         "0.051724366130276964",
         "0.5196497322605539",
         "0.312752267739446",
         "0.31897",
         "0.3441",
         "0.33171",
         "0"
        ],
        [
         "2018-08-12 02:00:00",
         "0.29708",
         "0.30938",
         "0.29401",
         "0.29547",
         "35382260.6",
         "0.301695",
         "-0.00161",
         "0.3399457142857143",
         "0.42691799999999996",
         "0.33642274437291286",
         "0.41233259449556536",
         "16.473890117366892",
         "0.36365611601807074",
         "0.4043384036042111",
         "-0.04068228758614034",
         "-0.02707356433153217",
         "0.408725",
         "0.0577937108670958",
         "0.5243124217341916",
         "0.2931375782658084",
         "0.29784",
         "0.31897",
         "0.3441",
         "0"
        ],
        [
         "2018-08-13 02:00:00",
         "0.29575",
         "0.309",
         "0.27127",
         "0.2743",
         "43767335.33999998",
         "0.290135",
         "-0.02145",
         "0.32014571428571426",
         "0.42144",
         "0.32089205827968464",
         "0.40342726581843213",
         "15.588282633188456",
         "0.3499090212460599",
         "0.3947059292631584",
         "-0.04479690801709851",
         "-0.030618233068645445",
         "0.3994975",
         "0.06379109704215861",
         "0.5270796940843172",
         "0.2719153059156828",
         "0.29547",
         "0.29784",
         "0.31897",
         "0"
        ],
        [
         "2018-08-14 02:00:00",
         "0.2743",
         "0.27732",
         "0.24672",
         "0.2725",
         "56101898.99999996",
         "0.26202",
         "-0.0017999999999999",
         "0.3049842857142857",
         "0.4156296666666667",
         "0.3087940437097635",
         "0.39498034544304944",
         "16.122856667221555",
         "0.3379999410543584",
         "0.3856536382066282",
         "-0.0476536971522698",
         "-0.034025325885370314",
         "0.3901325",
         "0.06807684751150903",
         "0.526286195023018",
         "0.25397880497698194",
         "0.2743",
         "0.29547",
         "0.29784",
         "0"
        ],
        [
         "2018-08-15 02:00:00",
         "0.2728",
         "0.30234",
         "0.2728",
         "0.28039",
         "72676585.19999997",
         "0.28757",
         "0.0075899999999999",
         "0.2976528571428571",
         "0.40891833333333333",
         "0.3016930327823226",
         "0.3875874199305947",
         "14.979962033326288",
         "0.3291368731998417",
         "0.37785633167280386",
         "-0.04871945847296216",
         "-0.03696415240288868",
         "0.381668",
         "0.07075504167269814",
         "0.5231780833453963",
         "0.24015791665460373",
         "0.2725",
         "0.2743",
         "0.29547",
         "1"
        ],
        [
         "2018-08-16 02:00:00",
         "0.28",
         "0.30184",
         "0.2755",
         "0.29142",
         "46325561.50000004",
         "0.28867",
         "0.0114199999999999",
         "0.29012714285714286",
         "0.401723",
         "0.29912477458674197",
         "0.3813830702576531",
         "20.111490428244224",
         "0.323334277322943",
         "0.37145364043778134",
         "-0.04811936311483833",
         "-0.03919519454527862",
         "0.373464",
         "0.07125442460130559",
         "0.5159728492026112",
         "0.23095515079738885",
         "0.28039",
         "0.2725",
         "0.2743",
         "1"
        ],
        [
         "2018-08-17 02:00:00",
         "0.29161",
         "0.37506",
         "0.29085",
         "0.3672",
         "84683658.1",
         "0.332955",
         "0.07559",
         "0.29701714285714287",
         "0.3976736666666667",
         "0.31614358094005646",
         "0.38046803346683683",
         "37.67236438420823",
         "0.3300828500424903",
         "0.37113855596090867",
         "-0.041055705918418395",
         "-0.039567296819906575",
         "0.36900350000000004",
         "0.06852888175414559",
         "0.5060612635082913",
         "0.23194573649170885",
         "0.29142",
         "0.28039",
         "0.2725",
         "1"
        ],
        [
         "2018-08-18 02:00:00",
         "0.36721",
         "0.37",
         "0.31039",
         "0.32829",
         "80106581.6000001",
         "0.340195",
         "-0.0389199999999999",
         "0.3013671428571429",
         "0.392721",
         "0.31918018570504236",
         "0.3771017087270409",
         "34.377307408318984",
         "0.32980702695903025",
         "0.36796458885269323",
         "-0.03815756189366298",
         "-0.039285349834657854",
         "0.36276050000000004",
         "0.06610414418691306",
         "0.4949687883738262",
         "0.23055221162617393",
         "0.3672",
         "0.29142",
         "0.28039",
         "0"
        ],
        [
         "2018-08-19 02:00:00",
         "0.32848",
         "0.35281",
         "0.316",
         "0.34201",
         "63806323.29999998",
         "0.334405",
         "0.0135299999999999",
         "0.3080157142857143",
         "0.3893083333333333",
         "0.3248876392787818",
         "0.37483772751884475",
         "36.15875011223848",
         "0.3316844074268717",
         "0.3660420267154567",
         "-0.034357619288584995",
         "-0.03829980372544328",
         "0.357594",
         "0.06328829387060936",
         "0.48417058774121874",
         "0.2310174122587813",
         "0.32829",
         "0.3672",
         "0.29142",
         "1"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 2428
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>30_day_SMA</th>\n",
       "      <th>7_day_EMA</th>\n",
       "      <th>...</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>candle_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-01 02:00:00</th>\n",
       "      <td>0.46797</td>\n",
       "      <td>0.46989</td>\n",
       "      <td>0.45007</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>31676174.1</td>\n",
       "      <td>0.459980</td>\n",
       "      <td>-0.00575</td>\n",
       "      <td>0.461927</td>\n",
       "      <td>0.553292</td>\n",
       "      <td>0.467235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040771</td>\n",
       "      <td>-0.039598</td>\n",
       "      <td>0.503660</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.581151</td>\n",
       "      <td>0.426168</td>\n",
       "      <td>0.46796</td>\n",
       "      <td>0.45321</td>\n",
       "      <td>0.44575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-02 02:00:00</th>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.49540</td>\n",
       "      <td>0.45200</td>\n",
       "      <td>0.48990</td>\n",
       "      <td>39873781.8</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>0.02768</td>\n",
       "      <td>0.463163</td>\n",
       "      <td>0.548199</td>\n",
       "      <td>0.472901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037110</td>\n",
       "      <td>-0.039100</td>\n",
       "      <td>0.500374</td>\n",
       "      <td>0.036849</td>\n",
       "      <td>0.574072</td>\n",
       "      <td>0.426677</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.46796</td>\n",
       "      <td>0.45321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-03 02:00:00</th>\n",
       "      <td>0.48913</td>\n",
       "      <td>0.52000</td>\n",
       "      <td>0.47801</td>\n",
       "      <td>0.48440</td>\n",
       "      <td>44333181.6</td>\n",
       "      <td>0.499005</td>\n",
       "      <td>-0.00473</td>\n",
       "      <td>0.467649</td>\n",
       "      <td>0.541342</td>\n",
       "      <td>0.475776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034257</td>\n",
       "      <td>-0.038132</td>\n",
       "      <td>0.498163</td>\n",
       "      <td>0.036389</td>\n",
       "      <td>0.570941</td>\n",
       "      <td>0.425386</td>\n",
       "      <td>0.48990</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.46796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04 02:00:00</th>\n",
       "      <td>0.48469</td>\n",
       "      <td>0.50800</td>\n",
       "      <td>0.47941</td>\n",
       "      <td>0.49097</td>\n",
       "      <td>26722886.3</td>\n",
       "      <td>0.493705</td>\n",
       "      <td>0.00628</td>\n",
       "      <td>0.470630</td>\n",
       "      <td>0.535872</td>\n",
       "      <td>0.479574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031107</td>\n",
       "      <td>-0.036727</td>\n",
       "      <td>0.494828</td>\n",
       "      <td>0.033595</td>\n",
       "      <td>0.562018</td>\n",
       "      <td>0.427637</td>\n",
       "      <td>0.48440</td>\n",
       "      <td>0.48990</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05 02:00:00</th>\n",
       "      <td>0.49155</td>\n",
       "      <td>0.50295</td>\n",
       "      <td>0.46887</td>\n",
       "      <td>0.47690</td>\n",
       "      <td>30689285.9</td>\n",
       "      <td>0.485910</td>\n",
       "      <td>-0.01465</td>\n",
       "      <td>0.475080</td>\n",
       "      <td>0.529281</td>\n",
       "      <td>0.478906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029408</td>\n",
       "      <td>-0.035263</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.032594</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.426855</td>\n",
       "      <td>0.49097</td>\n",
       "      <td>0.48440</td>\n",
       "      <td>0.48990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-17 01:00:00</th>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76480</td>\n",
       "      <td>2.60750</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>212813356.0</td>\n",
       "      <td>2.686150</td>\n",
       "      <td>-0.06840</td>\n",
       "      <td>2.619271</td>\n",
       "      <td>2.782387</td>\n",
       "      <td>2.639626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032975</td>\n",
       "      <td>-0.055473</td>\n",
       "      <td>2.629525</td>\n",
       "      <td>0.246332</td>\n",
       "      <td>3.122190</td>\n",
       "      <td>2.136860</td>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76190</td>\n",
       "      <td>2.73840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-18 01:00:00</th>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.66990</td>\n",
       "      <td>2.46930</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>227170019.0</td>\n",
       "      <td>2.569600</td>\n",
       "      <td>-0.09710</td>\n",
       "      <td>2.640657</td>\n",
       "      <td>2.769190</td>\n",
       "      <td>2.620420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035382</td>\n",
       "      <td>-0.051455</td>\n",
       "      <td>2.604250</td>\n",
       "      <td>0.223850</td>\n",
       "      <td>3.051949</td>\n",
       "      <td>2.156551</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 01:00:00</th>\n",
       "      <td>2.56290</td>\n",
       "      <td>2.74700</td>\n",
       "      <td>2.51210</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>208577133.0</td>\n",
       "      <td>2.629550</td>\n",
       "      <td>0.17490</td>\n",
       "      <td>2.678429</td>\n",
       "      <td>2.756940</td>\n",
       "      <td>2.649765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022904</td>\n",
       "      <td>-0.045745</td>\n",
       "      <td>2.584760</td>\n",
       "      <td>0.190347</td>\n",
       "      <td>2.965454</td>\n",
       "      <td>2.204066</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.72830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-20 01:00:00</th>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.74900</td>\n",
       "      <td>2.66710</td>\n",
       "      <td>2.68770</td>\n",
       "      <td>161604635.0</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>-0.05010</td>\n",
       "      <td>2.696686</td>\n",
       "      <td>2.740737</td>\n",
       "      <td>2.659248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016864</td>\n",
       "      <td>-0.039969</td>\n",
       "      <td>2.567340</td>\n",
       "      <td>0.160464</td>\n",
       "      <td>2.888269</td>\n",
       "      <td>2.246411</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 01:00:00</th>\n",
       "      <td>2.68780</td>\n",
       "      <td>2.71600</td>\n",
       "      <td>2.50760</td>\n",
       "      <td>2.54120</td>\n",
       "      <td>227097007.0</td>\n",
       "      <td>2.611800</td>\n",
       "      <td>-0.14660</td>\n",
       "      <td>2.668514</td>\n",
       "      <td>2.719433</td>\n",
       "      <td>2.629736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023625</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>2.550510</td>\n",
       "      <td>0.142876</td>\n",
       "      <td>2.836263</td>\n",
       "      <td>2.264757</td>\n",
       "      <td>2.68770</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2428 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close       volume  \\\n",
       "datetime                                                               \n",
       "2018-07-01 02:00:00  0.46797  0.46989  0.45007  0.46222   31676174.1   \n",
       "2018-07-02 02:00:00  0.46222  0.49540  0.45200  0.48990   39873781.8   \n",
       "2018-07-03 02:00:00  0.48913  0.52000  0.47801  0.48440   44333181.6   \n",
       "2018-07-04 02:00:00  0.48469  0.50800  0.47941  0.49097   26722886.3   \n",
       "2018-07-05 02:00:00  0.49155  0.50295  0.46887  0.47690   30689285.9   \n",
       "...                      ...      ...      ...      ...          ...   \n",
       "2025-02-17 01:00:00  2.72830  2.76480  2.60750  2.65990  212813356.0   \n",
       "2025-02-18 01:00:00  2.65990  2.66990  2.46930  2.56280  227170019.0   \n",
       "2025-02-19 01:00:00  2.56290  2.74700  2.51210  2.73780  208577133.0   \n",
       "2025-02-20 01:00:00  2.73780  2.74900  2.66710  2.68770  161604635.0   \n",
       "2025-02-21 01:00:00  2.68780  2.71600  2.50760  2.54120  227097007.0   \n",
       "\n",
       "                        av_pr     diff  7_day_SMA  30_day_SMA  7_day_EMA  ...  \\\n",
       "datetime                                                                  ...   \n",
       "2018-07-01 02:00:00  0.459980 -0.00575   0.461927    0.553292   0.467235  ...   \n",
       "2018-07-02 02:00:00  0.473700  0.02768   0.463163    0.548199   0.472901  ...   \n",
       "2018-07-03 02:00:00  0.499005 -0.00473   0.467649    0.541342   0.475776  ...   \n",
       "2018-07-04 02:00:00  0.493705  0.00628   0.470630    0.535872   0.479574  ...   \n",
       "2018-07-05 02:00:00  0.485910 -0.01465   0.475080    0.529281   0.478906  ...   \n",
       "...                       ...      ...        ...         ...        ...  ...   \n",
       "2025-02-17 01:00:00  2.686150 -0.06840   2.619271    2.782387   2.639626  ...   \n",
       "2025-02-18 01:00:00  2.569600 -0.09710   2.640657    2.769190   2.620420  ...   \n",
       "2025-02-19 01:00:00  2.629550  0.17490   2.678429    2.756940   2.649765  ...   \n",
       "2025-02-20 01:00:00  2.708050 -0.05010   2.696686    2.740737   2.659248  ...   \n",
       "2025-02-21 01:00:00  2.611800 -0.14660   2.668514    2.719433   2.629736  ...   \n",
       "\n",
       "                         MACD  Signal_Line  20_day_SMA  20_day_STD  \\\n",
       "datetime                                                             \n",
       "2018-07-01 02:00:00 -0.040771    -0.039598    0.503660    0.038746   \n",
       "2018-07-02 02:00:00 -0.037110    -0.039100    0.500374    0.036849   \n",
       "2018-07-03 02:00:00 -0.034257    -0.038132    0.498163    0.036389   \n",
       "2018-07-04 02:00:00 -0.031107    -0.036727    0.494828    0.033595   \n",
       "2018-07-05 02:00:00 -0.029408    -0.035263    0.492043    0.032594   \n",
       "...                       ...          ...         ...         ...   \n",
       "2025-02-17 01:00:00 -0.032975    -0.055473    2.629525    0.246332   \n",
       "2025-02-18 01:00:00 -0.035382    -0.051455    2.604250    0.223850   \n",
       "2025-02-19 01:00:00 -0.022904    -0.045745    2.584760    0.190347   \n",
       "2025-02-20 01:00:00 -0.016864    -0.039969    2.567340    0.160464   \n",
       "2025-02-21 01:00:00 -0.023625    -0.036700    2.550510    0.142876   \n",
       "\n",
       "                     Upper_Band  Lower_Band    lag_1    lag_2    lag_3  \\\n",
       "datetime                                                                 \n",
       "2018-07-01 02:00:00    0.581151    0.426168  0.46796  0.45321  0.44575   \n",
       "2018-07-02 02:00:00    0.574072    0.426677  0.46222  0.46796  0.45321   \n",
       "2018-07-03 02:00:00    0.570941    0.425386  0.48990  0.46222  0.46796   \n",
       "2018-07-04 02:00:00    0.562018    0.427637  0.48440  0.48990  0.46222   \n",
       "2018-07-05 02:00:00    0.557232    0.426855  0.49097  0.48440  0.48990   \n",
       "...                         ...         ...      ...      ...      ...   \n",
       "2025-02-17 01:00:00    3.122190    2.136860  2.72830  2.76190  2.73840   \n",
       "2025-02-18 01:00:00    3.051949    2.156551  2.65990  2.72830  2.76190   \n",
       "2025-02-19 01:00:00    2.965454    2.204066  2.56280  2.65990  2.72830   \n",
       "2025-02-20 01:00:00    2.888269    2.246411  2.73780  2.56280  2.65990   \n",
       "2025-02-21 01:00:00    2.836263    2.264757  2.68770  2.73780  2.56280   \n",
       "\n",
       "                     candle_target  \n",
       "datetime                            \n",
       "2018-07-01 02:00:00              0  \n",
       "2018-07-02 02:00:00              1  \n",
       "2018-07-03 02:00:00              0  \n",
       "2018-07-04 02:00:00              1  \n",
       "2018-07-05 02:00:00              0  \n",
       "...                            ...  \n",
       "2025-02-17 01:00:00              0  \n",
       "2025-02-18 01:00:00              0  \n",
       "2025-02-19 01:00:00              1  \n",
       "2025-02-20 01:00:00              0  \n",
       "2025-02-21 01:00:00              0  \n",
       "\n",
       "[2428 rows x 24 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and preprocess the dataset (for training)\n",
    "df_scaled = preprocess_data(df, fit_scalers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle_target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d9683e08-55df-4328-92c1-ddab682c94e2",
       "rows": [
        [
         "2018-07-01 02:00:00",
         "0.0022497187851518697",
         "-0.03045195476363768",
         "-0.005081095336468633",
         "-0.017224446626879282",
         "-1.7260242115105275",
         "-0.017274774487141768",
         "-0.3419838523644657",
         "-0.011292108900760652",
         "0.3016808667794026",
         "0.008179476211545146",
         "0.24743905674173505",
         "0.28221482220963023",
         "0.05481817254292167",
         "0.2041491299262795",
         "0.15695128950245546",
         "0.129492557123146",
         "0.1259884261792711",
         "-0.1477772976831552",
         "-0.14454267971882137",
         "-0.10594952246917153",
         "0.0020486469694296332",
         "-0.04682841618167011",
         "-0.07107272773096539",
         "0"
        ],
        [
         "2018-07-02 02:00:00",
         "-0.01705756929637518",
         "0.05298836382072267",
         "0.0017054195419981995",
         "0.07571369813569694",
         "-1.5382809590473325",
         "0.029449701799420316",
         "1.5859284890426852",
         "-0.007122344034524546",
         "0.2836600170135975",
         "0.027282316862813988",
         "0.23785137707764561",
         "0.33145437238397046",
         "0.05906787167786168",
         "0.1955654413673134",
         "0.16338809382812156",
         "0.13049446999860745",
         "0.11475320126956301",
         "-0.17440428224738094",
         "-0.1574779916636851",
         "-0.10449292180491827",
         "-0.017228785169139397",
         "0.0027210198785618156",
         "-0.04600404929725365",
         "1"
        ],
        [
         "2018-07-03 02:00:00",
         "0.07330053892517173",
         "0.1334521755484868",
         "0.09316513559843516",
         "0.057246942492843976",
         "-1.4518020326839227",
         "0.11562775372591093",
         "-0.2831603229527064",
         "0.008014143456783519",
         "0.2593986857954152",
         "0.036973908538702235",
         "0.22761903286811022",
         "0.2904863937305523",
         "0.0597557334270487",
         "0.1861753106240677",
         "0.1684033164158659",
         "0.13244449112831613",
         "0.10719122797417077",
         "-0.1808648157942082",
         "-0.16320036271825014",
         "-0.10818947385057039",
         "0.0757327691158072",
         "-0.016561269137419874",
         "0.0035620374181949735",
         "0"
        ],
        [
         "2018-07-04 02:00:00",
         "0.05839195473700123",
         "0.09420153568128477",
         "0.09808799613203811",
         "0.07930632150621565",
         "-1.8647342226048227",
         "0.09757821113707874",
         "0.3517877739331105",
         "0.018074605047343782",
         "0.24004387562087112",
         "0.0497799641135352",
         "0.2195558190108446",
         "0.32938459892113964",
         "0.06381155329152234",
         "0.1792036033482284",
         "0.17394039575465686",
         "0.13527250456277878",
         "0.09578157491518022",
         "-0.22007740058241285",
         "-0.17950552024561486",
         "-0.10174310455491714",
         "0.05726136201439076",
         "0.07642370646578149",
         "-0.015726731242596468",
         "1"
        ],
        [
         "2018-07-05 02:00:00",
         "0.08142638886557091",
         "0.07768355807050394",
         "0.06102588897191333",
         "0.032065002979862665",
         "-1.7518429770661466",
         "0.07103176123520184",
         "-0.8552479815455529",
         "0.03309057910321143",
         "0.21672138833315385",
         "0.047525954686884024",
         "0.2087812544902079",
         "0.31082544513062277",
         "0.059804112161869045",
         "0.1690587274703617",
         "0.17692853191919233",
         "0.13821920138574129",
         "0.08625985006019458",
         "-0.23412962515905295",
         "-0.1882514796074857",
         "-0.1039829229215733",
         "0.07932629740644645",
         "0.05794764556196617",
         "0.07728949114951325",
         "0"
        ],
        [
         "2018-07-06 02:00:00",
         "0.034988163792958674",
         "0.007719292507216305",
         "0.02093973891257522",
         "0.03233361033466788",
         "-1.8622312436384783",
         "0.015197374302389564",
         "-0.05305651672432558",
         "0.04454899654487989",
         "0.19347202708022201",
         "0.04590287363598736",
         "0.19872019733934232",
         "0.43762587269495823",
         "0.0564554991643247",
         "0.15968630236652867",
         "0.17987007957546972",
         "0.1412501761059962",
         "0.07672273448615508",
         "-0.2524685853808889",
         "-0.19812170954421687",
         "-0.10448632835938489",
         "0.03207307960336834",
         "0.0800181401325238",
         "0.05880722152680356",
         "0"
        ],
        [
         "2018-07-07 02:00:00",
         "0.030690193576549143",
         "0.02878380256928138",
         "0.043233264471891325",
         "0.05906004213777858",
         "-1.8098130645822685",
         "0.03695899263118926",
         "0.4798154555940109",
         "0.05273426907998873",
         "0.17075341930556825",
         "0.05139445174745215",
         "0.1911364710515037",
         "0.43785549830133086",
         "0.05783078078807342",
         "0.15309549040913537",
         "0.18384675323361768",
         "0.14458561800093034",
         "0.06967207507934779",
         "-0.26967940680592384",
         "-0.20636971110775446",
         "-0.10336776552987909",
         "0.032341754615752664",
         "0.032753017056763443",
         "0.08088513269429501",
         "1"
        ],
        [
         "2018-07-08 02:00:00",
         "0.06010442724510193",
         "0.028718384836169494",
         "0.08293261834644636",
         "0.03961958483375715",
         "-1.731066439432143",
         "0.05614940253459868",
         "-0.35928489042675527",
         "0.06089543892800889",
         "0.1479958896091738",
         "0.05063317719927942",
         "0.18271218651964144",
         "0.4739703352320349",
         "0.05593311021735702",
         "0.14547456876386383",
         "0.186660704180684",
         "0.14789836900878847",
         "0.059488549305023355",
         "-0.3051554738425868",
         "-0.22104694772534597",
         "-0.09741932484154815",
         "0.05907491834798432",
         "0.033021759760819024",
         "0.033604126586744894",
         "0"
        ],
        [
         "2018-07-09 02:00:00",
         "0.03834595302452861",
         "0.0091911915022364",
         "0.06552679003120744",
         "0.018970394433112346",
         "-1.8657217902859957",
         "0.037554968094027995",
         "-0.3402537485582431",
         "0.05274873069224145",
         "0.12624679152150817",
         "0.04487884607046542",
         "0.1734188895208753",
         "0.425881054676126",
         "0.051075674285055925",
         "0.13680543866150854",
         "0.18848113318851067",
         "0.15096544982077237",
         "0.04660480737660058",
         "-0.36746517051396976",
         "-0.24415302360914679",
         "-0.08278214647749853",
         "0.03962956432667516",
         "0.05976165881434071",
         "0.03387295959943893",
         "0"
        ],
        [
         "2018-07-10 02:00:00",
         "0.01846784077363466",
         "-0.019036560335592943",
         "-0.04520240868533251",
         "-0.08051505460283903",
         "-1.7528434798811297",
         "-0.03076084781766557",
         "-1.7076124567474091",
         "0.03297006566777101",
         "0.1098948665818444",
         "0.015590185902718153",
         "0.15791982504506452",
         "0.4214144111085655",
         "0.03129914497336604",
         "0.12100855930175199",
         "0.18620940911657388",
         "0.15289888745794633",
         "0.030223952063040325",
         "-0.41084988385912036",
         "-0.264200514041129",
         "-0.07879647402854094",
         "0.018975172749636646",
         "0.04031140560832435",
         "0.060621844362487735",
         "0"
        ],
        [
         "2018-07-11 02:00:00",
         "-0.08337390661988155",
         "-0.09112690222502062",
         "-0.04200254933849054",
         "-0.06255193775024565",
         "-1.808333319275782",
         "-0.06674073790276235",
         "0.35005767012688216",
         "0.012603295078351768",
         "0.09206508806821946",
         "-0.0018671941963262638",
         "0.14464947315870746",
         "0.37615765073227614",
         "0.01739388603739431",
         "0.1077847554575339",
         "0.18566332204646063",
         "0.15432058309979835",
         "0.015542916165043063",
         "-0.4758638125427893",
         "-0.28897093180811007",
         "-0.06456095002010587",
         "-0.0805353349621758",
         "0.01965181023405799",
         "0.041165055068762585",
         "1"
        ],
        [
         "2018-07-12 02:00:00",
         "-0.061447542937729756",
         "-0.09773409326933302",
         "-0.09815832271108967",
         "-0.10274231321296372",
         "-1.76008947363956",
         "-0.09737387669267704",
         "-0.7168396770472822",
         "-0.006751162653368271",
         "0.07804729898080592",
         "-0.02504884737722468",
         "0.12948603708884857",
         "0.4185905921374813",
         "-0.0007010494022256736",
         "0.09240158655370226",
         "0.1840463694128553",
         "0.15508765589432597",
         "0.007777443362153873",
         "-0.4535042586304149",
         "-0.28729875248997744",
         "-0.0801886337623388",
         "-0.06256769350897975",
         "-0.0798837687804961",
         "0.020498517217914347",
         "0"
        ],
        [
         "2018-07-13 02:00:00",
         "-0.1015395463626748",
         "-0.11156994382252176",
         "-0.07561865412509336",
         "-0.10008981558426316",
         "-1.6884679383553745",
         "-0.09366180095270933",
         "0.017301038062283843",
         "-0.025763362228438044",
         "0.06730484858045568",
         "-0.0417692553243667",
         "0.11548233219409648",
         "0.3893217765741318",
         "-0.015594448685841556",
         "0.07836507419974263",
         "0.18339840215494102",
         "0.15555292900039364",
         "-0.0012021861661376974",
         "-0.44455188333821494",
         "-0.2897658449474614",
         "-0.09136202581200373",
         "-0.10276819223697144",
         "-0.06191160044678477",
         "-0.07907050985861064",
         "1"
        ],
        [
         "2018-07-14 02:00:00",
         "-0.09969276228531135",
         "-0.11415394428044594",
         "-0.07213748846204561",
         "-0.09639646445569261",
         "-1.8520524322132284",
         "-0.09332124354537291",
         "0.049019607843137546",
         "-0.04808245047199077",
         "0.05326347044956297",
         "-0.05338245352221069",
         "0.10263473703601857",
         "0.31994317167135",
         "-0.027614948268210412",
         "0.06565675769491697",
         "0.18356047238483467",
         "0.15596226172484234",
         "-0.007131033161869713",
         "-0.4309170537154911",
         "-0.2893838258601756",
         "-0.10189126452435254",
         "-0.10011502648967721",
         "-0.10212222754108821",
         "-0.06109230213470207",
         "1"
        ],
        [
         "2018-07-15 02:00:00",
         "-0.0962342393767944",
         "-0.09537905487730092",
         "-0.05775570304602001",
         "-0.0689649383462183",
         "-1.6710872604578402",
         "-0.076582846974786",
         "0.46078431372549866",
         "-0.0636720684805543",
         "0.04314730915358092",
         "-0.05520646997084042",
         "0.092492481595684",
         "0.38492851187553623",
         "-0.03346638267181079",
         "0.05603222593108029",
         "0.18534688896735246",
         "0.15669881903176533",
         "-0.013020548320017526",
         "-0.43112740505034214",
         "-0.29258537052817657",
         "-0.1067377158907345",
         "-0.09642074506939396",
         "-0.09946839333854034",
         "-0.10131644165903561",
         "1"
        ],
        [
         "2018-07-16 02:00:00",
         "-0.06833101086244811",
         "0.021587851926961082",
         "-0.028183376554876675",
         "0.04828217202622262",
         "-1.5072560832904682",
         "-0.0013707435645291496",
         "1.9953863898500694",
         "-0.05946373931497736",
         "0.037129744162080286",
         "-0.027143024973728443",
         "0.0910248925560533",
         "0.4193798952493567",
         "-0.01995420182377771",
         "0.0562777319274235",
         "0.19213719936363516",
         "0.15884305253379513",
         "-0.00810748878187607",
         "-0.4270071832924574",
         "-0.28888761727758916",
         "-0.10430453002695723",
         "-0.06898230942965353",
         "-0.0957731811577773",
         "-0.09866171565868291",
         "1"
        ],
        [
         "2018-07-17 02:00:00",
         "0.048452898611554156",
         "0.1340736440130509",
         "0.05269218935431416",
         "0.13406864596711207",
         "-1.3841568773221378",
         "0.0963522044706674",
         "1.46309111880047",
         "-0.028655684679006366",
         "0.03490175900548599",
         "0.015438743621558997",
         "0.09552023878616767",
         "0.5392072239443687",
         "0.004988338080955163",
         "0.06320505651116555",
         "0.20145643954434597",
         "0.1626925543615623",
         "-0.0017494117325163262",
         "-0.39498493937211976",
         "-0.2771535250328667",
         "-0.11204725501221592",
         "0.04829433347606677",
         "-0.0683278325061098",
         "-0.09496526173414101",
         "1"
        ],
        [
         "2018-07-18 02:00:00",
         "0.13165891576985722",
         "0.1506243304903876",
         "0.08328425124170366",
         "0.07161743597491865",
         "-1.3743734960529819",
         "0.1197825540954159",
         "-1.0386389850057673",
         "-0.009392817158220924",
         "0.02900213923138049",
         "0.03169852062917396",
         "0.09545356701663606",
         "0.4462491688428838",
         "0.016259109999571253",
         "0.06474174776319068",
         "0.20645891363017263",
         "0.16691772723383075",
         "0.005591961256429702",
         "-0.3952390434905229",
         "-0.27329717028375355",
         "-0.10579538494451994",
         "0.13410241555628294",
         "0.048978357814113985",
         "-0.06751069031277042",
         "0"
        ],
        [
         "2018-07-19 02:00:00",
         "0.07182311166328098",
         "0.051680009158482566",
         "0.06939475187903826",
         "0.03196427522181083",
         "-1.6081525286688472",
         "0.06154723744088155",
         "-0.6920415224913421",
         "0.009947178961246767",
         "0.020572594544149142",
         "0.03393958731645363",
         "0.09267870908326734",
         "0.4540544507598324",
         "0.019551567353542177",
         "0.06306766092204175",
         "0.20897457706788342",
         "0.17087395489505197",
         "0.009638010287840414",
         "-0.39857646110331507",
         "-0.272004251362832",
         "-0.1010450308464548",
         "0.07163547517694756",
         "0.13480805892183773",
         "0.04983491972814266",
         "0"
        ],
        [
         "2018-07-20 02:00:00",
         "0.032671289223175526",
         "-0.006214684645640358",
         "-0.07213748846204561",
         "-0.07709031082907351",
         "-1.520639378349052",
         "-0.03712927133485728",
         "-1.8927335640138465",
         "0.013249247092312021",
         "0.009394926291610657",
         "0.008245423580629989",
         "0.08262295923652048",
         "0.35852661546023024",
         "0.005164209422921472",
         "0.053000314879116786",
         "0.20661430395400698",
         "0.17349843219526068",
         "0.005607351975484159",
         "-0.38802704667762344",
         "-0.2714113109274124",
         "-0.10872551873390843",
         "0.03197232647372434",
         "0.0723253802289352",
         "0.13569346315727565",
         "0"
        ],
        [
         "2018-07-21 02:00:00",
         "-0.07689337340295144",
         "-0.06607191044312334",
         "-0.059478704232780996",
         "-0.04126480488193875",
         "-1.8126729402985224",
         "-0.06216024077408703",
         "0.6043829296424544",
         "0.021164569532034397",
         "1.7102056522133863e-05",
         "-0.0020322539248647693",
         "0.07566662302052492",
         "0.36764953226300134",
         "-0.001368116039517435",
         "0.04647670384756999",
         "0.20651242218143423",
         "0.17557468301084608",
         "0.004382934770712266",
         "-0.3856778584698508",
         "-0.27145391075683933",
         "-0.1107095718557518",
         "-0.07710972855427668",
         "0.03265223854274272",
         "0.07318978770593038",
         "1"
        ],
        [
         "2018-07-22 02:00:00",
         "-0.04240887799472819",
         "-0.04942309736611855",
         "-0.01977935035822597",
         "-0.06298842470180405",
         "-1.7118258716025756",
         "-0.03426858911323101",
         "-0.3610149942329837",
         "0.022022625192369662",
         "-0.003942318891432802",
         "-0.01519359134803765",
         "0.06767307129510129",
         "0.36597618657368475",
         "-0.01031637794423215",
         "0.038739688144118635",
         "0.20577725731783544",
         "0.17706733019761595",
         "-0.0026814052752542933",
         "-0.3887367441880055",
         "-0.27602477978945816",
         "-0.11537749268289631",
         "-0.041275198777528777",
         "-0.07645729930378846",
         "0.03350331420698474",
         "0"
        ],
        [
         "2018-07-23 02:00:00",
         "-0.0628242365226735",
         "-0.05066603429524659",
         "-0.0330359105094281",
         "-0.07507575566803504",
         "-1.7618153447903282",
         "-0.04133515531546249",
         "-0.21799307958476485",
         "0.004311970720055795",
         "-0.009256930387258291",
         "-0.028098765274549655",
         "0.05936839471411424",
         "0.37230958076127085",
         "-0.019791426910902136",
         "0.030631752809700357",
         "0.20495681824349313",
         "0.17807356660449353",
         "-0.009420830141184361",
         "-0.3882537609677892",
         "-0.2794999239915553",
         "-0.12121864891573035",
         "-0.0630042904041042",
         "-0.04061374115038672",
         "-0.0756428889467626",
         "0"
        ],
        [
         "2018-07-24 02:00:00",
         "-0.0742071420176956",
         "-0.025185827248121413",
         "-0.04752318579403101",
         "-0.028539531448045673",
         "-1.4666746033107612",
         "-0.035085926890838566",
         "0.7768166089965444",
         "-0.019033891993448668",
         "-0.0109624182307923",
         "-0.026096087911774042",
         "0.05478282951890873",
         "0.5032435338519927",
         "-0.020480521489071674",
         "0.02675892811322363",
         "0.2065276368278641",
         "0.17923827470699868",
         "-0.014913606763708342",
         "-0.40132033079045304",
         "-0.285836593913057",
         "-0.12048656481737524",
         "-0.07509466596139493",
         "-0.062348307340875014",
         "-0.03978728587870579",
         "1"
        ],
        [
         "2018-07-25 02:00:00",
         "-0.03320853550022669",
         "-0.03408263895135386",
         "5.274493428855783e-05",
         "-0.02534981910973469",
         "-1.4833702037274727",
         "-0.016678799024303033",
         "0.1274509803921634",
         "-0.0329556040555181",
         "-0.013492343143918352",
         "-0.02379339591297674",
         "0.05071130056635691",
         "0.4901463257569708",
         "-0.020561304127135947",
         "0.02342209885075385",
         "0.2081434539140147",
         "0.18054006486649",
         "-0.017837843384042845",
         "-0.40520386974761247",
         "-0.2884100949118119",
         "-0.12135075579625616",
         "-0.028546720065825593",
         "-0.07444172902337229",
         "-0.06152915578032982",
         "1"
        ],
        [
         "2018-07-26 02:00:00",
         "-0.025082685559827338",
         "-0.03378825915234974",
         "-0.0215726781240385",
         "-0.059328649492583985",
         "-1.576653291878843",
         "-0.026997688466597634",
         "-0.5957324106112954",
         "-0.04606264529401062",
         "-0.013883921265669986",
         "-0.030595768328995403",
         "0.044578117777321395",
         "0.4965887741391912",
         "-0.02598044770170025",
         "0.01767866354802219",
         "0.20822357453583115",
         "0.1815998446940679",
         "-0.02250636149720949",
         "-0.4075913451245828",
         "-0.29152607041749606",
         "-0.12428623310575014",
         "-0.025356204293762737",
         "-0.027882055545757754",
         "-0.07362664135155794",
         "0"
        ],
        [
         "2018-07-27 02:00:00",
         "-0.06218625656867513",
         "-0.05625925047632284",
         "-0.02642521207858992",
         "-0.03978746443051053",
         "-1.6387533282756837",
         "-0.041045681519226496",
         "0.3771626297577935",
         "-0.04070702822304133",
         "-0.015605921439639268",
         "-0.030792304752078652",
         "0.040177345423821176",
         "0.5114844715728207",
         "-0.027488644451151636",
         "0.013886852810907603",
         "0.2093351433901119",
         "0.18270221890020477",
         "-0.02754083670789105",
         "-0.41935015468979886",
         "-0.29727739490564586",
         "-0.1237039974817323",
         "-0.05934359336036883",
         "-0.024690735935098723",
         "-0.02705132190232962",
         "1"
        ],
        [
         "2018-07-28 02:00:00",
         "-0.039621912932525157",
         "-0.06649712570835144",
         "-0.012254406399718743",
         "-0.03673205576960224",
         "-1.8312292545196738",
         "-0.03951317318621241",
         "0.042099192618224014",
         "-0.04005625567166338",
         "-0.014348625422207018",
         "-0.030172736102221587",
         "0.036269500106709034",
         "0.5109366170848475",
         "-0.028283662905612527",
         "0.01061454723038113",
         "0.21055354516459676",
         "0.1838631334513727",
         "-0.0314295583889678",
         "-0.4277759043005844",
         "-0.3015487821733392",
         "-0.12352236070603921",
         "-0.03979748620941548",
         "-0.05868668799811877",
         "-0.023858929876588837",
         "1"
        ],
        [
         "2018-07-29 02:00:00",
         "-0.036499168947165164",
         "-0.06774006263747946",
         "-0.00532723836314883",
         "-0.047677805477911395",
         "-1.7386751474420734",
         "-0.036805741797887606",
         "-0.19953863898500118",
         "-0.037858090609231544",
         "-0.014355702135250734",
         "-0.03245566989282103",
         "0.031865026215494884",
         "0.47497207644581296",
         "-0.030680043976147903",
         "0.006729761319356473",
         "0.21125693170061904",
         "0.1849529412902163",
         "-0.034824066980409595",
         "-0.43244981367181196",
         "-0.304579322578009",
         "-0.12445786115049276",
         "-0.036741307943544875",
         "-0.03913565627808151",
         "-0.05786630598237451",
         "0"
        ],
        [
         "2018-07-30 02:00:00",
         "-0.047512717626714565",
         "-0.07519768421224786",
         "-0.06222144081578835",
         "-0.07390059849076253",
         "-1.7141257710038078",
         "-0.06823919049504275",
         "-0.46078431372548145",
         "-0.037689371799615075",
         "-0.01702362295272915",
         "-0.040750335349610416",
         "0.02595093310640571",
         "0.31338161141439946",
         "-0.03683716431258308",
         "0.0010847125553430812",
         "0.21091067516284426",
         "0.1857454944788256",
         "-0.03448718124110785",
         "-0.43342384288725233",
         "-0.3046529113627261",
         "-0.12377825429559666",
         "-0.047689814698202555",
         "-0.03607870801945036",
         "-0.038308704308889024",
         "0"
        ],
        [
         "2018-07-31 02:00:00",
         "-0.0709836643553884",
         "-0.1072523734371296",
         "-0.0869060700628543",
         "-0.10761082151880678",
         "-1.7232241424974495",
         "-0.09688006845203878",
         "-0.6366782006920337",
         "-0.049041737418095845",
         "-0.0201987082050067",
         "-0.05543329983822733",
         "0.018112435442597847",
         "0.14403492350344732",
         "-0.047355525673607",
         "-0.006774984539811447",
         "0.20943324311562034",
         "0.18604120366015223",
         "-0.03678210846010744",
         "-0.4257796357557849",
         "-0.3038889340545536",
         "-0.12881958268343346",
         "-0.07391921278221382",
         "-0.047029973209711744",
         "-0.03525072878949536",
         "0"
        ],
        [
         "2018-08-01 02:00:00",
         "-0.10744925541023782",
         "-0.05030623676313058",
         "-0.08722253966858604",
         "-0.07027439920089332",
         "-1.5391058951589622",
         "-0.0673877969767015",
         "0.6309111880046173",
         "-0.05549161648286354",
         "-0.025326966257347334",
         "-0.0570733065509254",
         "0.013333657615372932",
         "0.2615188521986795",
         "-0.05037615446547495",
         "-0.011136472187112556",
         "0.2100540325705542",
         "0.18641993239156646",
         "-0.035128461201707255",
         "-0.4313928084895199",
         "-0.30446677080032114",
         "-0.1251441176188823",
         "-0.10763792683643579",
         "-0.07326597969312944",
         "-0.04620567405677413",
         "1"
        ],
        [
         "2018-08-02 02:00:00",
         "-0.06906972449339349",
         "-0.09917328339779709",
         "-0.08096347413300517",
         "-0.12624545675841295",
         "-1.682884142757647",
         "-0.08979647437944055",
         "-0.9896193771626242",
         "-0.06509894755616795",
         "-0.031772672387992695",
         "-0.07235320831370916",
         "0.005034469342098437",
         "0.2471678529470298",
         "-0.06174606848807121",
         "-0.019546278859047153",
         "0.20841418021820096",
         "0.1863473875999745",
         "-0.03646061343986016",
         "-0.4244359291231982",
         "-0.30336732595174504",
         "-0.12909867111135395",
         "-0.0702921001150267",
         "-0.1069931890520941",
         "-0.07245049692102182",
         "0"
        ],
        [
         "2018-08-03 02:00:00",
         "-0.12454040259892893",
         "-0.10797196850136162",
         "-0.09218056349171456",
         "-0.09072213408543407",
         "-1.4442001233085464",
         "-0.0998088621551324",
         "0.5732410611303437",
         "-0.07241170281868861",
         "-0.03774541819688299",
         "-0.07489604361090235",
         "-0.00029930280030480695",
         "0.43283333452853556",
         "-0.06577275825067183",
         "-0.02455873201138332",
         "0.20884359699698926",
         "0.186387688624891",
         "-0.03617160993761619",
         "-0.42553476794046413",
         "-0.3034989923663676",
         "-0.12840823271506854",
         "-0.12627725582059235",
         "-0.06963795318838034",
         "-0.10618904001411364",
         "1"
        ],
        [
         "2018-08-04 02:00:00",
         "-0.08841059046723646",
         "-0.11186432362152572",
         "-0.08476110940178445",
         "-0.12590969756490655",
         "-1.6424078409492775",
         "-0.09824229808138464",
         "-0.6516724336793465",
         "-0.08521505019987134",
         "-0.04329474067532464",
         "-0.08563597858482727",
         "-0.007695977521695756",
         "0.3215125358030223",
         "-0.07472109058918913",
         "-0.03194807410637294",
         "0.2079357338347772",
         "0.18621202790150215",
         "-0.03907190543942228",
         "-0.41421429302496493",
         "-0.30210135196804",
         "-0.1354567252375475",
         "-0.09074498543277683",
         "-0.1256372141459441",
         "-0.06882125124965346",
         "0"
        ],
        [
         "2018-08-05 02:00:00",
         "-0.12578278461460973",
         "-0.13786787253354707",
         "-0.08602698782471102",
         "-0.1102968950668582",
         "-1.6455123639103708",
         "-0.11239245835621454",
         "0.258362168396772",
         "-0.0942053524837215",
         "-0.04830505351027073",
         "-0.08977179245555844",
         "-0.013547448506796823",
         "0.37879432833360027",
         "-0.07983414287543351",
         "-0.037570682983318095",
         "0.20811243219147876",
         "0.18611196341759056",
         "-0.04714861278318925",
         "-0.4211821587401925",
         "-0.3082308298861915",
         "-0.13937732272804437",
         "-0.12594141205511208",
         "-0.09009599153460489",
         "-0.12483933026975703",
         "1"
        ],
        [
         "2018-08-06 02:00:00",
         "-0.11057199939559802",
         "-0.1380641257328831",
         "-0.17667794822205604",
         "-0.18282088086424433",
         "-1.5239800174656992",
         "-0.15639247538408488",
         "-1.2485582468281389",
         "-0.10984317586646129",
         "-0.05680182697141768",
         "-0.11107867801340097",
         "-0.023982432455436426",
         "0.30667723331228425",
         "-0.09558122817064744",
         "-0.04844099374560254",
         "0.20545535243114305",
         "0.18542343799222602",
         "-0.06328834683156408",
         "-0.45771012113524145",
         "-0.3263643405730437",
         "-0.1379877752526873",
         "-0.11032467696027826",
         "-0.12530128576587476",
         "-0.08928616434098104",
         "0"
        ],
        [
         "2018-08-07 02:00:00",
         "-0.18138777428940794",
         "-0.20779942923027866",
         "-0.2730253615225704",
         "-0.2978855564788934",
         "-1.5124377574210104",
         "-0.23935225981124644",
         "-2.008650519031143",
         "-0.13716116141207993",
         "-0.06865768022397781",
         "-0.15594246311024595",
         "-0.04161522880224145",
         "0.1362241693996744",
         "-0.12702540237174426",
         "-0.06749275557952739",
         "0.19883142270897544",
         "0.1833557313309385",
         "-0.08210777607529823",
         "-0.4054391358162601",
         "-0.32281090176876354",
         "-0.1750788672024171",
         "-0.1828669303040228",
         "-0.10968061609264912",
         "-0.12450328900388961",
         "0"
        ],
        [
         "2018-08-08 02:00:00",
         "-0.29773517116330606",
         "-0.3289530709537087",
         "-0.46498175904355826",
         "-0.45542377007210444",
         "-1.051788318383273",
         "-0.3953786359824443",
         "-2.7162629757785575",
         "-0.19245754612953003",
         "-0.08532215998973881",
         "-0.2291356621302386",
         "-0.06888687895846352",
         "0.06664058703504872",
         "-0.17844021501730273",
         "-0.09743715829515687",
         "0.18740091988740942",
         "0.17908396978646068",
         "-0.10693129583014131",
         "-0.2592324664757734",
         "-0.29800940054895586",
         "-0.25553084344524457",
         "-0.297960588734121",
         "-0.18224114618763293",
         "-0.1088773701410533",
         "0"
        ],
        [
         "2018-08-09 02:00:00",
         "-0.45440961670835933",
         "-0.3964641715252963",
         "-0.4343193705771172",
         "-0.4138232059966593",
         "-1.3243114682902744",
         "-0.41567585745969726",
         "0.6891580161476454",
         "-0.233745449111394",
         "-0.09703058172055522",
         "-0.27358795668838565",
         "-0.09155336747799932",
         "0.13843112542648828",
         "-0.2153940410578185",
         "-0.12191441396519581",
         "0.18065291412223627",
         "0.1741212606958789",
         "-0.1240816870964212",
         "-0.1742440562196915",
         "-0.285046242926448",
         "-0.3045752730131031",
         "-0.45553848349747716",
         "-0.2973638020374057",
         "-0.18146228356842223",
         "1"
        ],
        [
         "2018-08-10 02:00:00",
         "-0.41367963332941593",
         "-0.43277101340245816",
         "-0.48931475539536695",
         "-0.49819949132482205",
         "-1.5507462066953057",
         "-0.4612083828205817",
         "-1.4596309111880075",
         "-0.29224749121155763",
         "-0.11233397367757607",
         "-0.3281073758542175",
         "-0.11852928958721909",
         "0.08240606871247752",
         "-0.2599497508827241",
         "-0.15116840674674203",
         "0.17238835231641905",
         "0.1682585007664723",
         "-0.14735416438655996",
         "-0.07441618235550908",
         "-0.27149068898416734",
         "-0.3648023520293489",
         "-0.41392744095446815",
         "-0.4549813979659538",
         "-0.29662362538119674",
         "0"
        ],
        [
         "2018-08-11 02:00:00",
         "-0.49806087671876853",
         "-0.5204634846390986",
         "-0.5770823260516019",
         "-0.5691454089127279",
         "-1.3747607217503497",
         "-0.5493616677096238",
         "-1.2289504036908838",
         "-0.3558834056614799",
         "-0.12871774382593645",
         "-0.38680583752122144",
         "-0.14861790856803192",
         "0.05937896983570562",
         "-0.3088228875324679",
         "-0.18379637992194708",
         "0.16359077789843318",
         "0.1615536397616493",
         "-0.17313361880267078",
         "0.034420164122306404",
         "-0.2569292712935316",
         "-0.43080506505461297",
         "-0.49832497921966734",
         "-0.4133598716753589",
         "-0.4542941873262037",
         "0"
        ],
        [
         "2018-08-12 02:00:00",
         "-0.5715628829978343",
         "-0.5554619718540204",
         "-0.553839391675091",
         "-0.57710290179883",
         "-1.6357673373508979",
         "-0.5563260666896545",
         "-0.10322952710495449",
         "-0.42290333737856745",
         "-0.14547422086126557",
         "-0.43282717958706957",
         "-0.1773096612554296",
         "0.06010901686604869",
         "-0.35143017988582365",
         "-0.2146289538662721",
         "0.15710689798541294",
         "0.15470493617871411",
         "-0.19870273339170413",
         "0.11962203505029273",
         "-0.2484086803717961",
         "-0.48698702737938526",
         "-0.5692887668656543",
         "-0.49777867358679156",
         "-0.4126586744852268",
         "0"
        ],
        [
         "2018-08-13 02:00:00",
         "-0.5760287426758223",
         "-0.5567049087831484",
         "-0.6338007120566126",
         "-0.6481831230641386",
         "-1.4622805868465298",
         "-0.5956945029777491",
         "-1.2474048442906591",
         "-0.48971598598669763",
         "-0.16485733788798454",
         "-0.4851857964386316",
         "-0.20901259915488662",
         "0.04969999430097402",
         "-0.39867580496187555",
         "-0.24872906550966448",
         "0.14987298244341674",
         "0.14756939964791854",
         "-0.23026225785268692",
         "0.20381374683313974",
         "-0.24335177152170817",
         "-0.5477735571494993",
         "-0.5772482641075374",
         "-0.5687603402954492",
         "-0.4971058445977168",
         "0"
        ],
        [
         "2018-08-14 02:00:00",
         "-0.6480533216929975",
         "-0.6603265980325616",
         "-0.7201265878422923",
         "-0.654226788547254",
         "-1.2597500805007025",
         "-0.6914422180503943",
         "-0.11418685121106181",
         "-0.540876349599835",
         "-0.1854163687321331",
         "-0.5259718445068693",
         "-0.23908360515717408",
         "0.05598313133669536",
         "-0.43960459370372135",
         "-0.28077525890989813",
         "0.14485046051900463",
         "0.140710808038777",
         "-0.26229205428477625",
         "0.26397740109123363",
         "-0.24480181037510773",
         "-0.599148717655135",
         "-0.6483463892597167",
         "-0.5767218429030933",
         "-0.5681113640755086",
         "0"
        ],
        [
         "2018-08-15 02:00:00",
         "-0.6530900055403523",
         "-0.5784890139094455",
         "-0.6284207287591752",
         "-0.6277353881795978",
         "-1.0485991999975135",
         "-0.6044298004759292",
         "0.42733564013841085",
         "-0.5656153476270301",
         "-0.20916345880247272",
         "-0.5499114894251157",
         "-0.265402393257437",
         "0.0425500740892685",
         "-0.4700649337117543",
         "-0.30837865694730254",
         "0.14297674518822756",
         "0.13479485212620818",
         "-0.29124199682609175",
         "0.3015740714298709",
         "-0.2504815684404507",
         "-0.6387356113485756",
         "-0.6543915770383619",
         "-0.6478378809637788",
         "-0.5760755420765671",
         "1"
        ],
        [
         "2018-08-16 02:00:00",
         "-0.6289139230730487",
         "-0.5801244572372456",
         "-0.6189266405872266",
         "-0.5907011491358399",
         "-1.4159422388439709",
         "-0.6006836689952282",
         "0.6482122260669012",
         "-0.5910099387430205",
         "-0.23462311342938988",
         "-0.5585698607315144",
         "-0.28748985566551777",
         "0.10286369588027416",
         "-0.4900071305041969",
         "-0.3310449499683932",
         "0.14403177303603343",
         "0.13030368979499057",
         "-0.3193009877421473",
         "0.30858444267616675",
         "-0.26364840122507033",
         "-0.6650949093312758",
         "-0.6278935039419665",
         "-0.6538845918050273",
         "-0.647215478060706",
         "1"
        ],
        [
         "2018-08-17 02:00:00",
         "-0.589929990094522",
         "-0.34063013631420136",
         "-0.5649509911652233",
         "-0.33626283229667686",
         "-0.9238716162169319",
         "-0.44986782115627766",
         "4.34890426758942",
         "-0.5677604867778682",
         "-0.24895109843855262",
         "-0.5011943426265765",
         "-0.29074738333313277",
         "0.3092661219388505",
         "-0.4668138273522202",
         "-0.3321603867147613",
         "0.1564503910917981",
         "0.1295546354909875",
         "-0.33455661048484175",
         "0.2703230882891465",
         "-0.28176081629463723",
         "-0.6622575945610092",
         "-0.5908499366094895",
         "-0.6273798426175543",
         "-0.65326422084632",
         "1"
        ],
        [
         "2018-08-18 02:00:00",
         "-0.3360811241878348",
         "-0.35718082279153823",
         "-0.49624192343193685",
         "-0.4669067344900238",
         "-0.9691972416564664",
         "-0.425211464865118",
         "-2.2549019607843155",
         "-0.5530819503412335",
         "-0.26647539883912424",
         "-0.4909570340836622",
         "-0.30273148723815696",
         "0.27053753954994275",
         "-0.4677617682957136",
         "-0.34339661002670147",
         "0.16154561906128043",
         "0.1301222041870198",
         "-0.35590866805297133",
         "0.23628445871776568",
         "-0.3020311867459988",
         "-0.6662490399315485",
         "-0.3363475311285191",
         "-0.5903269422959027",
         "-0.6267505649693784",
         "0"
        ],
        [
         "2018-08-19 02:00:00",
         "-0.46612830112653836",
         "-0.41340736440130504",
         "-0.4765153180079994",
         "-0.42084057314094353",
         "-1.154780044017371",
         "-0.444929738749899",
         "0.7698961937716308",
         "-0.530647169199658",
         "-0.27855063019603976",
         "-0.47171549040222754",
         "-0.31079125215545655",
         "0.29147579677423413",
         "-0.46130964039670974",
         "-0.3502027100172008",
         "0.16822629941340853",
         "0.13210614141405985",
         "-0.37357892360731093",
         "0.19675536198565524",
         "-0.3217638004663573",
         "-0.6649165750740378",
         "-0.4670243402769033",
         "-0.3357604158793346",
         "-0.5896852133441988",
         "1"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 2428
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>30_day_SMA</th>\n",
       "      <th>7_day_EMA</th>\n",
       "      <th>...</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>candle_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-01 02:00:00</th>\n",
       "      <td>0.002250</td>\n",
       "      <td>-0.030452</td>\n",
       "      <td>-0.005081</td>\n",
       "      <td>-0.017224</td>\n",
       "      <td>-1.726024</td>\n",
       "      <td>-0.017275</td>\n",
       "      <td>-0.341984</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>0.301681</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.129493</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>-0.147777</td>\n",
       "      <td>-0.144543</td>\n",
       "      <td>-0.105950</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>-0.046828</td>\n",
       "      <td>-0.071073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-02 02:00:00</th>\n",
       "      <td>-0.017058</td>\n",
       "      <td>0.052988</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.075714</td>\n",
       "      <td>-1.538281</td>\n",
       "      <td>0.029450</td>\n",
       "      <td>1.585928</td>\n",
       "      <td>-0.007122</td>\n",
       "      <td>0.283660</td>\n",
       "      <td>0.027282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163388</td>\n",
       "      <td>0.130494</td>\n",
       "      <td>0.114753</td>\n",
       "      <td>-0.174404</td>\n",
       "      <td>-0.157478</td>\n",
       "      <td>-0.104493</td>\n",
       "      <td>-0.017229</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>-0.046004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-03 02:00:00</th>\n",
       "      <td>0.073301</td>\n",
       "      <td>0.133452</td>\n",
       "      <td>0.093165</td>\n",
       "      <td>0.057247</td>\n",
       "      <td>-1.451802</td>\n",
       "      <td>0.115628</td>\n",
       "      <td>-0.283160</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>0.259399</td>\n",
       "      <td>0.036974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168403</td>\n",
       "      <td>0.132444</td>\n",
       "      <td>0.107191</td>\n",
       "      <td>-0.180865</td>\n",
       "      <td>-0.163200</td>\n",
       "      <td>-0.108189</td>\n",
       "      <td>0.075733</td>\n",
       "      <td>-0.016561</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04 02:00:00</th>\n",
       "      <td>0.058392</td>\n",
       "      <td>0.094202</td>\n",
       "      <td>0.098088</td>\n",
       "      <td>0.079306</td>\n",
       "      <td>-1.864734</td>\n",
       "      <td>0.097578</td>\n",
       "      <td>0.351788</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>0.240044</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173940</td>\n",
       "      <td>0.135273</td>\n",
       "      <td>0.095782</td>\n",
       "      <td>-0.220077</td>\n",
       "      <td>-0.179506</td>\n",
       "      <td>-0.101743</td>\n",
       "      <td>0.057261</td>\n",
       "      <td>0.076424</td>\n",
       "      <td>-0.015727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05 02:00:00</th>\n",
       "      <td>0.081426</td>\n",
       "      <td>0.077684</td>\n",
       "      <td>0.061026</td>\n",
       "      <td>0.032065</td>\n",
       "      <td>-1.751843</td>\n",
       "      <td>0.071032</td>\n",
       "      <td>-0.855248</td>\n",
       "      <td>0.033091</td>\n",
       "      <td>0.216721</td>\n",
       "      <td>0.047526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176929</td>\n",
       "      <td>0.138219</td>\n",
       "      <td>0.086260</td>\n",
       "      <td>-0.234130</td>\n",
       "      <td>-0.188251</td>\n",
       "      <td>-0.103983</td>\n",
       "      <td>0.079326</td>\n",
       "      <td>0.057948</td>\n",
       "      <td>0.077289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-17 01:00:00</th>\n",
       "      <td>7.591961</td>\n",
       "      <td>7.475939</td>\n",
       "      <td>7.581152</td>\n",
       "      <td>7.361688</td>\n",
       "      <td>-0.172184</td>\n",
       "      <td>7.564112</td>\n",
       "      <td>-3.955017</td>\n",
       "      <td>7.268399</td>\n",
       "      <td>8.189014</td>\n",
       "      <td>7.331964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170657</td>\n",
       "      <td>0.097535</td>\n",
       "      <td>7.396788</td>\n",
       "      <td>2.766339</td>\n",
       "      <td>4.498948</td>\n",
       "      <td>4.793952</td>\n",
       "      <td>7.593260</td>\n",
       "      <td>7.708717</td>\n",
       "      <td>7.633177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-18 01:00:00</th>\n",
       "      <td>7.362289</td>\n",
       "      <td>7.165531</td>\n",
       "      <td>7.095196</td>\n",
       "      <td>7.035666</td>\n",
       "      <td>-0.118931</td>\n",
       "      <td>7.167192</td>\n",
       "      <td>-5.610150</td>\n",
       "      <td>7.340563</td>\n",
       "      <td>8.142319</td>\n",
       "      <td>7.267213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166426</td>\n",
       "      <td>0.105624</td>\n",
       "      <td>7.310344</td>\n",
       "      <td>2.450726</td>\n",
       "      <td>4.370591</td>\n",
       "      <td>4.850350</td>\n",
       "      <td>7.363542</td>\n",
       "      <td>7.595845</td>\n",
       "      <td>7.712147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 01:00:00</th>\n",
       "      <td>7.036583</td>\n",
       "      <td>7.417717</td>\n",
       "      <td>7.245695</td>\n",
       "      <td>7.623245</td>\n",
       "      <td>-0.188586</td>\n",
       "      <td>7.371357</td>\n",
       "      <td>10.076125</td>\n",
       "      <td>7.468018</td>\n",
       "      <td>8.098974</td>\n",
       "      <td>7.366145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188363</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>7.243685</td>\n",
       "      <td>1.980414</td>\n",
       "      <td>4.212529</td>\n",
       "      <td>4.986447</td>\n",
       "      <td>7.037438</td>\n",
       "      <td>7.366070</td>\n",
       "      <td>7.599237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-20 01:00:00</th>\n",
       "      <td>7.623860</td>\n",
       "      <td>7.424259</td>\n",
       "      <td>7.790726</td>\n",
       "      <td>7.455029</td>\n",
       "      <td>-0.396724</td>\n",
       "      <td>7.638694</td>\n",
       "      <td>-2.899654</td>\n",
       "      <td>7.529624</td>\n",
       "      <td>8.041641</td>\n",
       "      <td>7.398118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198983</td>\n",
       "      <td>0.128747</td>\n",
       "      <td>7.184105</td>\n",
       "      <td>1.560919</td>\n",
       "      <td>4.071481</td>\n",
       "      <td>5.107736</td>\n",
       "      <td>7.625165</td>\n",
       "      <td>7.039883</td>\n",
       "      <td>7.369385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 01:00:00</th>\n",
       "      <td>7.455971</td>\n",
       "      <td>7.316319</td>\n",
       "      <td>7.229871</td>\n",
       "      <td>6.963142</td>\n",
       "      <td>-0.119193</td>\n",
       "      <td>7.310908</td>\n",
       "      <td>-8.464821</td>\n",
       "      <td>7.434563</td>\n",
       "      <td>7.966262</td>\n",
       "      <td>7.298623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187095</td>\n",
       "      <td>0.135327</td>\n",
       "      <td>7.126544</td>\n",
       "      <td>1.314019</td>\n",
       "      <td>3.976446</td>\n",
       "      <td>5.160283</td>\n",
       "      <td>7.456907</td>\n",
       "      <td>7.627758</td>\n",
       "      <td>7.043089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2428 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close    volume  \\\n",
       "datetime                                                                \n",
       "2018-07-01 02:00:00  0.002250 -0.030452 -0.005081 -0.017224 -1.726024   \n",
       "2018-07-02 02:00:00 -0.017058  0.052988  0.001705  0.075714 -1.538281   \n",
       "2018-07-03 02:00:00  0.073301  0.133452  0.093165  0.057247 -1.451802   \n",
       "2018-07-04 02:00:00  0.058392  0.094202  0.098088  0.079306 -1.864734   \n",
       "2018-07-05 02:00:00  0.081426  0.077684  0.061026  0.032065 -1.751843   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2025-02-17 01:00:00  7.591961  7.475939  7.581152  7.361688 -0.172184   \n",
       "2025-02-18 01:00:00  7.362289  7.165531  7.095196  7.035666 -0.118931   \n",
       "2025-02-19 01:00:00  7.036583  7.417717  7.245695  7.623245 -0.188586   \n",
       "2025-02-20 01:00:00  7.623860  7.424259  7.790726  7.455029 -0.396724   \n",
       "2025-02-21 01:00:00  7.455971  7.316319  7.229871  6.963142 -0.119193   \n",
       "\n",
       "                        av_pr       diff  7_day_SMA  30_day_SMA  7_day_EMA  \\\n",
       "datetime                                                                     \n",
       "2018-07-01 02:00:00 -0.017275  -0.341984  -0.011292    0.301681   0.008179   \n",
       "2018-07-02 02:00:00  0.029450   1.585928  -0.007122    0.283660   0.027282   \n",
       "2018-07-03 02:00:00  0.115628  -0.283160   0.008014    0.259399   0.036974   \n",
       "2018-07-04 02:00:00  0.097578   0.351788   0.018075    0.240044   0.049780   \n",
       "2018-07-05 02:00:00  0.071032  -0.855248   0.033091    0.216721   0.047526   \n",
       "...                       ...        ...        ...         ...        ...   \n",
       "2025-02-17 01:00:00  7.564112  -3.955017   7.268399    8.189014   7.331964   \n",
       "2025-02-18 01:00:00  7.167192  -5.610150   7.340563    8.142319   7.267213   \n",
       "2025-02-19 01:00:00  7.371357  10.076125   7.468018    8.098974   7.366145   \n",
       "2025-02-20 01:00:00  7.638694  -2.899654   7.529624    8.041641   7.398118   \n",
       "2025-02-21 01:00:00  7.310908  -8.464821   7.434563    7.966262   7.298623   \n",
       "\n",
       "                     ...      MACD  Signal_Line  20_day_SMA  20_day_STD  \\\n",
       "datetime             ...                                                  \n",
       "2018-07-01 02:00:00  ...  0.156951     0.129493    0.125988   -0.147777   \n",
       "2018-07-02 02:00:00  ...  0.163388     0.130494    0.114753   -0.174404   \n",
       "2018-07-03 02:00:00  ...  0.168403     0.132444    0.107191   -0.180865   \n",
       "2018-07-04 02:00:00  ...  0.173940     0.135273    0.095782   -0.220077   \n",
       "2018-07-05 02:00:00  ...  0.176929     0.138219    0.086260   -0.234130   \n",
       "...                  ...       ...          ...         ...         ...   \n",
       "2025-02-17 01:00:00  ...  0.170657     0.097535    7.396788    2.766339   \n",
       "2025-02-18 01:00:00  ...  0.166426     0.105624    7.310344    2.450726   \n",
       "2025-02-19 01:00:00  ...  0.188363     0.117119    7.243685    1.980414   \n",
       "2025-02-20 01:00:00  ...  0.198983     0.128747    7.184105    1.560919   \n",
       "2025-02-21 01:00:00  ...  0.187095     0.135327    7.126544    1.314019   \n",
       "\n",
       "                     Upper_Band  Lower_Band     lag_1     lag_2     lag_3  \\\n",
       "datetime                                                                    \n",
       "2018-07-01 02:00:00   -0.144543   -0.105950  0.002049 -0.046828 -0.071073   \n",
       "2018-07-02 02:00:00   -0.157478   -0.104493 -0.017229  0.002721 -0.046004   \n",
       "2018-07-03 02:00:00   -0.163200   -0.108189  0.075733 -0.016561  0.003562   \n",
       "2018-07-04 02:00:00   -0.179506   -0.101743  0.057261  0.076424 -0.015727   \n",
       "2018-07-05 02:00:00   -0.188251   -0.103983  0.079326  0.057948  0.077289   \n",
       "...                         ...         ...       ...       ...       ...   \n",
       "2025-02-17 01:00:00    4.498948    4.793952  7.593260  7.708717  7.633177   \n",
       "2025-02-18 01:00:00    4.370591    4.850350  7.363542  7.595845  7.712147   \n",
       "2025-02-19 01:00:00    4.212529    4.986447  7.037438  7.366070  7.599237   \n",
       "2025-02-20 01:00:00    4.071481    5.107736  7.625165  7.039883  7.369385   \n",
       "2025-02-21 01:00:00    3.976446    5.160283  7.456907  7.627758  7.043089   \n",
       "\n",
       "                     candle_target  \n",
       "datetime                            \n",
       "2018-07-01 02:00:00              0  \n",
       "2018-07-02 02:00:00              1  \n",
       "2018-07-03 02:00:00              0  \n",
       "2018-07-04 02:00:00              1  \n",
       "2018-07-05 02:00:00              0  \n",
       "...                            ...  \n",
       "2025-02-17 01:00:00              0  \n",
       "2025-02-18 01:00:00              0  \n",
       "2025-02-19 01:00:00              1  \n",
       "2025-02-20 01:00:00              0  \n",
       "2025-02-21 01:00:00              0  \n",
       "\n",
       "[2428 rows x 24 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from optuna) (24.2)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 14.7 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 greenlet-3.1.1 optuna-4.2.1 sqlalchemy-2.0.38\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer._make_function.<locals>.one_step_on_data at 0x00000206DFD11E40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chidi\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\ops\\nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (1, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer._make_function.<locals>.one_step_on_data at 0x00000206DFD11E40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Final Performance Metrics:\n",
      "MAE: 1.4911\n",
      "RMSE: 2.8564\n",
      "MAPE: 474.9095\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, LSTM, Conv1D, Flatten, \n",
    "                                       Bidirectional, Dropout, BatchNormalization,\n",
    "                                       Attention, Concatenate, Input, Reshape)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== Data Preprocessing ======================\n",
    "class TimeSeriesPipeline:\n",
    "    def __init__(self, seq_length=30, test_size=0.2):\n",
    "        self.seq_length = seq_length\n",
    "        self.test_size = test_size\n",
    "        self.scalers = {}\n",
    "\n",
    "    def preprocess_data(self, df, fit_scalers=True, save_scalers=True, scalers_path=\"scalers.pkl\"):\n",
    "        \"\"\"\n",
    "        Preprocesses the input DataFrame by scaling different feature groups.\n",
    "        Returns both scaled and unscaled data for naive prediction.\n",
    "        \"\"\"\n",
    "        # Keep a copy of the unscaled data for naive prediction\n",
    "        unscaled_data = df.copy()\n",
    "\n",
    "        # Define feature groups\n",
    "        price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', '7_day_SMA', \n",
    "                      '30_day_SMA', '7_day_EMA', '30_day_EMA', '12_day_EMA', '26_day_EMA', '20_day_SMA']\n",
    "        volatility_cols = ['20_day_STD', 'Upper_Band', 'Lower_Band']\n",
    "        momentum_cols = ['RSI', 'MACD', 'Signal_Line']\n",
    "        lag_cols = ['lag_1', 'lag_2', 'lag_3']\n",
    "\n",
    "        # If loading for prediction, load previously saved scalers\n",
    "        if not fit_scalers:\n",
    "            with open(scalers_path, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "\n",
    "        # Apply RobustScaler to price-based features\n",
    "        if fit_scalers:\n",
    "            self.scalers['price'] = RobustScaler()\n",
    "            df[price_cols] = self.scalers['price'].fit_transform(df[price_cols])\n",
    "        else:\n",
    "            df[price_cols] = self.scalers['price'].transform(df[price_cols])\n",
    "\n",
    "        # Apply Log + RobustScaler to volume\n",
    "        if fit_scalers:\n",
    "            self.scalers['volume'] = RobustScaler()\n",
    "            df['volume'] = np.log1p(df['volume'])\n",
    "            df['volume'] = self.scalers['volume'].fit_transform(df[['volume']])\n",
    "        else:\n",
    "            df['volume'] = np.log1p(df['volume'])\n",
    "            df['volume'] = self.scalers['volume'].transform(df[['volume']])\n",
    "\n",
    "        # Apply StandardScaler to volatility indicators\n",
    "        if fit_scalers:\n",
    "            self.scalers['volatility'] = StandardScaler()\n",
    "            df[volatility_cols] = self.scalers['volatility'].fit_transform(df[volatility_cols])\n",
    "        else:\n",
    "            df[volatility_cols] = self.scalers['volatility'].transform(df[volatility_cols])\n",
    "\n",
    "        # Apply MinMaxScaler to momentum indicators (RSI, MACD, Signal Line)\n",
    "        if fit_scalers:\n",
    "            self.scalers['momentum'] = MinMaxScaler()\n",
    "            df[momentum_cols] = self.scalers['momentum'].fit_transform(df[momentum_cols])\n",
    "        else:\n",
    "            df[momentum_cols] = self.scalers['momentum'].transform(df[momentum_cols])\n",
    "\n",
    "        # Apply RobustScaler to lagged features\n",
    "        if fit_scalers:\n",
    "            self.scalers['lag'] = RobustScaler()\n",
    "            df[lag_cols] = self.scalers['lag'].fit_transform(df[lag_cols])\n",
    "        else:\n",
    "            df[lag_cols] = self.scalers['lag'].transform(df[lag_cols])\n",
    "\n",
    "        # Save the fitted scalers for later use\n",
    "        if fit_scalers and save_scalers:\n",
    "            with open(scalers_path, 'wb') as f:\n",
    "                pickle.dump(self.scalers, f)\n",
    "\n",
    "        # Create sequences for scaled and unscaled data\n",
    "        X_scaled, y_scaled = self.create_sequences(df)\n",
    "        X_unscaled, y_unscaled = self.create_sequences(unscaled_data)\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = self.time_based_split(X_scaled, y_scaled)\n",
    "        X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled = self.time_based_split(X_unscaled, y_unscaled)\n",
    "\n",
    "        return (\n",
    "            X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled,\n",
    "            X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled\n",
    "        )\n",
    "\n",
    "    def create_sequences(self, data):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - self.seq_length - 1):\n",
    "            seq = data.iloc[i:i+self.seq_length].values\n",
    "            target = data.iloc[i+self.seq_length]['close']  # Predict 'close' price\n",
    "            X.append(seq)\n",
    "            y.append(target)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def time_based_split(self, X, y):\n",
    "        split_idx = int(len(X) * (1 - self.test_size))\n",
    "        return X[:split_idx], X[split_idx:], y[:split_idx], y[split_idx:]\n",
    "\n",
    "    def inverse_transform_predictions(self, pred_scaled, feature_name='close', scalers_path=\"scalers.pkl\"):\n",
    "        \"\"\"\n",
    "        Rescales the model's predictions back to their original scale.\n",
    "        Instead of using scaler.inverse_transform on a single column (which expects all features),\n",
    "        we manually compute the inverse transformation using the specific feature's scale and center.\n",
    "        \"\"\"\n",
    "        if not self.scalers:\n",
    "            with open(scalers_path, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "\n",
    "        if feature_name in ['open', 'high', 'low', 'close', 'av_pr', 'diff', \n",
    "                            '7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA', \n",
    "                            '12_day_EMA', '26_day_EMA', '20_day_SMA']:\n",
    "            scaler = self.scalers['price']\n",
    "            price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', \n",
    "                          '7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA', \n",
    "                          '12_day_EMA', '26_day_EMA', '20_day_SMA']\n",
    "            # Find index of the target feature\n",
    "            col_index = price_cols.index(feature_name)\n",
    "            # Manually inverse transform the predictions for the target feature\n",
    "            pred_unscaled = pred_scaled * scaler.scale_[col_index] + scaler.center_[col_index]\n",
    "            return pred_unscaled.flatten()\n",
    "        elif feature_name == 'volume':\n",
    "            scaler = self.scalers['volume']\n",
    "            return np.expm1(scaler.inverse_transform(pred_scaled.reshape(-1, 1))).flatten()  # Inverse log transform\n",
    "        else:\n",
    "            raise ValueError(f\"Feature {feature_name} not recognized for inverse transformation.\")\n",
    "\n",
    "# ====================== Model Definitions ======================\n",
    "class HybridCNNRNN:\n",
    "    def __init__(self, input_shape):\n",
    "        self.model = self.build_model(input_shape)\n",
    "        \n",
    "    def build_model(self, input_shape):\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = Conv1D(64, kernel_size=3, dilation_rate=2, activation='relu')(inputs)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(32))(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        outputs = Dense(1)(x)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='mse',\n",
    "                      metrics=['mae', 'mse'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=5, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "        ]\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        return history\n",
    "\n",
    "class SimpleXGBoost:\n",
    "    def __init__(self):\n",
    "        self.model = XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        # Reshape input to 2D (batch_size, sequence_length * num_features)\n",
    "        X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "        self.model.fit(X_train_reshaped, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Reshape input to 2D (batch_size, sequence_length * num_features)\n",
    "        X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
    "        return self.model.predict(X_test_reshaped)\n",
    "\n",
    "class MetaModel:\n",
    "    def __init__(self, input_shape):\n",
    "        self.model = self.build_attention_model(input_shape)\n",
    "        \n",
    "    def build_attention_model(self, input_shape):\n",
    "        inputs = tf.keras.Input(shape=input_shape)\n",
    "        \n",
    "        # Reshape input to 3D (batch_size, 1, 3)\n",
    "        reshaped_inputs = Reshape((1, input_shape[0]))(inputs)\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        lstm_out = Bidirectional(LSTM(32, return_sequences=True))(reshaped_inputs)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attn_out = Attention()([lstm_out, lstm_out])\n",
    "        \n",
    "        # Dense layers\n",
    "        dense_out = Dense(16, activation='relu')(attn_out)\n",
    "        outputs = Dense(1)(dense_out)\n",
    "        \n",
    "        # Compile model\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                     loss='mse',\n",
    "                     metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "# ====================== Ensemble Training & Prediction ======================\n",
    "class TemporalEnsemble:\n",
    "    def __init__(self, data_pipeline, models):\n",
    "        self.pipeline = data_pipeline\n",
    "        self.models = models\n",
    "\n",
    "    def walk_forward_validation(self, X_scaled, X_unscaled, y_scaled, y_unscaled, window_size=30):\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        for i in range(len(X_scaled) - window_size):\n",
    "            # Train on scaled data\n",
    "            train_X_scaled, train_y_scaled = X_scaled[:i+window_size], y_scaled[:i+window_size]\n",
    "            test_X_scaled, test_y_scaled = X_scaled[i+window_size], y_scaled[i+window_size]\n",
    "\n",
    "            # Train on unscaled data for naive prediction\n",
    "            train_X_unscaled, train_y_unscaled = X_unscaled[:i+window_size], y_unscaled[:i+window_size]\n",
    "            test_X_unscaled, test_y_unscaled = X_unscaled[i+window_size], y_unscaled[i+window_size]\n",
    "\n",
    "            # Update models incrementally\n",
    "            self.update_models(train_X_scaled, train_y_scaled, train_X_unscaled, train_y_unscaled)\n",
    "\n",
    "            # Make prediction\n",
    "            pred = self.predict(test_X_scaled, test_X_unscaled)\n",
    "            predictions.append(pred)\n",
    "            actuals.append(test_y_scaled)\n",
    "\n",
    "        return np.array(predictions), np.array(actuals)\n",
    "\n",
    "    def update_models(self, X_scaled, y_scaled, X_unscaled, y_unscaled):\n",
    "        # Train CNN-RNN and XGBoost on scaled data\n",
    "        self.models['cnn_rnn'].model.train_on_batch(X_scaled, y_scaled)\n",
    "        self.models['xgb'].train(X_scaled, y_scaled)\n",
    "\n",
    "    def predict(self, X_scaled, X_unscaled):\n",
    "        # Add batch dimension to X_scaled\n",
    "        X_scaled = np.expand_dims(X_scaled, axis=0)  # Shape: (1, sequence_length, num_features)\n",
    "        \n",
    "        # Get predictions from CNN-RNN and XGBoost (scaled data)\n",
    "        cnn_rnn_pred = self.models['cnn_rnn'].model.predict(X_scaled).flatten()\n",
    "        xgb_pred = self.models['xgb'].predict(X_scaled)\n",
    "\n",
    "        # Get naive prediction (unscaled data) - use the last time step's first feature\n",
    "        naive_pred = X_unscaled[-1, 4]  \n",
    "\n",
    "        # Combine predictions\n",
    "        meta_input = np.vstack([cnn_rnn_pred, xgb_pred, naive_pred]).T\n",
    "        final_pred_scaled = self.models['meta'].model.predict(meta_input).flatten()\n",
    "\n",
    "        # Rescale the final predictions to the original scale\n",
    "        final_pred_unscaled = self.pipeline.inverse_transform_predictions(final_pred_scaled, feature_name='close')\n",
    "        return final_pred_unscaled\n",
    "\n",
    "    def evaluate(self, y_true, y_pred):\n",
    "        metrics = {\n",
    "            'MAE': mean_absolute_error(y_true, y_pred),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'MAPE': np.mean(np.abs((y_true - y_pred)/y_true)) * 100\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "# ====================== Main Execution ======================\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data (replace with your data loading logic)\n",
    "    df = pd.read_csv('xrpusdt_daily_dataset_with_features.csv')\n",
    "\n",
    "    # Initialize pipeline and preprocess data\n",
    "    pipeline = TimeSeriesPipeline(seq_length=30)\n",
    "    (X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled,\n",
    "     X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled) = pipeline.preprocess_data(df)\n",
    "\n",
    "    # Initialize models\n",
    "    cnn_rnn = HybridCNNRNN(X_train_scaled.shape[1:])\n",
    "    xgb = SimpleXGBoost()\n",
    "    meta = MetaModel(input_shape=(3,))\n",
    "\n",
    "    # Create ensemble\n",
    "    ensemble = TemporalEnsemble(\n",
    "        pipeline,\n",
    "        models={'cnn_rnn': cnn_rnn, 'xgb': xgb, 'meta': meta}\n",
    "    )\n",
    "\n",
    "    # Perform walk-forward validation\n",
    "    final_preds, actuals = ensemble.walk_forward_validation(X_test_scaled, X_test_unscaled, y_test_scaled, y_test_unscaled)\n",
    "\n",
    "    # Evaluate performance\n",
    "    metrics = ensemble.evaluate(actuals, final_preds)\n",
    "    print(\"Final Performance Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    # Visualize predictions\n",
    "    plt.plot(final_preds, label='Predictions')\n",
    "    plt.plot(actuals, label='Actuals')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Starting data preprocessing...\n",
      "Data preprocessing finished.\n",
      "Training samples: 1917, Test samples: 480\n",
      "Dataset loaded. Training samples: 1917, Test samples: 480\n",
      "Initializing CNN-RNN Hybrid Model...\n",
      "CNN-RNN Hybrid Model initialized.\n",
      "Initializing XGBoost Model...\n",
      "XGBoost Model initialized.\n",
      "Initializing Ensemble Meta Model (Deep NN)...\n",
      "Ensemble Meta Model initialized.\n",
      "All models initialized.\n",
      "Starting walk-forward validation...\n",
      "Iteration 1/450\n",
      "Updating base models on batch of size 30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chidi\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0839, MSE: 0.0102\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "Iteration 1 error (scaled): 0.4536\n",
      "Iteration 2/450\n",
      "Updating base models on batch of size 31...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0825, MSE: 0.0100\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Iteration 2 error (scaled): 0.4440\n",
      "Iteration 3/450\n",
      "Updating base models on batch of size 32...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0814, MSE: 0.0098\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Iteration 3 error (scaled): 0.4642\n",
      "Iteration 4/450\n",
      "Updating base models on batch of size 33...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0799, MSE: 0.0096\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Iteration 4 error (scaled): 0.4930\n",
      "Iteration 5/450\n",
      "Updating base models on batch of size 34...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0781, MSE: 0.0093\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Iteration 5 error (scaled): 0.5000\n",
      "Iteration 6/450\n",
      "Updating base models on batch of size 35...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0761, MSE: 0.0091\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Iteration 6 error (scaled): 0.5060\n",
      "Iteration 7/450\n",
      "Updating base models on batch of size 36...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0743, MSE: 0.0088\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 7 error (scaled): 0.4947\n",
      "Iteration 8/450\n",
      "Updating base models on batch of size 37...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0726, MSE: 0.0086\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Iteration 8 error (scaled): 0.5683\n",
      "Iteration 9/450\n",
      "Updating base models on batch of size 38...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0721, MSE: 0.0084\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Iteration 9 error (scaled): 0.5901\n",
      "Iteration 10/450\n",
      "Updating base models on batch of size 39...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0718, MSE: 0.0083\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 10 error (scaled): 0.6977\n",
      "Iteration 11/450\n",
      "Updating base models on batch of size 40...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0744, MSE: 0.0085\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Iteration 11 error (scaled): 0.6553\n",
      "Iteration 12/450\n",
      "Updating base models on batch of size 41...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0753, MSE: 0.0085\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 12 error (scaled): 0.6715\n",
      "Iteration 13/450\n",
      "Updating base models on batch of size 42...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0765, MSE: 0.0085\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 13 error (scaled): 0.5322\n",
      "Iteration 14/450\n",
      "Updating base models on batch of size 43...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0754, MSE: 0.0083\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 14 error (scaled): 0.5371\n",
      "Iteration 15/450\n",
      "Updating base models on batch of size 44...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0743, MSE: 0.0082\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 15 error (scaled): 0.5687\n",
      "Iteration 16/450\n",
      "Updating base models on batch of size 45...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0729, MSE: 0.0080\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 16 error (scaled): 0.5809\n",
      "Iteration 17/450\n",
      "Updating base models on batch of size 46...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0713, MSE: 0.0078\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Iteration 17 error (scaled): 0.5302\n",
      "Iteration 18/450\n",
      "Updating base models on batch of size 47...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0704, MSE: 0.0077\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 18 error (scaled): 0.5472\n",
      "Iteration 19/450\n",
      "Updating base models on batch of size 48...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0693, MSE: 0.0076\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 19 error (scaled): 0.5139\n",
      "Iteration 20/450\n",
      "Updating base models on batch of size 49...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0687, MSE: 0.0075\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 20 error (scaled): 0.5233\n",
      "Iteration 21/450\n",
      "Updating base models on batch of size 50...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0680, MSE: 0.0074\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Iteration 21 error (scaled): 0.4981\n",
      "Iteration 22/450\n",
      "Updating base models on batch of size 51...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0676, MSE: 0.0073\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Iteration 22 error (scaled): 0.5443\n",
      "Iteration 23/450\n",
      "Updating base models on batch of size 52...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0668, MSE: 0.0072\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 23 error (scaled): 0.5692\n",
      "Iteration 24/450\n",
      "Updating base models on batch of size 53...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0657, MSE: 0.0071\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 24 error (scaled): 0.5716\n",
      "Iteration 25/450\n",
      "Updating base models on batch of size 54...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0647, MSE: 0.0070\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 25 error (scaled): 0.5574\n",
      "Iteration 26/450\n",
      "Updating base models on batch of size 55...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0638, MSE: 0.0068\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Iteration 26 error (scaled): 0.5352\n",
      "Iteration 27/450\n",
      "Updating base models on batch of size 56...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0632, MSE: 0.0068\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Iteration 27 error (scaled): 0.6503\n",
      "Iteration 28/450\n",
      "Updating base models on batch of size 57...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0635, MSE: 0.0067\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 28 error (scaled): 0.5683\n",
      "Iteration 29/450\n",
      "Updating base models on batch of size 58...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0626, MSE: 0.0066\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 29 error (scaled): 0.6102\n",
      "Iteration 30/450\n",
      "Updating base models on batch of size 59...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0619, MSE: 0.0065\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 30 error (scaled): 0.6117\n",
      "Iteration 31/450\n",
      "Updating base models on batch of size 60...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0613, MSE: 0.0064\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 31 error (scaled): 0.5725\n",
      "Iteration 32/450\n",
      "Updating base models on batch of size 61...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0605, MSE: 0.0063\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Iteration 32 error (scaled): 0.5643\n",
      "Iteration 33/450\n",
      "Updating base models on batch of size 62...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0598, MSE: 0.0062\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Iteration 33 error (scaled): 0.5478\n",
      "Iteration 34/450\n",
      "Updating base models on batch of size 63...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0592, MSE: 0.0061\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 34 error (scaled): 0.5941\n",
      "Iteration 35/450\n",
      "Updating base models on batch of size 64...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0584, MSE: 0.0060\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Iteration 35 error (scaled): 0.5776\n",
      "Iteration 36/450\n",
      "Updating base models on batch of size 65...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0576, MSE: 0.0059\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 36 error (scaled): 0.4362\n",
      "Iteration 37/450\n",
      "Updating base models on batch of size 66...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0582, MSE: 0.0062\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Iteration 37 error (scaled): 0.4529\n",
      "Iteration 38/450\n",
      "Updating base models on batch of size 67...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0586, MSE: 0.0063\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 38 error (scaled): 0.4154\n",
      "Iteration 39/450\n",
      "Updating base models on batch of size 68...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0592, MSE: 0.0066\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 39 error (scaled): 0.3879\n",
      "Iteration 40/450\n",
      "Updating base models on batch of size 69...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0601, MSE: 0.0069\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Iteration 40 error (scaled): 0.3326\n",
      "Iteration 41/450\n",
      "Updating base models on batch of size 70...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0614, MSE: 0.0076\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 41 error (scaled): 0.4203\n",
      "Iteration 42/450\n",
      "Updating base models on batch of size 71...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0622, MSE: 0.0077\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 42 error (scaled): 0.3826\n",
      "Iteration 43/450\n",
      "Updating base models on batch of size 72...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0634, MSE: 0.0081\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 43 error (scaled): 0.4955\n",
      "Iteration 44/450\n",
      "Updating base models on batch of size 73...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0632, MSE: 0.0080\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 44 error (scaled): 0.4964\n",
      "Iteration 45/450\n",
      "Updating base models on batch of size 74...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0631, MSE: 0.0079\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 45 error (scaled): 0.3875\n",
      "Iteration 46/450\n",
      "Updating base models on batch of size 75...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0636, MSE: 0.0082\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 46 error (scaled): 0.4041\n",
      "Iteration 47/450\n",
      "Updating base models on batch of size 76...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0644, MSE: 0.0083\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 47 error (scaled): 0.4082\n",
      "Iteration 48/450\n",
      "Updating base models on batch of size 77...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0653, MSE: 0.0084\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 48 error (scaled): 0.4038\n",
      "Iteration 49/450\n",
      "Updating base models on batch of size 78...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0661, MSE: 0.0086\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 49 error (scaled): 0.4029\n",
      "Iteration 50/450\n",
      "Updating base models on batch of size 79...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0669, MSE: 0.0087\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 50 error (scaled): 0.3783\n",
      "Iteration 51/450\n",
      "Updating base models on batch of size 80...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0679, MSE: 0.0089\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 51 error (scaled): 0.3229\n",
      "Iteration 52/450\n",
      "Updating base models on batch of size 81...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0698, MSE: 0.0093\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 52 error (scaled): 0.2982\n",
      "Iteration 53/450\n",
      "Updating base models on batch of size 82...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0716, MSE: 0.0098\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Iteration 53 error (scaled): 0.3295\n",
      "Iteration 54/450\n",
      "Updating base models on batch of size 83...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0731, MSE: 0.0101\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Iteration 54 error (scaled): 0.3044\n",
      "Iteration 55/450\n",
      "Updating base models on batch of size 84...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0748, MSE: 0.0105\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 55 error (scaled): 0.2422\n",
      "Iteration 56/450\n",
      "Updating base models on batch of size 85...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0773, MSE: 0.0113\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Iteration 56 error (scaled): 0.2116\n",
      "Iteration 57/450\n",
      "Updating base models on batch of size 86...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0800, MSE: 0.0122\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 57 error (scaled): 0.2096\n",
      "Iteration 58/450\n",
      "Updating base models on batch of size 87...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0828, MSE: 0.0130\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 58 error (scaled): 0.1937\n",
      "Iteration 59/450\n",
      "Updating base models on batch of size 88...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0859, MSE: 0.0138\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "Iteration 59 error (scaled): 0.2544\n",
      "Iteration 60/450\n",
      "Updating base models on batch of size 89...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0882, MSE: 0.0143\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 60 error (scaled): 0.2443\n",
      "Iteration 61/450\n",
      "Updating base models on batch of size 90...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0906, MSE: 0.0148\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 61 error (scaled): 0.2199\n",
      "Iteration 62/450\n",
      "Updating base models on batch of size 91...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0931, MSE: 0.0154\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 62 error (scaled): 0.2538\n",
      "Iteration 63/450\n",
      "Updating base models on batch of size 92...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0951, MSE: 0.0157\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Iteration 63 error (scaled): 0.1679\n",
      "Iteration 64/450\n",
      "Updating base models on batch of size 93...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0979, MSE: 0.0165\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 64 error (scaled): 0.1391\n",
      "Iteration 65/450\n",
      "Updating base models on batch of size 94...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1010, MSE: 0.0174\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 65 error (scaled): 0.1472\n",
      "Iteration 66/450\n",
      "Updating base models on batch of size 95...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1040, MSE: 0.0182\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Iteration 66 error (scaled): 0.1615\n",
      "Iteration 67/450\n",
      "Updating base models on batch of size 96...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1068, MSE: 0.0188\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 67 error (scaled): 0.1879\n",
      "Iteration 68/450\n",
      "Updating base models on batch of size 97...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1092, MSE: 0.0193\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 68 error (scaled): 0.1342\n",
      "Iteration 69/450\n",
      "Updating base models on batch of size 98...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1121, MSE: 0.0200\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 69 error (scaled): 0.1481\n",
      "Iteration 70/450\n",
      "Updating base models on batch of size 99...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1147, MSE: 0.0207\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 70 error (scaled): 0.1403\n",
      "Iteration 71/450\n",
      "Updating base models on batch of size 100...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1170, MSE: 0.0213\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 71 error (scaled): 0.1678\n",
      "Iteration 72/450\n",
      "Updating base models on batch of size 101...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1192, MSE: 0.0217\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 72 error (scaled): 0.1714\n",
      "Iteration 73/450\n",
      "Updating base models on batch of size 102...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1213, MSE: 0.0221\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 73 error (scaled): 0.2097\n",
      "Iteration 74/450\n",
      "Updating base models on batch of size 103...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1228, MSE: 0.0224\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 74 error (scaled): 0.2039\n",
      "Iteration 75/450\n",
      "Updating base models on batch of size 104...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1243, MSE: 0.0226\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 75 error (scaled): 0.2109\n",
      "Iteration 76/450\n",
      "Updating base models on batch of size 105...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1256, MSE: 0.0228\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 76 error (scaled): 0.2279\n",
      "Iteration 77/450\n",
      "Updating base models on batch of size 106...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1267, MSE: 0.0230\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 77 error (scaled): 0.2034\n",
      "Iteration 78/450\n",
      "Updating base models on batch of size 107...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1279, MSE: 0.0232\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 78 error (scaled): 0.2471\n",
      "Iteration 79/450\n",
      "Updating base models on batch of size 108...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1287, MSE: 0.0233\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 79 error (scaled): 0.3290\n",
      "Iteration 80/450\n",
      "Updating base models on batch of size 109...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1285, MSE: 0.0231\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 80 error (scaled): 0.3356\n",
      "Iteration 81/450\n",
      "Updating base models on batch of size 110...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1283, MSE: 0.0230\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 81 error (scaled): 0.2868\n",
      "Iteration 82/450\n",
      "Updating base models on batch of size 111...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1286, MSE: 0.0229\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Iteration 82 error (scaled): 0.3122\n",
      "Iteration 83/450\n",
      "Updating base models on batch of size 112...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1286, MSE: 0.0228\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 83 error (scaled): 0.3310\n",
      "Iteration 84/450\n",
      "Updating base models on batch of size 113...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1283, MSE: 0.0227\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Iteration 84 error (scaled): 0.3318\n",
      "Iteration 85/450\n",
      "Updating base models on batch of size 114...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1281, MSE: 0.0226\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 85 error (scaled): 0.2877\n",
      "Iteration 86/450\n",
      "Updating base models on batch of size 115...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1283, MSE: 0.0225\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 86 error (scaled): 0.2582\n",
      "Iteration 87/450\n",
      "Updating base models on batch of size 116...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1287, MSE: 0.0226\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Iteration 87 error (scaled): 0.2357\n",
      "Iteration 88/450\n",
      "Updating base models on batch of size 117...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1292, MSE: 0.0226\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 88 error (scaled): 0.2718\n",
      "Iteration 89/450\n",
      "Updating base models on batch of size 118...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1295, MSE: 0.0226\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 89 error (scaled): 0.2637\n",
      "Iteration 90/450\n",
      "Updating base models on batch of size 119...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1297, MSE: 0.0226\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 90 error (scaled): 0.2930\n",
      "Iteration 91/450\n",
      "Updating base models on batch of size 120...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1297, MSE: 0.0225\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 91 error (scaled): 0.4141\n",
      "Iteration 92/450\n",
      "Updating base models on batch of size 121...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1287, MSE: 0.0223\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Iteration 92 error (scaled): 0.3779\n",
      "Iteration 93/450\n",
      "Updating base models on batch of size 122...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1280, MSE: 0.0222\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 93 error (scaled): 0.4183\n",
      "Iteration 94/450\n",
      "Updating base models on batch of size 123...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1271, MSE: 0.0220\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 94 error (scaled): 0.4679\n",
      "Iteration 95/450\n",
      "Updating base models on batch of size 124...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1264, MSE: 0.0218\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 95 error (scaled): 0.6117\n",
      "Iteration 96/450\n",
      "Updating base models on batch of size 125...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1266, MSE: 0.0219\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Iteration 96 error (scaled): 0.5549\n",
      "Iteration 97/450\n",
      "Updating base models on batch of size 126...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1265, MSE: 0.0218\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 97 error (scaled): 0.6258\n",
      "Iteration 98/450\n",
      "Updating base models on batch of size 127...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1267, MSE: 0.0219\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 98 error (scaled): 0.4376\n",
      "Iteration 99/450\n",
      "Updating base models on batch of size 128...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1257, MSE: 0.0217\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Iteration 99 error (scaled): 0.5069\n",
      "Iteration 100/450\n",
      "Updating base models on batch of size 129...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1252, MSE: 0.0216\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 100 error (scaled): 0.5582\n",
      "Iteration 101/450\n",
      "Updating base models on batch of size 130...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1250, MSE: 0.0215\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Iteration 101 error (scaled): 0.5352\n",
      "Iteration 102/450\n",
      "Updating base models on batch of size 131...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1247, MSE: 0.0214\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Iteration 102 error (scaled): 0.5355\n",
      "Iteration 103/450\n",
      "Updating base models on batch of size 132...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1243, MSE: 0.0213\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Iteration 103 error (scaled): 0.4935\n",
      "Iteration 104/450\n",
      "Updating base models on batch of size 133...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1237, MSE: 0.0212\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 104 error (scaled): 0.8812\n",
      "Iteration 105/450\n",
      "Updating base models on batch of size 134...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1255, MSE: 0.0223\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 105 error (scaled): 0.7614\n",
      "Iteration 106/450\n",
      "Updating base models on batch of size 135...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1264, MSE: 0.0228\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 106 error (scaled): 0.7642\n",
      "Iteration 107/450\n",
      "Updating base models on batch of size 136...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1274, MSE: 0.0232\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 107 error (scaled): 0.6993\n",
      "Iteration 108/450\n",
      "Updating base models on batch of size 137...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1279, MSE: 0.0234\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Iteration 108 error (scaled): 0.5828\n",
      "Iteration 109/450\n",
      "Updating base models on batch of size 138...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1277, MSE: 0.0234\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 109 error (scaled): 0.4804\n",
      "Iteration 110/450\n",
      "Updating base models on batch of size 139...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1270, MSE: 0.0232\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 110 error (scaled): 0.5367\n",
      "Iteration 111/450\n",
      "Updating base models on batch of size 140...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1265, MSE: 0.0231\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 111 error (scaled): 0.6250\n",
      "Iteration 112/450\n",
      "Updating base models on batch of size 141...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1265, MSE: 0.0231\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 112 error (scaled): 0.4210\n",
      "Iteration 113/450\n",
      "Updating base models on batch of size 142...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1260, MSE: 0.0229\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 113 error (scaled): 0.5126\n",
      "Iteration 114/450\n",
      "Updating base models on batch of size 143...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1254, MSE: 0.0228\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 114 error (scaled): 0.6123\n",
      "Iteration 115/450\n",
      "Updating base models on batch of size 144...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1253, MSE: 0.0228\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 115 error (scaled): 0.5152\n",
      "Iteration 116/450\n",
      "Updating base models on batch of size 145...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1247, MSE: 0.0226\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 116 error (scaled): 0.5355\n",
      "Iteration 117/450\n",
      "Updating base models on batch of size 146...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1242, MSE: 0.0225\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Iteration 117 error (scaled): 0.5874\n",
      "Iteration 118/450\n",
      "Updating base models on batch of size 147...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1239, MSE: 0.0224\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Iteration 118 error (scaled): 0.6123\n",
      "Iteration 119/450\n",
      "Updating base models on batch of size 148...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1238, MSE: 0.0224\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 119 error (scaled): 0.5838\n",
      "Iteration 120/450\n",
      "Updating base models on batch of size 149...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1236, MSE: 0.0223\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 120 error (scaled): 0.5166\n",
      "Iteration 121/450\n",
      "Updating base models on batch of size 150...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1230, MSE: 0.0222\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 121 error (scaled): 0.5598\n",
      "Iteration 122/450\n",
      "Updating base models on batch of size 151...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1226, MSE: 0.0221\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 122 error (scaled): 0.5794\n",
      "Iteration 123/450\n",
      "Updating base models on batch of size 152...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1223, MSE: 0.0220\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 123 error (scaled): 0.5499\n",
      "Iteration 124/450\n",
      "Updating base models on batch of size 153...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1219, MSE: 0.0219\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Iteration 124 error (scaled): 0.5780\n",
      "Iteration 125/450\n",
      "Updating base models on batch of size 154...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1216, MSE: 0.0218\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Iteration 125 error (scaled): 0.5199\n",
      "Iteration 126/450\n",
      "Updating base models on batch of size 155...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1210, MSE: 0.0217\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 126 error (scaled): 0.4357\n",
      "Iteration 127/450\n",
      "Updating base models on batch of size 156...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1207, MSE: 0.0216\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 127 error (scaled): 0.4001\n",
      "Iteration 128/450\n",
      "Updating base models on batch of size 157...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1207, MSE: 0.0215\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 128 error (scaled): 0.4660\n",
      "Iteration 129/450\n",
      "Updating base models on batch of size 158...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1200, MSE: 0.0214\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 129 error (scaled): 0.4423\n",
      "Iteration 130/450\n",
      "Updating base models on batch of size 159...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1194, MSE: 0.0213\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 130 error (scaled): 0.4625\n",
      "Iteration 131/450\n",
      "Updating base models on batch of size 160...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1187, MSE: 0.0211\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Iteration 131 error (scaled): 0.4672\n",
      "Iteration 132/450\n",
      "Updating base models on batch of size 161...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1181, MSE: 0.0210\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Iteration 132 error (scaled): 0.5338\n",
      "Iteration 133/450\n",
      "Updating base models on batch of size 162...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1175, MSE: 0.0209\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 133 error (scaled): 0.5306\n",
      "Iteration 134/450\n",
      "Updating base models on batch of size 163...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1170, MSE: 0.0208\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 134 error (scaled): 0.5401\n",
      "Iteration 135/450\n",
      "Updating base models on batch of size 164...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1166, MSE: 0.0207\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 135 error (scaled): 0.5153\n",
      "Iteration 136/450\n",
      "Updating base models on batch of size 165...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1160, MSE: 0.0205\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 136 error (scaled): 0.3057\n",
      "Iteration 137/450\n",
      "Updating base models on batch of size 166...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1164, MSE: 0.0206\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Iteration 137 error (scaled): 0.0748\n",
      "Iteration 138/450\n",
      "Updating base models on batch of size 167...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1183, MSE: 0.0213\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Iteration 138 error (scaled): 0.1534\n",
      "Iteration 139/450\n",
      "Updating base models on batch of size 168...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1196, MSE: 0.0216\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 139 error (scaled): 0.1325\n",
      "Iteration 140/450\n",
      "Updating base models on batch of size 169...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1210, MSE: 0.0220\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Iteration 140 error (scaled): 0.1246\n",
      "Iteration 141/450\n",
      "Updating base models on batch of size 170...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1223, MSE: 0.0224\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 141 error (scaled): 0.1168\n",
      "Iteration 142/450\n",
      "Updating base models on batch of size 171...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1236, MSE: 0.0229\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 142 error (scaled): 0.1406\n",
      "Iteration 143/450\n",
      "Updating base models on batch of size 172...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1248, MSE: 0.0232\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 143 error (scaled): 0.1393\n",
      "Iteration 144/450\n",
      "Updating base models on batch of size 173...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1259, MSE: 0.0235\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 144 error (scaled): 0.2242\n",
      "Iteration 145/450\n",
      "Updating base models on batch of size 174...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1265, MSE: 0.0236\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Iteration 145 error (scaled): 0.2081\n",
      "Iteration 146/450\n",
      "Updating base models on batch of size 175...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1271, MSE: 0.0237\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 146 error (scaled): 0.3097\n",
      "Iteration 147/450\n",
      "Updating base models on batch of size 176...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1272, MSE: 0.0236\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 147 error (scaled): 0.2697\n",
      "Iteration 148/450\n",
      "Updating base models on batch of size 177...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1274, MSE: 0.0236\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Iteration 148 error (scaled): 0.2091\n",
      "Iteration 149/450\n",
      "Updating base models on batch of size 178...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1280, MSE: 0.0237\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Iteration 149 error (scaled): 0.1995\n",
      "Iteration 150/450\n",
      "Updating base models on batch of size 179...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1285, MSE: 0.0238\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Iteration 150 error (scaled): 0.1972\n",
      "Iteration 151/450\n",
      "Updating base models on batch of size 180...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1291, MSE: 0.0239\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 151 error (scaled): 0.1672\n",
      "Iteration 152/450\n",
      "Updating base models on batch of size 181...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1297, MSE: 0.0240\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 152 error (scaled): 0.1395\n",
      "Iteration 153/450\n",
      "Updating base models on batch of size 182...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1305, MSE: 0.0242\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 153 error (scaled): 0.1549\n",
      "Iteration 154/450\n",
      "Updating base models on batch of size 183...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1312, MSE: 0.0244\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Iteration 154 error (scaled): 0.1077\n",
      "Iteration 155/450\n",
      "Updating base models on batch of size 184...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1321, MSE: 0.0246\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Iteration 155 error (scaled): 0.1634\n",
      "Iteration 156/450\n",
      "Updating base models on batch of size 185...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1327, MSE: 0.0248\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 156 error (scaled): 0.1683\n",
      "Iteration 157/450\n",
      "Updating base models on batch of size 186...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1333, MSE: 0.0249\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 157 error (scaled): 0.2141\n",
      "Iteration 158/450\n",
      "Updating base models on batch of size 187...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1336, MSE: 0.0249\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 158 error (scaled): 0.2089\n",
      "Iteration 159/450\n",
      "Updating base models on batch of size 188...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1339, MSE: 0.0249\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Iteration 159 error (scaled): 0.2062\n",
      "Iteration 160/450\n",
      "Updating base models on batch of size 189...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1342, MSE: 0.0250\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Iteration 160 error (scaled): 0.2394\n",
      "Iteration 161/450\n",
      "Updating base models on batch of size 190...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1343, MSE: 0.0250\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 161 error (scaled): 0.1884\n",
      "Iteration 162/450\n",
      "Updating base models on batch of size 191...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1347, MSE: 0.0250\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 162 error (scaled): 0.1599\n",
      "Iteration 163/450\n",
      "Updating base models on batch of size 192...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1352, MSE: 0.0251\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 163 error (scaled): 0.1717\n",
      "Iteration 164/450\n",
      "Updating base models on batch of size 193...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1357, MSE: 0.0252\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 164 error (scaled): 0.1093\n",
      "Iteration 165/450\n",
      "Updating base models on batch of size 194...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1364, MSE: 0.0254\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 165 error (scaled): 0.1248\n",
      "Iteration 166/450\n",
      "Updating base models on batch of size 195...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1372, MSE: 0.0256\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 166 error (scaled): 0.1084\n",
      "Iteration 167/450\n",
      "Updating base models on batch of size 196...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1380, MSE: 0.0258\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 167 error (scaled): 0.1279\n",
      "Iteration 168/450\n",
      "Updating base models on batch of size 197...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1386, MSE: 0.0260\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 168 error (scaled): 0.1105\n",
      "Iteration 169/450\n",
      "Updating base models on batch of size 198...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1393, MSE: 0.0262\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Iteration 169 error (scaled): 0.1739\n",
      "Iteration 170/450\n",
      "Updating base models on batch of size 199...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1397, MSE: 0.0262\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 170 error (scaled): 0.1630\n",
      "Iteration 171/450\n",
      "Updating base models on batch of size 200...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1401, MSE: 0.0263\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 171 error (scaled): 0.1864\n",
      "Iteration 172/450\n",
      "Updating base models on batch of size 201...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1404, MSE: 0.0264\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 172 error (scaled): 0.1780\n",
      "Iteration 173/450\n",
      "Updating base models on batch of size 202...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1407, MSE: 0.0264\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 173 error (scaled): 0.1373\n",
      "Iteration 174/450\n",
      "Updating base models on batch of size 203...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1411, MSE: 0.0265\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 174 error (scaled): 0.2314\n",
      "Iteration 175/450\n",
      "Updating base models on batch of size 204...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1411, MSE: 0.0265\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 175 error (scaled): 0.2364\n",
      "Iteration 176/450\n",
      "Updating base models on batch of size 205...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1412, MSE: 0.0264\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 176 error (scaled): 0.2018\n",
      "Iteration 177/450\n",
      "Updating base models on batch of size 206...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1414, MSE: 0.0265\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 177 error (scaled): 0.2129\n",
      "Iteration 178/450\n",
      "Updating base models on batch of size 207...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1415, MSE: 0.0265\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 178 error (scaled): 0.2377\n",
      "Iteration 179/450\n",
      "Updating base models on batch of size 208...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1415, MSE: 0.0264\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 179 error (scaled): 0.2576\n",
      "Iteration 180/450\n",
      "Updating base models on batch of size 209...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1415, MSE: 0.0264\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 180 error (scaled): 0.2146\n",
      "Iteration 181/450\n",
      "Updating base models on batch of size 210...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1416, MSE: 0.0264\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 181 error (scaled): 0.2339\n",
      "Iteration 182/450\n",
      "Updating base models on batch of size 211...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1416, MSE: 0.0263\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 182 error (scaled): 0.2169\n",
      "Iteration 183/450\n",
      "Updating base models on batch of size 212...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1417, MSE: 0.0263\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 183 error (scaled): 0.1994\n",
      "Iteration 184/450\n",
      "Updating base models on batch of size 213...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1419, MSE: 0.0263\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 184 error (scaled): 0.1815\n",
      "Iteration 185/450\n",
      "Updating base models on batch of size 214...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1421, MSE: 0.0264\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 185 error (scaled): 0.1767\n",
      "Iteration 186/450\n",
      "Updating base models on batch of size 215...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1424, MSE: 0.0264\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 186 error (scaled): 0.1806\n",
      "Iteration 187/450\n",
      "Updating base models on batch of size 216...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1426, MSE: 0.0265\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 187 error (scaled): 0.1633\n",
      "Iteration 188/450\n",
      "Updating base models on batch of size 217...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1429, MSE: 0.0265\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Iteration 188 error (scaled): 0.1853\n",
      "Iteration 189/450\n",
      "Updating base models on batch of size 218...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1430, MSE: 0.0266\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 189 error (scaled): 0.2060\n",
      "Iteration 190/450\n",
      "Updating base models on batch of size 219...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1431, MSE: 0.0266\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 190 error (scaled): 0.2066\n",
      "Iteration 191/450\n",
      "Updating base models on batch of size 220...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1432, MSE: 0.0266\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 191 error (scaled): 0.1931\n",
      "Iteration 192/450\n",
      "Updating base models on batch of size 221...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1434, MSE: 0.0266\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Iteration 192 error (scaled): 0.1170\n",
      "Iteration 193/450\n",
      "Updating base models on batch of size 222...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1438, MSE: 0.0267\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 193 error (scaled): 0.0957\n",
      "Iteration 194/450\n",
      "Updating base models on batch of size 223...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1443, MSE: 0.0269\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 194 error (scaled): 0.1157\n",
      "Iteration 195/450\n",
      "Updating base models on batch of size 224...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1448, MSE: 0.0270\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 195 error (scaled): 0.1084\n",
      "Iteration 196/450\n",
      "Updating base models on batch of size 225...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1452, MSE: 0.0272\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 196 error (scaled): 0.0513\n",
      "Iteration 197/450\n",
      "Updating base models on batch of size 226...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1459, MSE: 0.0275\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 197 error (scaled): 0.0866\n",
      "Iteration 198/450\n",
      "Updating base models on batch of size 227...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1464, MSE: 0.0276\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 198 error (scaled): 0.0361\n",
      "Iteration 199/450\n",
      "Updating base models on batch of size 228...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1471, MSE: 0.0279\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 199 error (scaled): 0.0252\n",
      "Iteration 200/450\n",
      "Updating base models on batch of size 229...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1478, MSE: 0.0282\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 200 error (scaled): 0.0783\n",
      "Iteration 201/450\n",
      "Updating base models on batch of size 230...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1483, MSE: 0.0284\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 201 error (scaled): 0.0719\n",
      "Iteration 202/450\n",
      "Updating base models on batch of size 231...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1489, MSE: 0.0285\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 202 error (scaled): 0.1235\n",
      "Iteration 203/450\n",
      "Updating base models on batch of size 232...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1492, MSE: 0.0286\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 203 error (scaled): 0.0786\n",
      "Iteration 204/450\n",
      "Updating base models on batch of size 233...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1496, MSE: 0.0287\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 204 error (scaled): 0.0830\n",
      "Iteration 205/450\n",
      "Updating base models on batch of size 234...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1501, MSE: 0.0289\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 205 error (scaled): 0.0699\n",
      "Iteration 206/450\n",
      "Updating base models on batch of size 235...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1505, MSE: 0.0290\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Iteration 206 error (scaled): 0.0713\n",
      "Iteration 207/450\n",
      "Updating base models on batch of size 236...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1510, MSE: 0.0292\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 207 error (scaled): 0.0634\n",
      "Iteration 208/450\n",
      "Updating base models on batch of size 237...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1515, MSE: 0.0294\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 208 error (scaled): 0.0413\n",
      "Iteration 209/450\n",
      "Updating base models on batch of size 238...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1521, MSE: 0.0296\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 209 error (scaled): 0.0222\n",
      "Iteration 210/450\n",
      "Updating base models on batch of size 239...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1527, MSE: 0.0298\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 210 error (scaled): 0.0262\n",
      "Iteration 211/450\n",
      "Updating base models on batch of size 240...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1533, MSE: 0.0301\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 211 error (scaled): 0.0033\n",
      "Iteration 212/450\n",
      "Updating base models on batch of size 241...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1539, MSE: 0.0303\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 212 error (scaled): 0.0217\n",
      "Iteration 213/450\n",
      "Updating base models on batch of size 242...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1544, MSE: 0.0306\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 213 error (scaled): 0.0079\n",
      "Iteration 214/450\n",
      "Updating base models on batch of size 243...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1550, MSE: 0.0308\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Iteration 214 error (scaled): 0.0102\n",
      "Iteration 215/450\n",
      "Updating base models on batch of size 244...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1556, MSE: 0.0310\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 215 error (scaled): 0.0201\n",
      "Iteration 216/450\n",
      "Updating base models on batch of size 245...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1561, MSE: 0.0312\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 216 error (scaled): 0.0224\n",
      "Iteration 217/450\n",
      "Updating base models on batch of size 246...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1566, MSE: 0.0314\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 217 error (scaled): 0.0498\n",
      "Iteration 218/450\n",
      "Updating base models on batch of size 247...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1570, MSE: 0.0316\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 218 error (scaled): 0.0105\n",
      "Iteration 219/450\n",
      "Updating base models on batch of size 248...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1575, MSE: 0.0318\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 219 error (scaled): 0.1283\n",
      "Iteration 220/450\n",
      "Updating base models on batch of size 249...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1585, MSE: 0.0324\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 220 error (scaled): 0.1550\n",
      "Iteration 221/450\n",
      "Updating base models on batch of size 250...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1596, MSE: 0.0330\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 221 error (scaled): 0.0743\n",
      "Iteration 222/450\n",
      "Updating base models on batch of size 251...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1604, MSE: 0.0334\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 222 error (scaled): 0.1704\n",
      "Iteration 223/450\n",
      "Updating base models on batch of size 252...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1615, MSE: 0.0341\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 223 error (scaled): 0.1293\n",
      "Iteration 224/450\n",
      "Updating base models on batch of size 253...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1625, MSE: 0.0346\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 224 error (scaled): 0.1159\n",
      "Iteration 225/450\n",
      "Updating base models on batch of size 254...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1634, MSE: 0.0351\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Iteration 225 error (scaled): 0.1041\n",
      "Iteration 226/450\n",
      "Updating base models on batch of size 255...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1642, MSE: 0.0355\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 226 error (scaled): 0.0689\n",
      "Iteration 227/450\n",
      "Updating base models on batch of size 256...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1649, MSE: 0.0359\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "Iteration 227 error (scaled): 0.0165\n",
      "Iteration 228/450\n",
      "Updating base models on batch of size 257...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1653, MSE: 0.0360\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Iteration 228 error (scaled): 0.1883\n",
      "Iteration 229/450\n",
      "Updating base models on batch of size 258...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1651, MSE: 0.0359\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Iteration 229 error (scaled): 0.1707\n",
      "Iteration 230/450\n",
      "Updating base models on batch of size 259...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1650, MSE: 0.0359\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Iteration 230 error (scaled): 0.2265\n",
      "Iteration 231/450\n",
      "Updating base models on batch of size 260...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1647, MSE: 0.0358\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 231 error (scaled): 0.3676\n",
      "Iteration 232/450\n",
      "Updating base models on batch of size 261...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1642, MSE: 0.0356\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 232 error (scaled): 0.5235\n",
      "Iteration 233/450\n",
      "Updating base models on batch of size 262...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1644, MSE: 0.0356\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Iteration 233 error (scaled): 0.3478\n",
      "Iteration 234/450\n",
      "Updating base models on batch of size 263...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1638, MSE: 0.0355\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 234 error (scaled): 0.3602\n",
      "Iteration 235/450\n",
      "Updating base models on batch of size 264...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1633, MSE: 0.0354\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 235 error (scaled): 0.4342\n",
      "Iteration 236/450\n",
      "Updating base models on batch of size 265...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1630, MSE: 0.0353\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 236 error (scaled): 0.4611\n",
      "Iteration 237/450\n",
      "Updating base models on batch of size 266...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1628, MSE: 0.0352\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Iteration 237 error (scaled): 0.5045\n",
      "Iteration 238/450\n",
      "Updating base models on batch of size 267...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1627, MSE: 0.0351\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 238 error (scaled): 0.4699\n",
      "Iteration 239/450\n",
      "Updating base models on batch of size 268...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1625, MSE: 0.0350\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 239 error (scaled): 0.5389\n",
      "Iteration 240/450\n",
      "Updating base models on batch of size 269...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1625, MSE: 0.0350\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 240 error (scaled): 0.4795\n",
      "Iteration 241/450\n",
      "Updating base models on batch of size 270...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1623, MSE: 0.0349\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Iteration 241 error (scaled): 0.4915\n",
      "Iteration 242/450\n",
      "Updating base models on batch of size 271...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1622, MSE: 0.0348\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 242 error (scaled): 0.4654\n",
      "Iteration 243/450\n",
      "Updating base models on batch of size 272...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1619, MSE: 0.0348\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Iteration 243 error (scaled): 0.4839\n",
      "Iteration 244/450\n",
      "Updating base models on batch of size 273...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1617, MSE: 0.0347\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Iteration 244 error (scaled): 0.4875\n",
      "Iteration 245/450\n",
      "Updating base models on batch of size 274...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1615, MSE: 0.0346\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Iteration 245 error (scaled): 0.5736\n",
      "Iteration 246/450\n",
      "Updating base models on batch of size 275...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1616, MSE: 0.0346\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Iteration 246 error (scaled): 0.5600\n",
      "Iteration 247/450\n",
      "Updating base models on batch of size 276...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1617, MSE: 0.0346\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Iteration 247 error (scaled): 0.4701\n",
      "Iteration 248/450\n",
      "Updating base models on batch of size 277...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1614, MSE: 0.0345\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Iteration 248 error (scaled): 0.3487\n",
      "Iteration 249/450\n",
      "Updating base models on batch of size 278...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1609, MSE: 0.0344\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 249 error (scaled): 0.3291\n",
      "Iteration 250/450\n",
      "Updating base models on batch of size 279...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1605, MSE: 0.0343\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Iteration 250 error (scaled): 0.2200\n",
      "Iteration 251/450\n",
      "Updating base models on batch of size 280...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1603, MSE: 0.0342\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 251 error (scaled): 0.1026\n",
      "Iteration 252/450\n",
      "Updating base models on batch of size 281...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1606, MSE: 0.0343\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 252 error (scaled): 0.1538\n",
      "Iteration 253/450\n",
      "Updating base models on batch of size 282...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1607, MSE: 0.0343\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 253 error (scaled): 0.4681\n",
      "Iteration 254/450\n",
      "Updating base models on batch of size 283...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1605, MSE: 0.0342\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 254 error (scaled): 0.5264\n",
      "Iteration 255/450\n",
      "Updating base models on batch of size 284...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1605, MSE: 0.0342\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 255 error (scaled): 0.4073\n",
      "Iteration 256/450\n",
      "Updating base models on batch of size 285...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1601, MSE: 0.0341\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Iteration 256 error (scaled): 0.4214\n",
      "Iteration 257/450\n",
      "Updating base models on batch of size 286...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1597, MSE: 0.0340\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 257 error (scaled): 0.3136\n",
      "Iteration 258/450\n",
      "Updating base models on batch of size 287...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1593, MSE: 0.0338\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 258 error (scaled): 0.3592\n",
      "Iteration 259/450\n",
      "Updating base models on batch of size 288...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1588, MSE: 0.0337\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Iteration 259 error (scaled): 0.3897\n",
      "Iteration 260/450\n",
      "Updating base models on batch of size 289...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1584, MSE: 0.0336\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Iteration 260 error (scaled): 0.3609\n",
      "Iteration 261/450\n",
      "Updating base models on batch of size 290...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1579, MSE: 0.0335\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "Iteration 261 error (scaled): 0.3282\n",
      "Iteration 262/450\n",
      "Updating base models on batch of size 291...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1574, MSE: 0.0334\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Iteration 262 error (scaled): 0.3379\n",
      "Iteration 263/450\n",
      "Updating base models on batch of size 292...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1569, MSE: 0.0333\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 263 error (scaled): 0.3489\n",
      "Iteration 264/450\n",
      "Updating base models on batch of size 293...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1563, MSE: 0.0332\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 264 error (scaled): 0.3355\n",
      "Iteration 265/450\n",
      "Updating base models on batch of size 294...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1559, MSE: 0.0331\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Iteration 265 error (scaled): 0.4522\n",
      "Iteration 266/450\n",
      "Updating base models on batch of size 295...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1556, MSE: 0.0330\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 266 error (scaled): 0.4395\n",
      "Iteration 267/450\n",
      "Updating base models on batch of size 296...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1554, MSE: 0.0329\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 267 error (scaled): 0.4597\n",
      "Iteration 268/450\n",
      "Updating base models on batch of size 297...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1553, MSE: 0.0328\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 268 error (scaled): 0.4542\n",
      "Iteration 269/450\n",
      "Updating base models on batch of size 298...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1550, MSE: 0.0327\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Iteration 269 error (scaled): 0.4953\n",
      "Iteration 270/450\n",
      "Updating base models on batch of size 299...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1550, MSE: 0.0327\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 270 error (scaled): 0.5050\n",
      "Iteration 271/450\n",
      "Updating base models on batch of size 300...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1549, MSE: 0.0327\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 271 error (scaled): 0.4641\n",
      "Iteration 272/450\n",
      "Updating base models on batch of size 301...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1547, MSE: 0.0326\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 272 error (scaled): 0.4205\n",
      "Iteration 273/450\n",
      "Updating base models on batch of size 302...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1545, MSE: 0.0325\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 273 error (scaled): 0.3465\n",
      "Iteration 274/450\n",
      "Updating base models on batch of size 303...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1539, MSE: 0.0324\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 274 error (scaled): 0.3526\n",
      "Iteration 275/450\n",
      "Updating base models on batch of size 304...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1534, MSE: 0.0323\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 275 error (scaled): 0.3281\n",
      "Iteration 276/450\n",
      "Updating base models on batch of size 305...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1530, MSE: 0.0322\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Iteration 276 error (scaled): 0.3411\n",
      "Iteration 277/450\n",
      "Updating base models on batch of size 306...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1525, MSE: 0.0320\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Iteration 277 error (scaled): 0.3401\n",
      "Iteration 278/450\n",
      "Updating base models on batch of size 307...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1521, MSE: 0.0319\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 278 error (scaled): 0.2763\n",
      "Iteration 279/450\n",
      "Updating base models on batch of size 308...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1517, MSE: 0.0319\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 279 error (scaled): 0.3454\n",
      "Iteration 280/450\n",
      "Updating base models on batch of size 309...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1512, MSE: 0.0317\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Iteration 280 error (scaled): 0.3164\n",
      "Iteration 281/450\n",
      "Updating base models on batch of size 310...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1509, MSE: 0.0317\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 281 error (scaled): 0.3162\n",
      "Iteration 282/450\n",
      "Updating base models on batch of size 311...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1505, MSE: 0.0316\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 282 error (scaled): 0.2710\n",
      "Iteration 283/450\n",
      "Updating base models on batch of size 312...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1502, MSE: 0.0315\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 283 error (scaled): 0.1879\n",
      "Iteration 284/450\n",
      "Updating base models on batch of size 313...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1502, MSE: 0.0314\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Iteration 284 error (scaled): 0.1999\n",
      "Iteration 285/450\n",
      "Updating base models on batch of size 314...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1501, MSE: 0.0314\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Iteration 285 error (scaled): 0.2156\n",
      "Iteration 286/450\n",
      "Updating base models on batch of size 315...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1500, MSE: 0.0313\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 286 error (scaled): 0.2487\n",
      "Iteration 287/450\n",
      "Updating base models on batch of size 316...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1498, MSE: 0.0312\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 287 error (scaled): 0.2543\n",
      "Iteration 288/450\n",
      "Updating base models on batch of size 317...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1495, MSE: 0.0312\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 288 error (scaled): 0.2326\n",
      "Iteration 289/450\n",
      "Updating base models on batch of size 318...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1493, MSE: 0.0311\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 289 error (scaled): 0.3239\n",
      "Iteration 290/450\n",
      "Updating base models on batch of size 319...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1489, MSE: 0.0310\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 290 error (scaled): 0.3609\n",
      "Iteration 291/450\n",
      "Updating base models on batch of size 320...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1485, MSE: 0.0309\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Iteration 291 error (scaled): 0.4382\n",
      "Iteration 292/450\n",
      "Updating base models on batch of size 321...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1484, MSE: 0.0308\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 292 error (scaled): 0.3569\n",
      "Iteration 293/450\n",
      "Updating base models on batch of size 322...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1479, MSE: 0.0307\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Iteration 293 error (scaled): 0.4076\n",
      "Iteration 294/450\n",
      "Updating base models on batch of size 323...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1477, MSE: 0.0307\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Iteration 294 error (scaled): 0.4015\n",
      "Iteration 295/450\n",
      "Updating base models on batch of size 324...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1474, MSE: 0.0306\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 295 error (scaled): 0.4030\n",
      "Iteration 296/450\n",
      "Updating base models on batch of size 325...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1471, MSE: 0.0305\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Iteration 296 error (scaled): 0.4147\n",
      "Iteration 297/450\n",
      "Updating base models on batch of size 326...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1469, MSE: 0.0304\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 297 error (scaled): 0.4107\n",
      "Iteration 298/450\n",
      "Updating base models on batch of size 327...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1466, MSE: 0.0303\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 298 error (scaled): 0.4549\n",
      "Iteration 299/450\n",
      "Updating base models on batch of size 328...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1464, MSE: 0.0303\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 299 error (scaled): 0.4240\n",
      "Iteration 300/450\n",
      "Updating base models on batch of size 329...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1461, MSE: 0.0302\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 300 error (scaled): 0.4130\n",
      "Iteration 301/450\n",
      "Updating base models on batch of size 330...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1459, MSE: 0.0301\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Iteration 301 error (scaled): 0.4355\n",
      "Iteration 302/450\n",
      "Updating base models on batch of size 331...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1457, MSE: 0.0300\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 302 error (scaled): 0.4101\n",
      "Iteration 303/450\n",
      "Updating base models on batch of size 332...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1454, MSE: 0.0299\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 303 error (scaled): 0.4313\n",
      "Iteration 304/450\n",
      "Updating base models on batch of size 333...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1451, MSE: 0.0299\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 304 error (scaled): 0.4295\n",
      "Iteration 305/450\n",
      "Updating base models on batch of size 334...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1449, MSE: 0.0298\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Iteration 305 error (scaled): 0.5108\n",
      "Iteration 306/450\n",
      "Updating base models on batch of size 335...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1449, MSE: 0.0298\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 306 error (scaled): 0.6092\n",
      "Iteration 307/450\n",
      "Updating base models on batch of size 336...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1451, MSE: 0.0298\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 307 error (scaled): 0.5160\n",
      "Iteration 308/450\n",
      "Updating base models on batch of size 337...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1450, MSE: 0.0298\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 308 error (scaled): 0.4647\n",
      "Iteration 309/450\n",
      "Updating base models on batch of size 338...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1449, MSE: 0.0297\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 309 error (scaled): 0.2656\n",
      "Iteration 310/450\n",
      "Updating base models on batch of size 339...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1447, MSE: 0.0297\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 310 error (scaled): 0.1960\n",
      "Iteration 311/450\n",
      "Updating base models on batch of size 340...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1447, MSE: 0.0297\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 311 error (scaled): 0.2367\n",
      "Iteration 312/450\n",
      "Updating base models on batch of size 341...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1446, MSE: 0.0296\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 312 error (scaled): 0.2214\n",
      "Iteration 313/450\n",
      "Updating base models on batch of size 342...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1445, MSE: 0.0296\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Iteration 313 error (scaled): 0.2352\n",
      "Iteration 314/450\n",
      "Updating base models on batch of size 343...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1444, MSE: 0.0295\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 314 error (scaled): 0.2199\n",
      "Iteration 315/450\n",
      "Updating base models on batch of size 344...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1443, MSE: 0.0294\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 315 error (scaled): 0.2255\n",
      "Iteration 316/450\n",
      "Updating base models on batch of size 345...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1442, MSE: 0.0294\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Iteration 316 error (scaled): 0.2030\n",
      "Iteration 317/450\n",
      "Updating base models on batch of size 346...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1442, MSE: 0.0294\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Iteration 317 error (scaled): 0.2198\n",
      "Iteration 318/450\n",
      "Updating base models on batch of size 347...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1441, MSE: 0.0293\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 318 error (scaled): 0.2478\n",
      "Iteration 319/450\n",
      "Updating base models on batch of size 348...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1439, MSE: 0.0292\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 319 error (scaled): 0.2509\n",
      "Iteration 320/450\n",
      "Updating base models on batch of size 349...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1438, MSE: 0.0292\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 320 error (scaled): 0.2261\n",
      "Iteration 321/450\n",
      "Updating base models on batch of size 350...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1437, MSE: 0.0291\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 321 error (scaled): 0.2808\n",
      "Iteration 322/450\n",
      "Updating base models on batch of size 351...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1434, MSE: 0.0290\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Iteration 322 error (scaled): 0.2616\n",
      "Iteration 323/450\n",
      "Updating base models on batch of size 352...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1432, MSE: 0.0290\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "Iteration 323 error (scaled): 0.2805\n",
      "Iteration 324/450\n",
      "Updating base models on batch of size 353...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1429, MSE: 0.0289\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 324 error (scaled): 0.2698\n",
      "Iteration 325/450\n",
      "Updating base models on batch of size 354...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1427, MSE: 0.0288\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 325 error (scaled): 0.2748\n",
      "Iteration 326/450\n",
      "Updating base models on batch of size 355...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1425, MSE: 0.0288\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 326 error (scaled): 0.2691\n",
      "Iteration 327/450\n",
      "Updating base models on batch of size 356...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1423, MSE: 0.0287\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 327 error (scaled): 0.2832\n",
      "Iteration 328/450\n",
      "Updating base models on batch of size 357...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1420, MSE: 0.0286\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 328 error (scaled): 0.2725\n",
      "Iteration 329/450\n",
      "Updating base models on batch of size 358...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1418, MSE: 0.0285\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 329 error (scaled): 0.2354\n",
      "Iteration 330/450\n",
      "Updating base models on batch of size 359...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1417, MSE: 0.0285\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 330 error (scaled): 0.2064\n",
      "Iteration 331/450\n",
      "Updating base models on batch of size 360...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1416, MSE: 0.0285\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 331 error (scaled): 0.2242\n",
      "Iteration 332/450\n",
      "Updating base models on batch of size 361...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1415, MSE: 0.0284\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Iteration 332 error (scaled): 0.1245\n",
      "Iteration 333/450\n",
      "Updating base models on batch of size 362...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1417, MSE: 0.0284\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 333 error (scaled): 0.1534\n",
      "Iteration 334/450\n",
      "Updating base models on batch of size 363...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1417, MSE: 0.0284\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 334 error (scaled): 0.1666\n",
      "Iteration 335/450\n",
      "Updating base models on batch of size 364...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1418, MSE: 0.0284\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 335 error (scaled): 0.1750\n",
      "Iteration 336/450\n",
      "Updating base models on batch of size 365...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1417, MSE: 0.0284\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 336 error (scaled): 0.2022\n",
      "Iteration 337/450\n",
      "Updating base models on batch of size 366...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1417, MSE: 0.0283\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 337 error (scaled): 0.1851\n",
      "Iteration 338/450\n",
      "Updating base models on batch of size 367...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1416, MSE: 0.0283\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Iteration 338 error (scaled): 0.1389\n",
      "Iteration 339/450\n",
      "Updating base models on batch of size 368...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1416, MSE: 0.0283\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Iteration 339 error (scaled): 0.1489\n",
      "Iteration 340/450\n",
      "Updating base models on batch of size 369...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1417, MSE: 0.0283\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Iteration 340 error (scaled): 0.1417\n",
      "Iteration 341/450\n",
      "Updating base models on batch of size 370...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1418, MSE: 0.0283\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 341 error (scaled): 0.1169\n",
      "Iteration 342/450\n",
      "Updating base models on batch of size 371...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1419, MSE: 0.0283\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 342 error (scaled): 0.1177\n",
      "Iteration 343/450\n",
      "Updating base models on batch of size 372...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1420, MSE: 0.0283\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 343 error (scaled): 0.1521\n",
      "Iteration 344/450\n",
      "Updating base models on batch of size 373...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1419, MSE: 0.0283\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Iteration 344 error (scaled): 0.2469\n",
      "Iteration 345/450\n",
      "Updating base models on batch of size 374...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1417, MSE: 0.0282\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 345 error (scaled): 0.2999\n",
      "Iteration 346/450\n",
      "Updating base models on batch of size 375...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1415, MSE: 0.0282\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 346 error (scaled): 0.2952\n",
      "Iteration 347/450\n",
      "Updating base models on batch of size 376...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1412, MSE: 0.0281\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Iteration 347 error (scaled): 0.3131\n",
      "Iteration 348/450\n",
      "Updating base models on batch of size 377...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1408, MSE: 0.0280\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 348 error (scaled): 0.4130\n",
      "Iteration 349/450\n",
      "Updating base models on batch of size 378...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1406, MSE: 0.0280\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Iteration 349 error (scaled): 0.5261\n",
      "Iteration 350/450\n",
      "Updating base models on batch of size 379...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1407, MSE: 0.0280\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 350 error (scaled): 0.8126\n",
      "Iteration 351/450\n",
      "Updating base models on batch of size 380...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1415, MSE: 0.0284\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 351 error (scaled): 0.7813\n",
      "Iteration 352/450\n",
      "Updating base models on batch of size 381...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1422, MSE: 0.0287\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 352 error (scaled): 1.0642\n",
      "Iteration 353/450\n",
      "Updating base models on batch of size 382...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1434, MSE: 0.0298\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 353 error (scaled): 1.4644\n",
      "Iteration 354/450\n",
      "Updating base models on batch of size 383...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1458, MSE: 0.0325\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 354 error (scaled): 2.2336\n",
      "Iteration 355/450\n",
      "Updating base models on batch of size 384...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1501, MSE: 0.0404\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 355 error (scaled): 2.0100\n",
      "Iteration 356/450\n",
      "Updating base models on batch of size 385...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1537, MSE: 0.0461\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Iteration 356 error (scaled): 2.2048\n",
      "Iteration 357/450\n",
      "Updating base models on batch of size 386...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1581, MSE: 0.0532\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 357 error (scaled): 2.1600\n",
      "Iteration 358/450\n",
      "Updating base models on batch of size 387...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1622, MSE: 0.0599\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 358 error (scaled): 2.1874\n",
      "Iteration 359/450\n",
      "Updating base models on batch of size 388...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1663, MSE: 0.0666\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Iteration 359 error (scaled): 2.6682\n",
      "Iteration 360/450\n",
      "Updating base models on batch of size 389...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1717, MSE: 0.0775\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 360 error (scaled): 3.4270\n",
      "Iteration 361/450\n",
      "Updating base models on batch of size 390...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1789, MSE: 0.0972\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 361 error (scaled): 3.4014\n",
      "Iteration 362/450\n",
      "Updating base models on batch of size 391...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1865, MSE: 0.1163\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Iteration 362 error (scaled): 3.2887\n",
      "Iteration 363/450\n",
      "Updating base models on batch of size 392...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.1936, MSE: 0.1335\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 363 error (scaled): 3.2218\n",
      "Iteration 364/450\n",
      "Updating base models on batch of size 393...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.2006, MSE: 0.1498\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 364 error (scaled): 3.1766\n",
      "Iteration 365/450\n",
      "Updating base models on batch of size 394...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.2076, MSE: 0.1651\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 365 error (scaled): 3.4247\n",
      "Iteration 366/450\n",
      "Updating base models on batch of size 395...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.2151, MSE: 0.1832\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 366 error (scaled): 3.6775\n",
      "Iteration 367/450\n",
      "Updating base models on batch of size 396...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.2238, MSE: 0.2043\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 367 error (scaled): 4.5559\n",
      "Iteration 368/450\n",
      "Updating base models on batch of size 397...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.2348, MSE: 0.2388\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 368 error (scaled): 5.0670\n",
      "Iteration 369/450\n",
      "Updating base models on batch of size 398...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.2475, MSE: 0.2823\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 369 error (scaled): 6.2209\n",
      "Iteration 370/450\n",
      "Updating base models on batch of size 399...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.2637, MSE: 0.3512\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Iteration 370 error (scaled): 7.6690\n",
      "Iteration 371/450\n",
      "Updating base models on batch of size 400...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.2853, MSE: 0.4605\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Iteration 371 error (scaled): 6.9542\n",
      "Iteration 372/450\n",
      "Updating base models on batch of size 401...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.3055, MSE: 0.5447\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 372 error (scaled): 6.4587\n",
      "Iteration 373/450\n",
      "Updating base models on batch of size 402...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.3242, MSE: 0.6133\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Iteration 373 error (scaled): 6.1019\n",
      "Iteration 374/450\n",
      "Updating base models on batch of size 403...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.3423, MSE: 0.6728\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 374 error (scaled): 6.6992\n",
      "Iteration 375/450\n",
      "Updating base models on batch of size 404...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.3630, MSE: 0.7457\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 375 error (scaled): 7.3092\n",
      "Iteration 376/450\n",
      "Updating base models on batch of size 405...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.3868, MSE: 0.8346\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 376 error (scaled): 7.2976\n",
      "Iteration 377/450\n",
      "Updating base models on batch of size 406...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.4110, MSE: 0.9217\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Iteration 377 error (scaled): 5.9696\n",
      "Iteration 378/450\n",
      "Updating base models on batch of size 407...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.4303, MSE: 0.9756\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 378 error (scaled): 6.4405\n",
      "Iteration 379/450\n",
      "Updating base models on batch of size 408...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.4516, MSE: 1.0412\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Iteration 379 error (scaled): 6.5255\n",
      "Iteration 380/450\n",
      "Updating base models on batch of size 409...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.4731, MSE: 1.1077\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 380 error (scaled): 6.3332\n",
      "Iteration 381/450\n",
      "Updating base models on batch of size 410...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.4941, MSE: 1.1694\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 381 error (scaled): 6.5774\n",
      "Iteration 382/450\n",
      "Updating base models on batch of size 411...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.5160, MSE: 1.2370\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 382 error (scaled): 6.5158\n",
      "Iteration 383/450\n",
      "Updating base models on batch of size 412...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.5374, MSE: 1.3020\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 383 error (scaled): 6.6938\n",
      "Iteration 384/450\n",
      "Updating base models on batch of size 413...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.5595, MSE: 1.3703\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 384 error (scaled): 6.8315\n",
      "Iteration 385/450\n",
      "Updating base models on batch of size 414...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.5817, MSE: 1.4408\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 385 error (scaled): 7.0962\n",
      "Iteration 386/450\n",
      "Updating base models on batch of size 415...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.6053, MSE: 1.5178\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 386 error (scaled): 6.2335\n",
      "Iteration 387/450\n",
      "Updating base models on batch of size 416...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.6253, MSE: 1.5735\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 387 error (scaled): 5.9577\n",
      "Iteration 388/450\n",
      "Updating base models on batch of size 417...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.6441, MSE: 1.6238\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 388 error (scaled): 6.0881\n",
      "Iteration 389/450\n",
      "Updating base models on batch of size 418...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.6634, MSE: 1.6761\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Iteration 389 error (scaled): 5.9742\n",
      "Iteration 390/450\n",
      "Updating base models on batch of size 419...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.6818, MSE: 1.7255\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 390 error (scaled): 5.8626\n",
      "Iteration 391/450\n",
      "Updating base models on batch of size 420...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.6998, MSE: 1.7715\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Iteration 391 error (scaled): 6.0594\n",
      "Iteration 392/450\n",
      "Updating base models on batch of size 421...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.7185, MSE: 1.8216\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Iteration 392 error (scaled): 6.2635\n",
      "Iteration 393/450\n",
      "Updating base models on batch of size 422...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.7378, MSE: 1.8749\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Iteration 393 error (scaled): 6.1702\n",
      "Iteration 394/450\n",
      "Updating base models on batch of size 423...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.7566, MSE: 1.9260\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 394 error (scaled): 5.6861\n",
      "Iteration 395/450\n",
      "Updating base models on batch of size 424...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.7735, MSE: 1.9680\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 395 error (scaled): 5.6351\n",
      "Iteration 396/450\n",
      "Updating base models on batch of size 425...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.7899, MSE: 2.0079\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Iteration 396 error (scaled): 5.7743\n",
      "Iteration 397/450\n",
      "Updating base models on batch of size 426...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.8068, MSE: 2.0508\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 397 error (scaled): 5.4921\n",
      "Iteration 398/450\n",
      "Updating base models on batch of size 427...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.8223, MSE: 2.0868\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Iteration 398 error (scaled): 5.3745\n",
      "Iteration 399/450\n",
      "Updating base models on batch of size 428...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.8374, MSE: 2.1215\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 399 error (scaled): 5.4634\n",
      "Iteration 400/450\n",
      "Updating base models on batch of size 429...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.8526, MSE: 2.1562\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 400 error (scaled): 6.3030\n",
      "Iteration 401/450\n",
      "Updating base models on batch of size 430...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.8707, MSE: 2.2072\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 401 error (scaled): 6.5545\n",
      "Iteration 402/450\n",
      "Updating base models on batch of size 431...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.8895, MSE: 2.2617\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 402 error (scaled): 6.7370\n",
      "Iteration 403/450\n",
      "Updating base models on batch of size 432...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.9089, MSE: 2.3201\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Iteration 403 error (scaled): 6.6160\n",
      "Iteration 404/450\n",
      "Updating base models on batch of size 433...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.9276, MSE: 2.3752\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 404 error (scaled): 6.5367\n",
      "Iteration 405/450\n",
      "Updating base models on batch of size 434...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.9459, MSE: 2.4284\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Iteration 405 error (scaled): 6.5971\n",
      "Iteration 406/450\n",
      "Updating base models on batch of size 435...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.9643, MSE: 2.4830\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 406 error (scaled): 6.1092\n",
      "Iteration 407/450\n",
      "Updating base models on batch of size 436...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.9806, MSE: 2.5260\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 407 error (scaled): 6.4377\n",
      "Iteration 408/450\n",
      "Updating base models on batch of size 437...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.9981, MSE: 2.5763\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Iteration 408 error (scaled): 6.1149\n",
      "Iteration 409/450\n",
      "Updating base models on batch of size 438...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.0141, MSE: 2.6185\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Iteration 409 error (scaled): 6.3347\n",
      "Iteration 410/450\n",
      "Updating base models on batch of size 439...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.0308, MSE: 2.6657\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Iteration 410 error (scaled): 7.1297\n",
      "Iteration 411/450\n",
      "Updating base models on batch of size 440...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.0502, MSE: 2.7286\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 411 error (scaled): 6.9110\n",
      "Iteration 412/450\n",
      "Updating base models on batch of size 441...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.0686, MSE: 2.7863\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Iteration 412 error (scaled): 6.9596\n",
      "Iteration 413/450\n",
      "Updating base models on batch of size 442...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.0870, MSE: 2.8440\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 413 error (scaled): 7.4434\n",
      "Iteration 414/450\n",
      "Updating base models on batch of size 443...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.1069, MSE: 2.9133\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Iteration 414 error (scaled): 9.0494\n",
      "Iteration 415/450\n",
      "Updating base models on batch of size 444...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.1323, MSE: 3.0255\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 415 error (scaled): 9.4544\n",
      "Iteration 416/450\n",
      "Updating base models on batch of size 445...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.1586, MSE: 3.1484\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "Iteration 416 error (scaled): 9.6266\n",
      "Iteration 417/450\n",
      "Updating base models on batch of size 446...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.1853, MSE: 3.2750\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Iteration 417 error (scaled): 9.5541\n",
      "Iteration 418/450\n",
      "Updating base models on batch of size 447...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.2117, MSE: 3.3982\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 418 error (scaled): 8.4988\n",
      "Iteration 419/450\n",
      "Updating base models on batch of size 448...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.2338, MSE: 3.4877\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Iteration 419 error (scaled): 8.9479\n",
      "Iteration 420/450\n",
      "Updating base models on batch of size 449...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.2578, MSE: 3.5913\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 420 error (scaled): 9.1850\n",
      "Iteration 421/450\n",
      "Updating base models on batch of size 450...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.2824, MSE: 3.7002\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 421 error (scaled): 9.2085\n",
      "Iteration 422/450\n",
      "Updating base models on batch of size 451...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.3077, MSE: 3.8071\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 422 error (scaled): 8.9906\n",
      "Iteration 423/450\n",
      "Updating base models on batch of size 452...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.3309, MSE: 3.9065\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Iteration 423 error (scaled): 8.9194\n",
      "Iteration 424/450\n",
      "Updating base models on batch of size 453...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.3537, MSE: 4.0035\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 424 error (scaled): 8.9329\n",
      "Iteration 425/450\n",
      "Updating base models on batch of size 454...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.3761, MSE: 4.0991\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 425 error (scaled): 8.6468\n",
      "Iteration 426/450\n",
      "Updating base models on batch of size 455...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.3979, MSE: 4.1879\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 426 error (scaled): 8.7480\n",
      "Iteration 427/450\n",
      "Updating base models on batch of size 456...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.4192, MSE: 4.2771\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 427 error (scaled): 8.7517\n",
      "Iteration 428/450\n",
      "Updating base models on batch of size 457...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.4410, MSE: 4.3672\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Iteration 428 error (scaled): 8.7894\n",
      "Iteration 429/450\n",
      "Updating base models on batch of size 458...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.4620, MSE: 4.4560\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 429 error (scaled): 8.9775\n",
      "Iteration 430/450\n",
      "Updating base models on batch of size 459...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.4842, MSE: 4.5508\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Iteration 430 error (scaled): 8.6810\n",
      "Iteration 431/450\n",
      "Updating base models on batch of size 460...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.5045, MSE: 4.6351\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 431 error (scaled): 8.1294\n",
      "Iteration 432/450\n",
      "Updating base models on batch of size 461...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.5236, MSE: 4.7068\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Iteration 432 error (scaled): 7.1415\n",
      "Iteration 433/450\n",
      "Updating base models on batch of size 462...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.5386, MSE: 4.7553\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 433 error (scaled): 7.5204\n",
      "Iteration 434/450\n",
      "Updating base models on batch of size 463...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.5554, MSE: 4.8122\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 434 error (scaled): 6.9309\n",
      "Iteration 435/450\n",
      "Updating base models on batch of size 464...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.5696, MSE: 4.8557\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Iteration 435 error (scaled): 6.4712\n",
      "Iteration 436/450\n",
      "Updating base models on batch of size 465...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.5826, MSE: 4.8904\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Iteration 436 error (scaled): 6.3299\n",
      "Iteration 437/450\n",
      "Updating base models on batch of size 466...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.5944, MSE: 4.9206\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Iteration 437 error (scaled): 6.5874\n",
      "Iteration 438/450\n",
      "Updating base models on batch of size 467...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.6071, MSE: 4.9552\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Iteration 438 error (scaled): 6.6280\n",
      "Iteration 439/450\n",
      "Updating base models on batch of size 468...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.6198, MSE: 4.9908\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 439 error (scaled): 6.5017\n",
      "Iteration 440/450\n",
      "Updating base models on batch of size 469...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.6324, MSE: 5.0245\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Iteration 440 error (scaled): 6.6367\n",
      "Iteration 441/450\n",
      "Updating base models on batch of size 470...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.6452, MSE: 5.0600\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 441 error (scaled): 6.5611\n",
      "Iteration 442/450\n",
      "Updating base models on batch of size 471...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.6573, MSE: 5.0937\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Iteration 442 error (scaled): 6.7749\n",
      "Iteration 443/450\n",
      "Updating base models on batch of size 472...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.6705, MSE: 5.1316\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Iteration 443 error (scaled): 7.0564\n",
      "Iteration 444/450\n",
      "Updating base models on batch of size 473...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.6839, MSE: 5.1740\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Iteration 444 error (scaled): 7.6582\n",
      "Iteration 445/450\n",
      "Updating base models on batch of size 474...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.6996, MSE: 5.2291\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Iteration 445 error (scaled): 7.7575\n",
      "Iteration 446/450\n",
      "Updating base models on batch of size 475...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.7148, MSE: 5.2846\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Iteration 446 error (scaled): 7.6564\n",
      "Iteration 447/450\n",
      "Updating base models on batch of size 476...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.7301, MSE: 5.3372\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Iteration 447 error (scaled): 7.4137\n",
      "Iteration 448/450\n",
      "Updating base models on batch of size 477...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.7440, MSE: 5.3849\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Iteration 448 error (scaled): 7.0770\n",
      "Iteration 449/450\n",
      "Updating base models on batch of size 478...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.7573, MSE: 5.4259\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Iteration 449 error (scaled): 7.6420\n",
      "Iteration 450/450\n",
      "Updating base models on batch of size 479...\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 1.7718, MSE: 5.4781\n",
      "Base models updated.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Iteration 450 error (scaled): 7.4923\n",
      "Walk-forward validation finished.\n",
      "Final Performance Metrics (Scaled Data):\n",
      "MAE: 1.6605\n",
      "RMSE: 3.1488\n",
      "MAPE: 108.4762\n",
      "Inverse transformation for 'close' completed.\n",
      "Final ensemble predictions (rescaled to original scale):\n",
      "[0.47398955 0.47405057 0.4742379  0.47398186 0.47398797 0.4737976\n",
      " 0.47365489 0.47073438 0.46744443 0.46430688 0.46321833 0.4617069\n",
      " 0.46020269 0.45922339 0.45813277 0.45859683 0.45769447 0.45731144\n",
      " 0.45724502 0.45664372 0.45635766 0.45499584 0.45458105 0.45416571\n",
      " 0.45348167 0.45268733 0.45252176 0.45264149 0.45227327 0.45242062\n",
      " 0.45248053 0.45264491 0.4524505  0.45244633 0.45257869 0.45238578\n",
      " 0.45190052 0.45197656 0.45235796 0.45243507 0.45241214 0.45294783\n",
      " 0.4532358  0.45405844 0.4544985  0.45435919 0.45471594 0.45542364\n",
      " 0.45570794 0.45582184 0.45582802 0.45547353 0.45527793 0.45574752\n",
      " 0.45535379 0.45528943 0.45566701 0.45610271 0.4565328  0.45753283\n",
      " 0.4586184  0.45959557 0.46070136 0.46188608 0.46196404 0.4624091\n",
      " 0.46264427 0.46323144 0.46280053 0.4632022  0.46383504 0.46364348\n",
      " 0.46375342 0.46317901 0.46327998 0.46361822 0.46412895 0.46419867\n",
      " 0.46422021 0.4643348  0.46416778 0.46412824 0.46401018 0.46338365\n",
      " 0.46341506 0.46408706 0.46399629 0.46403839 0.46395884 0.46333631\n",
      " 0.46278136 0.46246321 0.46212647 0.46194155 0.46200226 0.4618251\n",
      " 0.46131613 0.4608708  0.46112958 0.46074285 0.46059431 0.46019939\n",
      " 0.46102419 0.46055937 0.46123102 0.46150211 0.46072647 0.46062927\n",
      " 0.46001503 0.45924896 0.459141   0.45912739 0.45801793 0.45802804\n",
      " 0.45806217 0.4572077  0.45755792 0.45823881 0.45781511 0.45792628\n",
      " 0.45768226 0.45752235 0.45742053 0.45706474 0.45615308 0.45563557\n",
      " 0.45502852 0.45470116 0.45535664 0.45525739 0.45525307 0.45570396\n",
      " 0.45605539 0.45634345 0.45512711 0.45576566 0.45653437 0.45762118\n",
      " 0.45824024 0.45939646 0.46032699 0.46061537 0.46150659 0.4620379\n",
      " 0.46261021 0.46375104 0.46415978 0.46523461 0.46598942 0.46736673\n",
      " 0.46809147 0.46875306 0.46896097 0.46853542 0.46883906 0.46787127\n",
      " 0.46793985 0.46799336 0.46819196 0.46889124 0.46838143 0.46947214\n",
      " 0.46976186 0.46964012 0.46872436 0.46702437 0.46721819 0.467275\n",
      " 0.46701096 0.46716144 0.46788492 0.46829328 0.46871889 0.46877811\n",
      " 0.46660334 0.46669084 0.4655009  0.46520592 0.46487972 0.46439458\n",
      " 0.46434471 0.46409018 0.46440499 0.46453831 0.46496354 0.46492465\n",
      " 0.46486783 0.46472523 0.46433174 0.4642532  0.46399702 0.46426104\n",
      " 0.46408572 0.46413767 0.46462708 0.46491348 0.46580736 0.46615968\n",
      " 0.46710258 0.4674924  0.46768772 0.46792679 0.46758603 0.46856814\n",
      " 0.46797638 0.46765372 0.4677134  0.4673955  0.46739546 0.46790982\n",
      " 0.46882263 0.46882954 0.4692489  0.46964947 0.47010311 0.4703308\n",
      " 0.47048079 0.47033561 0.47109865 0.47126228 0.47092019 0.4702593\n",
      " 0.47010618 0.47010965 0.4698095  0.46962425 0.46958315 0.46960749\n",
      " 0.46964779 0.46975278 0.46982257 0.47007693 0.4661127  0.46601408\n",
      " 0.46439324 0.46106512 0.45773281 0.45754807 0.45739339 0.45678339\n",
      " 0.45701269 0.45698653 0.45706452 0.45669954 0.45686465 0.45622436\n",
      " 0.45638607 0.45683207 0.45777126 0.45726877 0.45834548 0.46039898\n",
      " 0.46079894 0.45982037 0.45917823 0.45859473 0.4593878  0.4614127\n",
      " 0.46092069 0.46122544 0.46294966 0.46315325 0.46257546 0.46317487\n",
      " 0.46382558 0.4628117  0.46297701 0.46231944 0.46337912 0.46229165\n",
      " 0.46177375 0.46216324 0.46340166 0.46427547 0.46417127 0.46509983\n",
      " 0.46491455 0.46490334 0.46483781 0.46297563 0.46373996 0.46368161\n",
      " 0.46512686 0.46525332 0.46527384 0.46541599 0.46504881 0.4655141\n",
      " 0.46613658 0.46529919 0.4650803  0.46430227 0.46520102 0.46432904\n",
      " 0.4651617  0.46328157 0.46277551 0.46211664 0.46083344 0.46169067\n",
      " 0.46138674 0.46096105 0.46203848 0.4608854  0.46166873 0.45975202\n",
      " 0.45771366 0.45830954 0.45918254 0.46332391 0.4635153  0.46345133\n",
      " 0.46356425 0.46310779 0.46383753 0.46404428 0.46503494 0.46498929\n",
      " 0.46458058 0.46474748 0.46467656 0.46379251 0.46465935 0.46373026\n",
      " 0.46466848 0.46384477 0.4638601  0.46373885 0.46378269 0.46431948\n",
      " 0.46521728 0.46511678 0.46771722 0.46717213 0.4673767  0.46817021\n",
      " 0.46778196 0.46814474 0.46874586 0.46808985 0.46819623 0.46843431\n",
      " 0.46871319 0.46827281 0.46626832 0.46577856 0.46604879 0.46538381\n",
      " 0.46402329 0.46199555 0.4571158  0.45664784 0.45605273 0.45565288\n",
      " 0.45564578 0.45703772 0.45697338 0.45263196 0.45231503 0.45191624\n",
      " 0.455466   0.45361057 0.45465196 0.45230245 0.44962635 0.44681162\n",
      " 0.44371129 0.44218493 0.44090358 0.44041928 0.43899847 0.43377615\n",
      " 0.42724148 0.43047079 0.43299488 0.42783663 0.43446915 0.45270401\n",
      " 0.45058681 0.45217891 0.46273923 0.45989634 0.45327248 0.44945539\n",
      " 0.45382222 0.45376234 0.46460913 0.46606858 0.45869958 0.45701808\n",
      " 0.4570235  0.45833139 0.45960053 0.46240333 0.46827644 0.46451234\n",
      " 0.45848257 0.45798824 0.45641066 0.45556547 0.45024273 0.44820317\n",
      " 0.44963593 0.45256686 0.45515905 0.45169257 0.45573957 0.45097621\n",
      " 0.45470601 0.45294304 0.44628644 0.45040092 0.45040596 0.44768954\n",
      " 0.42927228 0.42509912 0.42418869 0.42749343 0.44033834 0.43819914\n",
      " 0.43769815 0.44171383 0.44441396 0.44747764 0.44699927 0.44976088\n",
      " 0.45064573 0.45052566 0.45380008 0.45062179 0.45658993 0.45302108\n",
      " 0.46027264 0.46315319 0.45367692 0.4397539  0.43486787 0.44496329\n",
      " 0.45637621 0.44708047 0.45898497 0.45562215 0.45826561 0.45754472\n",
      " 0.45146292 0.44796461 0.45187172 0.45504268 0.4617676  0.45625658]\n",
      "Inverse transformation for 'close' completed.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXuNJREFUeJzt3QeYE9XaB/B3e9+ls3RRunREBa+CghQRwYLlqmC/1iuicuW7V71W7L2gFxU7WCgWLKgUkaI0KQKC9F63sz3f8z8nk0yyybIlu5NJ/j+fmEoymcnOvPOe95wT4XA4HEJERERkkUirPpiIiIgIGIwQERGRpRiMEBERkaUYjBAREZGlGIwQERGRpRiMEBERkaUYjBAREZGlGIwQERGRpaLFBkpLS2XPnj2SkpIiERERVi8OERERVQDGVc3OzpamTZtKZGSkvYMRBCItWrSwejGIiIioCnbu3CnNmze3dzCCjIjxZVJTU61eHCIiIqqArKwslUwwjuO2DkaMphkEIgxGiIiI7OV4JRYsYCUiIiJLMRghIiIiSzEYISIiIkvZomakIkpKSqSoqMjqxSAKalFRURIdHc0u8kQUVEIiGMnJyZFdu3ap/sxEVL7ExERp0qSJxMbGWr0oREShEYwgI4JABDvYhg0b8oyPyA8E64WFhXLw4EHZunWrtG3bttxBiIiIaovtgxE0zWAni0AkISHB6sUhCmr4G4mJiZHt27erwCQ+Pt7qRSIiCp0CVmZEiCqG2RAiCjbcKxEREZGlGIwQERGRpRiMhIFrrrlGRo4c6brfv39/GTt2bLXeMxDvEQhvvfWWDBo0SOxmypQpUqdOnYA0T86cOVPdPnTokDRq1EgVdBMR2QmDEQsDBBxIcEEXyzZt2sjDDz8sxcXFNf7Z06dPl0ceeaRCr503b55axoyMjCq/R03Jz8+X+++/Xx588EG/gdfxvkcoadCggYwePdpjfRAR2QGDEQsNGTJE9u7dK5s2bZK7775b/vvf/8rTTz/t87Xo+RAo9erVO+4MirXxHtX12WefqYkTzzjjDEuXI5hce+218uGHH8qRI0esXhQiOp5NP4is/9LqpQgKIReMoJtvXmGxJZfKDroWFxcn6enp0qpVK7nllltk4MCB8sUXX3ic4T/22GPStGlTad++vXp8586dcumll6oUPwKCESNGyLZt2zzGXRk3bpx6vn79+jJ+/Pgyy+XdxFJQUCD/+te/1DTPWCZkadD8gfc9++yz1Wvq1q2rMgtYLl/vcfToUXVWjtdhzJehQ4eqIMu7WeK7776Tjh07SnJysisYM2cvTj31VElKSlKvRZCBLqj+TJ06VYYPHy5VgcCve/fu8v7778sJJ5wgaWlpcvnll0t2drZHsNOlSxfVHRbrEtsnNzfX9fzbb78tJ598slpnGETs9ttvdz333HPPqX+L74L1euutt6rB+coza9Ys6dmzp+pue+KJJ8pDDz3kkSnD+jzrrLPU8506dZI5c+aUeQ8sD34vM2bMqNJ6IaJaUpgr8uHFItOuEjmwXsKd7ccZ8XasqEQ6PfCdJZ/9x8ODJTG26qsUB73Dhw+77v/444/qzN846GBMlcGDB0ufPn3k559/VsN6P/roo+qgvnr1atXc8+yzz6oDPw6UOOjjPg5M55xzjt/PRRCxePFieemll6Rbt25qQCzUH+Ag+vnnn8vFF18sGzduVMvibywXBCk4WCKYwusQ3Jx33nnyxx9/qHEtIC8vT5555hkVAKB76VVXXSX33HOPOpPHQRfB14033igff/yxygT9+uuv5XbZXrhwoVx99dVVXt9//fWXqrf46quvVDCFIO+JJ55QASCCpCuuuEKeeuopufDCC1WQgnVuBHavv/66CvrwegRemZmZ8ssvv7jeG98P67N169ayZcsWFYwgMHzttdd8LgveG9sB/+bMM89Uy3bTTTep59DsUlpaKhdddJE0btxYli5dqj7PX80OAjq83/XXX1/ldUNENcwcgPz+sci5D0s4C7lgxI5wgEPggazBHXfc4XocZ9WTJ092Ddv9wQcfqIMSHjMO0u+8847KIiCrgELOF154QSZMmKAOXDBp0iT1vv78+eef8sknn6iAB2f+gLNyA7IvgMJIfwWXRhCCg3Hfvn3VYwgwEMzgYD9q1ChXMIXlOemkk9R9ZBJQJwNZWVnqAHv++ee7nkcw5Q9qP/B6ZAGqCusSgZvR3ITABtvBCEYQIGE9InMFyHQYEASiae3OO+90Pda7d2/XbXOggMwLXn/zzTf7DUaQBbnvvvtkzJgxrm2AmhwEMAhGfvjhB9mwYYPalsZ3fvzxx1Ug5A3Pr1y5ssrrhYhqwb417tu/TxUZ8KBIZJSEq5ALRhJiolSGwqrPrgyckaO5AgdpHBj//ve/q+YDAw5+5vlDfv/9d9m8eXOZWg0UcuJMGgdnHERPO+0013PInpxyyil+m5BWrVqlJk/r16+fVNX69evV55g/F80aaFrCcwY03xiBBqBp48CBA66gB9kVZH7OPfdcFRghU4HX+HLs2DF1XZ0RRBEkmNeleXmQIRowYIDaBlgmBHqXXHKJaobCa/bs2aOe9wfBw8SJE1UAgUALgQ22E7JDWA/esG0RzCEQMje5Gf8G6xHBnTn4QobMF2Sv8G+IKIjtX+u+nbNfJO+wSHIjCVchF4wgY1CdppLahHoMpPsRcOAggwO6GTIjZqg56NWrl8o6eMNw+FVRm0PoG8015m1lDpKQ5fnnP/8p3377rUybNk3+85//qIzN6aefXua9EOzg36N5xQxNRL7qTJBJQdBlXqe+lgdBIeC1+OxFixbJ999/Ly+//LL8+9//Vk0k6LVSHtTaIMODOiAEFwi00KSEZhM0P/kKRrBtkR0xMlpmlQ24ULxa1d8DEdWS/es87xcXSDgLuQJWO8GBEcWiLVu2LBOI+ILiRjSJoMkE/858QQEmLji7xwHTgDPy5cuX+31PnPnjADx//nyfzxuZGZyl+4PmFHyO+XNR+4I6ExRaVkaPHj1UMxOCgM6dO8tHH33kd7nw3qhJMUM2Zt26daoo12zFihWqfsM7ACkPghMU0SJIQLMHPhP1N8imIKuCJh1fsL6xTlGvg0CqXbt2KpNyvG2L9eW9XXFB/QnWMYqXzQW/S5Ys8flea9euVeuRiIIUTsK8g5GSwPWYtCMGIzZy5ZVXqrNy9KBBgSIKTVErgmyCMdAVahhQVIlaDTQRoHCyvLE1cFBFncJ1112n/o3xnqgjAdRL4KCMJiXM9uqrRwhmf8UyofgUGQA0OaA4tVmzZurxisDnIghBIS0yG8hGIPAqr24EzSf4PO91hOVFMSiCAjRroZgXtTSo8agoBFaoyVi2bJns2LFDjauC728sD5rTEGyg4BTLiWAH2RNAAIGmN9xH8SoKdlErU54HHnhA3nvvPRX4IJhCswx6CyE7BGi2QlCDbYX1i+2PTI03NM/ge9txIDiisJGfIVKQpW/HJutrZkbILpDeX7BggcqkIJ2PAyNS/6grQPME4ICLQkwctFBTgLN49AYpD5qKUA+BwKVDhw4qqDC6sCKgMIor0ZPD3H3VDE0saEJC8wQ+F80vs2fPrnAmAt8NwRN67uCgi54kt912m/zjH//w+2/w3fEZqJUxoMgWB2oEAxdccIHqvouAAV1ty3svb1ifWNfoEYTlQVCA4MMoGMX6RYCDglR0p8X3Nroyo94En/fkk0+q7A6a1VA/Uh4EVgj4EIShEBYZleeff95VPIvsCLIyqJVBb5kbbrjBo77E3D0Yvw/0yCGiIJXr7DUZmyISn6Zvl4R3MBLhqOzgGBZAASCaIHDQMQ66BhyIcVaNFDynQw8/6KmDJg5kVUhUEINMGYqh/eHfDJHFti8WeWeISN0TcBgWObpV5LrvRVq6OwGEivKO32bMjJCtYcRa9EgiPTcNMmYYH4WIgljeIX2d1FAkOk7fDvPMiD26nRCVU/NiHpslnKGeCOOSEFGQy3UGI4kN3LUixSxgJSIiotoORpIaMDPixGCEiIjIkmaaBiJRzmCkOF9fb12gJ9ALM2ymISIiqk25B001I85RttFMM+8JkXkTRSKiRO75UwcrYYKZESIiIqtqRozMSEGWyPwn9W1Hicgh96zn4YDBCBERkWU1I87MyOG/RBx6OgrlyBYJJwxGiIiIrK4ZOeyVCWEwQkRERDUC44xihl6jmcbIjBza7Pk6BiNEepI4zFVTVZidFnO0YMI7O45dgqHeqwNz12AoegOG0+d4KESkxhUpLda341LcmZHMHfo6rUX5wUjW3pCsJ2EwYjFMDIfp6ocNG2bJQbOmYGI4DDfet29fdX/btm0qwFm1alWZ1/bv31/Gjh0roeyee+6Rd999V02cR0RhzAhEIDLaPc6I4cR++vrIVp1FMcP95zqIvHKKu+4kRDAYsdhbb72lzpgxKdvxppm3C0x39Morr6iJ7Mg9Oiomw8OkhEQUxkqL3LejYsoGI60RjESIFGTq7Ig5IDGad+DQnxJKQi8YwYYrzLXmUsk5B3NycmTatGlyyy23qMzIlClTyrzmyy+/VLO4YkIzHNCMGXiRTdi+fbvcddddKuOAi6/mAUD2BFkUw2+//Sbnnnuuej9MYNSvXz9ZsWJFuU0umK23SZMmajkwk2x5s9BiCvu//vqrStkewHeZPHmy+q6Yzbdt27byxRdfuJ4/evSoXHnlldKwYUNJSEhQz2PWYMOuXbvU/Cz16tWTpKQkOeWUU2Tp0qXqOSzXiBEj1AzEmNMG6/aHH8ofYCgjI0PNkovPw0RP55xzjvz+++8er3niiSfUe2KWZGMmZW/Dhw+XqVOnVmmdEFGIKPHKjBjNNIYG7UTaDNC3X+4pMulMkZIid48bQ36WhJLQG/SsKE/k8abWfPb/7RGJTarwyz/55BPp0KGDtG/fXq666irVVIHZZ43A4uuvv1YH5H//+9/y3nvvqaBg9uzZ6rnp06erqepvuukmufHGGyu1mNnZ2TJmzBh5+eWXVRbj2WeflfPOO082bdqkDqbeXnrpJRUMYHkxPf3OnTvVxZ+ff/5Z2rVr5/O9Kuqhhx6Sp556Sk2Eh+VE8IHgCwHG/fffL3/88Yd88803KqDavHmzHDt2zBXgIbhq1qyZWub09HQVaJWWlrqex3d97LHHJC4uTq1XBAkbN25U383fzMAIevB5CN7eeOMNGTBggPz5559qebBeEAS++uqr8re//U3ef/99tc5OPPFEj/c59dRTVaCEJitzcEhEYdhMg4HNsK83ClgNqc1EzrhTZLPzJGn/Gp0hadhe5IgpGMnZL6Ek9IIRmzXRIAiBIUOGqCmW58+fr7IegAPm5Zdfrg7MBgQggIMgak1wwMcBtzJwZm/25ptvSp06ddRnn3/++WVev2PHDpV9wIEWgRIyI+VB0NC0afUCwmuuucY1++zjjz+uDu6//vqrWk9Ynh49eqiMB5gP7B999JEcPHhQZX+wjgCFtOb1Z6xDeOSRR2TGjBkqcEH2x9vChQvV5x44cEAFL/DMM8+o4t7PPvtMBYPIPCEbYjRLPfrooyrb4p0dMdYJ1g+DEaIwb6ZBE4269sqMJNQROeFMkd43ivz2P/1Y9j4djJgzIzkHJJSEXjASk6gzFFZ9dgXhTBwHORwIITo6Wi677DIVoBjBCIo9K5v1qIj9+/fLf/7zH5k3b546yJaUlEheXp46yPsLDNCsgwwOggEELIMGDfL7/shSoDmnOrp27eq6jaYWNI9gWQHNWhdffLHKeGA5Ro4c6SqUxTpDoGIEIt6QGUEWA1mnvXv3SnFxsVpef98dzTH4N/Xr1y/zHdHkA+vXr5ebb77Z4/k+ffrI3LlzPR5DdgWwrokozDMjaKIBc81IdII7SBn2jK4L2TpfByPAzIiNIO1ViaYSqyDowIHQnEFAkwnOvlH8ieYA4+BVGZGRkep9zIqKTAVTIqqJ5vDhw/Liiy+qLAc+EwdPNAP50rNnT9m6datqpsAZ/6WXXioDBw5UmQFf0HSyZs0aj8cQTACyP75qMvB9zWJinH+QTsjIGE0tQ4cOVdkFNFnNmTNHNZncdtttKmNxvHWGXi34N3gtMiZ4/SWXXOL3uyMQQa0MAjdvyCZVxpEjR9Q1ak+IKMxrRoxgJMrUTBOv95MuKU30dfZefX04dIOR0CtgtQEEIahVQK0GzuSNC87CEZx8/PHHruzAjz/+6Pd9YmNjVVbDDAe6ffv2eQQk3t1pf/nlF/nnP/+paidOPvlkFYwcOlR+NzEEE8jc/O9//1NFt59//rnr4OoNmYkNGzZ4LAMyFQhSUNxqlpWVpWo+UGNSGfieCKo++OAD1UyCpiZjneH7+ls2fHdkelCL06VLF9XEhRoOfxCIYX0ic4XgxXzB94GOHTu6CmQNS5YsKfNea9euVUEW1jkRhSnvZhpzZiTOOxhp7A48DmwQObgxZJtpGIxY4KuvvlI9QlBj0LlzZ48Lmh+QNYEHH3xQBSa4RlMAsg1PPumcSMlZK4Euwbt373YFE2jiQc0Eij/RjICiSmQ0zFD/gSJLvCcOoigOLS+j8Nxzz6nlQICBos1PP/1UHcT9ZQbOPvtslVFYt26dx+Pjxo1T9R8ffvihWjY0Uxm9Yi666KIKr78HHnhAZs2apYIYfAbWJwICQJ0Jlg1NNwg8MK4HAieM52J8dxT/GsHf3//+d1fGxRdkgJA1wvt9//33KnDBQG4oKl62bJl6zZ133ilvv/226tGD9YPt5f3djcLeM888s0oZLyIK0WaaimRGlrwm8tppIiUF7tczM0LVhWADBznvpglAMIKD3OrVq1VggQM/iivRXReFpziAGx5++GF1cDzppJNcqX8clF977TUVhKBQE69H04T35yMYwln/1VdfrbIkjRo18ru8KJJFcIOCUXSFxWeiiQRNQr6gvgKZBwQdZuPHj1cHagRUyGDgu6IeBLUVlTlAIyOEXkd4j7POOksV8hpdZvEcggZ8H2R+kP1At1u8xgis6tatq2pM0IsGY39gPfiD5iF8V3zOtddeqzI4KCpGMxG68gIyRujhg+/Xq1cv9RzqWrxhGWuiBoiI7NhMU5HMSLrn/fptRcZ8GZKZkQiHd4FBEEIqHwdu1BsYtQcG9FhAPQNG+6xu0SQFDoIpFL0iA4LxPMIdslN33323Wi9o8rES/2aILLRjicjbg0Xqtha5c5XIph9EPrxYP9dphMil77lfu32xyDtD3MPE37laD18xsZl+bMJukbhk2x6/q5wZweiROBvFG+KC9LV3E4A3nNljLA3s9HCWaoyTQaENvxNkQHDQI5Hc3FzVjGN1IEJEQdJM46oZMTXTlJcZQaCCbDSCD6PnZu5BCRWVCkaaN2+uUt4oQkRTApoNMJqlr/ZxQNs62vBRG7Fy5UrV7o4LCvko9KFQFAEoieqxc9ppp1m9GERkNWM01Ugf44zEp/kPRpr1LBu0FGRLWAYjaGNHOzyKANF2jkG5kIL31XMA0HUU41Lce++9qpYBA0yhfR5dV4mIiMK3gDXq+JmRmASRkwboIeLbDTG9LiW8gxEzdClFQR7Sz2iu8QU9GFCoaYaCQaNnAxERUVg303hkRlLLvv7q6SK3/eo5flYIBiOVbsBG91IEHyiCQ1YEI4h26tTJ52sxPoPR48CA+3i8PAUFBepiLoA5HhvU4RIFBf6tEAVDM42PEVjj/BR4OucrC+VgpNKZEQwJjjEaMD4Fui9i4ClMWhZImBEW1bfGpUWLFn5fa3TZ9DeCJhF5Moaj9x7llohqs5nGV9felIq9hysYyQrfzAjGcTAmHsOYCpiQDLUhmMnUGwafwjwoZrh/vIndMIYEBsgyZ0b8BSTonYBp5jHQF3au/sa+IAp3yIggEMEcPxiwzgjkiciKZhpj0LOqBCOhV8Ba7X6GGL3S3KRihuYcDGc+duxY12OYF8RfjYkBw5MbM6QeDwalwtwh6EKKwaaIqHwIRCo70zMR1VQzjamAtaKTrYZgM02lghFkLDBJWcuWLSU7O1tN144JxL777jv1/OjRo6VZs2aqmcUYJrtfv35qDpZhw4apgld0CTbmEQkUZGvQw4dNNUTlQ/aQGRGiIGqmMWdGoit2Eh72wQjSuwg4MPU6ajkwsBUCEYy0CZiG3dxMgiG3EbBguvr/+7//UwHDzJkz1RwsgYbP5WiSRERkj4nyfMxNk1LBjKUx6mq4BiPGBG7++JpmfdSoUepCREQU9lxz0zgPvziBv3qGSGFeJYIRFrASERFRoJpp4KRzKvceIVjAyq4nREREtd1MY2RGqiLOmRkpzJFQwWCEiIiotptpjJqRqogLvQJWBiNERERWNtNUFoMRIiIiCopmmgIGI0RERFTdifKqIi7VXTNSWiKhgMEIERGRVV17qyLONGx8iBSxMhghIiKyUzNNdJx7sLT80BhrhMEIERGRnZppICZBXUlxvoQCBiNERES1PlFeNeeIinLOY8NghIiIiGq9ay9EO+diKw6NCWIZjBAREdmtmSbaWTNSUiChgMEIERFRrTfTVHNquCg20xAREVG1mmmqGYxEG8EIm2mIiIjIkmaaOH3NZhoiIiKypJkm2siMMBghIiKiKg16FhOgmpECCQUMRoiIiGqLMZdMdccZiXb2pmEBKxEREVWpmSYqQOOMlLCAlYiIiKwY9CyKzTRERERk1UR51Slg3bVcZM1nEmyquTaIiIiowkqMrr3Rtd+1t7hAZPI5+nZac5GWp0uwYGaEiIjIboOeRRkFrJWoGfnzO/ftLfMlmDAYISIislvX3uj4yvem+X2q+/b2hfoaTTazx7t7+ViEzTRERGRv+ZkiMUnVb/qwVTNNbOWbaXYvc9/esVSkKF/k8+v1/SZdRXpcJVZhZoSIiOwre5/IEy1F3hoo4dVME1f5AtaCbPdtBDH717rv714uVmIwQkRE9rXxG329Z6WEVzNNXOWCETTDFOXp2/Xb6uuj29zPZ+wUKzEYISIi+6ru4GGWNdMEKBjJ3ClyaNPxX28EItC4k74+/Jf7MbyPhRiMEBGRfZkzDA6H2KeZJiowBax7Voq8copI1t7yX1+Yq68jIkUatNO3D6xzP5+xw9L1x2CEiIjsy3xQN4ZaD4uJ8mI975sDC18KcvR1bLJInVb69v4/PDMnWbvFKgxGiIjIvswHZXNTRKgXsEY7m2kMxwtuCs3BSEt9+7BX886B9WIVG/SDIiIiqgAEIwl1JGiVloo4SgNbM2I43oR5RjNNbJJIXWdmxOzmX0QaOAtbLcBghIiI7Mto9oCiYxLUzAFDoLr2emc+jpsZSRJJbaZrR4zAqHEXkfTOYiU20xARkX0ZvVPs0ExjHucDzSWBzIwUVDQYSdZZmZSmpmVJEqsxGCEiIvuyU2akIMsUEAS4ZqQwp2LNNHHOICi5kfs54zELMRghIiL7MvegMQ64wTxsPcSlVv+9oiqbGTHVjEBSQ/dzzIwQEREFoHeKnTIj8WnVf6/oSmZGXF17nYFHsjkYSRGrMRghIiL7MheFBnvNiJEZiQ9AZiS6qgWszsAjic00REREgW+mMYIRdKH9cqzIopeDa1TW/KwANtPEhlQzDbv2EhFRaBWwYjba5e/o24V5Iv3/JcHVTBOIzEh81QpYXc00jQLXsycAmBkhIqLQ6tprHPTBCEqCKTNiRc1IYbZXZqSB+zkGI0RERAHOjJh71QRTUWtBAJtpIqOq1kwTF5w1I2ymISKi0Oraa84SmHvbWGX2vXq0UyMwCkQzjbfCatSMeGdZLMDMCBERhVbXXnNmpLw5W1Dc+tU4kcWv1uyoq7++KfLbZJEDfwSumQYGPCDSsEPFxljx7tqbWM/9XHGBWI3BCBERhUhvGj/BiL8eNVvniyx7S+S7/6u55SvKd98+5JwlNy5AwciZd4tc+n7ZoeYr0rXX3Mzj3TPHAmymISKi0BpnxLvJorTE9/DrGTtreOG8xj4xliuQzTRxye73RtAVEeH7dccynJ9tCoSGPCGybaFIxwvEagxGiIgoRJpp8nw3WSBg8RWM5GeYXlNc/flifCk2ZUYMgWqmMTe7YD2guSXGq8uv0b25wDngWkpj9+On36IvQYDNNEREFLrNNOXVjRw76r5dXEO9bnz15glEbxpf3XL91Y3k7NPXMYmB/WyrgpGJEydK7969JSUlRRo1aiQjR46UjRs3lvtvpkyZIhERER6X+HgfkRsREVG1uvb6yYz461GTd6Tmizh9BSOBbKaJjNJBhnksEW/Z+/V1cmP/zTh2Ckbmz58vt912myxZskTmzJkjRUVFMmjQIMnNLb+KNzU1Vfbu3eu6bN++vbrLTURE5CczklOxzEjO/rL/NtC8My4RkSIJdQP7GXEp5RexZu/V1ylNJFhVqoHs22+/LZP1QIZk+fLlctZZZ/n9d8iGpKenV30piYiIfDFnPVzjjFSwmcY4SNdoZsSrZgTFooGeCyYuVQdWxgiv/oIuc71IkKlWzUhmpi6IqVfP1F/Zh5ycHGnVqpW0aNFCRowYIevWrSv39QUFBZKVleVxISIiqtigZ97BiJ9mmmxnLUWN1ox4zSTc947Af0Z8atlh8G2WGalyMFJaWipjx46VM844Qzp37uz3de3bt5e3335bZs2aJR988IH6d3379pVdu3aVW5uSlpbmuiCIISIiKrdmxDgYV6SZBgGKRzONj14vge5Nc8ErIs1PCfxnxDmDEX+ZEXPNSKgFI6gdWbt2rUydOrXc1/Xp00dGjx4t3bt3l379+sn06dOlYcOG8sYbb/j9NxMmTFBZF+Oyc2ct9AUnIiL7MWc9EHSguaVMAaspYDHkHtBDtJfXBTcQjFoUNM/0vLpmPiPe/pmRKnWqvv322+Wrr76SBQsWSPPmzSv1b2NiYqRHjx6yefNmv6+Ji4tTFyIionJ5Zz1QxFmmmcZHMLJvjef9mg5GYhKkxsQZmRHnWCKhXjPicDhUIDJjxgz56aefpHXr1pX+wJKSElmzZo00aRK8ERoREdmEd9YDB2QjGImI8t9Ms2NJ7QQjxvvWZDASn+Y/M4JRWTOdZREpTSUkMiNomvnoo49U/QfGGtm3Txf/oK4jIUGvaDTJNGvWTNV9wMMPPyynn366tGnTRjIyMuTpp59WXXtvuOGGmvg+REQUTryLU83BCLrQ5h3ynRnZudTzfnVqRtZ8pme+7Tjcf2YkujYyI1lln8s9qGto0KW4bisJiWDk9ddfV9f9+/f3ePydd96Ra665Rt3esWOHREa6Ey5Hjx6VG2+8UQUudevWlV69esmiRYukU6dOgfkGREQUvrwzIzj4inNivIQ6voOR4kKR3cv17bqtRY5urXpmBMWhn1+vb4/f6jkbrkczTQ0O9hlfTs3I4b/0dVpzHTCFQjCCZprjmTdvnsf9559/Xl2IiIgCzjvQyNrjvBHhzhh4N9McWKeDD2RO0jtXLxg5uMF9e8dikQ7DPJ83ugwbo6TWdmbkyBZ9Xe9ECWacm4aIiOw/6JlRN2GMHYKBxaLjfWdPjOLV9K7uIKGqI7AeNE2JghlwvRnNP8ay1HZm5IgzM1LvJAlmnLWXiIjsnxlJrK/rRYxurAhGjFl4jdcgu//Df0WWTtL307u4h1Cv6gisB9d7BiN/fqfni2kz0HPQs1rpTZPlXKY/ddfl1dNEVrxni8wIgxEiIrKvUlMwgiYJj2Ak1rOZBhmRX15w/9vGnUX2rKzeCKzmzMi+1SIfXapv/+egSHRsLfWmSXVnRhBUvdmv7Miv9YM7M8JmGiIisi8j65HgLBz1GYwUlR3+3ciMGIWlVc6MOGtGvCe/M8b8cPWmia+dzMiGr8oGIpHR+rsGMQYjREQUAs009bxqRpL1QVi9plBk/Zf6QG3WoJ07SKhKzUjeEZG8w/r20Kc8nzPqN2pj0LN4Z71MYba7WcbQ9XKRG+fq3jRBjM00REQUGs00rq69XpmRzT+I/Ok567wMekw3o0RXIzOSsV1fJ6eLnHyRyNrpIn9+4xmM1EYzTZwzMwJbPHu0SpdRIk26SrBjZoSIiOwJBalGbxrvZhIVjMTo296BSP8JIn1v17ddwUgVMiMZO/R1nRa6WPbvU0UadnA305SW1s6gZ9GmoEqJ0JPynXWvyEnniB0wM0JERPZkBCLgPdiYaqZxDgfvzTxhXHVqRjKck7jWaVk2S/HeCJGmPU29aWqwZgSSGolkOoOjlPSam5SvhjAzQkRE9h/wzGimMZibacoLRqpTM2JkRtJalO3ZAntWuAtqa3LQM2jQRlyCvD7EFwYjRERkT+bBzIzeNOZgJNLZTOMt1UcwUpURWF3NND4yI95qsjcN1G8rLubgyCbYTENERPafJC+5UdlgpLSk4pmRqgQjmb6aaVJ8v7YmC1ihgTkYYWaEiIiodhiDmWFG2qSGZWtG/DXTmLMoRi1HUYAyI+ZmmtoMRuqbmmnMy2MTDEaIiMjezTRojlFjbUT47k0DrfuJpDQVaTdUxDSzfLmZERSoYlZeXzDAmNF915yJiHOO+eEdGOFSkxq0c99Obix2w2YaIiKydwErgg70nEH33mNHfAcjqU1FrppetoeNv2DkWIbI63317fFbPN8LjDltEAjhs8rLjKCGI8IUKNWE1Ka+b9sEgxEiIrJ3115jpFV073UFIymezTSo5TAmzvPVfOIdjOxf5858bPu57Hgdxuu9C1N9FbDWRrNJRITIpe+JHP5LpFkvsRsGI0REZP/MiNG99/Bm371p/BWWGlkNNLtgkDKjCefoNvdr/vjCfzDiPX6Ir8+prRqOTiPErlgzQkRE9q8Z8R5rxLuZxl8wgp41KIDFe+UecD+OGYANG51DvJsZBa/eI6v6aqaxYUFpbWMwQkRE9u7aazS/mHvJePem8ReMIGAxuvpm7nI/fuQv9+2cfZ4DrJmHjy+TGWEwUhUMRoiIyJ5KnEO4R8Xp68S65WRG/HS5NQ8SNnmAyHsjy2ZGzAWrZTIjXsEIMyNVwmCEiIjsPc5ItDMYMXefrWgzjTHRnWHLXN2d97BXMJKf4Tsz4h2MxJh61th4RNTaxgJWIiKyp2JnMGIEHUZQ4mtumvKCEe8RSzd9J1KITEiE7qGTd1jPwuvx2QW+m2kwEmyH8/UyJafrepRkrwHZqAwGI0REZO/MiBF0GM01gPFEzL1pyht0zDtzseYz5+PN9b9TwYizm6/BmFjPu4AVXWwv/7DSXyXcMRghIqLQCEa8h1yvcDONV03H1vn6ut6J7i68ZTIjfrr2UpWwZoSIiEIjGOl8sUhqc5Gul3sOhna8AtaUdN+PIxhRw8yjgLWCmRGqEmZGiIgoNApY0ZNl7Br3wGXG88fLjDTuLHLmPSKpTUS++4+7OLX+Se5eNMyM1ChmRoiIKDQKWME8CZ55iHdzcas31HkMuF+k9w0iLU71nRnxDkZcmREGI4HAYISIiGzeTOMn0DA/XtGJ6k74m1cw4mze8S5gNXrTMBgJCDbTEBFRaNSMeGszQKTLKJGmPSr+nubX1m3tPzPiGoGVNSOBwGCEiIhsHoyYmmnM0L334smVe88T+4ucfKHu1ot6EKPwtUwBq58RWKlKGIwQEVFoFLAGAgKbUVPc943MSO5BkbeHiCQ1ELnsA2ZGAozBCBERhWZmJBCMYGTnUs/iVWZGAooFrEREZPPeNAHMjPgLRsxy9rt76jAYCQgGI0REFJoFrDUVjGAiPY4zElAMRoiIyOY1IzUYjGDiO/NIrkZmhCOwBhSDESIisqfayIwk1BU5537/zTTMjAQEgxEiIrKn2ghG4G9jRS59X6RhB32fmZGAYzBCREQ2L2Ct4WAEOl2gJ+IDZkYCjsEIERHZU21lRsz1I5BzgL1pAozBCBER2VNtFLCaJafr6+x9HGckwBiMEBGRPVmVGUEwUuKcKI8jsAYEgxEiIgrNWXsDLcWZGcnZ536MmZGAYDBCREQ2L2CtweHgzVKaiCQ5syMGBiMBwWCEiIjsqSYmyitPRIRIq77u++jqG8Up3gKBwQgREdmTUbdRWzUj0OoM922jqy9VG4MRIiKyp5Ki2m2mgVZ93LcZjAQM80tERGRPtV3ACo07i/T9p0hcikj9k2rvc0McgxEiIrKn2i5gNepGBj1Se58XJirVTDNx4kTp3bu3pKSkSKNGjWTkyJGycePG4/67Tz/9VDp06CDx8fHSpUsXmT17dnWWmYiIqPYLWCk4gpH58+fLbbfdJkuWLJE5c+ZIUVGRDBo0SHJzc/3+m0WLFskVV1wh119/vaxcuVIFMLisXbs2EMtPREThyOGwpoCVakSEw4EtWjUHDx5UGRIEKWeddZbP11x22WUqWPnqq69cj51++unSvXt3mTRpUoU+JysrS9LS0iQzM1NSU1OrurhERBRKxauPNNC3/7VdJKGO1UtE1Th+V6s3Dd4c6tWr5/c1ixcvloEDB3o8NnjwYPU4ERFRtZpogJmR8C1gLS0tlbFjx8oZZ5whnTt39vu6ffv2SePGjT0ew3087k9BQYG6mCMrIiIil2L3MYI1I/ZX5cwIakdQ9zF16tTALpGzUBZpHePSokWLgH8GERGFwBgjEZEikVFWLw1ZEYzcfvvtqgZk7ty50rx583Jfm56eLvv37/d4DPfxuD8TJkxQTUDGZefOnVVZTCIiClUsXg3fYAS1rghEZsyYIT/99JO0bt36uP+mT58+8uOPP3o8hp44eNyfuLg4VehivhAREZUdfZVNNGFXM4KmmY8++khmzZqlxhox6j7QlJKQkKBujx49Wpo1a6aaWuDOO++Ufv36ybPPPivDhg1TzTrLli2TN998sya+DxERhdXoq7U44BkFR2bk9ddfV80m/fv3lyZNmrgu06ZNc71mx44dsnfvXtf9vn37qgAGwUe3bt3ks88+k5kzZ5Zb9EpERFShAlYWr4ZfZqQiQ5LMmzevzGOjRo1SFyIiooAGI6wZCQmctZeIiOynwDnkQzxrCkMBgxEiIrJvMBLHYCQUMBghIiL7yWcwEkoYjBARkf2wmSakMBghIiL7KcjW13EpVi8JBQCDESIish8204QUBiNERGTjAlZmRkIBgxEiIrJvMw1rRkICgxEiIrKf/Ex9zWaakMBghIiI7IfjjIQUBiNERGQ/bKYJKQxGiIjIxr1pWMAaChiMEBGRjccZYWYkFDAYISIi+83YW+KctZeZkZDAYISIiOzZRAMMRkICgxEiIrJnT5rYFJHIKKuXhgKAwQgREdkLR18NOQxGiIjIXgrz9HVsktVLQgHCYISIiOylOF9fR8dbvSQUIAxGiIjInsFIDIORUMFghIiI7IWZkZDDYISIiOyliMFIqGEwQkRENs2MxFm9JBQgDEaIiMimNSMJVi8JBQiDESIishdmRkIOgxEiIrJpzQgzI6GCwQgREdkLMyMhh8EIERHZC2tGQg6DESIishdmRkIOgxEiIrIXjjMSchiMEBGRvXAE1pDDYISIiOyFwUjIYTBCRET2wgLWkMNghIiI7KW4QF+zgDVkMBghIiJ7KTqmrznoWchgMEJERPbCzEjIYTBCRET2UuzMjLBmJGQwGCEiInthZiTkMBghIiJ74UR5IYfBCBER2QuHgw85DEaIiMg+SktFSpzNNKwZCRkMRoiIyD6MQASYGQkZDEaIiMh+Y4wAa0ZCBoMRIiKyX0+aiCiRqGirl4YChMEIERHZB8cYCUkMRoiIyD44xkhIYjBCRET2wXlpQhKDESIiso/8DH0dl2L1kpCVwciCBQtk+PDh0rRpU4mIiJCZM2eW+/p58+ap13lf9u3bV53lJiKicJSxU1+nNbd6ScjKYCQ3N1e6desmr776aqX+3caNG2Xv3r2uS6NGjSr70UREFO4yd+nrOi2sXhIKoEr3ixo6dKi6VBaCjzp16lT63xEREblkGpkRBiOhpNZqRrp37y5NmjSRc889V3755ZdyX1tQUCBZWVkeFyIiInczDYORUFLjwQgCkEmTJsnnn3+uLi1atJD+/fvLihUr/P6biRMnSlpamuuCf0NEROTKjLCZJqREOBwOR5X/cUSEzJgxQ0aOHFmpf9evXz9p2bKlvP/++34zI7gYkBlBQJKZmSmpqalVXVwiIrKz0hKRRxuJlBaL3LWORaw2gOM3kgrHO35bMpbuqaeeKgsXLvT7fFxcnLoQEVEYD242+x6R5HSRPreKJNQVydmvA5HIaJGUJlYvIQWQJcHIqlWrVPMNERGRT7t+E1nxnr69e7nI1dPd9SKpTUUioyxdPLI4GMnJyZHNmze77m/dulUFF/Xq1VNNLxMmTJDdu3fLe+/pH9ELL7wgrVu3lpNPPlny8/Nl8uTJ8tNPP8n3338f2G9CREShoyDHfXvLXJH8TPakCWGVDkaWLVsmZ599tuv+uHHj1PWYMWNkypQpagyRHTt2uJ4vLCyUu+++WwUoiYmJ0rVrV/nhhx883oOIiMjnhHjgKBXZ+SuDkRBW6WAEPWHKq3lFQGI2fvx4dSEiIqr0HDSG7b+I5DuHeWBPmpBjSc0IERFRuYryPO9vmSeS5By5m71oQg6DESIiCt7MSOt+ItsXiexZ6X6OzTQhh7P2EhFR8CnK19d1TxDpMsrzOQYjIYfBCBERBW8zTUyiSN87PJ9jM03IYTBCRETB20wTkyDSuJNIs17u52ITLVssqhkMRoiIKLgzIzBqiki9E0VOu8XSxaKawQJWIiIKPsXOmpGYeH1dp6XIP01FrBRSmBkhIqIgzowkWL0kVAsYjBARURDXjLA+JBwwGCEiouANRqKdzTQU0hiMEBFR8GFmJKwwGCEiouDu2kshj8EIEREFf9deCmkMRoiIKIgzI6wZCQcMRoiIKIjHGWFmJBwwGCEiouDDcUbCCoMRIiIKLiVFIqXF+jaDkbDAYISIiIIzKwLRDEbCAYMRIiIKLkXOehGJEImOs3hhqDYwGCEiouDt1hsRYfXSUC1gMEJERMGFA56FHQYjREQUXBiMhB0GI0REFJzNNJwkL2wwGCEiouBSkK2v41OtXhKqJQxGiIgouBRk6es4BiPhgsEIEREFl/xMfR2fZvWSUC1hMEJERMEl35kZYTNN2GAwQkREwSU/Q18zMxI2GIwQEVGQ1owwGAkXDEaIiCi4sJkm7DAYISKi4MIC1rDDYISIiIILu/aGHQYjREQUXJgZCTsMRoiIKLiwZiTsMBghIqLgbKZhZiRsMBghIqLgUVwgUpyvb7NmJGwwGCEiIuuUFIv8/KzIjqWeTTQQl2LZYlHtiq7lzyMiInJbN0Pkx4f17e5XiqS1cGdFIqMsXTSqPQxGiIjIOlm73LdXfei+zSaasMJmGiIisk5iA9+PpzSu7SUhCzEYISIi6zhKyz7WaaTIyNetWBqyCJtpiIjIOkXHPO9f+IZIt8utWhqyCDMjRERknaI8z/v1TrJqSchCDEaIiMg6xpgihvoMRsIRgxEiIgqezEhiPauWhCzEYISIiIKjZqRZLyuXhCzEYISIiKxT5Gym6X6VyOgvrF4askswsmDBAhk+fLg0bdpUIiIiZObMmcf9N/PmzZOePXtKXFyctGnTRqZMmVLV5SUiolBspknvIhKXbPXSkF2CkdzcXOnWrZu8+uqrFXr91q1bZdiwYXL22WfLqlWrZOzYsXLDDTfId999V5XlJSKiUCxgjYm3eknITuOMDB06VF0qatKkSdK6dWt59tln1f2OHTvKwoUL5fnnn5fBgwdX9uOJiCgUMyMxiVYvCYVyzcjixYtl4MCBHo8hCMHjREQU5owC1mhmRsJZjY/Aum/fPmnc2HOOAdzPysqSY8eOSUJCQpl/U1BQoC4GvJaIiEI4GGFmJKwFZW+aiRMnSlpamuvSooVzSmkiIgrRYKTsiSmFjxoPRtLT02X//v0ej+F+amqqz6wITJgwQTIzM12XnTt31vRiEhGRFVjASrXRTNOnTx+ZPXu2x2Nz5sxRj/uDLsC4EBFRiGMBK1UlM5KTk6O66OJidN3F7R07driyGqNHj3a9/uabb5YtW7bI+PHjZcOGDfLaa6/JJ598InfddVcgvwcREdkRC1ipKsHIsmXLpEePHuoC48aNU7cfeOABdX/v3r2uwATQrffrr79W2RCMT4IuvpMnT2a3XiKicOdwsICVlAiHA7+G4IbeNChkRf0Iak2IiChEhoJ/zNnb8r6dIvHcv4eaih6/g7I3DRERhdmMvexNE9YYjBARkbU9aSKjRaJirF4ashCDESIisrh4lVmRcMdghIiIrMEBz8iJwQgREVmDwQg5MRghIiKLBzxjMBLuGIwQEZE1CnP0dWyS1UtCFmMwQkRE1jh2VF8n1LV6SchiDEaIiMgaeUf0dUI9q5eELMZghIiIrM2MJDIYCXcMRoiIyBrHjMwIm2nCHYMRIiKyuGaEmZFwx2CEiIgsrhlhZiTcMRghIiJrHMvQ14kMRsIdgxEiIrIGa0bIicEIERFZgzUj5MRghIiIal9Rvns4eGZGwh6DESIisi4rEhElEp9m9dKQxRiMEBGRtfUiERFWLw1ZjMEIERHVPs5LQyYMRoiIqPblHNDXSQ2sXhIKAgxGiIio9mXv09cpTaxeEgoCDEaIiKj2Ze/V1wxGiMEIERFZmxlJt3pJKAgwGKHgVVpi9RIQUU1hZoRMGIxQcDr4p8iTJ4j88F+rl4SIajQYYWaEGIxQsFrxrkhBlsjC50UcDquXhohqqpkmtanVS0JBgMEIBaf4Ou7bhzdbuSREFEgF2SJvDxUpzNH3kxtbvUQUBBiMUHAydlTw57fMjhCFij+/E9mxyH0/LtnKpaEgwWCEgnuoaPj+PyJfj7NyaYgoUHIPWr0EFIQYjBwPzsiLC6xeivCTZwpGYMV7Ill7rFoaIgp04Sqc94yVS0JBhMHI8eCs/IlWIlt/tnpJwnPeihGvijTrJVJaLLLsbauXioiqK8sZjAx8SOTUG61eGgoSDEbKU1IksvgVkeJjIu+eL/Lm2e4KcKqdzEhac5E+t+nb62ZYukhEFMDMCHvRkAmDkfLsXOp5f88KkTWfVe29WIDp29FtIkX55UwvXk/kpAEiEZG6V03m7lpfRCIKII68Sj4wGCmvmeC7f+vbjbuIRMXq23tXVf69Fr0i8li6yPbFgV1Gu8reL/LuBSLT/yHyYjeR7/6vbOBmZEYS64kk1BFp2kPf37pAJHOXyGt9RX55yf2YsYMrLRXZ+K1Ixo7a/EZE1kEwv3xK2TqroB/sjJkRcmMw4s+0q92Bx4AHRC7/WN/e43wMZ+hb5lcs4/H9v0WK80XeGSLy+Y0in4wWObrd/byvzEAoWzpJZOt8kdVT9f1lb5Xt1lta5M6MQOuz9DX+3ex7RQ6sE5lzv8imH0TeHS7ywSU6EPniDpGPLxN54yyRfWvdwU9xoS5EZoaKQs3C50S+vFPk+/vFFmOMGN32Uzi+CLlFm26HNxyk9q8V2bVMZPMPItucBasXTRZpN0gk95C+f3iTyJwHRRa/qg+YqAY/5XqRSFNcd2SLyJrP9WNtB3l+zppP9PWhzSJXfCyy6kOR+U+KnHyRLtaMTZSQd+Qv38013/xL5IQzRTqerx+Ljnevj9b99GisCADzM93/zghk9q8R+fkZkVUfuDNbn10r0uZckSWvYQPrxzuNELn0vZr9fhQYf/0ksmmOyLkPi0TFVOzfLH9X/yZ6XSvS6xqRiAgJ+f2W0XT85zc6IDfvi4K1eDU2RSQuxeqloSAS4XAE/6liVlaWpKWlSWZmpqSmpgbujfHVsbMqzBWZdpXe+Zl1v1JkJA5kTs+dLJK1y8cbRYhc9oFIq74i+9bo98JQ5pWFne4Zd0rIe7G7yNGtno817ChycL3nY6nNRMb9oW8XHRN5oqVISeHx3/9v40R+fdNz4DSzG+eKNOtZ9vEt83Tzzu4VugdPz6sr/JWoBrx8ig7+ETwiiDT74wuR9V+KDH1SN+UZEys+004kz3nigL/JjsPLvu/+dboY+sy7RWISKr9cyLAh2A2Gmgd8l9f7uu/f8JNI814StP6aK/L+SJEG7URu/83qpaEgOn6Hd2YE3Xb3rNRn5Vm7RaLiRFqeps8usEM76x7P17cZoOdMQTEluqUtf0dnQXDWPe1Kz9c26iQSEaXP2KHuCSJpLUSGPqXP7PHZu5d5/pudv0rIw07cCERumi/y+Q36gOMdiAC2iQEHjRanuTNW/tRpJdL/Ph0M/jZZP3b6bSI7FusCZPjlhbLZEdTzvGc64GHbommNXQ+tS+fjd2FMmmj+G0HmEtlEY/RO/E0hc7L9F3cgAms+LRuMoIeccfCOTxPpe0fllmvVRyJf3aV/G8NfEuk1RiyFoMxsw1fBHYwY+7iGHaxeEgoy4RuMICuydrpItnMgrYS6In//RKTFqf7/zbBnRXrfIJLcSJ8VtRus3wNnWYc2ul/XuLPIjT/pYOSHB/VOcdS7Ik27u19z44/6DxM1EI1OFpl6hbsexdvO33SRJw6wyNTgrN2ujO+IoAHro3En90Gn5xh9YEHzysbZIu2Hef5bbBsjGElt7s5SNWivA7x6rUXOf0EkOk4fZDbMFjnpHJHBj+kMGGpIJp0hsvEbkWMZujDWoJpynJIaieQeEFnwDIMRqxj1PmD8PnBW/fHlOhAwYOwZXHCmfehPd8E5TgLQxFOY59n0iWZRA5r8jheM5BzUzR8xiSKrPxHZ9J37uW/vE2l9pki9EyUgUIBqZHnMSor1fqLVGSIx8Z7P/TFLX7cboqdNQEbw1JtEUptIUEIgaZzYEZmEbzCCg9OYL0X+mKlH9kQW5Hj93nH21aSr+37D9iJnTxA5616dXUEzD85MzntaHxABB0JcfMHBFRecBaKpBwfXw3+J1D/J83WoldjlPKP4dbLIhTYMRpBtwjpf9LK+37KPvja3G5/2D72zvfR9vV28A8MeV+leA10v1/eXvKqvcUDxblJBJupur2xLemd3cxAOSth5IyhB2t0IJm9ZpJuHnmwlkrNPN+HFJgVyTVBF7P3dffvQJpH5T4nM9fN3pF5jyp6c95TuqZW5Qze9dTjPdyYBn2E01fqDgGOtV3f+ln11dnT7QpGZt4pc87VIZJRUC37XKEK94GWRzpfoTKCjVA+djsJU1Jqhnmrw4yKrp+kge+3n+rccGSNy4SRdxI1sK8ZG8rfPsToramSD0V2fyCR8gxFo0KZsU0xVREXr98LltJsq/+9xQK7fRp8BvtxT5PznRU65zn1WhJ2eATvX4+1AgzEbMmWYSGJ9kYztupt0v/HuM7qVH+gAoPHJ7vXZ5ZKy74Mz0PFb9Pc3H5g6eGVQynPyhSLz1pftTgxI6RvLgBQ+si3o9YTsDdWufavdt9G8htoIIyDFgQwZstNu1s2sGA8IzWyn3yJy0tkidVqKtB2oMybbFnoGIzn73beR/Xqlt8g1X/mu/8DvzFxHhgAaJwpn/9vd3IPmP/x+q9Ncg89BIALoDYYLZrLF78+cBcJ3fuNMfRsBh+HE/jqzi30GDvaoWwtGat9Vqpto6rSwemkoyIR3MBJMUPxqpKNnjxepd5KurTB2Ujj7QW0KmpWe7aDPxHDBAb7ffSLth0jQQjs7ikmNglIU6RrZnw7n60JDI1NSEQjEOl8s8vNzIp0u8J3a9gdBzrzHPR/repnObiEgNGdWcOaMjBeDEWszI1BSIJLeVeSCV5zb/yJ3drKbM1Pmnb1AMII6ErOcA+7eHIXOupTf0CPLIfL7VJEhE911JsjIYPA99Oq6c3XZrqj9/qW7l6NppOulVSuGhV0+CjnNQROgaRb1acY0CUbAjEAEv10wfr/IrgZzEw2zIuQDg5FgMfC/+oC88n29A/3wEs+eIyjeRMYAZxdoPjCg9wfa0S9733fPgZqAMzmcceLsFZkGnMXtWKLPetC0YjRR+drZNj9V78QNOLBUZbkbdRS5e4PeIVcGgqChT4t8c6+uW7ljhV6v3oxgBJkcql0Yd+fgBn07NtkdxKIWoqIZwVbO4Ba/UTSDIvuI3jZGgevF/xP59Fo91cOCpzzHF0ITR95hkZ+f1Y817+17TAw0Dc59XA8JgEENkZHBbyouVeTEfnpyx0GP6myNP6hp+caZJTQbPUsXvOM9sSz4G8Pyo9kGWRAM9IfvaG7mNIIRNPd618pYDfuMzc4sE+tFyAcGI8ECZ/fdr9AHd6OA06zrKL2jw5kdsgkonsUfOM7+fv9I985pO1hnTvC6mmzGQaZj1q3uehZ8ntEW3PEC3VPF+HwcCIyz3Ms+FGl7bsXHjDgeFBJXBYpSUeyKZh9fgYgRjAAyI8eDcR5SmoiccEbVloc8HfhDT4yIAe/Q/RYH9S6jdFf7isKcRvhdIphEzQWKz3FQR8CM+iyMP3PHcpHnvbNejrJNeCgc9QVBQfe/u8e6wYmBMfLvxq/1NbqxYowcdEFGAO0NPbvQ1ITvimX89X8i5z7kWS9lNCHht2oUpmLsI1/7EFfz4lZ3k6OVEED9/rEOLrFvQpYJWWAiLwxGgg0KOJGKfvpEd0+RiyfrHjoYzOhWryHl0YSA9CcOmo82dNdhXPyW7vZYE9BGbsCZGi6G9V/odDcCqwMbdJu6o0QkraV7MDOrIVBCUFSeigYjaJ///Pryxy+hqtWLoFi87+36UhW9rxeZ84Dupo2DO5p5AE2bOLCnNXO/FsHAvX/pZhcMnIbMBgJWNIugsNofNOug6Q8BN3rbIPOG3nNm6Akz/Ub9+/AOxNfN1NcoTEXTk9H8VNXfNbIju5freZwqEowgcMEAjqjjQFCE5UfAEBmtg8L6bXWTaLRzOozKQsE6ehQaMF5MVZuzKKQxGAlGSfVFhjypz9CwkzL34PGGnh4DHxSZ5ZzZFtBL5MeHda8CX9B7xLsppaIydorsWKTPLjGbLgrp0JUSo8miiQnjP8y8RfeGwXIY2g8VW6loMILuowYccG5d6j/b4t27aMHT+my2st2HEQAdWC/S8nSdxsfUBD8+pA90579Ysc8PZkYmrUm36r0PapOQScRvFIWoaOoA4xpGTtIH44ve0MF+eb3ffMHfEc70cUEBLaC2AwFB+/N08yoOxthm6DGDbY3f1MIXdOEtenHhwB+ovw9XMFJO3Uh+lg7QkCnavsh3zYoZevJc+VnlewxhDql5T+jbGMPpb2P1gIREPth8rxXCTr9Zt5FXZGhn9DBA+nnJJD2hHIZER2CAwb9wsMOBC8EJmiVw9oSdL8bjqEgPAKPnzt7VegeG0UmN1DV22t2uEGnQVu+Uzxqvd/54nUcgMkyPLmsnSPEDDhz+ei/t/8M9sBrgbBTNZhiLxtd2QwAy/wmdykcdBEYQhaY9Kz5QFboivzVYpChXH8TQowTb2hgiH1mrJt1FBj3ins/HTrCOUI8ERiajOtCciWAENRZtBurHkp0ZREAGD5dAQkH2ivd1RgVj2eBvA12E0dyEoAOTRJprkfC3ZB7zpjqQyQDUsuDz4lN193T8xhC4IjhCATeyIL6gVxsyR8YIs+gJh0Dug4t1EIdmKWSNAH8XCByRQfJVu4VMEWpy8JnXfWevHoBkj+HgX331VXn66adl37590q1bN3n55Zfl1FN9DxY2ZcoUufbaaz0ei4uLk/z8fOuHgw9F2Jzo/oczMcx3g7lzPrtG74zNEhuIjDedPRlFfmYY0G36TXrnZC6ahaum+y5Ew+cveknkp0f13CD9nAGR3XZEmFjvscY6yLt7Y9mun5hb6BVTAIG5UBCEKRH6ADNqivvAh4Ps0td9dynGgeJvd+mdenoXz+ewXbAsi1/WgR7Gt0DwURHY/ghIsV1RVInZUmfdrs/IcWA6535dixQsfnhIT/oGWN6xq3VdRnWLYdU0AgUiPa7W667LpbqAtbZgMDMMU4+5rNCtHYXpqDFqfoou6sQYIegVFgjIiGB4gOPB+sUyIDODGjQEr2hK9c6qoR7KaIYE/D5vXqhrQXCCg5qXpIYiF/2vbKHu5IE66zLsOd1kRmEpq6aGg582bZqMGzdOJk2aJKeddpq88MILMnjwYNm4caM0auS7oBALgOcNEXY7MNkJ1u2A/4p8NEpkHUaHne5+LjndHVSgVwHGbsAgYGgnR7YEzT04KGbv000Ixlm/dyCCA6+/inh8PtLjOGOvalNQMEAbOUZ5xcBZGGvEOxgxD4SFYALNaUhLb0azjUOPDYPiSGQnmp2i6wiMCQJRjIkAATvxRa/ocTQ+uVqP8okupEYAg2zHq6e7Rwk2632jznghy4IDGQKLeROd0xM4hwX33v5mODOffoOuKwiWrsuqi61Tn9urH4gYNViY4gHBuDGhXFULn6sKwTgyNNgmCETQaw6TYqI+I9BjBuE9e47WWRGj2zqyFugqjFFt8RtE/dkl7+hMKYIF1Dn5+1tFPQzmhfrCWbeDk5wZN+tefQhuATVjKNRFZhSjKqM4GF2iMekooLmKKNCZEQQgvXv3llde0YPulJaWSosWLeSOO+6Q++67z2dmZOzYsZKRkSFVxcxIFXu8oIcN2oUBzSkojEVRGg5a6K2DroPYUZrHdMAOyjigGWdCaGJBIS0K/lCfgJFqwyGgnHK+HmgKI7zi4F+3VdmzT6wbDDZlZJXQjIKeA5/fqAMZbxgX4srP3WegmBJg6pV6AC7DOf/RgQma3Yz3wBk1MlTGAeD6OeVPXYBt+t2/dQExeqaYPx/zKqHGBOl3zNszxGvcFW+oK0CghSCqprY7sgdPtda3cTBFzVSguqbOf1pk7qPWTkiJ9bd0ki4uP+FvNftZCGKXYuyTUe7aJ8CuHk2JeKyyPdqQnXt7sHt+J4ivI9J/gm4aNObgMublQnbwwDodiGPqCwpbWRU8flcqGCksLJTExET57LPPZOTIka7Hx4wZo4KNWbOc8yR4BSM33HCDNGvWTAUuPXv2lMcff1xOPtl/pXdBQYG6mL8MAh4GI1Wghqmfq89wjAMm5rp5d7huz4WYJF2DYIYULkZJRRATrtXvaNIwmkQw6By6XeMs87f/uR+7d7Pv9n5MMTDjH57NYxe+KdLtMt8FxagfMafDzc68Rwc8+JwPL9VZGwQ0FaknQjodf+LoaoozXDRR4N9t/Fbk48t03QkGoSrK092yUWBpDjjwPV7qqX8r6Hra6UJdYB1oCHjeGaqzUeOco60Gyo6lIm+busKi+Qzbkirnx0dEfn7G/Vs+eaTOqKCebOrfdXCCTF1BpjuAvma2SIveli42hWAzzaFDh6SkpEQaN/YcAAj3N2xwDlLkpX379vL2229L165d1cI888wz0rdvX1m3bp00b97c57+ZOHGiPPTQQ5VZNPIHZ0GneNbsqJ3Ddd+I/PKiTtP3GK2DERS9IQOCgxXSuxirIZyZzyrR3o9eBeZCQRQY+ys8RPYIcx/hjB9nlLiPzIIv2KHj4LhlrsjulTqzgu7QgGJUDBJndK281jl+RUUZPSDQpdIMxZx1W+vxKIzJ35AFwmBwmLgRQ6Tj92AEXvD13SKz79VNT8iq4SwfQ/GXly3BWXruobLzLXlDkxM0qoHZXL27W7ezWc+uYIHCbNQboYjVHFSjt99dzokNj2zV9WIo0MbfBwMRqqBKZUb27NmjMhyLFi2SPn3cw3ePHz9e5s+fL0uXLj3uexQVFUnHjh3liiuukEceecTna5gZoaCA3gDorgtopsEonMg0oc0fA3DVVJMFDuCY8RnjxKDwtSIZkKo2HaBLOGamRaEuJl0zpDT1XaviDdkUDOiFcTqM4kzUaRTk6OAGAQxqkJCqR08vfxDkYFh11IrUxCRv067S2SfU9qBLOhHZNzPSoEEDiYqKkv37PedNwP30dB8TTfkQExMjPXr0kM2bN/t9DXrb4FLTrn5rqazakaGOKZGRERIZEYGWTlVgmxofLYNOTpeLejaTdo29eplQeMD8QAYcICtQkIvYPrugWA7nFMrhnAI5lFMoxaWlEhcdJbHRkRIXHal+YyUOh4oz8FxuQYkcyStUzSkp8THStE6CNEqJlqKMbCkoLpWiklIpLC6VwhL37frJcXJigySJj4mSxNioqhWFI/OFYccBGZwXu7tT7M5AJL9uO9l95lOSW7ejOIryJCZrpyQdWi0JWZulwYYPJRKD3OHiVBIZJ0fSTpY6WRskpiTP9fjGTx+UaSc+IaXOc5+kuCi1ToylHrlxhWDqtB8O1ZP1P25y97BOipXhXZtIWkJM9QrfMf5Kz2s4FHk14ff918EcyS8qleioCMnMK5KSUgdKtiW3oFjtQ+Ni8BuPEDyK6xMaJEqzOgm277iw43Ce+s74+6QgKWBFN1505wXUgbRs2VJuv/12nwWs3tDMg3qR8847T557ztmNz6IC1gtf+0VW7jh+YW3bRsnSukGS+hGmp8VLE3VJkPTUeKmbFCPJcdG2+EPDgexgdoHsy8qX/Zn56hr3ccDDAc440BUYBz/nY9FRkRIbFSHFpQ51v6jYoV5TVIyhtfWJO3Y6kTqSU9fYKUVHRqgDcGxUpMTHRkmC88CJa+PxmOhIiXG+Pz4H/xbvZazO/KISySkokfiYSHVAwiU1IcbjPdR1tH4en4mdo7GseG8VAFR1+6x4Txz1TpLMRr1lT0a+7M44JkdyCyTzWJG6HMktVOvQuCD4QNBQm7BukuNiJEatwwiJiYyUqMgIdTEzrwP82eMvH8EBdgC4blqwVWIKM6RL8Vq5IWq25Eq8DC94TA6J7/l/ukb8JS/GvCKtI70mdXPa56gr2Y5EaRu5W90/q+B52eEoO8dLiuTJsribJS6iWM4teEo2Oco2D2Ibdm6WJiO7N5XzuzaVlPho9f0qsl3xe8jJL1bb7s/92Wr71EuMlfrJsZIUFy07j+TJ5gN6/pvcwhLZfjhXCorcwR/WU92kWLWOip338W9T42PksHP743eA39zRXD2fFJYNy3xiwyT195Xl/L3kFBR7daBx/9ajIiIkOT5aLSuCNRzw8e/rJcWqv5vE2GjXNbZ1Rl6R1EmMUcvZpmGydG9RR4pKHfLHniz54vc9KjhQ29eh1x8++2hekVoWbH+sOywn/mbwN3WssER9Ll4XFRmpPgvwnQtLHOp3n1dQooLtysJPEZ9h/A23bZSiTvTOaNNAahN+C28u2KICpQt7NFP7ccgrLJa7P/ldFm46JF2ap8mTF3eVFvUSJTu/SP46mCtfr94jb/+yTa3PC7o1lbED20nzuglq/2K1bYdy5dPlO9U+958D2pZZJmxXfD+sd2xb/G5x8m1Ytu2I+v1f2LOZOkGwRQGr0bUXBatvvPGGCkrQtfeTTz5RNSOoHRk9erRqykHdBzz88MNy+umnS5s2bVSRK8YnmTlzpixfvlw6depkaTCyJ+OYOthhBWA1lDp0rR9+cFsO5srMVbtl3sYDUlRS/irCHzQOjjgoYOfWKCVOGiTHSUIsHouS+Gj9nH6NPojij0Lt3Eod6rbHxVH2Mf26UrVjwzJjR6WunUFDqfP98G+N76DOWJy3sVPFjrPyo8rYH7ZPYkyU2h7YPtgOCCCx4wWsU30pUQch3MYfLnZYh7IL5XBuwXF/A97w/jhg1U+KVTsH82fgB2cEC9iB4LU4qOA2DljbDudKdn6xOuDEGsGaKfDCfRwwEfjUlEgpVb/VpPhYdZBUyxqpD5hg/G6Li0skLSJXBkatlNYRe2VLQmdpHJkpRxJPlIOpXVQQes3mf0rr7OXy/Qn3ypqmo9S/yyss0esCY/Yd/VYu3fmY7I9rJS+0e9+j+WvF9gzZuD/b73Kq9Wg6qEYhIHOuW/zWsfPFZ1HgGCcG2I747eI3CQiS8FdSUORe3/idbD2Uq17rC4JKI8BCwHQgu0Dtz05tXU/Obt9QBUwIEKKd2xUBwsCOjaVLszSPA+rxYD+ODORPGw7I5yt2qcew7Hed207tR6f9tlN2HHFn8gD7iWOm7+INvzEEJH1Pqq+CE3yXnzcdkh/X75fiEp0hxSLWS9IZ1QEdGknv1vXUcQfHCGQ3K6qguER2Hjmmfs9rdmXI7ox8WbcnUzbsy1bBsAEB3rOj9MjFE7/ZIKt3ZahAA/sKrD9sj8apcfLwiM7SMT1V3l28Td7+Zav6W8FJ97OXdpOuzQM0AF9NByOAbr3GoGfdu3eXl156SWVMoH///nLCCSeoXjRw1113yfTp09Vr69atK7169ZJHH31UNdUE+svUBJzxLN9+VPZmHpO9yCZk5qsfk8ouZOWroMBO8INsnBqvfpDI8jRKiVcHaSOD4MpmmA5++MNCMIM/PtfBMSpS7SDACOZ04GMEdjqAMjIs+IM/VlQqxwr1wUFlYUr082iq0FkZvIf7TB3vp7IpcVEeZ5e44P2M99ZnsDUfZeEMFenmhilxrjM8PIb7DZPjpAGusZNJilUH8ppkrO/84hIVMOUWFuvtVFqqrrFO0QykXqvWqA609X19pmpulsTxH9sWzZM4c8JZbMC+g9G1ttNI3TS0+Udd3IvxVNDbB12oMcUAuolikDav75l1rFgFhHM3HpRPfttZbnBSHhx8OjVNVb+pjLxCtYPGesO269gk1ZVVQjYCQavx+8dvEfsB/G0ge4f1dySnULLyi/T2T8aBJVb9feA+1isOvggotx7KUQda9XtJ1FlUPK++G/4ztolDN9nprEi0Wq7oyEj17/E++JvRF31bB8zRKjuCz0U2ZNOBHLXM+A0O6Zwu7RunuOerLC51Bb11ErGMOkuAv1dkPpAxUVmR/GLVVIiTmryCYvXbQFCMz6ifFCcx0RFyQn3dPFiZAymW05xNXPDnQRUAYB9RFeo7npwu/do1lLaNk9XfJbaNL79tOyKjJnnN6eUDtu+9g9vL7DV75fddmR6f1a15mlx6Sgu1z/z3jLUqEKjioivYLiO6NZVnL+1eJoMJ+G19v26/fLNmr8roIXuHrJ0/COiMoPvFy7vLrqPH5Onv3GN7VXSZPr+lr/RsGYDxfWorGKltwTzOCA6KxsERUTR2HAeyCtTOE+kxlcEoLlG38UeJ+ziAIqrHj99ozjDuG2fL2DH6eg4Bg8q2ODMxSKsZQQR2HPhdR3ndxvvgGtkaHCgrc0ZhF9ixHs0rVAcOHFDUgSUqUgUqSC0bO3FcsKPHYzkFRWo9GesU10Zdh3Em0cAZZNRGgBGyti8WeWeI52MDHtT1Gz8/K/LHLD13yW1L9Dg3x4HmByPgcmcN3dlDXON5wAEYZ6w4wBpn8KEK+xUEDnZoMgbsNw/l6P0k/i6x/2yQHKu25YyVu2VvRr7ad6JmD0EyrN+brbMcXgdm7NIQNJzdvpHcM7i9+rvF3zyy0te9+5vM26gn8+zWoo5c3ruFXNKruWqu+WjpDhWgndWuoQzq1Fh6OA/ECFaxL0cAieDcGzLRyOKs35clL/24ydXcj6Do7A4N1X4eASBOvrDvRTPq9JW7VNCZEhftauqadFVPGdK5iTo2jHn7V9l8IFcFw+t2Z5b5jkmxUeokAd8N+35A02XTtAS59owT5LV5f8lzc/4ss6zYj6HZCeuxVYNEeW3uX/Le4m1qnZ/ZtoH6tz1a1JUFmw7KiO6mySMDhMEIEQUHjKPyRCv3uDa+YJZpjIVDdBw4cC/667DMXr1X1u7JUgW1CMQMOFi3aZQkS7cecWWeEKzMvae/tKqfVCPLhFohBMEIpvwFg2gyQYBySqu68vjs9fK/n7dKh/QUefyiLjLt150ybdlOj9ef1DBJLujWTLo2T1OZt85Ny2+awnoZ8covqukGrji1pUw4r4MqMkbzlhkCNQSBlWkqqioGI0QUPL4aJ7LMNNy7ofMlerZbzNNCVAXIUhzKLZCN+7Ll0a/W+2zGu2tgO7lzoHMSwSCAjFC/p+aWyX7ceGZr1WSIzhF9Tqpf6SwXakom/7xFZXXGD2lfIwWplcVghIiCh5pY7SE9C+z+tXqaAkyiePYEq5eMQgjO9tH8ghqKczo2kl82H5KW9RKlf/tano+oAtbsypTnf/hTVu44KnUTY+Xav7WWq093TjkRQhiMEFFwwvDhmHCt2+XuEWKJKCTV2Ky9RETVguHDcSEicgrt8nIiIiIKegxGiIiIyFIMRoiIiMhSDEaIiIjIUgxGiIiIyFIMRoiIiMhSDEaIiIjIUgxGiIiIyFIMRoiIiMhSDEaIiIjIUgxGiIiIyFIMRoiIiMhSDEaIiIjIUraYtdfhcLimIiYiIiJ7MI7bxnHc1sFIdna2um7RooXVi0JERERVOI6npaX5fT7CcbxwJQiUlpbKnj17JCUlRSIiIgIasSHA2blzp6SmpgbsfanquE2CC7dH8OE2CS7cHuVDiIFApGnTphIZGWnvzAi+QPPmzWvs/fED4o8ouHCbBBduj+DDbRJcuD38Ky8jYmABKxEREVmKwQgRERFZKqyDkbi4OHnwwQfVNQUHbpPgwu0RfLhNggu3R2DYooCViIiIQldYZ0aIiIjIegxGiIiIyFIMRoiIiMhSDEaIiIjIUmEdjLz66qtywgknSHx8vJx22mny66+/Wr1IIWnBggUyfPhwNQIfRtCdOXOmx/OooX7ggQekSZMmkpCQIAMHDpRNmzZ5vObIkSNy5ZVXqkGF6tSpI9dff73k5OTU8jcJDRMnTpTevXurEY0bNWokI0eOlI0bN3q8Jj8/X2677TapX7++JCcny8UXXyz79+/3eM2OHTtk2LBhkpiYqN7n3nvvleLi4lr+Nvb3+uuvS9euXV2DZvXp00e++eYb1/PcFtZ74okn1L5r7Nixrse4XQIrbIORadOmybhx41SXrBUrVki3bt1k8ODBcuDAAasXLeTk5uaq9Yvgz5ennnpKXnrpJZk0aZIsXbpUkpKS1LbAH7sBgci6detkzpw58tVXX6kA56abbqrFbxE65s+fr3aiS5YsUeuzqKhIBg0apLaT4a677pIvv/xSPv30U/V6TMdw0UUXuZ4vKSlRO9nCwkJZtGiRvPvuuzJlyhQVVFLlYHRpHOyWL18uy5Ytk3POOUdGjBihfu/AbWGt3377Td544w0VMJpxuwSYI0ydeuqpjttuu811v6SkxNG0aVPHxIkTLV2uUIef3IwZM1z3S0tLHenp6Y6nn37a9VhGRoYjLi7O8fHHH6v7f/zxh/p3v/32m+s133zzjSMiIsKxe/fuWv4GoefAgQNq/c6fP9+1/mNiYhyffvqp6zXr169Xr1m8eLG6P3v2bEdkZKRj3759rte8/vrrjtTUVEdBQYEF3yK01K1b1zF58mRuC4tlZ2c72rZt65gzZ46jX79+jjvvvFM9zu0SeGGZGUGkirMQNAeY57/B/cWLF1u6bOFm69atsm/fPo9tgXkM0GxmbAtco2nmlFNOcb0Gr8c2QyaFqiczM1Nd16tXT13jbwPZEvM26dChg7Rs2dJjm3Tp0kUaN27seg2yWZg0zDijp8rD2fTUqVNVlgrNNdwW1kIGEdkN8/oHbpfAs8VEeYF26NAh9Udv/pEA7m/YsMGy5QpHCETA17YwnsM12lvNoqOj1cHTeA1VfUZstIOfccYZ0rlzZ/UY1mlsbKwKAMvbJr62mfEcVc6aNWtU8IGmSdQfzJgxQzp16iSrVq3itrAIgkI04aOZxhv/RgIvLIMRInKf+a1du1YWLlxo9aKEtfbt26vAA1mqzz77TMaMGaPqEMgaO3fulDvvvFPVVKGDA9W8sGymadCggURFRZWpfMb99PR0y5YrHBnru7xtgWvvwmJUpKOHDbdX1d1+++2qGHju3LmqiNKAdYqmzIyMjHK3ia9tZjxHlYOz7DZt2kivXr1UbycUfL/44ovcFhZBMwz2OT179lRZWFwQHKLQHreR4eB2CazIcP3Dxx/9jz/+6JGuxn2kSqn2tG7dWv1hmrcF2lRRC2JsC1zjjx47CMNPP/2kthlqS6hyUEeMQARNAViP2AZm+NuIiYnx2Cbo+otuiuZtgqYFc5CIs0h0TUXzAlUPftsFBQXcFhYZMGCAWqfIVhkX1KyhV59xm9slwBxhaurUqarHxpQpU1RvjZtuuslRp04dj8pnClxF+sqVK9UFP7nnnntO3d6+fbt6/oknnlDrftasWY7Vq1c7RowY4WjdurXj2LFjrvcYMmSIo0ePHo6lS5c6Fi5cqCrcr7jiCgu/lX3dcsstjrS0NMe8efMce/fudV3y8vJcr7n55psdLVu2dPz000+OZcuWOfr06aMuhuLiYkfnzp0dgwYNcqxatcrx7bffOho2bOiYMGGCRd/Kvu677z7Vk2nr1q3q94/76Cn2/fffq+e5LYKDuTcNcLsEVtgGI/Dyyy+rH1NsbKzq6rtkyRKrFykkzZ07VwUh3pcxY8a4uvfef//9jsaNG6sAccCAAY6NGzd6vMfhw4dV8JGcnKy6xl177bUqyKHK87UtcHnnnXdcr0EgeOutt6oupomJiY4LL7xQBSxm27ZtcwwdOtSRkJDgaNCggePuu+92FBUVWfCN7O26665ztGrVSu2HcLDC798IRIDbIjiDEW6XwIrA/wKdbSEiIiKqqLCsGSEiIqLgwWCEiIiILMVghIiIiCzFYISIiIgsxWCEiIiILMVghIiIiCzFYISIiIgsxWCEiIiILMVghIiIiCzFYISIiIgsxWCEiIiILMVghIiIiMRK/w8NJ7UxfoWBzgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, LSTM, Conv1D, Flatten, \n",
    "                                       Bidirectional, Dropout, BatchNormalization,\n",
    "                                       Attention, Concatenate, Input, Reshape)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== Data Preprocessing ======================\n",
    "class TimeSeriesPipeline:\n",
    "    def __init__(self, seq_length=30, test_size=0.2):\n",
    "        self.seq_length = seq_length\n",
    "        self.test_size = test_size\n",
    "        self.scalers = {}\n",
    "\n",
    "    def preprocess_data(self, df, fit_scalers=True, save_scalers=True, scalers_path=\"scalers.pkl\"):\n",
    "        print(\"Starting data preprocessing...\")\n",
    "        unscaled_data = df.copy()\n",
    "\n",
    "        price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', '7_day_SMA', \n",
    "                      '30_day_SMA', '7_day_EMA', '30_day_EMA', '12_day_EMA', '26_day_EMA', '20_day_SMA']\n",
    "        volatility_cols = ['20_day_STD', 'Upper_Band', 'Lower_Band']\n",
    "        momentum_cols = ['RSI', 'MACD', 'Signal_Line']\n",
    "        lag_cols = ['lag_1', 'lag_2', 'lag_3']\n",
    "\n",
    "        if not fit_scalers:\n",
    "            with open(scalers_path, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['price'] = RobustScaler()\n",
    "            df[price_cols] = self.scalers['price'].fit_transform(df[price_cols])\n",
    "        else:\n",
    "            df[price_cols] = self.scalers['price'].transform(df[price_cols])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['volume'] = RobustScaler()\n",
    "            df['volume'] = np.log1p(df['volume'])\n",
    "            df['volume'] = self.scalers['volume'].fit_transform(df[['volume']])\n",
    "        else:\n",
    "            df['volume'] = np.log1p(df['volume'])\n",
    "            df['volume'] = self.scalers['volume'].transform(df[['volume']])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['volatility'] = StandardScaler()\n",
    "            df[volatility_cols] = self.scalers['volatility'].fit_transform(df[volatility_cols])\n",
    "        else:\n",
    "            df[volatility_cols] = self.scalers['volatility'].transform(df[volatility_cols])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['momentum'] = MinMaxScaler()\n",
    "            df[momentum_cols] = self.scalers['momentum'].fit_transform(df[momentum_cols])\n",
    "        else:\n",
    "            df[momentum_cols] = self.scalers['momentum'].transform(df[momentum_cols])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['lag'] = RobustScaler()\n",
    "            df[lag_cols] = self.scalers['lag'].fit_transform(df[lag_cols])\n",
    "        else:\n",
    "            df[lag_cols] = self.scalers['lag'].transform(df[lag_cols])\n",
    "\n",
    "        if fit_scalers and save_scalers:\n",
    "            with open(scalers_path, 'wb') as f:\n",
    "                pickle.dump(self.scalers, f)\n",
    "\n",
    "        X_scaled, y_scaled = self.create_sequences(df)\n",
    "        X_unscaled, y_unscaled = self.create_sequences(unscaled_data)\n",
    "\n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = self.time_based_split(X_scaled, y_scaled)\n",
    "        X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled = self.time_based_split(X_unscaled, y_unscaled)\n",
    "\n",
    "        print(\"Data preprocessing finished.\")\n",
    "        print(f\"Training samples: {len(X_train_scaled)}, Test samples: {len(X_test_scaled)}\")\n",
    "        return (\n",
    "            X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled,\n",
    "            X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled\n",
    "        )\n",
    "\n",
    "    def create_sequences(self, data):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - self.seq_length - 1):\n",
    "            seq = data.iloc[i:i+self.seq_length].values\n",
    "            target = data.iloc[i+self.seq_length]['close']\n",
    "            X.append(seq)\n",
    "            y.append(target)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def time_based_split(self, X, y):\n",
    "        split_idx = int(len(X) * (1 - self.test_size))\n",
    "        return X[:split_idx], X[split_idx:], y[:split_idx], y[split_idx:]\n",
    "\n",
    "    def inverse_transform_predictions(self, pred_scaled, feature_name='close', scalers_path=\"scalers.pkl\"):\n",
    "        if not self.scalers:\n",
    "            with open(scalers_path, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "\n",
    "        if feature_name in ['open', 'high', 'low', 'close', 'av_pr', 'diff', \n",
    "                            '7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA', \n",
    "                            '12_day_EMA', '26_day_EMA', '20_day_SMA']:\n",
    "            scaler = self.scalers['price']\n",
    "            price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', \n",
    "                          '7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA', \n",
    "                          '12_day_EMA', '26_day_EMA', '20_day_SMA']\n",
    "            col_index = price_cols.index(feature_name)\n",
    "            pred_unscaled = pred_scaled * scaler.scale_[col_index] + scaler.center_[col_index]\n",
    "            print(f\"Inverse transformation for '{feature_name}' completed.\")\n",
    "            return pred_unscaled.flatten()\n",
    "        elif feature_name == 'volume':\n",
    "            scaler = self.scalers['volume']\n",
    "            return np.expm1(scaler.inverse_transform(pred_scaled.reshape(-1, 1))).flatten()\n",
    "        else:\n",
    "            raise ValueError(f\"Feature {feature_name} not recognized for inverse transformation.\")\n",
    "\n",
    "# ====================== Model Definitions ======================\n",
    "class HybridCNNRNN:\n",
    "    def __init__(self, input_shape):\n",
    "        print(\"Initializing CNN-RNN Hybrid Model...\")\n",
    "        self.model = self.build_model(input_shape)\n",
    "        print(\"CNN-RNN Hybrid Model initialized.\")\n",
    "\n",
    "    def build_model(self, input_shape):\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = Conv1D(64, kernel_size=3, dilation_rate=2, activation='relu')(inputs)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(32))(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        outputs = Dense(1)(x)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='mse',\n",
    "                      metrics=['mae', 'mse'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        print(\"Training CNN-RNN Hybrid Model...\")\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=5, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "        ]\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=100,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        print(\"Finished training CNN-RNN Hybrid Model.\")\n",
    "        print(\"CNN-RNN training metrics (last epoch):\", {k: v[-1] for k, v in history.history.items()})\n",
    "        return history\n",
    "\n",
    "class SimpleXGBoost:\n",
    "    def __init__(self):\n",
    "        print(\"Initializing XGBoost Model...\")\n",
    "        self.model = XGBRegressor(n_estimators=10, learning_rate=0.001)\n",
    "        print(\"XGBoost Model initialized.\")\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"Training XGBoost Model...\")\n",
    "        X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "        self.model.fit(X_train_reshaped, y_train)\n",
    "        preds = self.model.predict(X_train_reshaped)\n",
    "        mae = np.mean(np.abs(preds - y_train))\n",
    "        mse = np.mean((preds - y_train)**2)\n",
    "        print(f\"Finished training XGBoost Model. Training MAE: {mae:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
    "        return self.model.predict(X_test_reshaped)\n",
    "\n",
    "# ---------------------- Updated MetaModel Definition ----------------------\n",
    "class MetaModel:\n",
    "    def __init__(self, input_shape):\n",
    "        print(\"Initializing Ensemble Meta Model (Deep NN)...\")\n",
    "        self.model = self.build_deep_nn(input_shape)\n",
    "        print(\"Ensemble Meta Model initialized.\")\n",
    "\n",
    "    def build_deep_nn(self, input_shape):\n",
    "        model = Sequential([\n",
    "            Dense(32, activation='relu', input_shape=input_shape),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='mse',\n",
    "                      metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "# ====================== Ensemble Training & Prediction ======================\n",
    "class TemporalEnsemble:\n",
    "    def __init__(self, data_pipeline, models):\n",
    "        self.pipeline = data_pipeline\n",
    "        self.models = models\n",
    "\n",
    "    def walk_forward_validation(self, X_scaled, X_unscaled, y_scaled, y_unscaled, window_size=30):\n",
    "        print(\"Starting walk-forward validation...\")\n",
    "        predictions_scaled = []\n",
    "        actuals_scaled = []\n",
    "        total_iterations = len(X_scaled) - window_size\n",
    "        for i in range(total_iterations):\n",
    "            print(f\"Iteration {i+1}/{total_iterations}\")\n",
    "            train_X_scaled, train_y_scaled = X_scaled[:i+window_size], y_scaled[:i+window_size]\n",
    "            test_X_scaled, test_y_scaled = X_scaled[i+window_size], y_scaled[i+window_size]\n",
    "\n",
    "            train_X_unscaled, train_y_unscaled = X_unscaled[:i+window_size], y_unscaled[:i+window_size]\n",
    "            test_X_unscaled, test_y_unscaled = X_unscaled[i+window_size], y_unscaled[i+window_size]\n",
    "\n",
    "            self.update_models(train_X_scaled, train_y_scaled, train_X_unscaled, train_y_unscaled)\n",
    "\n",
    "            pred_scaled = self.predict(test_X_scaled, test_X_unscaled)\n",
    "            error = abs(pred_scaled - test_y_scaled)\n",
    "            print(f\"Iteration {i+1} error (scaled): {error:.4f}\")\n",
    "            predictions_scaled.append(pred_scaled)\n",
    "            actuals_scaled.append(test_y_scaled)\n",
    "\n",
    "        print(\"Walk-forward validation finished.\")\n",
    "        # Evaluate using scaled predictions and then rescale final predictions for final output\n",
    "        return np.array(predictions_scaled), np.array(actuals_scaled)\n",
    "\n",
    "    def update_models(self, X_scaled, y_scaled, X_unscaled, y_unscaled):\n",
    "        print(f\"Updating base models on batch of size {len(X_scaled)}...\")\n",
    "        self.models['cnn_rnn'].model.train_on_batch(X_scaled, y_scaled)\n",
    "        self.models['xgb'].train(X_scaled, y_scaled)\n",
    "        print(\"Base models updated.\")\n",
    "\n",
    "    def predict(self, X_scaled, X_unscaled):\n",
    "        X_scaled_expanded = np.expand_dims(X_scaled, axis=0)\n",
    "        cnn_rnn_pred = self.models['cnn_rnn'].model.predict(X_scaled_expanded).flatten()\n",
    "        xgb_pred = self.models['xgb'].predict(X_scaled_expanded)\n",
    "        naive_pred = X_unscaled[-1, 3]\n",
    "        meta_input = np.vstack([cnn_rnn_pred, xgb_pred, naive_pred]).T\n",
    "        # The meta-model prediction remains in the scaled domain\n",
    "        final_pred_scaled = self.models['meta'].model.predict(meta_input).flatten()\n",
    "        return final_pred_scaled[0]\n",
    "\n",
    "    def evaluate(self, y_true, y_pred):\n",
    "        metrics = {\n",
    "            'MAE': mean_absolute_error(y_true, y_pred),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'MAPE': np.mean(np.abs((y_true - y_pred)/y_true)) * 100\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "# ====================== Main Execution ======================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv('xrpusdt_daily_dataset_with_features.csv')\n",
    "\n",
    "    pipeline = TimeSeriesPipeline(seq_length=30)\n",
    "    (X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled,\n",
    "     X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled) = pipeline.preprocess_data(df)\n",
    "    \n",
    "    print(f\"Dataset loaded. Training samples: {len(X_train_scaled)}, Test samples: {len(X_test_scaled)}\")\n",
    "\n",
    "    cnn_rnn = HybridCNNRNN(X_train_scaled.shape[1:])\n",
    "    xgb = SimpleXGBoost()\n",
    "    meta = MetaModel(input_shape=(3,))\n",
    "\n",
    "    print(\"All models initialized.\")\n",
    "\n",
    "    ensemble = TemporalEnsemble(pipeline, models={'cnn_rnn': cnn_rnn, 'xgb': xgb, 'meta': meta})\n",
    "    \n",
    "    preds_scaled, actuals_scaled = ensemble.walk_forward_validation(X_test_scaled, X_test_unscaled, y_test_scaled, y_test_unscaled)\n",
    "    \n",
    "    metrics_scaled = ensemble.evaluate(actuals_scaled, preds_scaled)\n",
    "    print(\"Final Performance Metrics (Scaled Data):\")\n",
    "    for k, v in metrics_scaled.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    \n",
    "    # Rescale final predictions for final output/saving\n",
    "    final_preds_unscaled = pipeline.inverse_transform_predictions(preds_scaled, feature_name='close')\n",
    "    \n",
    "    print(\"Final ensemble predictions (rescaled to original scale):\")\n",
    "    print(final_preds_unscaled)\n",
    "    \n",
    "    plt.plot(final_preds_unscaled, label='Predictions (Unscaled)')\n",
    "    plt.plot(pipeline.inverse_transform_predictions(actuals_scaled, feature_name='close'), label='Actuals (Unscaled)')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Starting data preprocessing...\n",
      "Data preprocessing finished.\n",
      "Training samples: 1917, Test samples: 480\n",
      "Dataset loaded. Training samples: 1917, Test samples: 480\n",
      "Initializing CNN-RNN Hybrid Model...\n",
      "CNN-RNN Hybrid Model initialized.\n",
      "Training CNN-RNN Hybrid Model...\n",
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - loss: 0.3255 - mae: 0.3653 - mse: 0.3255 - val_loss: 3.4528 - val_mae: 0.9722 - val_mse: 3.4528\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - loss: 0.0861 - mae: 0.2006 - mse: 0.0861 - val_loss: 3.2270 - val_mae: 0.8281 - val_mse: 3.2270\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.0730 - mae: 0.1865 - mse: 0.0730 - val_loss: 3.4151 - val_mae: 0.8167 - val_mse: 3.4151\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 181ms/step - loss: 0.0588 - mae: 0.1626 - mse: 0.0588 - val_loss: 4.2226 - val_mae: 0.9055 - val_mse: 4.2226\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 0.0620 - mae: 0.1682 - mse: 0.0620 - val_loss: 3.4529 - val_mae: 0.8272 - val_mse: 3.4529\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 0.0559 - mae: 0.1628 - mse: 0.0559 - val_loss: 3.8844 - val_mae: 0.8861 - val_mse: 3.8844\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - loss: 0.0571 - mae: 0.1661 - mse: 0.0571 - val_loss: 3.3940 - val_mae: 0.8431 - val_mse: 3.3940\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - loss: 0.0480 - mae: 0.1527 - mse: 0.0480 - val_loss: 3.7545 - val_mae: 0.8824 - val_mse: 3.7545\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - loss: 0.0482 - mae: 0.1505 - mse: 0.0482 - val_loss: 3.6416 - val_mae: 0.8642 - val_mse: 3.6416\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - loss: 0.0439 - mae: 0.1446 - mse: 0.0439 - val_loss: 3.5602 - val_mae: 0.8942 - val_mse: 3.5602\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - loss: 0.0448 - mae: 0.1423 - mse: 0.0448 - val_loss: 3.8012 - val_mae: 0.8901 - val_mse: 3.8012\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - loss: 0.0363 - mae: 0.1307 - mse: 0.0363 - val_loss: 3.7654 - val_mae: 0.9005 - val_mse: 3.7654\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - loss: 0.0450 - mae: 0.1413 - mse: 0.0450 - val_loss: 3.6410 - val_mae: 0.8836 - val_mse: 3.6410\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.0383 - mae: 0.1334 - mse: 0.0383 - val_loss: 4.2584 - val_mae: 0.9397 - val_mse: 4.2584\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.0489 - mae: 0.1450 - mse: 0.0489 - val_loss: 3.6225 - val_mae: 0.8890 - val_mse: 3.6225\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - loss: 0.0344 - mae: 0.1274 - mse: 0.0344 - val_loss: 3.8281 - val_mae: 0.9043 - val_mse: 3.8281\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 129ms/step - loss: 0.0445 - mae: 0.1353 - mse: 0.0445 - val_loss: 3.4353 - val_mae: 0.8576 - val_mse: 3.4353\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - loss: 0.0332 - mae: 0.1233 - mse: 0.0332 - val_loss: 3.5905 - val_mae: 0.8682 - val_mse: 3.5905\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - loss: 0.0359 - mae: 0.1315 - mse: 0.0359 - val_loss: 3.3049 - val_mae: 0.8295 - val_mse: 3.3049\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 147ms/step - loss: 0.0361 - mae: 0.1265 - mse: 0.0361 - val_loss: 3.2485 - val_mae: 0.8479 - val_mse: 3.2485\n",
      "Finished training CNN-RNN Hybrid Model.\n",
      "Initializing XGBoost Model...\n",
      "XGBoost Model initialized.\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0225, MSE: 0.0009\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step\n",
      "Initializing Ensemble Meta Model (Deep NN)...\n",
      "Ensemble Meta Model initialized.\n",
      "Training Meta Model...\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chidi\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 - 2s - 29ms/step - loss: 0.1588 - mae: 0.2275\n",
      "Epoch 2/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0043 - mae: 0.0473\n",
      "Epoch 3/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0020 - mae: 0.0318\n",
      "Epoch 4/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0012 - mae: 0.0256\n",
      "Epoch 5/150\n",
      "60/60 - 0s - 3ms/step - loss: 9.8486e-04 - mae: 0.0233\n",
      "Epoch 6/150\n",
      "60/60 - 0s - 3ms/step - loss: 9.2123e-04 - mae: 0.0227\n",
      "Epoch 7/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.9994e-04 - mae: 0.0225\n",
      "Epoch 8/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.8738e-04 - mae: 0.0223\n",
      "Epoch 9/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.7982e-04 - mae: 0.0223\n",
      "Epoch 10/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.7349e-04 - mae: 0.0223\n",
      "Epoch 11/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.7034e-04 - mae: 0.0223\n",
      "Epoch 12/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.6926e-04 - mae: 0.0223\n",
      "Epoch 13/150\n",
      "60/60 - 0s - 2ms/step - loss: 8.6803e-04 - mae: 0.0223\n",
      "Epoch 14/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.6836e-04 - mae: 0.0223\n",
      "Epoch 15/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.6458e-04 - mae: 0.0223\n",
      "Epoch 16/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.6533e-04 - mae: 0.0223\n",
      "Epoch 17/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.6053e-04 - mae: 0.0222\n",
      "Epoch 18/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.5995e-04 - mae: 0.0222\n",
      "Epoch 19/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.5470e-04 - mae: 0.0222\n",
      "Epoch 20/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.5706e-04 - mae: 0.0222\n",
      "Epoch 21/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.4608e-04 - mae: 0.0221\n",
      "Epoch 22/150\n",
      "60/60 - 0s - 2ms/step - loss: 8.4003e-04 - mae: 0.0220\n",
      "Epoch 23/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.3647e-04 - mae: 0.0220\n",
      "Epoch 24/150\n",
      "60/60 - 0s - 2ms/step - loss: 8.3206e-04 - mae: 0.0220\n",
      "Epoch 25/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.2178e-04 - mae: 0.0219\n",
      "Epoch 26/150\n",
      "60/60 - 0s - 2ms/step - loss: 8.1048e-04 - mae: 0.0218\n",
      "Epoch 27/150\n",
      "60/60 - 0s - 3ms/step - loss: 8.0691e-04 - mae: 0.0217\n",
      "Epoch 28/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.9273e-04 - mae: 0.0216\n",
      "Epoch 29/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.8804e-04 - mae: 0.0215\n",
      "Epoch 30/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.8298e-04 - mae: 0.0215\n",
      "Epoch 31/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.7640e-04 - mae: 0.0214\n",
      "Epoch 32/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.7029e-04 - mae: 0.0213\n",
      "Epoch 33/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6794e-04 - mae: 0.0213\n",
      "Epoch 34/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6478e-04 - mae: 0.0212\n",
      "Epoch 35/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6439e-04 - mae: 0.0212\n",
      "Epoch 36/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6715e-04 - mae: 0.0212\n",
      "Epoch 37/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5871e-04 - mae: 0.0211\n",
      "Epoch 38/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5851e-04 - mae: 0.0211\n",
      "Epoch 39/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6299e-04 - mae: 0.0211\n",
      "Epoch 40/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.5608e-04 - mae: 0.0210\n",
      "Epoch 41/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6834e-04 - mae: 0.0211\n",
      "Epoch 42/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.7018e-04 - mae: 0.0211\n",
      "Epoch 43/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.6898e-04 - mae: 0.0211\n",
      "Epoch 44/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.7000e-04 - mae: 0.0211\n",
      "Epoch 45/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6843e-04 - mae: 0.0210\n",
      "Epoch 46/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6807e-04 - mae: 0.0210\n",
      "Epoch 47/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.6803e-04 - mae: 0.0210\n",
      "Epoch 48/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6828e-04 - mae: 0.0210\n",
      "Epoch 49/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6323e-04 - mae: 0.0210\n",
      "Epoch 50/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6333e-04 - mae: 0.0209\n",
      "Epoch 51/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6284e-04 - mae: 0.0209\n",
      "Epoch 52/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6666e-04 - mae: 0.0209\n",
      "Epoch 53/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6583e-04 - mae: 0.0209\n",
      "Epoch 54/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6514e-04 - mae: 0.0209\n",
      "Epoch 55/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6737e-04 - mae: 0.0210\n",
      "Epoch 56/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5732e-04 - mae: 0.0208\n",
      "Epoch 57/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5852e-04 - mae: 0.0208\n",
      "Epoch 58/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5157e-04 - mae: 0.0208\n",
      "Epoch 59/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6613e-04 - mae: 0.0209\n",
      "Epoch 60/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.5740e-04 - mae: 0.0208\n",
      "Epoch 61/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5546e-04 - mae: 0.0208\n",
      "Epoch 62/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5377e-04 - mae: 0.0208\n",
      "Epoch 63/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5459e-04 - mae: 0.0208\n",
      "Epoch 64/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.5712e-04 - mae: 0.0208\n",
      "Epoch 65/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5792e-04 - mae: 0.0208\n",
      "Epoch 66/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5665e-04 - mae: 0.0208\n",
      "Epoch 67/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5223e-04 - mae: 0.0208\n",
      "Epoch 68/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5229e-04 - mae: 0.0208\n",
      "Epoch 69/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.5262e-04 - mae: 0.0208\n",
      "Epoch 70/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5001e-04 - mae: 0.0207\n",
      "Epoch 71/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.5607e-04 - mae: 0.0208\n",
      "Epoch 72/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.3849e-04 - mae: 0.0206\n",
      "Epoch 73/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.4291e-04 - mae: 0.0207\n",
      "Epoch 74/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.4463e-04 - mae: 0.0207\n",
      "Epoch 75/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6109e-04 - mae: 0.0209\n",
      "Epoch 76/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.6298e-04 - mae: 0.0209\n",
      "Epoch 77/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.4595e-04 - mae: 0.0207\n",
      "Epoch 78/150\n",
      "60/60 - 0s - 4ms/step - loss: 7.4907e-04 - mae: 0.0208\n",
      "Epoch 79/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.4548e-04 - mae: 0.0207\n",
      "Epoch 80/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.4069e-04 - mae: 0.0207\n",
      "Epoch 81/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.4247e-04 - mae: 0.0207\n",
      "Epoch 82/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.3964e-04 - mae: 0.0206\n",
      "Epoch 83/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.4136e-04 - mae: 0.0206\n",
      "Epoch 84/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.3271e-04 - mae: 0.0205\n",
      "Epoch 85/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.3684e-04 - mae: 0.0206\n",
      "Epoch 86/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.3486e-04 - mae: 0.0205\n",
      "Epoch 87/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.3807e-04 - mae: 0.0206\n",
      "Epoch 88/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.3007e-04 - mae: 0.0205\n",
      "Epoch 89/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.3647e-04 - mae: 0.0206\n",
      "Epoch 90/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.3135e-04 - mae: 0.0205\n",
      "Epoch 91/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.3341e-04 - mae: 0.0205\n",
      "Epoch 92/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.2672e-04 - mae: 0.0205\n",
      "Epoch 93/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.3026e-04 - mae: 0.0205\n",
      "Epoch 94/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.2640e-04 - mae: 0.0204\n",
      "Epoch 95/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.2927e-04 - mae: 0.0205\n",
      "Epoch 96/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.2386e-04 - mae: 0.0204\n",
      "Epoch 97/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.2506e-04 - mae: 0.0204\n",
      "Epoch 98/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.2074e-04 - mae: 0.0204\n",
      "Epoch 99/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.2519e-04 - mae: 0.0204\n",
      "Epoch 100/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.2145e-04 - mae: 0.0204\n",
      "Epoch 101/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.4922e-04 - mae: 0.0209\n",
      "Epoch 102/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.3153e-04 - mae: 0.0205\n",
      "Epoch 103/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.2047e-04 - mae: 0.0204\n",
      "Epoch 104/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1878e-04 - mae: 0.0203\n",
      "Epoch 105/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1796e-04 - mae: 0.0203\n",
      "Epoch 106/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1435e-04 - mae: 0.0203\n",
      "Epoch 107/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1877e-04 - mae: 0.0203\n",
      "Epoch 108/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.1536e-04 - mae: 0.0203\n",
      "Epoch 109/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.2285e-04 - mae: 0.0204\n",
      "Epoch 110/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1100e-04 - mae: 0.0202\n",
      "Epoch 111/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1245e-04 - mae: 0.0203\n",
      "Epoch 112/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1341e-04 - mae: 0.0203\n",
      "Epoch 113/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1959e-04 - mae: 0.0203\n",
      "Epoch 114/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1458e-04 - mae: 0.0203\n",
      "Epoch 115/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1200e-04 - mae: 0.0202\n",
      "Epoch 116/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.0610e-04 - mae: 0.0202\n",
      "Epoch 117/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.0751e-04 - mae: 0.0202\n",
      "Epoch 118/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.0988e-04 - mae: 0.0202\n",
      "Epoch 119/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.0621e-04 - mae: 0.0202\n",
      "Epoch 120/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.0664e-04 - mae: 0.0201\n",
      "Epoch 121/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.0502e-04 - mae: 0.0201\n",
      "Epoch 122/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.0390e-04 - mae: 0.0202\n",
      "Epoch 123/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.0310e-04 - mae: 0.0201\n",
      "Epoch 124/150\n",
      "60/60 - 0s - 2ms/step - loss: 7.0132e-04 - mae: 0.0201\n",
      "Epoch 125/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9948e-04 - mae: 0.0201\n",
      "Epoch 126/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9664e-04 - mae: 0.0201\n",
      "Epoch 127/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9468e-04 - mae: 0.0201\n",
      "Epoch 128/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.1116e-04 - mae: 0.0202\n",
      "Epoch 129/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9600e-04 - mae: 0.0200\n",
      "Epoch 130/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.0844e-04 - mae: 0.0202\n",
      "Epoch 131/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9867e-04 - mae: 0.0201\n",
      "Epoch 132/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9476e-04 - mae: 0.0200\n",
      "Epoch 133/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9604e-04 - mae: 0.0200\n",
      "Epoch 134/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9411e-04 - mae: 0.0200\n",
      "Epoch 135/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.8773e-04 - mae: 0.0199\n",
      "Epoch 136/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9682e-04 - mae: 0.0200\n",
      "Epoch 137/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9753e-04 - mae: 0.0201\n",
      "Epoch 138/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9862e-04 - mae: 0.0201\n",
      "Epoch 139/150\n",
      "60/60 - 0s - 3ms/step - loss: 7.0026e-04 - mae: 0.0200\n",
      "Epoch 140/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9448e-04 - mae: 0.0200\n",
      "Epoch 141/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9045e-04 - mae: 0.0199\n",
      "Epoch 142/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.8704e-04 - mae: 0.0199\n",
      "Epoch 143/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.8585e-04 - mae: 0.0199\n",
      "Epoch 144/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9357e-04 - mae: 0.0200\n",
      "Epoch 145/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.8698e-04 - mae: 0.0199\n",
      "Epoch 146/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.9346e-04 - mae: 0.0200\n",
      "Epoch 147/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.8901e-04 - mae: 0.0199\n",
      "Epoch 148/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.8494e-04 - mae: 0.0199\n",
      "Epoch 149/150\n",
      "60/60 - 0s - 3ms/step - loss: 6.8387e-04 - mae: 0.0199\n",
      "Epoch 150/150\n",
      "60/60 - 0s - 2ms/step - loss: 6.8908e-04 - mae: 0.0200\n",
      "Finished training Meta Model.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Inverse transformation for 'close' completed.\n",
      "\n",
      "Final Performance Metrics:\n",
      "MAE: 0.2847\n",
      "RMSE: 0.6576\n",
      "MAPE: 13.6337\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, LSTM, Conv1D, Flatten, \n",
    "                                       Bidirectional, Dropout, BatchNormalization,\n",
    "                                       Attention, Concatenate, Input, Reshape)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== Data Preprocessing ======================\n",
    "class TimeSeriesPipeline:\n",
    "    def __init__(self, seq_length=30, test_size=0.2):\n",
    "        self.seq_length = seq_length\n",
    "        self.test_size = test_size\n",
    "        self.scalers = {}\n",
    "\n",
    "    def preprocess_data(self, df, fit_scalers=True, save_scalers=True, scalers_path=\"scalers.pkl\"):\n",
    "        print(\"Starting data preprocessing...\")\n",
    "        unscaled_data = df.copy()\n",
    "\n",
    "        price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', '7_day_SMA', \n",
    "                      '30_day_SMA', '7_day_EMA', '30_day_EMA', '12_day_EMA', '26_day_EMA', '20_day_SMA']\n",
    "        volatility_cols = ['20_day_STD', 'Upper_Band', 'Lower_Band']\n",
    "        momentum_cols = ['RSI', 'MACD', 'Signal_Line']\n",
    "        lag_cols = ['lag_1', 'lag_2', 'lag_3']\n",
    "\n",
    "        if not fit_scalers:\n",
    "            with open(scalers_path, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['price'] = RobustScaler()\n",
    "            df[price_cols] = self.scalers['price'].fit_transform(df[price_cols])\n",
    "        else:\n",
    "            df[price_cols] = self.scalers['price'].transform(df[price_cols])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['volume'] = RobustScaler()\n",
    "            df['volume'] = np.log1p(df['volume'])\n",
    "            df['volume'] = self.scalers['volume'].fit_transform(df[['volume']])\n",
    "        else:\n",
    "            df['volume'] = np.log1p(df['volume'])\n",
    "            df['volume'] = self.scalers['volume'].transform(df[['volume']])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['volatility'] = StandardScaler()\n",
    "            df[volatility_cols] = self.scalers['volatility'].fit_transform(df[volatility_cols])\n",
    "        else:\n",
    "            df[volatility_cols] = self.scalers['volatility'].transform(df[volatility_cols])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['momentum'] = MinMaxScaler()\n",
    "            df[momentum_cols] = self.scalers['momentum'].fit_transform(df[momentum_cols])\n",
    "        else:\n",
    "            df[momentum_cols] = self.scalers['momentum'].transform(df[momentum_cols])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['lag'] = RobustScaler()\n",
    "            df[lag_cols] = self.scalers['lag'].fit_transform(df[lag_cols])\n",
    "        else:\n",
    "            df[lag_cols] = self.scalers['lag'].transform(df[lag_cols])\n",
    "\n",
    "        if fit_scalers and save_scalers:\n",
    "            with open(scalers_path, 'wb') as f:\n",
    "                pickle.dump(self.scalers, f)\n",
    "\n",
    "        X_scaled, y_scaled = self.create_sequences(df)\n",
    "        X_unscaled, y_unscaled = self.create_sequences(unscaled_data)\n",
    "\n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = self.time_based_split(X_scaled, y_scaled)\n",
    "        X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled = self.time_based_split(X_unscaled, y_unscaled)\n",
    "\n",
    "        print(\"Data preprocessing finished.\")\n",
    "        print(f\"Training samples: {len(X_train_scaled)}, Test samples: {len(X_test_scaled)}\")\n",
    "        return (\n",
    "            X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled,\n",
    "            X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled\n",
    "        )\n",
    "\n",
    "    def create_sequences(self, data):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - self.seq_length - 1):\n",
    "            seq = data.iloc[i:i+self.seq_length].values\n",
    "            target = data.iloc[i+self.seq_length]['close']\n",
    "            X.append(seq)\n",
    "            y.append(target)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def time_based_split(self, X, y):\n",
    "        split_idx = int(len(X) * (1 - self.test_size))\n",
    "        return X[:split_idx], X[split_idx:], y[:split_idx], y[split_idx:]\n",
    "\n",
    "    def inverse_transform_predictions(self, pred_scaled, feature_name='close', scalers_path=\"scalers.pkl\"):\n",
    "        if not self.scalers:\n",
    "            with open(scalers_path, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "\n",
    "        if feature_name in ['open', 'high', 'low', 'close', 'av_pr', 'diff', \n",
    "                            '7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA', \n",
    "                            '12_day_EMA', '26_day_EMA', '20_day_SMA']:\n",
    "            scaler = self.scalers['price']\n",
    "            price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', \n",
    "                          '7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA', \n",
    "                          '12_day_EMA', '26_day_EMA', '20_day_SMA']\n",
    "            col_index = price_cols.index(feature_name)\n",
    "            pred_unscaled = pred_scaled * scaler.scale_[col_index] + scaler.center_[col_index]\n",
    "            print(f\"Inverse transformation for '{feature_name}' completed.\")\n",
    "            return pred_unscaled.flatten()\n",
    "        elif feature_name == 'volume':\n",
    "            scaler = self.scalers['volume']\n",
    "            return np.expm1(scaler.inverse_transform(pred_scaled.reshape(-1, 1))).flatten()\n",
    "        else:\n",
    "            raise ValueError(f\"Feature {feature_name} not recognized for inverse transformation.\")\n",
    "\n",
    "# ====================== Model Definitions ======================\n",
    "class HybridCNNRNN:\n",
    "    def __init__(self, input_shape):\n",
    "        print(\"Initializing CNN-RNN Hybrid Model...\")\n",
    "        self.model = self.build_model(input_shape)\n",
    "        print(\"CNN-RNN Hybrid Model initialized.\")\n",
    "\n",
    "    def build_model(self, input_shape):\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = Conv1D(64, kernel_size=3, dilation_rate=2, activation='relu')(inputs)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(32))(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        outputs = Dense(1)(x)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='mse',\n",
    "                      metrics=['mae', 'mse'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        print(\"Training CNN-RNN Hybrid Model...\")\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            verbose=1\n",
    "        )\n",
    "        print(\"Finished training CNN-RNN Hybrid Model.\")\n",
    "        return history\n",
    "\n",
    "class SimpleXGBoost:\n",
    "    def __init__(self):\n",
    "        print(\"Initializing XGBoost Model...\")\n",
    "        self.model = XGBRegressor(n_estimators=55, learning_rate=0.1)\n",
    "        print(\"XGBoost Model initialized.\")\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"Training XGBoost Model...\")\n",
    "        X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "        self.model.fit(X_train_reshaped, y_train)\n",
    "        preds = self.model.predict(X_train_reshaped)\n",
    "        mae = np.mean(np.abs(preds - y_train))\n",
    "        mse = np.mean((preds - y_train)**2)\n",
    "        print(f\"Finished training XGBoost Model. Training MAE: {mae:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
    "        return self.model.predict(X_test_reshaped)\n",
    "\n",
    "class MetaModel:\n",
    "    def __init__(self, input_shape):\n",
    "        print(\"Initializing Ensemble Meta Model (Deep NN)...\")\n",
    "        self.model = self.build_deep_nn(input_shape)\n",
    "        print(\"Ensemble Meta Model initialized.\")\n",
    "\n",
    "    def build_deep_nn(self, input_shape):\n",
    "        model = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=input_shape),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='mse',\n",
    "                      metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"Training Meta Model...\")\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=150,\n",
    "            batch_size=32,\n",
    "            verbose=2\n",
    "        )\n",
    "        print(\"Finished training Meta Model.\")\n",
    "        return history\n",
    "\n",
    "# ====================== Main Execution ======================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv('xrpusdt_daily_dataset_with_features.csv')\n",
    "\n",
    "    pipeline = TimeSeriesPipeline(seq_length=30)\n",
    "    (X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled,\n",
    "     X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled) = pipeline.preprocess_data(df)\n",
    "    \n",
    "    print(f\"Dataset loaded. Training samples: {len(X_train_scaled)}, Test samples: {len(X_test_scaled)}\")\n",
    "\n",
    "    # Initialize and train CNN-RNN model\n",
    "    cnn_rnn = HybridCNNRNN(X_train_scaled.shape[1:])\n",
    "    cnn_rnn.train(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled)\n",
    "\n",
    "    # Initialize and train XGBoost model\n",
    "    xgb = SimpleXGBoost()\n",
    "    xgb.train(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    # Generate predictions for meta-model training\n",
    "    cnn_rnn_train_pred = cnn_rnn.model.predict(X_train_scaled).flatten()\n",
    "    xgb_train_pred = xgb.predict(X_train_scaled)\n",
    "    naive_train_pred = X_train_unscaled[:, -1, 3]  # Assuming 'close' is the 4th column (index 3)\n",
    "    meta_X_train = np.column_stack((cnn_rnn_train_pred, xgb_train_pred, naive_train_pred))\n",
    "\n",
    "    # Train the meta-model\n",
    "    meta = MetaModel(input_shape=(3,))\n",
    "    meta.train(meta_X_train, y_train_scaled)\n",
    "\n",
    "    # Generate test predictions\n",
    "    cnn_rnn_test_pred = cnn_rnn.model.predict(X_test_scaled).flatten()\n",
    "    xgb_test_pred = xgb.predict(X_test_scaled)\n",
    "    naive_test_pred = X_test_unscaled[:, -1, 3]\n",
    "    meta_X_test = np.column_stack((cnn_rnn_test_pred, xgb_test_pred, naive_test_pred))\n",
    "    meta_preds_scaled = meta.model.predict(meta_X_test).flatten()\n",
    "\n",
    "    # Inverse transform predictions to original scale\n",
    "    final_preds_unscaled = pipeline.inverse_transform_predictions(meta_preds_scaled, feature_name='close')\n",
    "\n",
    "    # Evaluate performance\n",
    "    actuals_unscaled = y_test_unscaled\n",
    "    metrics = {\n",
    "        'MAE': mean_absolute_error(actuals_unscaled, final_preds_unscaled),\n",
    "        'RMSE': np.sqrt(mean_squared_error(actuals_unscaled, final_preds_unscaled)),\n",
    "        'MAPE': np.mean(np.abs((actuals_unscaled - final_preds_unscaled) / actuals_unscaled)) * 100\n",
    "    }\n",
    "\n",
    "    print(\"\\nFinal Performance Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    # Plot predictions vs actuals\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(actuals_unscaled, label='Actual Prices', color='blue')\n",
    "    plt.plot(final_preds_unscaled, label='Predicted Prices', color='red', linestyle='--')\n",
    "    plt.title('Actual vs Predicted Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Starting data preprocessing...\n",
      "Data preprocessing finished.\n",
      "Training samples: 1917, Test samples: 480\n",
      "Dataset loaded. Training samples: 1917, Test samples: 480\n",
      "Initializing CNN-RNN Hybrid Model...\n",
      "CNN-RNN Hybrid Model initialized.\n",
      "Training CNN-RNN Hybrid Model...\n",
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - loss: 0.3289 - mae: 0.3601 - mse: 0.3289 - val_loss: 4.0998 - val_mae: 1.0924 - val_mse: 4.0998\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 0.0877 - mae: 0.2016 - mse: 0.0877 - val_loss: 4.0547 - val_mae: 0.9599 - val_mse: 4.0547\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 0.0726 - mae: 0.1817 - mse: 0.0726 - val_loss: 3.9225 - val_mae: 0.8833 - val_mse: 3.9225\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.0697 - mae: 0.1734 - mse: 0.0697 - val_loss: 3.9429 - val_mae: 0.8761 - val_mse: 3.9429\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.0551 - mae: 0.1601 - mse: 0.0551 - val_loss: 3.7558 - val_mae: 0.8463 - val_mse: 3.7558\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.0610 - mae: 0.1655 - mse: 0.0610 - val_loss: 3.9278 - val_mae: 0.9032 - val_mse: 3.9278\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.0576 - mae: 0.1581 - mse: 0.0576 - val_loss: 3.9464 - val_mae: 0.9008 - val_mse: 3.9464\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.0518 - mae: 0.1573 - mse: 0.0518 - val_loss: 3.5850 - val_mae: 0.8538 - val_mse: 3.5850\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.0520 - mae: 0.1488 - mse: 0.0520 - val_loss: 3.9221 - val_mae: 0.8858 - val_mse: 3.9221\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.0492 - mae: 0.1508 - mse: 0.0492 - val_loss: 3.8411 - val_mae: 0.8749 - val_mse: 3.8411\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.0527 - mae: 0.1450 - mse: 0.0527 - val_loss: 3.8296 - val_mae: 0.8915 - val_mse: 3.8296\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.0448 - mae: 0.1452 - mse: 0.0448 - val_loss: 3.9157 - val_mae: 0.8938 - val_mse: 3.9157\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 175ms/step - loss: 0.0467 - mae: 0.1428 - mse: 0.0467 - val_loss: 3.8407 - val_mae: 0.8967 - val_mse: 3.8407\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.0432 - mae: 0.1418 - mse: 0.0432 - val_loss: 3.7208 - val_mae: 0.9255 - val_mse: 3.7208\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 0.0374 - mae: 0.1301 - mse: 0.0374 - val_loss: 3.7972 - val_mae: 0.8849 - val_mse: 3.7972\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - loss: 0.0423 - mae: 0.1365 - mse: 0.0423 - val_loss: 3.8666 - val_mae: 0.8929 - val_mse: 3.8666\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 0.0344 - mae: 0.1253 - mse: 0.0344 - val_loss: 4.0188 - val_mae: 0.9140 - val_mse: 4.0188\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 0.0367 - mae: 0.1273 - mse: 0.0367 - val_loss: 3.8562 - val_mae: 0.8963 - val_mse: 3.8562\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.0395 - mae: 0.1356 - mse: 0.0395 - val_loss: 3.9864 - val_mae: 0.9093 - val_mse: 3.9864\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.0435 - mae: 0.1362 - mse: 0.0435 - val_loss: 3.8845 - val_mae: 0.8923 - val_mse: 3.8845\n",
      "Finished training CNN-RNN Hybrid Model.\n",
      "Initializing XGBoost Model...\n",
      "XGBoost Model initialized.\n",
      "Training XGBoost Model...\n",
      "Finished training XGBoost Model. Training MAE: 0.0317, MSE: 0.0020\n",
      "Initializing CNN-RNN Hybrid Model...\n",
      "CNN-RNN Hybrid Model initialized.\n",
      "Training CNN-RNN Hybrid Model...\n",
      "Epoch 1/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 120ms/step - loss: 0.8992 - mae: 0.4570 - mse: 0.8992 - val_loss: 0.0133 - val_mae: 0.1155 - val_mse: 0.0133\n",
      "Epoch 2/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - loss: 0.3532 - mae: 0.3020 - mse: 0.3532 - val_loss: 0.0193 - val_mae: 0.1390 - val_mse: 0.0193\n",
      "Epoch 3/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - loss: 0.2303 - mae: 0.2572 - mse: 0.2303 - val_loss: 0.0128 - val_mae: 0.1132 - val_mse: 0.0128\n",
      "Epoch 4/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - loss: 0.1481 - mae: 0.2215 - mse: 0.1481 - val_loss: 0.0119 - val_mae: 0.1092 - val_mse: 0.0119\n",
      "Epoch 5/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - loss: 0.1945 - mae: 0.2385 - mse: 0.1945 - val_loss: 0.0026 - val_mae: 0.0506 - val_mse: 0.0026\n",
      "Epoch 6/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.1918 - mae: 0.2307 - mse: 0.1918 - val_loss: 0.0052 - val_mae: 0.0724 - val_mse: 0.0052\n",
      "Epoch 7/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - loss: 0.1658 - mae: 0.2141 - mse: 0.1658 - val_loss: 4.4613e-04 - val_mae: 0.0211 - val_mse: 4.4613e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - loss: 0.1398 - mae: 0.2056 - mse: 0.1398 - val_loss: 7.1995e-05 - val_mae: 0.0085 - val_mse: 7.1995e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.2143 - mae: 0.2249 - mse: 0.2143 - val_loss: 2.0948e-04 - val_mae: 0.0145 - val_mse: 2.0948e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.1233 - mae: 0.1906 - mse: 0.1233 - val_loss: 0.0016 - val_mae: 0.0394 - val_mse: 0.0016\n",
      "Epoch 11/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.1418 - mae: 0.1985 - mse: 0.1418 - val_loss: 8.7025e-05 - val_mae: 0.0093 - val_mse: 8.7025e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - loss: 0.0969 - mae: 0.1809 - mse: 0.0969 - val_loss: 2.8057e-04 - val_mae: 0.0168 - val_mse: 2.8057e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.1004 - mae: 0.1873 - mse: 0.1004 - val_loss: 1.0327e-04 - val_mae: 0.0102 - val_mse: 1.0327e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.0944 - mae: 0.1787 - mse: 0.0944 - val_loss: 0.0021 - val_mae: 0.0454 - val_mse: 0.0021\n",
      "Epoch 15/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - loss: 0.0810 - mae: 0.1676 - mse: 0.0810 - val_loss: 1.0542e-04 - val_mae: 0.0103 - val_mse: 1.0542e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.0780 - mae: 0.1676 - mse: 0.0780 - val_loss: 8.6009e-04 - val_mae: 0.0293 - val_mse: 8.6009e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.0842 - mae: 0.1700 - mse: 0.0842 - val_loss: 5.9445e-04 - val_mae: 0.0244 - val_mse: 5.9445e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.1166 - mae: 0.1883 - mse: 0.1166 - val_loss: 4.4088e-04 - val_mae: 0.0210 - val_mse: 4.4088e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.0898 - mae: 0.1750 - mse: 0.0898 - val_loss: 9.1871e-04 - val_mae: 0.0303 - val_mse: 9.1871e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - loss: 0.0772 - mae: 0.1592 - mse: 0.0772 - val_loss: 0.0035 - val_mae: 0.0592 - val_mse: 0.0035\n",
      "Finished training CNN-RNN Hybrid Model.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
      "Initializing Ensemble Meta Model (Deep NN)...\n",
      "Ensemble Meta Model initialized.\n",
      "Training Meta Model...\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chidi\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 - 3s - 52ms/step - loss: 0.1202 - mae: 0.2359\n",
      "Epoch 2/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0069 - mae: 0.0583\n",
      "Epoch 3/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0035 - mae: 0.0400\n",
      "Epoch 4/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0024 - mae: 0.0338\n",
      "Epoch 5/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0021 - mae: 0.0322\n",
      "Epoch 6/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0019 - mae: 0.0307\n",
      "Epoch 7/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0018 - mae: 0.0306\n",
      "Epoch 8/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0017 - mae: 0.0300\n",
      "Epoch 9/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0016 - mae: 0.0296\n",
      "Epoch 10/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0016 - mae: 0.0294\n",
      "Epoch 11/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0292\n",
      "Epoch 12/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0016 - mae: 0.0295\n",
      "Epoch 13/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0287\n",
      "Epoch 14/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0290\n",
      "Epoch 15/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0290\n",
      "Epoch 16/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0289\n",
      "Epoch 17/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0289\n",
      "Epoch 18/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0286\n",
      "Epoch 19/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0287\n",
      "Epoch 20/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0288\n",
      "Epoch 21/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0288\n",
      "Epoch 22/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0291\n",
      "Epoch 23/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0290\n",
      "Epoch 24/150\n",
      "60/60 - 0s - 6ms/step - loss: 0.0015 - mae: 0.0290\n",
      "Epoch 25/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0015 - mae: 0.0289\n",
      "Epoch 26/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0289\n",
      "Epoch 27/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0014 - mae: 0.0289\n",
      "Epoch 28/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0288\n",
      "Epoch 29/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0288\n",
      "Epoch 30/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0014 - mae: 0.0288\n",
      "Epoch 31/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0014 - mae: 0.0285\n",
      "Epoch 32/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0286\n",
      "Epoch 33/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0014 - mae: 0.0285\n",
      "Epoch 34/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0286\n",
      "Epoch 35/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0014 - mae: 0.0286\n",
      "Epoch 36/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0287\n",
      "Epoch 37/150\n",
      "60/60 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0286\n",
      "Epoch 38/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0287\n",
      "Epoch 39/150\n",
      "60/60 - 0s - 8ms/step - loss: 0.0014 - mae: 0.0286\n",
      "Epoch 40/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0286\n",
      "Epoch 41/150\n",
      "60/60 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0289\n",
      "Epoch 42/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0288\n",
      "Epoch 43/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0288\n",
      "Epoch 44/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0285\n",
      "Epoch 45/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0289\n",
      "Epoch 46/150\n",
      "60/60 - 0s - 7ms/step - loss: 0.0014 - mae: 0.0287\n",
      "Epoch 47/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0288\n",
      "Epoch 48/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0287\n",
      "Epoch 49/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0286\n",
      "Epoch 50/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0284\n",
      "Epoch 51/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0014 - mae: 0.0287\n",
      "Epoch 52/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0285\n",
      "Epoch 53/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0287\n",
      "Epoch 54/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0285\n",
      "Epoch 55/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0287\n",
      "Epoch 56/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0284\n",
      "Epoch 57/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0286\n",
      "Epoch 58/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0285\n",
      "Epoch 59/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0284\n",
      "Epoch 60/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0014 - mae: 0.0284\n",
      "Epoch 61/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0285\n",
      "Epoch 62/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0283\n",
      "Epoch 63/150\n",
      "60/60 - 0s - 2ms/step - loss: 0.0014 - mae: 0.0283\n",
      "Epoch 64/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0285\n",
      "Epoch 65/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0281\n",
      "Epoch 66/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0284\n",
      "Epoch 67/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0283\n",
      "Epoch 68/150\n",
      "60/60 - 0s - 2ms/step - loss: 0.0014 - mae: 0.0281\n",
      "Epoch 69/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0282\n",
      "Epoch 70/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0283\n",
      "Epoch 71/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0281\n",
      "Epoch 72/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0282\n",
      "Epoch 73/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0281\n",
      "Epoch 74/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0281\n",
      "Epoch 75/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0280\n",
      "Epoch 76/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0013 - mae: 0.0280\n",
      "Epoch 77/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0281\n",
      "Epoch 78/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0014 - mae: 0.0280\n",
      "Epoch 79/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0281\n",
      "Epoch 80/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0279\n",
      "Epoch 81/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0281\n",
      "Epoch 82/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0279\n",
      "Epoch 83/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0279\n",
      "Epoch 84/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0013 - mae: 0.0279\n",
      "Epoch 85/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0014 - mae: 0.0280\n",
      "Epoch 86/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0279\n",
      "Epoch 87/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0279\n",
      "Epoch 88/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 89/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0014 - mae: 0.0280\n",
      "Epoch 90/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0279\n",
      "Epoch 91/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0278\n",
      "Epoch 92/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0013 - mae: 0.0278\n",
      "Epoch 93/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 94/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 95/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 96/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0280\n",
      "Epoch 97/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0013 - mae: 0.0276\n",
      "Epoch 98/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 99/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0013 - mae: 0.0278\n",
      "Epoch 100/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0278\n",
      "Epoch 101/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 102/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 103/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0278\n",
      "Epoch 104/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0013 - mae: 0.0278\n",
      "Epoch 105/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 106/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0278\n",
      "Epoch 107/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0013 - mae: 0.0276\n",
      "Epoch 108/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 109/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0278\n",
      "Epoch 110/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0278\n",
      "Epoch 111/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 112/150\n",
      "60/60 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0275\n",
      "Epoch 113/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 114/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0276\n",
      "Epoch 115/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 116/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0013 - mae: 0.0278\n",
      "Epoch 117/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0276\n",
      "Epoch 118/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0275\n",
      "Epoch 119/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0275\n",
      "Epoch 120/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 121/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0275\n",
      "Epoch 122/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0275\n",
      "Epoch 123/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 124/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0275\n",
      "Epoch 125/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0275\n",
      "Epoch 126/150\n",
      "60/60 - 0s - 4ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 127/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 128/150\n",
      "60/60 - 0s - 2ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 129/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 130/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 131/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 132/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 133/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 134/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0275\n",
      "Epoch 135/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 136/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 137/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 138/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0273\n",
      "Epoch 139/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0271\n",
      "Epoch 140/150\n",
      "60/60 - 0s - 2ms/step - loss: 0.0013 - mae: 0.0273\n",
      "Epoch 141/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0271\n",
      "Epoch 142/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 143/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 144/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 145/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0271\n",
      "Epoch 146/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 147/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 148/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0271\n",
      "Epoch 149/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 150/150\n",
      "60/60 - 0s - 3ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Finished training Meta Model.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Inverse transformation for 'close' completed.\n",
      "\n",
      "Final Performance Metrics:\n",
      "MAE: 0.0202\n",
      "RMSE: 0.0329\n",
      "MAPE: 1.9284\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, LSTM, Conv1D, Flatten, \n",
    "                                       Bidirectional, Dropout, BatchNormalization,\n",
    "                                       Attention, Concatenate, Input, Reshape)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== Data Preprocessing ======================\n",
    "class TimeSeriesPipeline:\n",
    "    def __init__(self, seq_length=30, test_size=0.2):\n",
    "        self.seq_length = seq_length\n",
    "        self.test_size = test_size\n",
    "        self.scalers = {}\n",
    "\n",
    "    def preprocess_data(self, df, fit_scalers=True, save_scalers=True, scalers_path=\"scalers.pkl\"):\n",
    "        print(\"Starting data preprocessing...\")\n",
    "        unscaled_data = df.copy()\n",
    "\n",
    "        price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', '7_day_SMA', \n",
    "                      '30_day_SMA', '7_day_EMA', '30_day_EMA', '12_day_EMA', '26_day_EMA', '20_day_SMA']\n",
    "        volatility_cols = ['20_day_STD', 'Upper_Band', 'Lower_Band']\n",
    "        momentum_cols = ['RSI', 'MACD', 'Signal_Line']\n",
    "        lag_cols = ['lag_1', 'lag_2', 'lag_3']\n",
    "\n",
    "        if not fit_scalers:\n",
    "            with open(scalers_path, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['price'] = RobustScaler()\n",
    "            df[price_cols] = self.scalers['price'].fit_transform(df[price_cols])\n",
    "        else:\n",
    "            df[price_cols] = self.scalers['price'].transform(df[price_cols])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['volume'] = RobustScaler()\n",
    "            df['volume'] = np.log1p(df['volume'])\n",
    "            df['volume'] = self.scalers['volume'].fit_transform(df[['volume']])\n",
    "        else:\n",
    "            df['volume'] = np.log1p(df['volume'])\n",
    "            df['volume'] = self.scalers['volume'].transform(df[['volume']])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['volatility'] = StandardScaler()\n",
    "            df[volatility_cols] = self.scalers['volatility'].fit_transform(df[volatility_cols])\n",
    "        else:\n",
    "            df[volatility_cols] = self.scalers['volatility'].transform(df[volatility_cols])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['momentum'] = MinMaxScaler()\n",
    "            df[momentum_cols] = self.scalers['momentum'].fit_transform(df[momentum_cols])\n",
    "        else:\n",
    "            df[momentum_cols] = self.scalers['momentum'].transform(df[momentum_cols])\n",
    "\n",
    "        if fit_scalers:\n",
    "            self.scalers['lag'] = RobustScaler()\n",
    "            df[lag_cols] = self.scalers['lag'].fit_transform(df[lag_cols])\n",
    "        else:\n",
    "            df[lag_cols] = self.scalers['lag'].transform(df[lag_cols])\n",
    "\n",
    "        if fit_scalers and save_scalers:\n",
    "            with open(scalers_path, 'wb') as f:\n",
    "                pickle.dump(self.scalers, f)\n",
    "\n",
    "        X_scaled, y_scaled = self.create_sequences(df)\n",
    "        X_unscaled, y_unscaled = self.create_sequences(unscaled_data)\n",
    "\n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = self.time_based_split(X_scaled, y_scaled)\n",
    "        X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled = self.time_based_split(X_unscaled, y_unscaled)\n",
    "\n",
    "        print(\"Data preprocessing finished.\")\n",
    "        print(f\"Training samples: {len(X_train_scaled)}, Test samples: {len(X_test_scaled)}\")\n",
    "        return (\n",
    "            X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled,\n",
    "            X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled\n",
    "        )\n",
    "\n",
    "    def create_sequences(self, data):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - self.seq_length - 1):\n",
    "            seq = data.iloc[i:i+self.seq_length].values\n",
    "            target = data.iloc[i+self.seq_length]['close']\n",
    "            X.append(seq)\n",
    "            y.append(target)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def time_based_split(self, X, y):\n",
    "        split_idx = int(len(X) * (1 - self.test_size))\n",
    "        return X[:split_idx], X[split_idx:], y[:split_idx], y[split_idx:]\n",
    "\n",
    "    def inverse_transform_predictions(self, pred_scaled, feature_name='close', scalers_path=\"scalers.pkl\"):\n",
    "        if not self.scalers:\n",
    "            with open(scalers_path, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "\n",
    "        if feature_name in ['open', 'high', 'low', 'close', 'av_pr', 'diff', \n",
    "                            '7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA', \n",
    "                            '12_day_EMA', '26_day_EMA', '20_day_SMA']:\n",
    "            scaler = self.scalers['price']\n",
    "            price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', \n",
    "                          '7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA', \n",
    "                          '12_day_EMA', '26_day_EMA', '20_day_SMA']\n",
    "            col_index = price_cols.index(feature_name)\n",
    "            pred_unscaled = pred_scaled * scaler.scale_[col_index] + scaler.center_[col_index]\n",
    "            print(f\"Inverse transformation for '{feature_name}' completed.\")\n",
    "            return pred_unscaled.flatten()\n",
    "        elif feature_name == 'volume':\n",
    "            scaler = self.scalers['volume']\n",
    "            return np.expm1(scaler.inverse_transform(pred_scaled.reshape(-1, 1))).flatten()\n",
    "        else:\n",
    "            raise ValueError(f\"Feature {feature_name} not recognized for inverse transformation.\")\n",
    "\n",
    "# ====================== Model Definitions ======================\n",
    "class HybridCNNRNN:\n",
    "    def __init__(self, input_shape):\n",
    "        print(\"Initializing CNN-RNN Hybrid Model...\")\n",
    "        self.model = self.build_model(input_shape)\n",
    "        print(\"CNN-RNN Hybrid Model initialized.\")\n",
    "\n",
    "    def build_model(self, input_shape):\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = Conv1D(64, kernel_size=3, dilation_rate=2, activation='relu')(inputs)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(32))(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        outputs = Dense(1)(x)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='mse',\n",
    "                      metrics=['mae', 'mse'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        print(\"Training CNN-RNN Hybrid Model...\")\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            verbose=1\n",
    "        )\n",
    "        print(\"Finished training CNN-RNN Hybrid Model.\")\n",
    "        return history\n",
    "\n",
    "class SimpleXGBoost:\n",
    "    def __init__(self):\n",
    "        print(\"Initializing XGBoost Model...\")\n",
    "        self.model = XGBRegressor(n_estimators=55, learning_rate=0.1)\n",
    "        print(\"XGBoost Model initialized.\")\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"Training XGBoost Model...\")\n",
    "        X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "        self.model.fit(X_train_reshaped, y_train)\n",
    "        preds = self.model.predict(X_train_reshaped)\n",
    "        mae = np.mean(np.abs(preds - y_train))\n",
    "        mse = np.mean((preds - y_train)**2)\n",
    "        print(f\"Finished training XGBoost Model. Training MAE: {mae:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
    "        return self.model.predict(X_test_reshaped)\n",
    "\n",
    "class MetaModel:\n",
    "    def __init__(self, input_shape):\n",
    "        print(\"Initializing Ensemble Meta Model (Deep NN)...\")\n",
    "        self.model = self.build_deep_nn(input_shape)\n",
    "        print(\"Ensemble Meta Model initialized.\")\n",
    "\n",
    "    def build_deep_nn(self, input_shape):\n",
    "        model = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=input_shape),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='mse',\n",
    "                      metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"Training Meta Model...\")\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            verbose=2\n",
    "        )\n",
    "        print(\"Finished training Meta Model.\")\n",
    "        return history\n",
    "\n",
    "# ====================== Main Execution (Updated) ======================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv('xrpusdt_daily_dataset_with_features.csv')\n",
    "\n",
    "    pipeline = TimeSeriesPipeline(seq_length=30)\n",
    "    (X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled,\n",
    "     X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled) = pipeline.preprocess_data(df)\n",
    "    \n",
    "    print(f\"Dataset loaded. Training samples: {len(X_train_scaled)}, Test samples: {len(X_test_scaled)}\")\n",
    "\n",
    "    # ---- Original Models ----\n",
    "    # CNN-RNN trained on training data\n",
    "    cnn_rnn = HybridCNNRNN(X_train_scaled.shape[1:])\n",
    "    cnn_rnn.train(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled)\n",
    "\n",
    "     # ---- New: CNN-RNN trained on ALL data (train + test) ----\n",
    "    # Combine training and test data\n",
    "    X_all_scaled = np.concatenate([X_train_scaled, X_test_scaled], axis=0)\n",
    "    y_all_scaled = np.concatenate([y_train_scaled, y_test_scaled], axis=0)\n",
    "\n",
    "    # XGBoost trained on training data\n",
    "    xgb = SimpleXGBoost()\n",
    "    xgb.train(X_all_scaled, y_all_scaled)\n",
    "\n",
    "    # ---- New: CNN-RNN trained on ALL data (train + test) ----\n",
    "    # Combine training and test data\n",
    "    X_all_scaled = np.concatenate([X_train_scaled, X_test_scaled], axis=0)\n",
    "    y_all_scaled = np.concatenate([y_train_scaled, y_test_scaled], axis=0)\n",
    "    \n",
    "    cnn_rnn_all_data = HybridCNNRNN(X_all_scaled.shape[1:])\n",
    "    cnn_rnn_all_data.train(X_all_scaled, y_all_scaled, X_all_scaled[:1], y_all_scaled[:1])  # Dummy validation\n",
    "\n",
    "    # ---- Generate Predictions ----\n",
    "    # Training set predictions\n",
    "    cnnrnn_train_pred = cnn_rnn.model.predict(X_train_scaled).flatten()\n",
    "    xgb_train_pred = xgb.predict(X_train_scaled)\n",
    "    naive_train_pred = X_train_scaled[:, -1, 3]  # Last 'close' price\n",
    "    cnnrnn_all_train_pred = cnn_rnn_all_data.model.predict(X_train_scaled).flatten()\n",
    "\n",
    "    # Test set predictions \n",
    "    cnnrnn_test_pred = cnn_rnn.model.predict(X_test_scaled).flatten()\n",
    "    xgb_test_pred = xgb.predict(X_test_scaled)\n",
    "    naive_test_pred = X_test_scaled[:, -1, 3]\n",
    "    cnnrnn_all_test_pred = cnn_rnn_all_data.model.predict(X_test_scaled).flatten()\n",
    "\n",
    "    # ---- Prepare Meta-Model Inputs ----\n",
    "    # Stack all 4 predictions\n",
    "    meta_X_train = np.column_stack((\n",
    "        cnnrnn_train_pred, xgb_train_pred, \n",
    "        naive_train_pred, cnnrnn_all_train_pred\n",
    "    ))\n",
    "    meta_X_test = np.column_stack((\n",
    "        cnnrnn_test_pred, xgb_test_pred,\n",
    "        naive_test_pred, cnnrnn_all_test_pred\n",
    "    ))\n",
    "\n",
    "    # ---- Train Meta-Model ----\n",
    "    meta = MetaModel(input_shape=(4,))  # Updated input shape\n",
    "    meta.train(meta_X_train, y_train_scaled)\n",
    "\n",
    "    # ---- Final Predictions ----\n",
    "    meta_preds_scaled = meta.model.predict(meta_X_test).flatten()\n",
    "    final_preds_unscaled = pipeline.inverse_transform_predictions(meta_preds_scaled, feature_name='close')\n",
    "\n",
    "    # ---- Evaluation ----\n",
    "    actuals_unscaled = y_test_unscaled\n",
    "    metrics = {\n",
    "        'MAE': mean_absolute_error(actuals_unscaled, final_preds_unscaled),\n",
    "        'RMSE': np.sqrt(mean_squared_error(actuals_unscaled, final_preds_unscaled)),\n",
    "        'MAPE': np.mean(np.abs((actuals_unscaled - final_preds_unscaled) / actuals_unscaled)) * 100\n",
    "    }\n",
    "\n",
    "    print(\"\\nFinal Performance Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    # ---- Visualization ----\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(actuals_unscaled, label='Actual Prices', color='blue')\n",
    "    plt.plot(final_preds_unscaled, label='Ensemble Predictions', color='red', linestyle='--')\n",
    "    plt.title('Actual vs Predicted Prices (4-Model Ensemble)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, LSTM, Conv1D, \n",
    "                                     Bidirectional, Dropout, BatchNormalization, Input)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ====================== Data Preprocessing ======================\n",
    "class TimeSeriesPipeline:\n",
    "    def __init__(self, seq_length=30, test_size=0.2):\n",
    "        self.seq_length = seq_length\n",
    "        self.test_size = test_size\n",
    "        self.scalers = {}\n",
    "\n",
    "    def preprocess_data(self, df, fit_scalers=True, save_scalers=True, scalers_path=\"scalers.pkl\"):\n",
    "        print(\"Starting data preprocessing...\")\n",
    "        unscaled_data = df.copy()\n",
    "\n",
    "        # Define feature categories\n",
    "        price_cols = ['open', 'high', 'low', 'close', 'av_pr', 'diff', '7_day_SMA', \n",
    "                     '30_day_SMA', '7_day_EMA', '30_day_EMA', '12_day_EMA', '26_day_EMA', '20_day_SMA']\n",
    "        volatility_cols = ['20_day_STD', 'Upper_Band', 'Lower_Band']\n",
    "        momentum_cols = ['RSI', 'MACD', 'Signal_Line']\n",
    "        lag_cols = ['lag_1', 'lag_2', 'lag_3']\n",
    "\n",
    "        # Load or fit scalers\n",
    "        if not fit_scalers:\n",
    "            with open(scalers_path, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "        else:\n",
    "            self._fit_scalers(df, price_cols, volatility_cols, momentum_cols, lag_cols)\n",
    "            if save_scalers:\n",
    "                with open(scalers_path, 'wb') as f:\n",
    "                    pickle.dump(self.scalers, f)\n",
    "\n",
    "        # Transform data\n",
    "        df = self._transform_features(df, price_cols, volatility_cols, momentum_cols, lag_cols)\n",
    "\n",
    "        # Create sequences\n",
    "        X_scaled, y_scaled = self.create_sequences(df)\n",
    "        X_unscaled, y_unscaled = self.create_sequences(unscaled_data)\n",
    "\n",
    "        # Split data\n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = self.time_based_split(X_scaled, y_scaled)\n",
    "        X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled = self.time_based_split(X_unscaled, y_unscaled)\n",
    "\n",
    "        print(f\"Data preprocessing finished. Training samples: {len(X_train_scaled)}, Test samples: {len(X_test_scaled)}\")\n",
    "        return (X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled,\n",
    "                X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled)\n",
    "\n",
    "    def _fit_scalers(self, df, price_cols, volatility_cols, momentum_cols, lag_cols):\n",
    "        \"\"\"Initialize and fit all scalers\"\"\"\n",
    "        self.scalers = {\n",
    "            'price': RobustScaler().fit(df[price_cols]),\n",
    "            'volume': RobustScaler().fit(np.log1p(df[['volume']])),\n",
    "            'volatility': StandardScaler().fit(df[volatility_cols]),\n",
    "            'momentum': MinMaxScaler().fit(df[momentum_cols]),\n",
    "            'lag': RobustScaler().fit(df[lag_cols])\n",
    "        }\n",
    "\n",
    "    def _transform_features(self, df, price_cols, volatility_cols, momentum_cols, lag_cols):\n",
    "        \"\"\"Apply feature transformations\"\"\"\n",
    "        df[price_cols] = self.scalers['price'].transform(df[price_cols])\n",
    "        df['volume'] = self.scalers['volume'].transform(np.log1p(df[['volume']]))\n",
    "        df[volatility_cols] = self.scalers['volatility'].transform(df[volatility_cols])\n",
    "        df[momentum_cols] = self.scalers['momentum'].transform(df[momentum_cols])\n",
    "        df[lag_cols] = self.scalers['lag'].transform(df[lag_cols])\n",
    "        return df\n",
    "\n",
    "    def create_sequences(self, data):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - self.seq_length):\n",
    "            seq = data.iloc[i:i+self.seq_length].values\n",
    "            target = data.iloc[i+self.seq_length]['close']\n",
    "            X.append(seq)\n",
    "            y.append(target)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def time_based_split(self, X, y):\n",
    "        split_idx = int(len(X) * (1 - self.test_size))\n",
    "        return X[:split_idx], X[split_idx:], y[:split_idx], y[split_idx:]\n",
    "\n",
    "    def inverse_transform_predictions(self, pred_scaled, feature_name='close'):\n",
    "        if feature_name == 'close':\n",
    "            scaler = self.scalers['price']\n",
    "            col_index = 3  # Position of 'close' in price_cols\n",
    "            return pred_scaled * scaler.scale_[col_index] + scaler.center_[col_index]\n",
    "        raise ValueError(f\"Unsupported feature for inversion: {feature_name}\")\n",
    "\n",
    "# ====================== Model Definitions ======================\n",
    "class HybridCNNRNN:\n",
    "    def __init__(self, input_shape):\n",
    "        if input_shape is None:\n",
    "            raise ValueError(\"Input shape must be provided for HybridCNNRNN\")\n",
    "        self.model = self._build_model(input_shape)\n",
    "\n",
    "    def _build_model(self, input_shape):\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = Conv1D(64, 3, dilation_rate=2, activation='relu')(inputs)\n",
    "        x = Dropout(0.4)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(32))(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        outputs = Dense(1)(x)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=Adam(0.001),\n",
    "                       loss=tf.keras.losses.Huber(delta=1.5),  # Changed to Huber\n",
    "                       metrics=['mae', 'mse'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, validation_data, epochs=50):\n",
    "        self.model.fit(X_train, y_train, \n",
    "                      validation_data=validation_data,\n",
    "                      epochs=epochs,\n",
    "                      callbacks=[EarlyStopping(patience=7)], \n",
    "                      batch_size=64, \n",
    "                      verbose=2)\n",
    "\n",
    "class SimpleXGBoost:\n",
    "    def __init__(self):\n",
    "        self.model = XGBRegressor(n_estimators=100, learning_rate=0.01)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X.reshape(X.shape[0], -1))\n",
    "\n",
    "class MetaModel:\n",
    "    def __init__(self, input_shape):\n",
    "        self.model = self._build_model(input_shape)\n",
    "\n",
    "    def _build_model(self, input_shape):\n",
    "        model = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=input_shape),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(0.0008),\n",
    "                      loss=tf.keras.losses.Huber(delta=1.5),  # Changed to Huber\n",
    "                      metrics=['mae', 'mse'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100):\n",
    "        self.model.fit(X_train, y_train, \n",
    "                      epochs=epochs, \n",
    "                      batch_size=32,\n",
    "                      callbacks=[ReduceLROnPlateau(factor=0.5, patience=5)], \n",
    "                      verbose=2)\n",
    "\n",
    "# ====================== Ensemble System ======================\n",
    "class TemporalEnsemble:\n",
    "    def __init__(self, pipeline, models):\n",
    "        self.pipeline = pipeline\n",
    "        self.models = models\n",
    "        self.full_data = None\n",
    "        self.scalers_path = \"scalers.pkl\"\n",
    "        self.model_dir = \"saved_models\"  # Directory to save models\n",
    "\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(self.model_dir, exist_ok=True)\n",
    "\n",
    "    def save_models(self):\n",
    "        \"\"\"Save all models and pipeline to disk\"\"\"\n",
    "        print(\"\\nSaving models and pipeline...\")\n",
    "        \n",
    "        # Save TensorFlow/Keras models\n",
    "        self.models['cnn_rnn'].model.save(os.path.join(self.model_dir, \"cnn_rnn_model.keras\"))\n",
    "        self.models['cnn_rnn_all_data'].model.save(os.path.join(self.model_dir, \"cnn_rnn_all_data_model.keras\"))\n",
    "        self.models['meta'].model.save(os.path.join(self.model_dir, \"meta_model.keras\"))\n",
    "\n",
    "        # Save XGBoost model\n",
    "        self.models['xgb'].model.save_model(os.path.join(self.model_dir, \"xgb_model.json\"))\n",
    "\n",
    "        # Save pipeline with scalers\n",
    "        with open(os.path.join(self.model_dir, \"pipeline.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.pipeline, f)\n",
    "\n",
    "        print(f\"Models and pipeline saved to {self.model_dir}\")\n",
    "\n",
    "    def load_models(self):\n",
    "        \"\"\"Load all models and pipeline from disk\"\"\"\n",
    "        print(\"\\nLoading models and pipeline...\")\n",
    "        \n",
    "        # Load TensorFlow/Keras models\n",
    "        self.models['cnn_rnn'].model = tf.keras.models.load_model(\n",
    "            os.path.join(self.model_dir, \"cnn_rnn_model\")\n",
    "        )\n",
    "        self.models['cnn_rnn_all_data'].model = tf.keras.models.load_model(\n",
    "            os.path.join(self.model_dir, \"cnn_rnn_all_data_model\")\n",
    "        )\n",
    "        self.models['meta'].model = tf.keras.models.load_model(\n",
    "            os.path.join(self.model_dir, \"meta_model\")\n",
    "        )\n",
    "\n",
    "        # Load XGBoost model\n",
    "        self.models['xgb'].model = XGBRegressor()\n",
    "        self.models['xgb'].model.load_model(\n",
    "            os.path.join(self.model_dir, \"xgb_model.json\")\n",
    "        )\n",
    "\n",
    "        # Load pipeline with scalers\n",
    "        with open(os.path.join(self.model_dir, \"pipeline.pkl\"), \"rb\") as f:\n",
    "            self.pipeline = pickle.load(f)\n",
    "\n",
    "        print(f\"Models and pipeline loaded from {self.model_dir}\")\n",
    "\n",
    "    def initialize_models(self, input_shape):\n",
    "        self.models = {\n",
    "            'cnn_rnn': HybridCNNRNN(input_shape),\n",
    "            'xgb': SimpleXGBoost(),\n",
    "            'cnn_rnn_all_data': HybridCNNRNN(input_shape),\n",
    "            'meta': MetaModel((4,))\n",
    "        }\n",
    "\n",
    "    def train_initial_models(self, X_train, y_train, X_val, y_val, X_all, y_all):\n",
    "        # Base CNN-RNN model\n",
    "        print(\"\\nTraining base CNN-RNN...\")\n",
    "        self.models['cnn_rnn'].train(X_train, y_train, (X_val, y_val))\n",
    "        \n",
    "        # XGBoost model trained on all data\n",
    "        print(\"\\nTraining XGBoost on all data...\")\n",
    "        self.models['xgb'].train(X_all, y_all)\n",
    "        \n",
    "        # CNN-RNN trained on all data\n",
    "        print(\"\\nTraining full-data CNN-RNN...\")\n",
    "        self.models['cnn_rnn_all_data'].train(X_all, y_all, (X_all[:1], y_all[:1]))\n",
    "        \n",
    "        # Prepare meta-model data\n",
    "        meta_X_train = self._prepare_meta_input(X_train, X_all, y_train)\n",
    "        print(\"\\nTraining Meta Model...\")\n",
    "        self.models['meta'].train(meta_X_train, y_train)\n",
    "\n",
    "    def _prepare_meta_input(self, X_base, X_all, y_true):\n",
    "        # Generate predictions from all base models\n",
    "        base_preds = [\n",
    "            self.models['cnn_rnn'].model.predict(X_base).flatten(),\n",
    "            self.models['xgb'].predict(X_base),\n",
    "            [x[-1, 3] for x in X_base],  # Naive forecast from scaled data\n",
    "            self.models['cnn_rnn_all_data'].model.predict(X_base).flatten()\n",
    "        ]\n",
    "        return np.column_stack(base_preds)\n",
    "\n",
    "    def predict_next_day(self, new_data):\n",
    "        # Prepare input sequence\n",
    "        seq_scaled, seq_unscaled = self._prepare_input_sequence(new_data)\n",
    "        \n",
    "        # Generate predictions\n",
    "        base_preds = [\n",
    "            self.models['cnn_rnn'].model.predict(seq_scaled).item(),\n",
    "            self.models['xgb'].predict(seq_scaled).item(),\n",
    "            seq_scaled[-1, 3],  # Naive forecast from raw data\n",
    "            self.models['cnn_rnn_all_data'].model.predict(seq_scaled).item()\n",
    "        ]\n",
    "        \n",
    "        # Get final prediction\n",
    "        meta_pred = self.models['meta'].model.predict([base_preds]).item()\n",
    "        return self.pipeline.inverse_transform_predictions([meta_pred], 'close')[0]\n",
    "\n",
    "    def _prepare_input_sequence(self, new_data):\n",
    "        # Update and maintain 30-day window\n",
    "        self.full_data = pd.concat([self.full_data, new_data]).iloc[-30:]\n",
    "        \n",
    "        # Process data using existing scalers\n",
    "        processed = self.pipeline.preprocess_data(\n",
    "            self.full_data.copy(), \n",
    "            fit_scalers=False, \n",
    "            save_scalers=False\n",
    "        )\n",
    "        return processed[0][-1:], self.full_data.iloc[-30:].values[-1:]\n",
    "\n",
    "    def update_models(self, new_data):\n",
    "        # Update data storage\n",
    "        self.full_data = pd.concat([self.full_data, new_data])\n",
    "        \n",
    "        # Process updated data\n",
    "        X_all, y_all, _, _, _, _, _, _ = self.pipeline.preprocess_data(\n",
    "            self.full_data, \n",
    "            fit_scalers=False\n",
    "        )\n",
    "        \n",
    "        # Update models incrementally\n",
    "        print(\"\\nUpdating models with new data...\")\n",
    "        self.models['cnn_rnn'].model.train_on_batch(X_all[-1:], y_all[-1:])\n",
    "        self.models['xgb'].train(X_all, y_all)\n",
    "        self.models['cnn_rnn_all_data'].model.train_on_batch(X_all[-1:], y_all[-1:])\n",
    "\n",
    "# ====================== Main Execution ======================\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize pipeline and load data\n",
    "    pipeline = TimeSeriesPipeline(seq_length=30)\n",
    "    df = pd.read_csv('xrpusdt_daily_dataset_with_features.csv')\n",
    "    \n",
    "    # Preprocess data\n",
    "    (X_train, X_test, y_train, y_test,\n",
    "     X_train_unscaled, X_test_unscaled, _, _) = pipeline.preprocess_data(df)\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    # Prepare combined dataset for full-data models\n",
    "    X_all = np.concatenate([X_train, X_test])\n",
    "    y_all = np.concatenate([y_train, y_test])\n",
    "\n",
    "    # Initialize ALL models\n",
    "    models = {\n",
    "        'cnn_rnn': HybridCNNRNN(input_shape),\n",
    "        'cnn_rnn_all_data': HybridCNNRNN(input_shape),  # Must be present\n",
    "        'meta': MetaModel(input_shape=(4,)),\n",
    "        'xgb': SimpleXGBoost()\n",
    "        \n",
    "        \n",
    "    }\n",
    "\n",
    "    # Initialize ensemble system\n",
    "    ensemble = TemporalEnsemble(pipeline, models)\n",
    "    ensemble.initialize_models(input_shape)\n",
    "    ensemble.full_data = df.copy()\n",
    "\n",
    "    # Train initial models\n",
    "    ensemble.train_initial_models(X_train, y_train, X_test, y_test, X_all, y_all)\n",
    "    ensemble.save_models()\n",
    "\n",
    "        \n",
    "\n",
    "    # Final evaluation\n",
    "    test_preds = ensemble.models['meta'].model.predict(\n",
    "        ensemble._prepare_meta_input(X_test, X_all, y_test)\n",
    "    )\n",
    "    final_preds = pipeline.inverse_transform_predictions(test_preds.flatten(), 'close')\n",
    "    \n",
    "    metrics = {\n",
    "        'MAE': mean_absolute_error(y_test_unscaled, final_preds),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test_unscaled, final_preds)),\n",
    "        'MAPE': np.mean(np.abs((y_test_unscaled - final_preds)/y_test_unscaled)) * 100\n",
    "    }\n",
    "    \n",
    "    print(\"\\nFinal Performance Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test_unscaled, label='Actual')\n",
    "    plt.plot(final_preds, label='Predicted')\n",
    "    plt.title(\"Actual vs Predicted Prices\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig('predviz.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty ensemble\n",
    "ensemble = TemporalEnsemble(None, {})\n",
    "\n",
    "# Load saved models\n",
    "ensemble.load_models()\n",
    "\n",
    "# Make predictions\n",
    "new_data = pd.read_csv('new_data.csv')\n",
    "prediction = ensemble.predict_next_day(new_data)\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4bd5f93e-4bb7-4aee-aab6-2fc0a03c4fbf",
       "rows": [
        [
         "0",
         "0.0022497187851518697",
         "-0.03045195476363768",
         "-0.005081095336468633",
         "-0.017224446626879282",
         "-1.7260242115105275",
         "-0.017274774487141768",
         "-0.3419838523644657",
         "0",
         "-0.01129210890076084",
         "0.30168086677940253",
         "0.008179476211545146",
         "0.24743905674173505",
         "0.28221482220963023",
         "0.05481817254292185",
         "0.2041491299262795",
         "0.1569512895024554",
         "0.12949255712314614",
         "0.1259884261792715",
         "-0.147777297683155",
         "-0.14454267971882137",
         "-0.10594952246917169",
         "0.0020486469694296332",
         "-0.04682841618167011",
         "-0.07107272773096539"
        ],
        [
         "1",
         "-0.01705756929637518",
         "0.05298836382072267",
         "0.0017054195419981995",
         "0.07571369813569694",
         "-1.5382809590473325",
         "0.029449701799420316",
         "1.5859284890426852",
         "1",
         "-0.007122344034524733",
         "0.28366001701359744",
         "0.0272823168628138",
         "0.23785137707764561",
         "0.33145437238397046",
         "0.059067871677861664",
         "0.1955654413673134",
         "0.16338809382812158",
         "0.1304944699986076",
         "0.11475320126956338",
         "-0.17440428224738094",
         "-0.1574779916636851",
         "-0.10449292180491827",
         "-0.017228785169139397",
         "0.0027210198785618156",
         "-0.04600404929725365"
        ],
        [
         "2",
         "0.07330053892517173",
         "0.1334521755484868",
         "0.09316513559843516",
         "0.057246942492843976",
         "-1.4518020326839227",
         "0.11562775372591093",
         "-0.2831603229527064",
         "0",
         "0.008014143456783331",
         "0.25939868579541514",
         "0.03697390853870205",
         "0.22761903286811022",
         "0.2904863937305523",
         "0.05975573342704888",
         "0.1861753106240677",
         "0.16840331641586592",
         "0.13244449112831624",
         "0.10719122797417116",
         "-0.1808648157942084",
         "-0.16320036271825014",
         "-0.10818947385057039",
         "0.0757327691158072",
         "-0.016561269137419874",
         "0.0035620374181949735"
        ],
        [
         "3",
         "0.05839195473700123",
         "0.09420153568128477",
         "0.09808799613203811",
         "0.07930632150621565",
         "-1.8647342226048227",
         "0.09757821113707874",
         "0.3517877739331105",
         "1",
         "0.018074605047343782",
         "0.24004387562087107",
         "0.04977996411353501",
         "0.2195558190108446",
         "0.32938459892113964",
         "0.06381155329152252",
         "0.1792036033482284",
         "0.1739403957546568",
         "0.13527250456277895",
         "0.0957815749151806",
         "-0.22007740058241215",
         "-0.17950552024561486",
         "-0.10174310455491714",
         "0.05726136201439076",
         "0.07642370646578149",
         "-0.015726731242596468"
        ],
        [
         "4",
         "0.08142638886557091",
         "0.07768355807050394",
         "0.06102588897191333",
         "0.032065002979862665",
         "-1.7518429770661466",
         "0.07103176123520184",
         "-0.8552479815455529",
         "0",
         "0.03309057910321143",
         "0.21672138833315382",
         "0.04752595468688384",
         "0.2087812544902079",
         "0.31082544513062277",
         "0.059804112161869226",
         "0.1690587274703617",
         "0.1769285319191924",
         "0.13821920138574148",
         "0.08625985006019478",
         "-0.23412962515905325",
         "-0.1882514796074857",
         "-0.10398292292157345",
         "0.07932629740644645",
         "0.05794764556196617",
         "0.07728949114951325"
        ],
        [
         "5",
         "0.034988163792958674",
         "0.007719292507216305",
         "0.02093973891257522",
         "0.03233361033466788",
         "-1.8622312436384783",
         "0.015197374302389564",
         "-0.05305651672432558",
         "0",
         "0.04454899654487989",
         "0.19347202708022196",
         "0.04590287363598736",
         "0.19872019733934232",
         "0.43762587269495823",
         "0.05645549916432488",
         "0.15968630236652867",
         "0.1798700795754698",
         "0.14125017610599627",
         "0.07672273448615545",
         "-0.2524685853808886",
         "-0.19812170954421687",
         "-0.10448632835938505",
         "0.03207307960336834",
         "0.0800181401325238",
         "0.05880722152680356"
        ],
        [
         "6",
         "0.030690193576549143",
         "0.02878380256928138",
         "0.043233264471891325",
         "0.05906004213777858",
         "-1.8098130645822685",
         "0.03695899263118926",
         "0.4798154555940109",
         "1",
         "0.052734269079988544",
         "0.17075341930556823",
         "0.05139445174745215",
         "0.1911364710515037",
         "0.43785549830133086",
         "0.05783078078807341",
         "0.15309549040913537",
         "0.18384675323361765",
         "0.14458561800093045",
         "0.06967207507934799",
         "-0.2696794068059241",
         "-0.20636971110775446",
         "-0.10336776552987909",
         "0.032341754615752664",
         "0.032753017056763443",
         "0.08088513269429501"
        ],
        [
         "7",
         "0.06010442724510193",
         "0.028718384836169494",
         "0.08293261834644636",
         "0.03961958483375715",
         "-1.731066439432143",
         "0.05614940253459868",
         "-0.35928489042675527",
         "0",
         "0.0608954389280087",
         "0.14799588960917376",
         "0.05063317719927942",
         "0.18271218651964144",
         "0.4739703352320349",
         "0.0559331102173572",
         "0.14547456876386383",
         "0.18666070418068398",
         "0.1478983690087886",
         "0.05948854930502374",
         "-0.30515547384258707",
         "-0.22104694772534597",
         "-0.09741932484154832",
         "0.05907491834798432",
         "0.033021759760819024",
         "0.033604126586744894"
        ],
        [
         "8",
         "0.03834595302452861",
         "0.0091911915022364",
         "0.06552679003120744",
         "0.018970394433112346",
         "-1.8657217902859957",
         "0.037554968094027995",
         "-0.3402537485582431",
         "0",
         "0.05274873069224145",
         "0.12624679152150814",
         "0.04487884607046542",
         "0.1734188895208753",
         "0.425881054676126",
         "0.051075674285056105",
         "0.13680543866150854",
         "0.18848113318851076",
         "0.1509654498207725",
         "0.046604807376600964",
         "-0.36746517051396965",
         "-0.24415302360914679",
         "-0.08278214647749868",
         "0.03962956432667516",
         "0.05976165881434071",
         "0.03387295959943893"
        ],
        [
         "9",
         "0.01846784077363466",
         "-0.019036560335592943",
         "-0.04520240868533251",
         "-0.08051505460283903",
         "-1.7528434798811297",
         "-0.03076084781766557",
         "-1.7076124567474091",
         "0",
         "0.03297006566777101",
         "0.10989486658184419",
         "0.015590185902718153",
         "0.15791982504506452",
         "0.4214144111085655",
         "0.031299144973366035",
         "0.12100855930175199",
         "0.18620940911657397",
         "0.1528988874579464",
         "0.030223952063040706",
         "-0.41084988385912014",
         "-0.264200514041129",
         "-0.0787964740285411",
         "0.018975172749636646",
         "0.04031140560832435",
         "0.060621844362487735"
        ],
        [
         "10",
         "-0.08337390661988155",
         "-0.09112690222502062",
         "-0.04200254933849054",
         "-0.06255193775024565",
         "-1.808333319275782",
         "-0.06674073790276235",
         "0.35005767012688216",
         "1",
         "0.012603295078351768",
         "0.09206508806821925",
         "-0.001867194196326451",
         "0.14464947315870746",
         "0.37615765073227614",
         "0.017393886037394307",
         "0.10778475545753369",
         "0.18566332204646074",
         "0.15432058309979843",
         "0.015542916165043443",
         "-0.4758638125427897",
         "-0.28897093180811007",
         "-0.06456095002010587",
         "-0.0805353349621758",
         "0.01965181023405799",
         "0.041165055068762585"
        ],
        [
         "11",
         "-0.061447542937729756",
         "-0.09773409326933302",
         "-0.09815832271108967",
         "-0.10274231321296372",
         "-1.76008947363956",
         "-0.09737387669267704",
         "-0.7168396770472822",
         "0",
         "-0.006751162653368458",
         "0.07804729898080591",
         "-0.02504884737722468",
         "0.12948603708884834",
         "0.4185905921374813",
         "-0.0007010494022254827",
         "0.09240158655370226",
         "0.18404636941285524",
         "0.155087655894326",
         "0.007777443362154253",
         "-0.4535042586304153",
         "-0.28729875248997744",
         "-0.08018863376233895",
         "-0.06256769350897975",
         "-0.0798837687804961",
         "0.020498517217914347"
        ],
        [
         "12",
         "-0.1015395463626748",
         "-0.11156994382252176",
         "-0.07561865412509336",
         "-0.10008981558426316",
         "-1.6884679383553745",
         "-0.09366180095270933",
         "0.017301038062283843",
         "1",
         "-0.025763362228438044",
         "0.06730484858045567",
         "-0.0417692553243667",
         "0.11548233219409648",
         "0.3893217765741318",
         "-0.015594448685841554",
         "0.07836507419974263",
         "0.18339840215494105",
         "0.15555292900039375",
         "-0.0012021861661373177",
         "-0.4445518833382151",
         "-0.2897658449474614",
         "-0.09136202581200373",
         "-0.10276819223697144",
         "-0.06191160044678477",
         "-0.07907050985861064"
        ],
        [
         "13",
         "-0.09969276228531135",
         "-0.11415394428044594",
         "-0.07213748846204561",
         "-0.09639646445569261",
         "-1.8520524322132284",
         "-0.09332124354537291",
         "0.049019607843137546",
         "1",
         "-0.04808245047199077",
         "0.05326347044956276",
         "-0.053382453522210875",
         "0.10263473703601857",
         "0.31994317167135",
         "-0.027614948268210406",
         "0.06565675769491677",
         "0.18356047238483475",
         "0.15596226172484234",
         "-0.007131033161869334",
         "-0.43091705371549077",
         "-0.2893838258601756",
         "-0.10189126452435271",
         "-0.10011502648967721",
         "-0.10212222754108821",
         "-0.06109230213470207"
        ],
        [
         "14",
         "-0.0962342393767944",
         "-0.09537905487730092",
         "-0.05775570304602001",
         "-0.0689649383462183",
         "-1.6710872604578402",
         "-0.076582846974786",
         "0.46078431372549866",
         "1",
         "-0.0636720684805545",
         "0.04314730915358071",
         "-0.05520646997084061",
         "0.092492481595684",
         "0.38492851187553623",
         "-0.033466382671810596",
         "0.05603222593108029",
         "0.1853468889673525",
         "0.15669881903176544",
         "-0.013020548320017146",
         "-0.43112740505034225",
         "-0.29258537052817657",
         "-0.1067377158907345",
         "-0.09642074506939396",
         "-0.09946839333854034",
         "-0.10131644165903561"
        ],
        [
         "15",
         "-0.06833101086244811",
         "0.021587851926961082",
         "-0.028183376554876675",
         "0.04828217202622262",
         "-1.5072560832904682",
         "-0.0013707435645291496",
         "1.9953863898500694",
         "1",
         "-0.05946373931497736",
         "0.03712974416208028",
         "-0.027143024973728443",
         "0.0910248925560531",
         "0.4193798952493567",
         "-0.019954201823777707",
         "0.0562777319274235",
         "0.19213719936363516",
         "0.15884305253379533",
         "-0.00810748878187569",
         "-0.427007183292458",
         "-0.28888761727758916",
         "-0.10430453002695723",
         "-0.06898230942965353",
         "-0.0957731811577773",
         "-0.09866171565868291"
        ],
        [
         "16",
         "0.048452898611554156",
         "0.1340736440130509",
         "0.05269218935431416",
         "0.13406864596711207",
         "-1.3841568773221378",
         "0.0963522044706674",
         "1.46309111880047",
         "1",
         "-0.028655684679006553",
         "0.03490175900548578",
         "0.015438743621558997",
         "0.09552023878616767",
         "0.5392072239443687",
         "0.004988338080955353",
         "0.06320505651116555",
         "0.20145643954434592",
         "0.16269255436156232",
         "-0.0017494117325159465",
         "-0.39498493937212015",
         "-0.2771535250328667",
         "-0.11204725501221592",
         "0.04829433347606677",
         "-0.0683278325061098",
         "-0.09496526173414101"
        ],
        [
         "17",
         "0.13165891576985722",
         "0.1506243304903876",
         "0.08328425124170366",
         "0.07161743597491865",
         "-1.3743734960529819",
         "0.1197825540954159",
         "-1.0386389850057673",
         "0",
         "-0.009392817158221111",
         "0.029002139231380487",
         "0.03169852062917377",
         "0.09545356701663585",
         "0.4462491688428838",
         "0.01625910999957144",
         "0.06474174776319049",
         "0.20645891363017266",
         "0.16691772723383078",
         "0.0055919612564298915",
         "-0.39523904349052247",
         "-0.27329717028375355",
         "-0.1057953849445201",
         "0.13410241555628294",
         "0.048978357814113985",
         "-0.06751069031277042"
        ],
        [
         "18",
         "0.07182311166328098",
         "0.051680009158482566",
         "0.06939475187903826",
         "0.03196427522181083",
         "-1.6081525286688472",
         "0.06154723744088155",
         "-0.6920415224913421",
         "0",
         "0.009947178961246767",
         "0.02057259454414894",
         "0.03393958731645363",
         "0.09267870908326714",
         "0.4540544507598324",
         "0.019551567353542364",
         "0.06306766092204175",
         "0.2089745770678834",
         "0.1708739548950521",
         "0.009638010287840603",
         "-0.3985764611033148",
         "-0.272004251362832",
         "-0.1010450308464548",
         "0.07163547517694756",
         "0.13480805892183773",
         "0.04983491972814266"
        ],
        [
         "19",
         "0.032671289223175526",
         "-0.006214684645640358",
         "-0.07213748846204561",
         "-0.07709031082907351",
         "-1.520639378349052",
         "-0.03712927133485728",
         "-1.8927335640138465",
         "0",
         "0.013249247092311834",
         "0.009394926291610458",
         "0.008245423580629803",
         "0.08262295923652029",
         "0.35852661546023024",
         "0.005164209422921661",
         "0.053000314879116585",
         "0.20661430395400707",
         "0.17349843219526068",
         "0.005607351975484539",
         "-0.3880270466776232",
         "-0.2714113109274124",
         "-0.10872551873390858",
         "0.03197232647372434",
         "0.0723253802289352",
         "0.13569346315727565"
        ],
        [
         "20",
         "-0.07689337340295144",
         "-0.06607191044312334",
         "-0.059478704232780996",
         "-0.04126480488193875",
         "-1.8126729402985224",
         "-0.06216024077408703",
         "0.6043829296424544",
         "1",
         "0.021164569532034397",
         "1.710205652213386e-05",
         "-0.0020322539248647693",
         "0.07566662302052472",
         "0.36764953226300146",
         "-0.0013681160395174348",
         "0.04647670384756999",
         "0.20651242218143423",
         "0.17557468301084614",
         "0.004382934770712456",
         "-0.3856778584698502",
         "-0.27145391075683933",
         "-0.11070957185575195",
         "-0.07710972855427668",
         "0.03265223854274272",
         "0.07318978770593038"
        ],
        [
         "21",
         "-0.04240887799472819",
         "-0.04942309736611855",
         "-0.01977935035822597",
         "-0.06298842470180405",
         "-1.7118258716025756",
         "-0.03426858911323101",
         "-0.3610149942329837",
         "0",
         "0.022022625192369662",
         "-0.003942318891432998",
         "-0.01519359134803765",
         "0.0676730712951011",
         "0.36597618657368475",
         "-0.010316377944231958",
         "0.038739688144118635",
         "0.20577725731783547",
         "0.17706733019761614",
         "-0.002681405275253914",
         "-0.3887367441880052",
         "-0.27602477978945816",
         "-0.11537749268289647",
         "-0.041275198777528777",
         "-0.07645729930378846",
         "0.03350331420698474"
        ],
        [
         "22",
         "-0.0628242365226735",
         "-0.05066603429524659",
         "-0.0330359105094281",
         "-0.07507575566803504",
         "-1.7618153447903282",
         "-0.04133515531546249",
         "-0.21799307958476485",
         "0",
         "0.004311970720055608",
         "-0.009256930387258486",
         "-0.028098765274549842",
         "0.05936839471411404",
         "0.37230958076127085",
         "-0.01979142691090194",
         "0.030631752809700357",
         "0.2049568182434932",
         "0.17807356660449367",
         "-0.009420830141183981",
         "-0.3882537609677896",
         "-0.2794999239915553",
         "-0.12121864891573035",
         "-0.0630042904041042",
         "-0.04061374115038672",
         "-0.0756428889467626"
        ],
        [
         "23",
         "-0.0742071420176956",
         "-0.025185827248121413",
         "-0.04752318579403101",
         "-0.028539531448045673",
         "-1.4666746033107612",
         "-0.035085926890838566",
         "0.7768166089965444",
         "1",
         "-0.019033891993448668",
         "-0.010962418230792298",
         "-0.026096087911774042",
         "0.054782829518908525",
         "0.5032435338519927",
         "-0.02048052148907148",
         "0.02675892811322363",
         "0.20652763682786407",
         "0.17923827470699882",
         "-0.014913606763708152",
         "-0.4013203307904532",
         "-0.285836593913057",
         "-0.12048656481737524",
         "-0.07509466596139493",
         "-0.062348307340875014",
         "-0.03978728587870579"
        ],
        [
         "24",
         "-0.03320853550022669",
         "-0.03408263895135386",
         "5.274493428855783e-05",
         "-0.02534981910973469",
         "-1.4833702037274727",
         "-0.016678799024303033",
         "0.1274509803921634",
         "1",
         "-0.03295560405551829",
         "-0.013492343143918348",
         "-0.023793395912976925",
         "0.05071130056635691",
         "0.4901463257569708",
         "-0.020561304127135752",
         "0.02342209885075385",
         "0.20814345391401465",
         "0.18054006486649",
         "-0.017837843384042654",
         "-0.40520386974761274",
         "-0.2884100949118119",
         "-0.12135075579625616",
         "-0.028546720065825593",
         "-0.07444172902337229",
         "-0.06152915578032982"
        ],
        [
         "25",
         "-0.025082685559827338",
         "-0.03378825915234974",
         "-0.0215726781240385",
         "-0.059328649492583985",
         "-1.576653291878843",
         "-0.026997688466597634",
         "-0.5957324106112954",
         "0",
         "-0.04606264529401062",
         "-0.013883921265669985",
         "-0.03059576832899559",
         "0.044578117777321395",
         "0.4965887741391912",
         "-0.025980447701700247",
         "0.017678663548021993",
         "0.2082235745358311",
         "0.1815998446940679",
         "-0.0225063614972093",
         "-0.4075913451245834",
         "-0.29152607041749606",
         "-0.12428623310575031",
         "-0.025356204293762737",
         "-0.027882055545757754",
         "-0.07362664135155794"
        ],
        [
         "26",
         "-0.06218625656867513",
         "-0.05625925047632284",
         "-0.02642521207858992",
         "-0.03978746443051053",
         "-1.6387533282756837",
         "-0.041045681519226496",
         "0.3771626297577935",
         "1",
         "-0.04070702822304133",
         "-0.015605921439639266",
         "-0.03079230475207884",
         "0.040177345423821176",
         "0.5114844715728207",
         "-0.027488644451151442",
         "0.013886852810907405",
         "0.20933514339011194",
         "0.18270221890020483",
         "-0.027540836707890672",
         "-0.41935015468979825",
         "-0.2972773949056459",
         "-0.1237039974817323",
         "-0.05934359336036883",
         "-0.024690735935098723",
         "-0.02705132190232962"
        ],
        [
         "27",
         "-0.039621912932525157",
         "-0.06649712570835144",
         "-0.012254406399718743",
         "-0.03673205576960224",
         "-1.8312292545196738",
         "-0.03951317318621241",
         "0.042099192618224014",
         "1",
         "-0.040056255671663564",
         "-0.014348625422207014",
         "-0.030172736102221775",
         "0.03626950010670884",
         "0.5109366170848475",
         "-0.02828366290561252",
         "0.01061454723038113",
         "0.21055354516459682",
         "0.18386313345137278",
         "-0.031429558388967604",
         "-0.42777590430058404",
         "-0.3015487821733393",
         "-0.12352236070603921",
         "-0.03979748620941548",
         "-0.05868668799811877",
         "-0.023858929876588837"
        ],
        [
         "28",
         "-0.036499168947165164",
         "-0.06774006263747946",
         "-0.00532723836314883",
         "-0.047677805477911395",
         "-1.7386751474420734",
         "-0.036805741797887606",
         "-0.19953863898500118",
         "0",
         "-0.037858090609231544",
         "-0.01435570213525073",
         "-0.03245566989282122",
         "0.03186502621549468",
         "0.47497207644581285",
         "-0.030680043976147896",
         "0.006729761319356473",
         "0.21125693170061907",
         "0.1849529412902163",
         "-0.03482406698040941",
         "-0.4324498136718125",
         "-0.304579322578009",
         "-0.12445786115049291",
         "-0.036741307943544875",
         "-0.03913565627808151",
         "-0.05786630598237451"
        ],
        [
         "29",
         "-0.047512717626714565",
         "-0.07519768421224786",
         "-0.06222144081578835",
         "-0.07390059849076253",
         "-1.7141257710038078",
         "-0.06823919049504275",
         "-0.46078431372548145",
         "0",
         "-0.037689371799615075",
         "-0.017023622952729148",
         "-0.0407503353496106",
         "0.025950933106405512",
         "0.31338161141439946",
         "-0.03683716431258289",
         "0.0010847125553428846",
         "0.21091067516284429",
         "0.1857454944788257",
         "-0.03448718124110766",
         "-0.43342384288725166",
         "-0.3046529113627262",
         "-0.12377825429559682",
         "-0.047689814698202555",
         "-0.03607870801945036",
         "-0.038308704308889024"
        ],
        [
         "30",
         "-0.0709836643553884",
         "-0.1072523734371296",
         "-0.0869060700628543",
         "-0.10761082151880678",
         "-1.7232241424974495",
         "-0.09688006845203878",
         "-0.6366782006920337",
         "0",
         "-0.04904173741809603",
         "-0.02019870820500689",
         "-0.05543329983822733",
         "0.01811243544259765",
         "0.14403492350344732",
         "-0.0473555256736068",
         "-0.006774984539811447",
         "0.20943324311562034",
         "0.1860412036601523",
         "-0.036782108460107064",
         "-0.42577963575578454",
         "-0.3038889340545537",
         "-0.12881958268343346",
         "-0.07391921278221382",
         "-0.047029973209711744",
         "-0.03525072878949536"
        ],
        [
         "31",
         "-0.10744925541023782",
         "-0.05030623676313058",
         "-0.08722253966858604",
         "-0.07027439920089332",
         "-1.5391058951589622",
         "-0.0673877969767015",
         "0.6309111880046173",
         "1",
         "-0.05549161648286354",
         "-0.025326966257347525",
         "-0.0570733065509254",
         "0.013333657615372932",
         "0.2615188521986795",
         "-0.05037615446547494",
         "-0.011136472187112556",
         "0.2100540325705542",
         "0.18641993239156648",
         "-0.03512846120170706",
         "-0.43139280848951983",
         "-0.3044667708003212",
         "-0.12514411761888244",
         "-0.10763792683643579",
         "-0.07326597969312944",
         "-0.04620567405677413"
        ],
        [
         "32",
         "-0.06906972449339349",
         "-0.09917328339779709",
         "-0.08096347413300517",
         "-0.12624545675841295",
         "-1.682884142757647",
         "-0.08979647437944055",
         "-0.9896193771626242",
         "0",
         "-0.06509894755616814",
         "-0.03177267238799288",
         "-0.07235320831370916",
         "0.005034469342098437",
         "0.2471678529470298",
         "-0.06174606848807101",
         "-0.01954627885904735",
         "0.20841418021820096",
         "0.18634738759997452",
         "-0.036460613439859964",
         "-0.4244359291231978",
         "-0.30336732595174504",
         "-0.12909867111135395",
         "-0.0702921001150267",
         "-0.1069931890520941",
         "-0.07245049692102182"
        ],
        [
         "33",
         "-0.12454040259892893",
         "-0.10797196850136162",
         "-0.09218056349171456",
         "-0.09072213408543407",
         "-1.4442001233085464",
         "-0.0998088621551324",
         "0.5732410611303437",
         "1",
         "-0.07241170281868861",
         "-0.037745418196882985",
         "-0.07489604361090253",
         "-0.00029930280030480695",
         "0.43283333452853556",
         "-0.06577275825067162",
         "-0.02455873201138332",
         "0.2088435969969892",
         "0.18638768862489102",
         "-0.036171609937616006",
         "-0.4255347679404643",
         "-0.30349899236636774",
         "-0.1284082327150687",
         "-0.12627725582059235",
         "-0.06963795318838034",
         "-0.10618904001411364"
        ],
        [
         "34",
         "-0.08841059046723646",
         "-0.11186432362152572",
         "-0.08476110940178445",
         "-0.12590969756490655",
         "-1.6424078409492775",
         "-0.09824229808138464",
         "-0.6516724336793465",
         "0",
         "-0.08521505019987134",
         "-0.043294740675324635",
         "-0.08563597858482747",
         "-0.007695977521695756",
         "0.3215125358030223",
         "-0.07472109058918912",
         "-0.03194807410637294",
         "0.2079357338347773",
         "0.1862120279015022",
         "-0.0390719054394219",
         "-0.4142142930249654",
         "-0.3021013519680401",
         "-0.13545672523754768",
         "-0.09074498543277683",
         "-0.1256372141459441",
         "-0.06882125124965346"
        ],
        [
         "35",
         "-0.12578278461460973",
         "-0.13786787253354707",
         "-0.08602698782471102",
         "-0.1102968950668582",
         "-1.6455123639103708",
         "-0.11239245835621454",
         "0.258362168396772",
         "1",
         "-0.0942053524837215",
         "-0.04830505351027072",
         "-0.08977179245555864",
         "-0.013547448506797021",
         "0.37879432833360027",
         "-0.0798341428754333",
         "-0.03757068298331829",
         "0.2081124321914788",
         "0.18611196341759073",
         "-0.04714861278318887",
         "-0.42118215874019194",
         "-0.3082308298861916",
         "-0.13937732272804437",
         "-0.12594141205511208",
         "-0.09009599153460489",
         "-0.12483933026975703"
        ],
        [
         "36",
         "-0.11057199939559802",
         "-0.1380641257328831",
         "-0.17667794822205604",
         "-0.18282088086424433",
         "-1.5239800174656992",
         "-0.15639247538408488",
         "-1.2485582468281389",
         "0",
         "-0.10984317586646129",
         "-0.05680182697141786",
         "-0.11107867801340116",
         "-0.023982432455436426",
         "0.30667723331228425",
         "-0.09558122817064724",
         "-0.04844099374560254",
         "0.20545535243114305",
         "0.1854234379922261",
         "-0.0632883468315637",
         "-0.4577101211352416",
         "-0.3263643405730438",
         "-0.13798777525268743",
         "-0.11032467696027826",
         "-0.12530128576587476",
         "-0.08928616434098104"
        ],
        [
         "37",
         "-0.18138777428940794",
         "-0.20779942923027866",
         "-0.2730253615225704",
         "-0.2978855564788934",
         "-1.5124377574210104",
         "-0.23935225981124644",
         "-2.008650519031143",
         "0",
         "-0.13716116141207993",
         "-0.0686576802239778",
         "-0.15594246311024612",
         "-0.04161522880224165",
         "0.1362241693996744",
         "-0.12702540237174403",
         "-0.06749275557952758",
         "0.19883142270897547",
         "0.18335573133093855",
         "-0.08210777607529804",
         "-0.4054391358162599",
         "-0.32281090176876354",
         "-0.17507886720241728",
         "-0.1828669303040228",
         "-0.10968061609264912",
         "-0.12450328900388961"
        ],
        [
         "38",
         "-0.29773517116330606",
         "-0.3289530709537087",
         "-0.46498175904355826",
         "-0.45542377007210444",
         "-1.051788318383273",
         "-0.3953786359824443",
         "-2.7162629757785575",
         "0",
         "-0.19245754612953023",
         "-0.0853221599897388",
         "-0.22913566213023875",
         "-0.06888687895846352",
         "0.06664058703504872",
         "-0.1784402150173027",
         "-0.09743715829515687",
         "0.18740091988740942",
         "0.17908396978646068",
         "-0.10693129583014094",
         "-0.2592324664757735",
         "-0.29800940054895586",
         "-0.25553084344524457",
         "-0.297960588734121",
         "-0.18224114618763293",
         "-0.1088773701410533"
        ],
        [
         "39",
         "-0.45440961670835933",
         "-0.3964641715252963",
         "-0.4343193705771172",
         "-0.4138232059966593",
         "-1.3243114682902744",
         "-0.41567585745969726",
         "0.6891580161476454",
         "1",
         "-0.2337454491113942",
         "-0.0970305817205554",
         "-0.27358795668838565",
         "-0.09155336747799932",
         "0.13843112542648828",
         "-0.21539404105781848",
         "-0.121914413965196",
         "0.18065291412223636",
         "0.1741212606958791",
         "-0.12408168709642083",
         "-0.1742440562196913",
         "-0.285046242926448",
         "-0.3045752730131032",
         "-0.45553848349747716",
         "-0.2973638020374057",
         "-0.18146228356842223"
        ],
        [
         "40",
         "-0.41367963332941593",
         "-0.43277101340245816",
         "-0.48931475539536695",
         "-0.49819949132482205",
         "-1.5507462066953057",
         "-0.4612083828205817",
         "-1.4596309111880075",
         "0",
         "-0.2922474912115578",
         "-0.11233397367757604",
         "-0.3281073758542177",
         "-0.11852928958721909",
         "0.08240606871247752",
         "-0.2599497508827238",
         "-0.15116840674674203",
         "0.17238835231641908",
         "0.16825850076647242",
         "-0.1473541643865596",
         "-0.07441618235550888",
         "-0.27149068898416734",
         "-0.3648023520293489",
         "-0.41392744095446815",
         "-0.4549813979659538",
         "-0.29662362538119674"
        ],
        [
         "41",
         "-0.49806087671876853",
         "-0.5204634846390986",
         "-0.5770823260516019",
         "-0.5691454089127279",
         "-1.3747607217503497",
         "-0.5493616677096238",
         "-1.2289504036908838",
         "0",
         "-0.3558834056614799",
         "-0.12871774382593662",
         "-0.38680583752122144",
         "-0.14861790856803192",
         "0.05937896983570562",
         "-0.3088228875324676",
         "-0.18379637992194708",
         "0.1635907778984333",
         "0.16155363976164935",
         "-0.17313361880267059",
         "0.03442016412230621",
         "-0.2569292712935316",
         "-0.43080506505461297",
         "-0.49832497921966734",
         "-0.4133598716753589",
         "-0.4542941873262037"
        ],
        [
         "42",
         "-0.5715628829978343",
         "-0.5554619718540204",
         "-0.553839391675091",
         "-0.57710290179883",
         "-1.6357673373508979",
         "-0.5563260666896545",
         "-0.10322952710495449",
         "0",
         "-0.42290333737856745",
         "-0.14547422086126574",
         "-0.4328271795870698",
         "-0.1773096612554298",
         "0.06010901686604869",
         "-0.3514301798858236",
         "-0.2146289538662721",
         "0.15710689798541294",
         "0.15470493617871425",
         "-0.19870273339170375",
         "0.11962203505029341",
         "-0.2484086803717961",
         "-0.48698702737938526",
         "-0.5692887668656543",
         "-0.49777867358679156",
         "-0.4126586744852268"
        ],
        [
         "43",
         "-0.5760287426758223",
         "-0.5567049087831484",
         "-0.6338007120566126",
         "-0.6481831230641386",
         "-1.4622805868465298",
         "-0.5956945029777491",
         "-1.2474048442906591",
         "0",
         "-0.48971598598669785",
         "-0.16485733788798448",
         "-0.4851857964386318",
         "-0.20901259915488685",
         "0.04969999430097402",
         "-0.39867580496187527",
         "-0.24872906550966448",
         "0.1498729824434167",
         "0.14756939964791865",
         "-0.23026225785268656",
         "0.20381374683314024",
         "-0.24335177152170817",
         "-0.5477735571494993",
         "-0.5772482641075374",
         "-0.5687603402954492",
         "-0.4971058445977168"
        ],
        [
         "44",
         "-0.6480533216929975",
         "-0.6603265980325616",
         "-0.7201265878422923",
         "-0.654226788547254",
         "-1.2597500805007025",
         "-0.6914422180503943",
         "-0.11418685121106181",
         "0",
         "-0.540876349599835",
         "-0.18541636873213307",
         "-0.5259718445068693",
         "-0.23908360515717428",
         "0.05598313133669536",
         "-0.43960459370372107",
         "-0.28077525890989813",
         "0.14485046051900458",
         "0.140710808038777",
         "-0.2622920542847759",
         "0.2639774010912339",
         "-0.24480181037510773",
         "-0.5991487176551352",
         "-0.6483463892597167",
         "-0.5767218429030933",
         "-0.5681113640755086"
        ],
        [
         "45",
         "-0.6530900055403523",
         "-0.5784890139094455",
         "-0.6284207287591752",
         "-0.6277353881795978",
         "-1.0485991999975135",
         "-0.6044298004759292",
         "0.42733564013841085",
         "1",
         "-0.5656153476270301",
         "-0.2091634588024729",
         "-0.5499114894251157",
         "-0.265402393257437",
         "0.0425500740892685",
         "-0.470064933711754",
         "-0.3083786569473027",
         "0.14297674518822762",
         "0.13479485212620834",
         "-0.29124199682609136",
         "0.301574071429871",
         "-0.2504815684404507",
         "-0.6387356113485757",
         "-0.6543915770383619",
         "-0.6478378809637788",
         "-0.5760755420765671"
        ],
        [
         "46",
         "-0.6289139230730487",
         "-0.5801244572372456",
         "-0.6189266405872266",
         "-0.5907011491358399",
         "-1.4159422388439709",
         "-0.6006836689952282",
         "0.6482122260669012",
         "1",
         "-0.5910099387430208",
         "-0.23462311342938985",
         "-0.5585698607315145",
         "-0.28748985566551777",
         "0.10286369588027416",
         "-0.49000713050419664",
         "-0.3310449499683934",
         "0.14403177303603343",
         "0.13030368979499063",
         "-0.31930098774214694",
         "0.30858444267616625",
         "-0.26364840122507033",
         "-0.665094909331276",
         "-0.6278935039419665",
         "-0.6538845918050273",
         "-0.647215478060706"
        ],
        [
         "47",
         "-0.589929990094522",
         "-0.34063013631420136",
         "-0.5649509911652233",
         "-0.33626283229667686",
         "-0.9238716162169319",
         "-0.44986782115627766",
         "4.34890426758942",
         "1",
         "-0.5677604867778684",
         "-0.24895109843855256",
         "-0.5011943426265767",
         "-0.290747383333133",
         "0.3092661219388505",
         "-0.46681382735221993",
         "-0.3321603867147615",
         "0.1564503910917982",
         "0.12955463549098764",
         "-0.3345566104848416",
         "0.27032308828914575",
         "-0.28176081629463723",
         "-0.6622575945610094",
         "-0.5908499366094895",
         "-0.6273798426175543",
         "-0.65326422084632"
        ],
        [
         "48",
         "-0.3360811241878348",
         "-0.35718082279153823",
         "-0.49624192343193685",
         "-0.4669067344900238",
         "-0.9691972416564664",
         "-0.425211464865118",
         "-2.2549019607843155",
         "0",
         "-0.5530819503412335",
         "-0.2664753988391242",
         "-0.4909570340836624",
         "-0.30273148723815696",
         "0.27053753954994275",
         "-0.4677617682957135",
         "-0.34339661002670163",
         "0.1615456190612805",
         "0.13012220418701992",
         "-0.35590866805297117",
         "0.23628445871776557",
         "-0.3020311867459988",
         "-0.6662490399315486",
         "-0.3363475311285191",
         "-0.5903269422959027",
         "-0.6267505649693784"
        ],
        [
         "49",
         "-0.46612830112653836",
         "-0.41340736440130504",
         "-0.4765153180079994",
         "-0.42084057314094353",
         "-1.154780044017371",
         "-0.444929738749899",
         "0.7698961937716308",
         "1",
         "-0.530647169199658",
         "-0.2785506301960397",
         "-0.47171549040222754",
         "-0.3107912521554567",
         "0.29147579677423413",
         "-0.46130964039670946",
         "-0.3502027100172008",
         "0.16822629941340864",
         "0.13210614141406002",
         "-0.37357892360731054",
         "0.19675536198565513",
         "-0.3217638004663574",
         "-0.6649165750740378",
         "-0.4670243402769033",
         "-0.3357604158793346",
         "-0.5896852133441988"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 2428
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>30_day_SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>26_day_EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002250</td>\n",
       "      <td>-0.030452</td>\n",
       "      <td>-0.005081</td>\n",
       "      <td>-0.017224</td>\n",
       "      <td>-1.726024</td>\n",
       "      <td>-0.017275</td>\n",
       "      <td>-0.341984</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>0.301681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204149</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.129493</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>-0.147777</td>\n",
       "      <td>-0.144543</td>\n",
       "      <td>-0.105950</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>-0.046828</td>\n",
       "      <td>-0.071073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.017058</td>\n",
       "      <td>0.052988</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.075714</td>\n",
       "      <td>-1.538281</td>\n",
       "      <td>0.029450</td>\n",
       "      <td>1.585928</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007122</td>\n",
       "      <td>0.283660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195565</td>\n",
       "      <td>0.163388</td>\n",
       "      <td>0.130494</td>\n",
       "      <td>0.114753</td>\n",
       "      <td>-0.174404</td>\n",
       "      <td>-0.157478</td>\n",
       "      <td>-0.104493</td>\n",
       "      <td>-0.017229</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>-0.046004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073301</td>\n",
       "      <td>0.133452</td>\n",
       "      <td>0.093165</td>\n",
       "      <td>0.057247</td>\n",
       "      <td>-1.451802</td>\n",
       "      <td>0.115628</td>\n",
       "      <td>-0.283160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>0.259399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186175</td>\n",
       "      <td>0.168403</td>\n",
       "      <td>0.132444</td>\n",
       "      <td>0.107191</td>\n",
       "      <td>-0.180865</td>\n",
       "      <td>-0.163200</td>\n",
       "      <td>-0.108189</td>\n",
       "      <td>0.075733</td>\n",
       "      <td>-0.016561</td>\n",
       "      <td>0.003562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058392</td>\n",
       "      <td>0.094202</td>\n",
       "      <td>0.098088</td>\n",
       "      <td>0.079306</td>\n",
       "      <td>-1.864734</td>\n",
       "      <td>0.097578</td>\n",
       "      <td>0.351788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>0.240044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179204</td>\n",
       "      <td>0.173940</td>\n",
       "      <td>0.135273</td>\n",
       "      <td>0.095782</td>\n",
       "      <td>-0.220077</td>\n",
       "      <td>-0.179506</td>\n",
       "      <td>-0.101743</td>\n",
       "      <td>0.057261</td>\n",
       "      <td>0.076424</td>\n",
       "      <td>-0.015727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081426</td>\n",
       "      <td>0.077684</td>\n",
       "      <td>0.061026</td>\n",
       "      <td>0.032065</td>\n",
       "      <td>-1.751843</td>\n",
       "      <td>0.071032</td>\n",
       "      <td>-0.855248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033091</td>\n",
       "      <td>0.216721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169059</td>\n",
       "      <td>0.176929</td>\n",
       "      <td>0.138219</td>\n",
       "      <td>0.086260</td>\n",
       "      <td>-0.234130</td>\n",
       "      <td>-0.188251</td>\n",
       "      <td>-0.103983</td>\n",
       "      <td>0.079326</td>\n",
       "      <td>0.057948</td>\n",
       "      <td>0.077289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>7.591961</td>\n",
       "      <td>7.475939</td>\n",
       "      <td>7.581152</td>\n",
       "      <td>7.361688</td>\n",
       "      <td>-0.172184</td>\n",
       "      <td>7.564112</td>\n",
       "      <td>-3.955017</td>\n",
       "      <td>0</td>\n",
       "      <td>7.268399</td>\n",
       "      <td>8.189014</td>\n",
       "      <td>...</td>\n",
       "      <td>7.758517</td>\n",
       "      <td>0.170657</td>\n",
       "      <td>0.097535</td>\n",
       "      <td>7.396788</td>\n",
       "      <td>2.766339</td>\n",
       "      <td>4.498948</td>\n",
       "      <td>4.793952</td>\n",
       "      <td>7.593260</td>\n",
       "      <td>7.708717</td>\n",
       "      <td>7.633177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>7.362289</td>\n",
       "      <td>7.165531</td>\n",
       "      <td>7.095196</td>\n",
       "      <td>7.035666</td>\n",
       "      <td>-0.118931</td>\n",
       "      <td>7.167192</td>\n",
       "      <td>-5.610150</td>\n",
       "      <td>0</td>\n",
       "      <td>7.340563</td>\n",
       "      <td>8.142319</td>\n",
       "      <td>...</td>\n",
       "      <td>7.733929</td>\n",
       "      <td>0.166426</td>\n",
       "      <td>0.105624</td>\n",
       "      <td>7.310344</td>\n",
       "      <td>2.450726</td>\n",
       "      <td>4.370591</td>\n",
       "      <td>4.850350</td>\n",
       "      <td>7.363542</td>\n",
       "      <td>7.595845</td>\n",
       "      <td>7.712147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>7.036583</td>\n",
       "      <td>7.417717</td>\n",
       "      <td>7.245695</td>\n",
       "      <td>7.623245</td>\n",
       "      <td>-0.188586</td>\n",
       "      <td>7.371357</td>\n",
       "      <td>10.076125</td>\n",
       "      <td>1</td>\n",
       "      <td>7.468018</td>\n",
       "      <td>8.098974</td>\n",
       "      <td>...</td>\n",
       "      <td>7.757053</td>\n",
       "      <td>0.188363</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>7.243685</td>\n",
       "      <td>1.980414</td>\n",
       "      <td>4.212529</td>\n",
       "      <td>4.986447</td>\n",
       "      <td>7.037438</td>\n",
       "      <td>7.366070</td>\n",
       "      <td>7.599237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>7.623860</td>\n",
       "      <td>7.424259</td>\n",
       "      <td>7.790726</td>\n",
       "      <td>7.455029</td>\n",
       "      <td>-0.396724</td>\n",
       "      <td>7.638694</td>\n",
       "      <td>-2.899654</td>\n",
       "      <td>0</td>\n",
       "      <td>7.529624</td>\n",
       "      <td>8.041641</td>\n",
       "      <td>...</td>\n",
       "      <td>7.765327</td>\n",
       "      <td>0.198983</td>\n",
       "      <td>0.128747</td>\n",
       "      <td>7.184105</td>\n",
       "      <td>1.560919</td>\n",
       "      <td>4.071481</td>\n",
       "      <td>5.107736</td>\n",
       "      <td>7.625165</td>\n",
       "      <td>7.039883</td>\n",
       "      <td>7.369385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>7.455971</td>\n",
       "      <td>7.316319</td>\n",
       "      <td>7.229871</td>\n",
       "      <td>6.963142</td>\n",
       "      <td>-0.119193</td>\n",
       "      <td>7.310908</td>\n",
       "      <td>-8.464821</td>\n",
       "      <td>0</td>\n",
       "      <td>7.434563</td>\n",
       "      <td>7.966262</td>\n",
       "      <td>...</td>\n",
       "      <td>7.734571</td>\n",
       "      <td>0.187095</td>\n",
       "      <td>0.135327</td>\n",
       "      <td>7.126544</td>\n",
       "      <td>1.314019</td>\n",
       "      <td>3.976446</td>\n",
       "      <td>5.160283</td>\n",
       "      <td>7.456907</td>\n",
       "      <td>7.627758</td>\n",
       "      <td>7.043089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2428 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open      high       low     close    volume     av_pr       diff  \\\n",
       "0     0.002250 -0.030452 -0.005081 -0.017224 -1.726024 -0.017275  -0.341984   \n",
       "1    -0.017058  0.052988  0.001705  0.075714 -1.538281  0.029450   1.585928   \n",
       "2     0.073301  0.133452  0.093165  0.057247 -1.451802  0.115628  -0.283160   \n",
       "3     0.058392  0.094202  0.098088  0.079306 -1.864734  0.097578   0.351788   \n",
       "4     0.081426  0.077684  0.061026  0.032065 -1.751843  0.071032  -0.855248   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "2423  7.591961  7.475939  7.581152  7.361688 -0.172184  7.564112  -3.955017   \n",
       "2424  7.362289  7.165531  7.095196  7.035666 -0.118931  7.167192  -5.610150   \n",
       "2425  7.036583  7.417717  7.245695  7.623245 -0.188586  7.371357  10.076125   \n",
       "2426  7.623860  7.424259  7.790726  7.455029 -0.396724  7.638694  -2.899654   \n",
       "2427  7.455971  7.316319  7.229871  6.963142 -0.119193  7.310908  -8.464821   \n",
       "\n",
       "      candle  7_day_SMA  30_day_SMA  ...  26_day_EMA      MACD  Signal_Line  \\\n",
       "0          0  -0.011292    0.301681  ...    0.204149  0.156951     0.129493   \n",
       "1          1  -0.007122    0.283660  ...    0.195565  0.163388     0.130494   \n",
       "2          0   0.008014    0.259399  ...    0.186175  0.168403     0.132444   \n",
       "3          1   0.018075    0.240044  ...    0.179204  0.173940     0.135273   \n",
       "4          0   0.033091    0.216721  ...    0.169059  0.176929     0.138219   \n",
       "...      ...        ...         ...  ...         ...       ...          ...   \n",
       "2423       0   7.268399    8.189014  ...    7.758517  0.170657     0.097535   \n",
       "2424       0   7.340563    8.142319  ...    7.733929  0.166426     0.105624   \n",
       "2425       1   7.468018    8.098974  ...    7.757053  0.188363     0.117119   \n",
       "2426       0   7.529624    8.041641  ...    7.765327  0.198983     0.128747   \n",
       "2427       0   7.434563    7.966262  ...    7.734571  0.187095     0.135327   \n",
       "\n",
       "      20_day_SMA  20_day_STD  Upper_Band  Lower_Band     lag_1     lag_2  \\\n",
       "0       0.125988   -0.147777   -0.144543   -0.105950  0.002049 -0.046828   \n",
       "1       0.114753   -0.174404   -0.157478   -0.104493 -0.017229  0.002721   \n",
       "2       0.107191   -0.180865   -0.163200   -0.108189  0.075733 -0.016561   \n",
       "3       0.095782   -0.220077   -0.179506   -0.101743  0.057261  0.076424   \n",
       "4       0.086260   -0.234130   -0.188251   -0.103983  0.079326  0.057948   \n",
       "...          ...         ...         ...         ...       ...       ...   \n",
       "2423    7.396788    2.766339    4.498948    4.793952  7.593260  7.708717   \n",
       "2424    7.310344    2.450726    4.370591    4.850350  7.363542  7.595845   \n",
       "2425    7.243685    1.980414    4.212529    4.986447  7.037438  7.366070   \n",
       "2426    7.184105    1.560919    4.071481    5.107736  7.625165  7.039883   \n",
       "2427    7.126544    1.314019    3.976446    5.160283  7.456907  7.627758   \n",
       "\n",
       "         lag_3  \n",
       "0    -0.071073  \n",
       "1    -0.046004  \n",
       "2     0.003562  \n",
       "3    -0.015727  \n",
       "4     0.077289  \n",
       "...        ...  \n",
       "2423  7.633177  \n",
       "2424  7.712147  \n",
       "2425  7.599237  \n",
       "2426  7.369385  \n",
       "2427  7.043089  \n",
       "\n",
       "[2428 rows x 24 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_groups = {\n",
    "    # Price Features (Absolute Values)\n",
    "    'price': ['open', 'high', 'low', 'close', 'av_pr'],\n",
    "    \n",
    "    # Derived Price Features\n",
    "    'price_derived': ['diff', 'lag_1', 'lag_2', 'lag_3'],\n",
    "    \n",
    "    # Volume (Separate Scaling)\n",
    "    'volume': ['volume'],\n",
    "    \n",
    "    # Moving Averages (Price-based)\n",
    "    'moving_averages': [\n",
    "        '7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA',\n",
    "        '12_day_EMA', '26_day_EMA', '20_day_SMA'\n",
    "    ],\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    'bollinger': ['20_day_STD', 'Upper_Band', 'Lower_Band'],\n",
    "    \n",
    "    # Momentum Indicators\n",
    "    'momentum': ['RSI'],\n",
    "    \n",
    "    # MACD Components\n",
    "    'macd': ['MACD', 'Signal_Line']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target variable\n",
    "df['candle_target'] = np.where(df['close'] > df['open'], 1, 0)\n",
    "\n",
    "# Drop the original 'candle' feature to avoid leakage\n",
    "df = df.drop(columns=['candle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def temporal_scaling_classification(df, window_size=30):\n",
    "    \"\"\"Rolling window scaling for classification tasks\"\"\"\n",
    "    scaled = df.copy()\n",
    "    \n",
    "    for i in range(window_size, len(df)):\n",
    "        window = df.iloc[i-window_size:i]\n",
    "        \n",
    "        # Scale price features using window statistics\n",
    "        price_cols = feature_groups['price'] + feature_groups['price_derived']\n",
    "        scaled.loc[i, price_cols] = RobustScaler().fit_transform(\n",
    "            df.loc[i, price_cols].values.reshape(1, -1))\n",
    "        \n",
    "        # Scale volume separately\n",
    "        scaled.loc[i, 'volume'] = RobustScaler().fit_transform(\n",
    "            window['volume'].values.reshape(-1, 1))[-1]\n",
    "            \n",
    "        # Scale indicators using their own window stats\n",
    "        for indicator in feature_groups['momentum'] + feature_groups['macd']:\n",
    "            scaled.loc[i, indicator] = (df.loc[i, indicator] - window[indicator].mean()) / window[indicator].std()\n",
    "            \n",
    "    return scaled.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define feature groups\n",
    "feature_groups = {\n",
    "    'price': ['open', 'high', 'low', 'close', 'av_pr'],\n",
    "    'price_derived': ['diff', 'lag_1', 'lag_2', 'lag_3'],\n",
    "    'volume': ['volume'],\n",
    "    'moving_averages': ['7_day_SMA', '30_day_SMA', '7_day_EMA', '30_day_EMA', '12_day_EMA', '26_day_EMA', '20_day_SMA'],\n",
    "    'bollinger': ['20_day_STD', 'Upper_Band', 'Lower_Band'],\n",
    "    'momentum': ['RSI'],\n",
    "    'macd': ['MACD', 'Signal_Line']\n",
    "}\n",
    "\n",
    "# Define safe log transformation\n",
    "log_transformer = FunctionTransformer(lambda x: np.log1p(x.clip(lower=1e-6)), validate=False)\n",
    "\n",
    "# Define difference transformer (keeping NaNs)\n",
    "diff_transformer = FunctionTransformer(lambda x: np.vstack([np.full((1, x.shape[1]), np.nan), np.diff(x, axis=0)]), validate=False)\n",
    "\n",
    "# Define ratio transformer for moving averages\n",
    "def moving_avg_ratio(X):\n",
    "    df = pd.DataFrame(X, columns=feature_groups['moving_averages'])\n",
    "    close_prices = df['7_day_SMA'].values.reshape(-1, 1)  # Assume `7_day_SMA` is a proxy for `close`\n",
    "    return (df / close_prices).values\n",
    "\n",
    "moving_avg_transformer = FunctionTransformer(moving_avg_ratio, validate=False)\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    # Price Features: Log-Robust Scaling\n",
    "    ('price', Pipeline([\n",
    "        ('log_transform', log_transformer),\n",
    "        ('diff', diff_transformer),\n",
    "        ('scaler', RobustScaler(quantile_range=(25, 75)))\n",
    "    ]), feature_groups['price']),\n",
    "    \n",
    "    # Derived Price Features: Direct Robust Scaling\n",
    "    ('price_derived', RobustScaler(), feature_groups['price_derived']),\n",
    "    \n",
    "    # Volume: Robust Scaling\n",
    "    ('volume', RobustScaler(), feature_groups['volume']),\n",
    "    \n",
    "    # Moving Averages: Ratio to Close Price + Standard Scaling\n",
    "    ('moving_averages', Pipeline([\n",
    "        ('ratio', moving_avg_transformer),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), feature_groups['moving_averages']),\n",
    "    \n",
    "    # Bollinger Bands: Z-score Normalization\n",
    "    ('bollinger', StandardScaler(), feature_groups['bollinger']),\n",
    "    \n",
    "    # RSI: Maintain 0-100 Range with MinMax Scaling (-1 to 1)\n",
    "    ('momentum', MinMaxScaler(feature_range=(-1, 1)), feature_groups['momentum']),\n",
    "    \n",
    "    # MACD: Center Around Zero (Only Mean Normalization)\n",
    "    ('macd', StandardScaler(with_mean=True, with_std=False), feature_groups['macd'])\n",
    "], remainder='drop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[315], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Walk-forward validation for time series\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_idx, test_idx \u001b[38;5;129;01min\u001b[39;00m TimeSeriesSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(X):\n\u001b[1;32m---> 14\u001b[0m     X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[train_idx], X\u001b[38;5;241m.\u001b[39miloc[test_idx]\n\u001b[0;32m     15\u001b[0m     y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_idx], y\u001b[38;5;241m.\u001b[39miloc[test_idx]\n\u001b[0;32m     17\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Full preprocessing and modeling pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('temporal_scaling', FunctionTransformer(temporal_scaling_classification)),\n",
    "    ('feature_processing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Walk-forward validation for time series\n",
    "for train_idx, test_idx in TimeSeriesSplit(n_splits=5).split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_original = df['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the hourly dataset\n",
    "# Moving Averages\n",
    "df['1_day_SMA'] = df['close'].rolling(window=24).mean()  # 1 days = 24 hours\n",
    "df['7_day_SMA'] = df['close'].rolling(window=168).mean()  # 7 days = 168 hours\n",
    "df['30_day_SMA'] = df['close'].rolling(window=720).mean()  # 30 days = 720 hours\n",
    "df['1_day_EMA'] = df['close'].ewm(span=24, adjust=False).mean()  # 1 days = 24 hours\n",
    "df['7_day_EMA'] = df['close'].ewm(span=168, adjust=False).mean()  # 7 days = 168 hours\n",
    "df['30_day_EMA'] = df['close'].ewm(span=720, adjust=False).mean()  # 30 days = 720 hours\n",
    "\n",
    "# RSI\n",
    "def calculate_rsi(data, period=336):  # 14 days = 336 hours\n",
    "    delta = data['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "df['RSI'] = calculate_rsi(df)\n",
    "\n",
    "# MACD\n",
    "df['12_day_EMA'] = df['close'].ewm(span=288, adjust=False).mean()  # 12 days = 288 hours\n",
    "df['26_day_EMA'] = df['close'].ewm(span=624, adjust=False).mean()  # 26 days = 624 hours\n",
    "df['MACD'] = df['12_day_EMA'] - df['26_day_EMA']\n",
    "df['Signal_Line'] = df['MACD'].ewm(span=216, adjust=False).mean()  # 9 days = 216 hours\n",
    "\n",
    "# Bollinger Bands\n",
    "window = 480  # 20 days = 480 hours\n",
    "df['20_day_SMA'] = df['close'].rolling(window=window).mean()\n",
    "df['20_day_STD'] = df['close'].rolling(window=window).std()\n",
    "df['Upper_Band'] = df['20_day_SMA'] + (df['20_day_STD'] * 2)\n",
    "df['Lower_Band'] = df['20_day_SMA'] - (df['20_day_STD'] * 2)\n",
    "\n",
    "# Lag Features\n",
    "df['lag_1'] = df['close'].shift(1)  # Lag by 1 hour\n",
    "df['lag_2'] = df['close'].shift(2)  # Lag by 2 hours\n",
    "df['lag_3'] = df['close'].shift(3)  # Lag by 3 hours\n",
    "\n",
    "# Drop rows with NaN values (created by rolling windows and shifts)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv('dataset_with_features_hr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1_day_EMA",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "abe874f3-b2f2-4fd5-9606-8d9ca6ab1962",
       "rows": [
        [
         "2024-02-01 05:00:00",
         "BINANCE:XRPUSDT",
         "0.4977",
         "0.4988",
         "0.4954",
         "0.496",
         "17875875.0",
         "0.4971",
         "-0.0016999999999999793",
         "0",
         "0.521835119047619",
         "0.5564677777777778",
         "0.5217690565511647",
         "0.5541265191135628",
         "44.1161907905595",
         "0.5290693117335377",
         "0.549258785305369",
         "-0.020189473571831318",
         "-0.019820153741063586",
         "0.543675",
         "0.025918414633595385",
         "0.5955118292671908",
         "0.4918381707328092",
         "0.4978",
         "0.4977",
         "0.494",
         "0.50555",
         "0.5053228680111399"
        ],
        [
         "2024-02-01 06:00:00",
         "BINANCE:XRPUSDT",
         "0.4959",
         "0.4974",
         "0.4955",
         "0.4957",
         "10485001.0",
         "0.49645",
         "-0.00020000000000003348",
         "0",
         "0.5217464285714286",
         "0.556281111111111",
         "0.5214605470061805",
         "0.553964448325453",
         "44.0851344662597",
         "0.528838382240572",
         "0.5490873971923917",
         "-0.020249014951819744",
         "-0.01982410637895074",
         "0.5434572916666666",
         "0.025881488152254092",
         "0.5952202679711748",
         "0.49169431536215835",
         "0.496",
         "0.4978",
         "0.4977",
         "0.5048708333333333",
         "0.5045530385702487"
        ],
        [
         "2024-02-01 07:00:00",
         "BINANCE:XRPUSDT",
         "0.4956",
         "0.4959",
         "0.4919",
         "0.4939",
         "26116194.0",
         "0.4939",
         "-0.0016999999999999793",
         "0",
         "0.5216440476190476",
         "0.5560945833333334",
         "0.5211343866865807",
         "0.5537978340443838",
         "44.05605935696621",
         "0.5285965941281805",
         "0.5489107975213761",
         "-0.020314203393195562",
         "-0.0198286234021235",
         "0.5432454166666667",
         "0.025870011895699225",
         "0.5949854404580651",
         "0.49150539287526823",
         "0.4957",
         "0.496",
         "0.4978",
         "0.5041458333333333",
         "0.5037007954846289"
        ],
        [
         "2024-02-01 08:00:00",
         "BINANCE:XRPUSDT",
         "0.4939",
         "0.494",
         "0.4916",
         "0.4929",
         "17569499.0",
         "0.4928",
         "-0.0010000000000000009",
         "0",
         "0.5215196428571429",
         "0.5559031944444445",
         "0.5208002519328934",
         "0.5536289080137474",
         "43.74276739957019",
         "0.5283495588746984",
         "0.5487315629693077",
         "-0.02038200409460933",
         "-0.019833723685003555",
         "0.5430335416666666",
         "0.025865000815384898",
         "0.5947635432974364",
         "0.4913035400358968",
         "0.4939",
         "0.4957",
         "0.496",
         "0.5033916666666667",
         "0.5028367318458585"
        ],
        [
         "2024-02-01 09:00:00",
         "BINANCE:XRPUSDT",
         "0.4929",
         "0.4938",
         "0.49",
         "0.4931",
         "18873523.0",
         "0.4919",
         "0.00019999999999997797",
         "1",
         "0.5214113095238095",
         "0.5557090277777778",
         "0.5204724383005515",
         "0.553461005356289",
         "43.95020746887968",
         "0.5281056172907904",
         "0.5485535419678059",
         "-0.020447924677015505",
         "-0.01983938452363961",
         "0.5428247916666666",
         "0.02586281033072055",
         "0.5945504123281078",
         "0.49109917100522554",
         "0.4929",
         "0.4939",
         "0.4957",
         "0.5026958333333333",
         "0.5020577932981899"
        ],
        [
         "2024-02-01 10:00:00",
         "BINANCE:XRPUSDT",
         "0.4931",
         "0.4961",
         "0.493",
         "0.4957",
         "14374976.0",
         "0.49455",
         "0.002599999999999991",
         "1",
         "0.5213172619047619",
         "0.5555118055555556",
         "0.520179273350249",
         "0.5533007806534975",
         "44.22027451628908",
         "0.5278813569635185",
         "0.548384410633509",
         "-0.0205030536699905",
         "-0.019845501289965425",
         "0.54261625",
         "0.025838319896080014",
         "0.59429288979216",
         "0.49093961020784",
         "0.4931",
         "0.4929",
         "0.4939",
         "0.5022625",
         "0.5015491698343347"
        ],
        [
         "2024-02-01 11:00:00",
         "BINANCE:XRPUSDT",
         "0.4957",
         "0.4976",
         "0.4938",
         "0.4938",
         "16570530.0",
         "0.49570000000000003",
         "-0.0018999999999999573",
         "0",
         "0.5212029761904762",
         "0.5553134722222222",
         "0.519867092600542",
         "0.5531357299443339",
         "44.26419466975667",
         "0.5276454998219023",
         "0.5482097405194818",
         "-0.02056424069757945",
         "-0.019852125616302882",
         "0.5424020833333334",
         "0.02581596008737805",
         "0.5940340035080895",
         "0.4907701631585773",
         "0.4957",
         "0.4931",
         "0.4929",
         "0.5019166666666667",
         "0.500929236247588"
        ],
        [
         "2024-02-01 12:00:00",
         "BINANCE:XRPUSDT",
         "0.4938",
         "0.495",
         "0.4924",
         "0.4927",
         "11659683.0",
         "0.4937",
         "-0.0010999999999999899",
         "0",
         "0.5210874999999999",
         "0.55512",
         "0.5195455885460977",
         "0.5529680857558614",
         "44.183740912095175",
         "0.5274036624528926",
         "0.5480321093498195",
         "-0.02062844689692689",
         "-0.019859280651147344",
         "0.5421775",
         "0.02577835820151729",
         "0.5937342164030346",
         "0.49062078359696537",
         "0.4938",
         "0.4957",
         "0.4931",
         "0.5013208333333333",
         "0.500270897347781"
        ],
        [
         "2024-02-01 13:00:00",
         "BINANCE:XRPUSDT",
         "0.4928",
         "0.4954",
         "0.4926",
         "0.4946",
         "12144325.0",
         "0.494",
         "0.0017999999999999683",
         "1",
         "0.5210065476190476",
         "0.5549322222222222",
         "0.5192503744804634",
         "0.5528061770575096",
         "44.556585043017876",
         "0.5271766474878207",
         "0.5478611265999002",
         "-0.02068447911207949",
         "-0.019866886166916304",
         "0.5419625",
         "0.025743817588890657",
         "0.5934501351777813",
         "0.4904748648222187",
         "0.4927",
         "0.4938",
         "0.4957",
         "0.5007958333333334",
         "0.4998172255599585"
        ],
        [
         "2024-02-01 14:00:00",
         "BINANCE:XRPUSDT",
         "0.4946",
         "0.4961",
         "0.4931",
         "0.4957",
         "11711475.0",
         "0.4946",
         "0.0010999999999999899",
         "1",
         "0.5209327380952381",
         "0.5547433333333333",
         "0.5189716718238899",
         "0.5526477687993749",
         "44.510680576254344",
         "0.5269588160173166",
         "0.5476942109947804",
         "-0.020735394977463795",
         "-0.01987489085641444",
         "0.5417489583333333",
         "0.025701438165131155",
         "0.5931518346635956",
         "0.49034608200307095",
         "0.4946",
         "0.4927",
         "0.4938",
         "0.5003791666666667",
         "0.49948784751516184"
        ],
        [
         "2024-02-01 15:00:00",
         "BINANCE:XRPUSDT",
         "0.4957",
         "0.5003",
         "0.4952",
         "0.4997",
         "18079854.0",
         "0.49774999999999997",
         "0.0040000000000000036",
         "1",
         "0.5208791666666667",
         "0.55456875",
         "0.5187436047017138",
         "0.5525008956543004",
         "44.69384386862519",
         "0.5267701736919373",
         "0.5475406295195971",
         "-0.020770455827659795",
         "-0.019883144911448956",
         "0.5415427083333333",
         "0.02564061864680985",
         "0.592823945626953",
         "0.49026147103971357",
         "0.4957",
         "0.4946",
         "0.4927",
         "0.5001666666666666",
         "0.49950481971394894"
        ],
        [
         "2024-02-01 16:00:00",
         "BINANCE:XRPUSDT",
         "0.4997",
         "0.5026",
         "0.4994",
         "0.4994",
         "15973829.0",
         "0.501",
         "-0.00029999999999996696",
         "0",
         "0.5208333333333334",
         "0.5543934722222222",
         "0.5185146863028769",
         "0.5523535977467988",
         "44.79735318444996",
         "0.5265807607252112",
         "0.5473865795051344",
         "-0.020805818779923158",
         "-0.019891648818070838",
         "0.5413595833333333",
         "0.02562702513680688",
         "0.5926136336069471",
         "0.4901055330597196",
         "0.4997",
         "0.4957",
         "0.4946",
         "0.4997833333333334",
         "0.49949643413683303"
        ],
        [
         "2024-02-01 17:00:00",
         "BINANCE:XRPUSDT",
         "0.4995",
         "0.5008",
         "0.4975",
         "0.5002",
         "13043674.0",
         "0.49915",
         "0.0006999999999999784",
         "1",
         "0.5207940476190477",
         "0.5542170833333333",
         "0.5182979444531387",
         "0.5522089275727439",
         "45.33466866967117",
         "0.5263981949070436",
         "0.547235582450718",
         "-0.02083738754367437",
         "-0.019900365304021103",
         "0.5411918749999999",
         "0.025632439581489662",
         "0.5924567541629792",
         "0.48992699583702054",
         "0.4994",
         "0.4997",
         "0.4957",
         "0.49937499999999996",
         "0.4995527194058864"
        ],
        [
         "2024-02-01 18:00:00",
         "BINANCE:XRPUSDT",
         "0.5002",
         "0.507",
         "0.5001",
         "0.5063",
         "18435984.0",
         "0.5035499999999999",
         "0.006099999999999994",
         "1",
         "0.5207833333333334",
         "0.5540552777777777",
         "0.5181559569448176",
         "0.5520815796460511",
         "46.12190666002325",
         "0.5262591070530156",
         "0.5471045885868757",
         "-0.020845481533860122",
         "-0.019909076052683217",
         "0.5410412499999999",
         "0.02562458628414888",
         "0.5922904225682977",
         "0.48979207743170217",
         "0.5002",
         "0.4994",
         "0.4997",
         "0.499075",
         "0.5000925018534156"
        ],
        [
         "2024-02-01 19:00:00",
         "BINANCE:XRPUSDT",
         "0.5062",
         "0.5066",
         "0.504",
         "0.505",
         "6947841.0",
         "0.5053000000000001",
         "-0.0011999999999999789",
         "0",
         "0.5207416666666667",
         "0.5538877777777778",
         "0.5180002651466542",
         "0.5519509788703338",
         "46.045431935002505",
         "0.5261119852048978",
         "0.5469698539033977",
         "-0.020857868698499926",
         "-0.019917820685363557",
         "0.5408877083333333",
         "0.025619268643810696",
         "0.5921262456209547",
         "0.48964917104571193",
         "0.5063",
         "0.5002",
         "0.4994",
         "0.4987791666666667",
         "0.5004851017051424"
        ],
        [
         "2024-02-01 20:00:00",
         "BINANCE:XRPUSDT",
         "0.505",
         "0.5107",
         "0.505",
         "0.5096",
         "12197349.0",
         "0.50785",
         "0.0046000000000000485",
         "1",
         "0.5207166666666667",
         "0.5537238888888889",
         "0.5179008537248004",
         "0.5518335004268655",
         "46.909272183449666",
         "0.5259977154110922",
         "0.5468502703709068",
         "-0.02085255495981464",
         "-0.019926435747800893",
         "0.5407410416666667",
         "0.0255963936606794",
         "0.5919338289880255",
         "0.4895482543453079",
         "0.505",
         "0.5063",
         "0.5002",
         "0.49872500000000003",
         "0.501214293568731"
        ],
        [
         "2024-02-01 21:00:00",
         "BINANCE:XRPUSDT",
         "0.5096",
         "0.5099",
         "0.5071",
         "0.5078",
         "7515078.0",
         "0.5085",
         "-0.0018000000000000238",
         "0",
         "0.5206827380952381",
         "0.5535598611111111",
         "0.5177813169943294",
         "0.5517113547946134",
         "46.66334661354582",
         "0.5258717796643027",
         "0.54672530950572",
         "-0.020853529841417306",
         "-0.01993498039382501",
         "0.540589375",
         "0.025575396572451708",
         "0.5917401681449035",
         "0.48943858185509664",
         "0.5096",
         "0.505",
         "0.5063",
         "0.4988166666666667",
         "0.5017411500832326"
        ],
        [
         "2024-02-01 22:00:00",
         "BINANCE:XRPUSDT",
         "0.5077",
         "0.5094",
         "0.507",
         "0.509",
         "5816505.0",
         "0.5082",
         "0.0012999999999999678",
         "1",
         "0.5206553571428572",
         "0.5533956944444445",
         "0.5176773960831539",
         "0.5515928766953219",
         "46.494587843463776",
         "0.5257550199434424",
         "0.5466045885153017",
         "-0.020849568571859267",
         "-0.01994340977795436",
         "0.5404489583333334",
         "0.025563395324976448",
         "0.5915757489832862",
         "0.4893221676833805",
         "0.5078",
         "0.5096",
         "0.505",
         "0.499025",
         "0.502321858076574"
        ],
        [
         "2024-02-01 23:00:00",
         "BINANCE:XRPUSDT",
         "0.509",
         "0.5091",
         "0.5039",
         "0.5056",
         "8875061.0",
         "0.5065",
         "-0.0033999999999999586",
         "0",
         "0.5206005952380952",
         "0.5532266666666666",
         "0.5175344683188562",
         "0.5514652959000506",
         "46.08998837788479",
         "0.5256155388365674",
         "0.5464733738320527",
         "-0.020857834995485325",
         "-0.019951837660143586",
         "0.5403202083333334",
         "0.025582993355294043",
         "0.5914861950439214",
         "0.4891542216227453",
         "0.509",
         "0.5078",
         "0.5096",
         "0.49917083333333334",
         "0.5025841094304482"
        ],
        [
         "2024-02-02 00:00:00",
         "BINANCE:XRPUSDT",
         "0.5056",
         "0.5063",
         "0.5046",
         "0.5058",
         "5432484.0",
         "0.50545",
         "0.00019999999999997797",
         "1",
         "0.5205529761904761",
         "0.5530616666666667",
         "0.5173955988712957",
         "0.5513386237893708",
         "46.16151545363909",
         "0.5254784070799129",
         "0.5463432190357902",
         "-0.020864811955877305",
         "-0.019960252169781686",
         "0.5401866666666667",
         "0.02559556225671297",
         "0.5913777911800926",
         "0.48899554215324076",
         "0.5056",
         "0.509",
         "0.5078",
         "0.49927499999999997",
         "0.5028413806760124"
        ],
        [
         "2024-02-02 01:00:00",
         "BINANCE:XRPUSDT",
         "0.5057",
         "0.5075",
         "0.5047",
         "0.5049",
         "11571408.0",
         "0.5061",
         "-0.0008000000000000229",
         "0",
         "0.5205190476190475",
         "0.552892638888889",
         "0.5172477219615763",
         "0.5512098065250453",
         "46.26144879267278",
         "0.5253359959582526",
         "0.5462106007348757",
         "-0.020874604776623062",
         "-0.01996867938274797",
         "0.5400535416666667",
         "0.025612600222241544",
         "0.5912787421111498",
         "0.48882834122218366",
         "0.5058",
         "0.5056",
         "0.509",
         "0.4994541666666667",
         "0.5030060702219314"
        ],
        [
         "2024-02-02 02:00:00",
         "BINANCE:XRPUSDT",
         "0.5048",
         "0.5067",
         "0.504",
         "0.5047",
         "9533932.0",
         "0.50535",
         "-9.999999999998899e-05",
         "0",
         "0.5204767857142857",
         "0.5527222222222222",
         "0.5170992282105518",
         "0.5510807918051421",
         "46.300000000000004",
         "0.5251931862976419",
         "0.5460777668125242",
         "-0.02088458051488229",
         "-0.019977120867836765",
         "0.5399197916666666",
         "0.025629270436124393",
         "0.5911783325389154",
         "0.4886612507944178",
         "0.5049",
         "0.5058",
         "0.5056",
         "0.4999",
         "0.5031415846041769"
        ],
        [
         "2024-02-02 03:00:00",
         "BINANCE:XRPUSDT",
         "0.5046",
         "0.5069",
         "0.5041",
         "0.5068",
         "8855189.0",
         "0.5055000000000001",
         "0.0021999999999999797",
         "1",
         "0.5204392857142858",
         "0.5525565277777778",
         "0.5169773438530305",
         "0.5509579602051279",
         "46.38935108153078",
         "0.5250658978111531",
         "0.5459520779587241",
         "-0.020886180147571043",
         "-0.019985499294378095",
         "0.5397856249999999",
         "0.02563374320773814",
         "0.5910531114154762",
         "0.48851813858452364",
         "0.5047",
         "0.5049",
         "0.5058",
         "0.5002791666666667",
         "0.5034342578358427"
        ],
        [
         "2024-02-02 04:00:00",
         "BINANCE:XRPUSDT",
         "0.5067",
         "0.5077",
         "0.5056",
         "0.5061",
         "10011046.0",
         "0.50665",
         "-0.0006000000000000449",
         "0",
         "0.5203958333333333",
         "0.5523898611111111",
         "0.5168486178902727",
         "0.5508335275831997",
         "46.35078969243558",
         "0.5249346459231866",
         "0.5458245513092562",
         "-0.020889905386069607",
         "-0.019993834834393688",
         "0.5396485416666666",
         "0.025637585721487534",
         "0.5909237131096418",
         "0.4883733702236916",
         "0.5068",
         "0.5047",
         "0.5049",
         "0.500625",
         "0.5036475172089753"
        ],
        [
         "2024-02-02 05:00:00",
         "BINANCE:XRPUSDT",
         "0.506",
         "0.5072",
         "0.5056",
         "0.5065",
         "11980027.0",
         "0.5064",
         "0.0004999999999999449",
         "1",
         "0.52035",
         "0.5522133333333333",
         "0.5167261490395003",
         "0.5507105496980869",
         "46.32401862940785",
         "0.524807070518874",
         "0.5456987127450665",
         "-0.020891642226192553",
         "-0.02000210955689875",
         "0.5395097916666667",
         "0.02563638805371805",
         "0.5907825677741028",
         "0.4882370155592306",
         "0.5061",
         "0.5068",
         "0.5047",
         "0.5010625",
         "0.5038757158322572"
        ],
        [
         "2024-02-02 06:00:00",
         "BINANCE:XRPUSDT",
         "0.5065",
         "0.5071",
         "0.505",
         "0.5067",
         "11490367.0",
         "0.50605",
         "0.000200000000000089",
         "1",
         "0.5203119047619048",
         "0.5520338888888889",
         "0.5166074963881453",
         "0.5505884677294376",
         "46.33294528521538",
         "0.5246817620723766",
         "0.5455739168642824",
         "-0.02089215479190576",
         "-0.020010312738788217",
         "0.5393660416666667",
         "0.025626485047009803",
         "0.5906190117606863",
         "0.48811307157264705",
         "0.5065",
         "0.5061",
         "0.5068",
         "0.5015208333333333",
         "0.5041016585656767"
        ],
        [
         "2024-02-02 07:00:00",
         "BINANCE:XRPUSDT",
         "0.5066",
         "0.5067",
         "0.5028",
         "0.5048",
         "20439851.0",
         "0.50475",
         "-0.0018000000000000238",
         "0",
         "0.5202678571428572",
         "0.551853888888889",
         "0.5164677627030786",
         "0.5504614539493281",
         "46.17807992041122",
         "0.5245441720234328",
         "0.5454434403303167",
         "-0.020899268306883823",
         "-0.020018505877664676",
         "0.5392193750000001",
         "0.025622428271072032",
         "0.5904642315421441",
         "0.487974518457856",
         "0.5067",
         "0.5065",
         "0.5061",
         "0.5019750000000001",
         "0.5041575258804226"
        ],
        [
         "2024-02-02 08:00:00",
         "BINANCE:XRPUSDT",
         "0.5047",
         "0.5076",
         "0.5047",
         "0.5069",
         "13277552.0",
         "0.5061500000000001",
         "0.0021999999999999797",
         "1",
         "0.5202404761904761",
         "0.5516802777777777",
         "0.5163545347420955",
         "0.5503406177386504",
         "46.65004156275977",
         "0.5244220670267309",
         "0.5453201013212596",
         "-0.020898034294528745",
         "-0.02002661213035467",
         "0.5390779166666666",
         "0.025613013961038916",
         "0.5903039445887445",
         "0.4878518887445888",
         "0.5048",
         "0.5067",
         "0.5065",
         "0.5025583333333333",
         "0.5043769238099889"
        ],
        [
         "2024-02-02 09:00:00",
         "BINANCE:XRPUSDT",
         "0.5069",
         "0.5074",
         "0.504",
         "0.5048",
         "18840225.0",
         "0.5057",
         "-0.0020999999999999908",
         "0",
         "0.5201892857142857",
         "0.5515051388888889",
         "0.5162177946859761",
         "0.5502142914758524",
         "46.53399668325042",
         "0.5242862741753348",
         "0.5451904369970315",
         "-0.020904162821696715",
         "-0.02003470015515967",
         "0.5389302083333333",
         "0.025605812719974738",
         "0.5901418337732828",
         "0.48771858289338377",
         "0.5069",
         "0.5048",
         "0.5067",
         "0.5030458333333333",
         "0.5044107699051898"
        ],
        [
         "2024-02-02 10:00:00",
         "BINANCE:XRPUSDT",
         "0.5047",
         "0.505",
         "0.5029",
         "0.5039",
         "17729161.0",
         "0.50395",
         "-0.0008000000000000229",
         "0",
         "0.5201309523809524",
         "0.5513227777777778",
         "0.5160720219677989",
         "0.5500858191000526",
         "46.10768461410236",
         "0.5241451926931525",
         "0.545058307598641",
         "-0.020913114905488528",
         "-0.02004279614364196",
         "0.538786875",
         "0.025608945597155864",
         "0.5900047661943117",
         "0.48756898380568825",
         "0.5048",
         "0.5069",
         "0.5048",
         "0.5033875",
         "0.5043699083127746"
        ],
        [
         "2024-02-02 11:00:00",
         "BINANCE:XRPUSDT",
         "0.5039",
         "0.5066",
         "0.5029",
         "0.5052",
         "15196406.0",
         "0.50475",
         "0.0012999999999999678",
         "1",
         "0.5200553571428572",
         "0.5511452777777778",
         "0.5159433589859315",
         "0.5499613091996364",
         "46.27810158201499",
         "0.5240140840931998",
         "0.5449307610143254",
         "-0.020916676921125532",
         "-0.020050850344356098",
         "0.5386439583333333",
         "0.025604557530736257",
         "0.5898530733948059",
         "0.4874348432718608",
         "0.5039",
         "0.5048",
         "0.5069",
         "0.5038625",
         "0.5044363156477526"
        ],
        [
         "2024-02-02 12:00:00",
         "BINANCE:XRPUSDT",
         "0.5052",
         "0.506",
         "0.5035",
         "0.5044",
         "14532207.0",
         "0.50475",
         "-0.0008000000000000229",
         "0",
         "0.5199559523809524",
         "0.5509868055555555",
         "0.5158067511872814",
         "0.5498349255402754",
         "46.17177097203728",
         "0.5238783464870185",
         "0.5448010625790795",
         "-0.020922716092060978",
         "-0.0200588859733672",
         "0.5384983333333333",
         "0.025600118193011133",
         "0.5896985697193555",
         "0.487298096947311",
         "0.5052",
         "0.5039",
         "0.5048",
         "0.50435",
         "0.5044334103959325"
        ],
        [
         "2024-02-02 13:00:00",
         "BINANCE:XRPUSDT",
         "0.5044",
         "0.5051",
         "0.5033",
         "0.5037",
         "15265733.0",
         "0.5042",
         "-0.0006999999999999229",
         "0",
         "0.5198589285714286",
         "0.5509054166666666",
         "0.5156634760253017",
         "0.549706950712147",
         "46.091151031270805",
         "0.5237387039507762",
         "0.5446695391788264",
         "-0.020930835228050282",
         "-0.020066922372027875",
         "0.5383491666666667",
         "0.025593833240262726",
         "0.5895368331471921",
         "0.4871615001861412",
         "0.5044",
         "0.5052",
         "0.5039",
         "0.5047291666666666",
         "0.5043747375642579"
        ],
        [
         "2024-02-02 14:00:00",
         "BINANCE:XRPUSDT",
         "0.5037",
         "0.5039",
         "0.4987",
         "0.5005",
         "31253317.0",
         "0.5013",
         "-0.0032000000000000917",
         "0",
         "0.5197553571428571",
         "0.5508111111111111",
         "0.515484026604884",
         "0.5495704543162743",
         "45.94594594594595",
         "0.523577882470148",
         "0.5445281966534542",
         "-0.020950314183306173",
         "-0.02007506423203966",
         "0.538198125",
         "0.02560284220230409",
         "0.5894038094046081",
         "0.4869924405953918",
         "0.5037",
         "0.5044",
         "0.5052",
         "0.5049291666666667",
         "0.5040647585591173"
        ],
        [
         "2024-02-02 15:00:00",
         "BINANCE:XRPUSDT",
         "0.5005",
         "0.5019",
         "0.4989",
         "0.4999",
         "20519840.0",
         "0.5004",
         "-0.0005999999999999339",
         "0",
         "0.5196321428571429",
         "0.5507255555555556",
         "0.5152996002545305",
         "0.5494326721961181",
         "46.29134647510859",
         "0.523414021691808",
         "0.5443853864241631",
         "-0.02097136473235517",
         "-0.02008332506614395",
         "0.5380474999999999",
         "0.025615059383560842",
         "0.5892776187671216",
         "0.4868173812328782",
         "0.5005",
         "0.5037",
         "0.5044",
         "0.5049375",
         "0.5037315778743879"
        ],
        [
         "2024-02-02 16:00:00",
         "BINANCE:XRPUSDT",
         "0.4999",
         "0.5042",
         "0.4999",
         "0.5027",
         "21392905.0",
         "0.50205",
         "0.0028000000000000247",
         "1",
         "0.5195214285714286",
         "0.5506230555555556",
         "0.5151504925592105",
         "0.5493030392635353",
         "46.963087248322154",
         "0.5232706720607229",
         "0.5442519931876059",
         "-0.020981321126883",
         "-0.02009160152753325",
         "0.5378985416666667",
         "0.025612279682217805",
         "0.5891231010311023",
         "0.48667398230223113",
         "0.4999",
         "0.5005",
         "0.5037",
         "0.505075",
         "0.503649051644437"
        ],
        [
         "2024-02-02 17:00:00",
         "BINANCE:XRPUSDT",
         "0.5026",
         "0.5049",
         "0.5021",
         "0.5026",
         "19121253.0",
         "0.5035000000000001",
         "0.0",
         "0",
         "0.5193875",
         "0.5505222222222222",
         "0.5150019660200482",
         "0.5491734885304881",
         "47.960932145305016",
         "0.5231276224270847",
         "0.5441187068094056",
         "-0.02099108438232089",
         "-0.020099891692093506",
         "0.53775375",
         "0.02561497691342976",
         "0.5889837038268595",
         "0.4865237961731405",
         "0.5027",
         "0.4999",
         "0.5005",
         "0.505175",
         "0.5035651275128821"
        ],
        [
         "2024-02-02 18:00:00",
         "BINANCE:XRPUSDT",
         "0.5025",
         "0.5064",
         "0.5021",
         "0.5028",
         "19525030.0",
         "0.50425",
         "0.000300000000000078",
         "1",
         "0.5192553571428571",
         "0.5504220833333333",
         "0.5148575640553139",
         "0.5490448519464923",
         "47.07215057511329",
         "0.522986946839354",
         "0.5439864869476154",
         "-0.02099954010826144",
         "-0.0201081833825651",
         "0.5376047916666666",
         "0.02560990230340356",
         "0.5888245962734737",
         "0.4863849870598595",
         "0.5026",
         "0.5027",
         "0.4999",
         "0.5050291666666668",
         "0.5035039173118515"
        ],
        [
         "2024-02-02 19:00:00",
         "BINANCE:XRPUSDT",
         "0.5028",
         "0.5037",
         "0.5009",
         "0.5034",
         "9260259.0",
         "0.5023",
         "0.0005999999999999339",
         "1",
         "0.5190797619047619",
         "0.55032875",
         "0.5147219715812866",
         "0.5489182365458086",
         "46.52227504842402",
         "0.5228513970342373",
         "0.543856610189383",
         "-0.021005213155145697",
         "-0.020116450938072756",
         "0.5374583333333334",
         "0.025604065221762565",
         "0.5886664637768585",
         "0.48625020288980825",
         "0.5028",
         "0.5026",
         "0.5027",
         "0.5049625",
         "0.5034956039269034"
        ],
        [
         "2024-02-02 20:00:00",
         "BINANCE:XRPUSDT",
         "0.5034",
         "0.5049",
         "0.5021",
         "0.5044",
         "7649530.0",
         "0.5035000000000001",
         "0.0010000000000000009",
         "1",
         "0.5189125",
         "0.5502323611111111",
         "0.514599818071449",
         "0.5487947462918673",
         "46.31430086618349",
         "0.5227237057052806",
         "0.543730349036777",
         "-0.021006643331496377",
         "-0.020124655476260994",
         "0.5373125",
         "0.02559256420095343",
         "0.5884976284019068",
         "0.4861273715980931",
         "0.5034",
         "0.5028",
         "0.5026",
         "0.5047458333333333",
         "0.5035679556127511"
        ],
        [
         "2024-02-02 21:00:00",
         "BINANCE:XRPUSDT",
         "0.5044",
         "0.5055",
         "0.5039",
         "0.5051",
         "6808346.0",
         "0.5046999999999999",
         "0.0007000000000000339",
         "1",
         "0.5187601190476191",
         "0.5501168055555555",
         "0.5144873941889466",
         "0.5486735403382144",
         "46.47090040686361",
         "0.5226017423439984",
         "0.5436067319198593",
         "-0.021004989575860944",
         "-0.020132769154598322",
         "0.5371662500000001",
         "0.025575604619834717",
         "0.5883174592396695",
         "0.48601504076033064",
         "0.5044",
         "0.5034",
         "0.5028",
         "0.5046333333333334",
         "0.5036905191637311"
        ],
        [
         "2024-02-02 22:00:00",
         "BINANCE:XRPUSDT",
         "0.505",
         "0.5086",
         "0.505",
         "0.5077",
         "10105783.0",
         "0.5068",
         "0.0027000000000000357",
         "1",
         "0.5186119047619048",
         "0.5500027777777778",
         "0.5144070699973614",
         "0.5485598828060695",
         "46.537102473498244",
         "0.5224986160994032",
         "0.5434918303777158",
         "-0.020993214278312577",
         "-0.02014069952440214",
         "0.5370218750000001",
         "0.025545855463094215",
         "0.5881135859261886",
         "0.4859301640738117",
         "0.5051",
         "0.5044",
         "0.5034",
         "0.5045791666666667",
         "0.5040112776306326"
        ],
        [
         "2024-02-02 23:00:00",
         "BINANCE:XRPUSDT",
         "0.5076",
         "0.5142",
         "0.5076",
         "0.511",
         "29196757.0",
         "0.5109",
         "0.0033999999999999586",
         "1",
         "0.518485119047619",
         "0.5499026388888889",
         "0.5143667496423631",
         "0.5484556945042496",
         "46.86346863468635",
         "0.5224190409014834",
         "0.543387856520507",
         "-0.02096881561902364",
         "-0.020148331930804182",
         "0.5368858333333334",
         "0.025510096395216033",
         "0.5879060261237654",
         "0.4858656405429013",
         "0.5077",
         "0.5051",
         "0.5044",
         "0.5048041666666666",
         "0.504570375420182"
        ],
        [
         "2024-02-03 00:00:00",
         "BINANCE:XRPUSDT",
         "0.511",
         "0.5114",
         "0.5088",
         "0.5105",
         "8673201.0",
         "0.5101",
         "-0.000500000000000056",
         "0",
         "0.5183553571428572",
         "0.5498029166666666",
         "0.5143209892915659",
         "0.5483504082504236",
         "47.02045133991537",
         "0.5223365561893624",
         "0.5432826153796414",
         "-0.02094605919027903",
         "-0.0201556842557763",
         "0.5367520833333334",
         "0.025479704884379895",
         "0.5877114931020931",
         "0.48579267356457356",
         "0.511",
         "0.5077",
         "0.5051",
         "0.505",
         "0.5050447453865675"
        ],
        [
         "2024-02-03 01:00:00",
         "BINANCE:XRPUSDT",
         "0.5106",
         "0.5109",
         "0.5074",
         "0.5079",
         "7292121.0",
         "0.50915",
         "-0.0027000000000000357",
         "0",
         "0.5182172619047619",
         "0.5497020833333334",
         "0.5142450012526124",
         "0.5482382018475097",
         "47.22025495750709",
         "0.5222366492261142",
         "0.5431693910104265",
         "-0.02093274178431226",
         "-0.0201628460763158",
         "0.5366183333333333",
         "0.025462262331966856",
         "0.587542857997267",
         "0.4856938086693996",
         "0.5105",
         "0.511",
         "0.5077",
         "0.5051249999999999",
         "0.5052731657556422"
        ],
        [
         "2024-02-03 02:00:00",
         "BINANCE:XRPUSDT",
         "0.5078",
         "0.5095",
         "0.5063",
         "0.5076",
         "4555860.0",
         "0.5079",
         "-0.00019999999999997797",
         "0",
         "0.5180773809523809",
         "0.5496108333333333",
         "0.5141663621845342",
         "0.5481254745192226",
         "46.7428163483848",
         "0.5221353575359682",
         "0.5430555689591932",
         "-0.020920211423224977",
         "-0.020169826402093763",
         "0.536478125",
         "0.02543630467740796",
         "0.587350734354816",
         "0.4856055156451841",
         "0.5079",
         "0.5105",
         "0.511",
         "0.5052458333333333",
         "0.5054593124951908"
        ],
        [
         "2024-02-03 03:00:00",
         "BINANCE:XRPUSDT",
         "0.5076",
         "0.5079",
         "0.506",
         "0.5063",
         "3378520.0",
         "0.50695",
         "-0.0013000000000000789",
         "0",
         "0.5179208333333334",
         "0.5495052777777778",
         "0.5140732691409303",
         "0.5480094537854661",
         "46.734475374732334",
         "0.5220257702865843",
         "0.5429379511385237",
         "-0.020912180851939466",
         "-0.020176668378590036",
         "0.5363347916666666",
         "0.02541204853632268",
         "0.587158888739312",
         "0.4855106945940213",
         "0.5076",
         "0.5079",
         "0.5105",
         "0.5052249999999999",
         "0.5055265674955756"
        ],
        [
         "2024-02-03 04:00:00",
         "BINANCE:XRPUSDT",
         "0.5063",
         "0.508",
         "0.5062",
         "0.5077",
         "4007558.0",
         "0.5071",
         "0.0014000000000000679",
         "1",
         "0.5177726190476191",
         "0.5494029166666666",
         "0.5139978458374873",
         "0.5478976383796811",
         "46.8293551834699",
         "0.5219266300077843",
         "0.5428251896948804",
         "-0.020898559687096085",
         "-0.020183321754705302",
         "0.5361970833333333",
         "0.02538768691723643",
         "0.5869724571678061",
         "0.48542170949886043",
         "0.5063",
         "0.5076",
         "0.5079",
         "0.5052916666666667",
         "0.5057004420959296"
        ],
        [
         "2024-02-03 05:00:00",
         "BINANCE:XRPUSDT",
         "0.5077",
         "0.5083",
         "0.5069",
         "0.5074",
         "3834891.0",
         "0.5076",
         "-0.000300000000000078",
         "0",
         "0.517614880952381",
         "0.5492976388888889",
         "0.513919764821659",
         "0.547785300963926",
         "46.62379421221865",
         "0.5218260996963117",
         "0.5427118290878568",
         "-0.020885729391545094",
         "-0.02018979555780982",
         "0.5360612499999999",
         "0.025366924828621285",
         "0.5867950996572425",
         "0.48532740034275734",
         "0.5077",
         "0.5063",
         "0.5076",
         "0.5053291666666667",
         "0.5058364067282553"
        ],
        [
         "2024-02-03 06:00:00",
         "BINANCE:XRPUSDT",
         "0.5075",
         "0.508",
         "0.5065",
         "0.5078",
         "3804494.0",
         "0.50725",
         "0.000300000000000078",
         "1",
         "0.5174738095238095",
         "0.5491955555555555",
         "0.5138473415693317",
         "0.5476743847337903",
         "46.72028596961574",
         "0.5217290332624271",
         "0.5426001112347756",
         "-0.02087107797234844",
         "-0.020196074658404648",
         "0.5359220833333332",
         "0.025338275317553876",
         "0.586598633968441",
         "0.4852455326982255",
         "0.5074",
         "0.5077",
         "0.5063",
         "0.505375",
         "0.5059934941899948"
        ]
       ],
       "shape": {
        "columns": 27,
        "rows": 9275
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>1_day_SMA</th>\n",
       "      <th>1_day_EMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-01 05:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>17875875.0</td>\n",
       "      <td>0.49710</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019820</td>\n",
       "      <td>0.543675</td>\n",
       "      <td>0.025918</td>\n",
       "      <td>0.595512</td>\n",
       "      <td>0.491838</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.505550</td>\n",
       "      <td>0.505323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 06:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>10485001.0</td>\n",
       "      <td>0.49645</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019824</td>\n",
       "      <td>0.543457</td>\n",
       "      <td>0.025881</td>\n",
       "      <td>0.595220</td>\n",
       "      <td>0.491694</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.504871</td>\n",
       "      <td>0.504553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 07:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>26116194.0</td>\n",
       "      <td>0.49390</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019829</td>\n",
       "      <td>0.543245</td>\n",
       "      <td>0.025870</td>\n",
       "      <td>0.594985</td>\n",
       "      <td>0.491505</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.504146</td>\n",
       "      <td>0.503701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 08:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>17569499.0</td>\n",
       "      <td>0.49280</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019834</td>\n",
       "      <td>0.543034</td>\n",
       "      <td>0.025865</td>\n",
       "      <td>0.594764</td>\n",
       "      <td>0.491304</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.503392</td>\n",
       "      <td>0.502837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 09:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>0.4938</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>18873523.0</td>\n",
       "      <td>0.49190</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019839</td>\n",
       "      <td>0.542825</td>\n",
       "      <td>0.025863</td>\n",
       "      <td>0.594550</td>\n",
       "      <td>0.491099</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.502696</td>\n",
       "      <td>0.502058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 11:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6787</td>\n",
       "      <td>2.6601</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>4420326.0</td>\n",
       "      <td>2.66940</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>1</td>\n",
       "      <td>2.684121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044497</td>\n",
       "      <td>2.562806</td>\n",
       "      <td>0.164862</td>\n",
       "      <td>2.892530</td>\n",
       "      <td>2.233082</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6715</td>\n",
       "      <td>2.6596</td>\n",
       "      <td>2.678383</td>\n",
       "      <td>2.671862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 12:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6758</td>\n",
       "      <td>2.6773</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>6597897.0</td>\n",
       "      <td>2.66400</td>\n",
       "      <td>-0.0251</td>\n",
       "      <td>0</td>\n",
       "      <td>2.683635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044301</td>\n",
       "      <td>2.562089</td>\n",
       "      <td>0.163724</td>\n",
       "      <td>2.889538</td>\n",
       "      <td>2.234641</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6715</td>\n",
       "      <td>2.677108</td>\n",
       "      <td>2.670169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 13:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6508</td>\n",
       "      <td>2.6661</td>\n",
       "      <td>2.6454</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>4207626.0</td>\n",
       "      <td>2.65575</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>1</td>\n",
       "      <td>2.683442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044106</td>\n",
       "      <td>2.561391</td>\n",
       "      <td>0.162561</td>\n",
       "      <td>2.886513</td>\n",
       "      <td>2.236269</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.676225</td>\n",
       "      <td>2.669803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 14:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.6655</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>16416120.0</td>\n",
       "      <td>2.69075</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>1</td>\n",
       "      <td>2.683311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043909</td>\n",
       "      <td>2.560812</td>\n",
       "      <td>0.161570</td>\n",
       "      <td>2.883953</td>\n",
       "      <td>2.237671</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.675996</td>\n",
       "      <td>2.672115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 15:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.7012</td>\n",
       "      <td>2.6793</td>\n",
       "      <td>2.6851</td>\n",
       "      <td>3973640.0</td>\n",
       "      <td>2.69025</td>\n",
       "      <td>-0.0136</td>\n",
       "      <td>0</td>\n",
       "      <td>2.683049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043711</td>\n",
       "      <td>2.560235</td>\n",
       "      <td>0.160625</td>\n",
       "      <td>2.881484</td>\n",
       "      <td>2.238986</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.675717</td>\n",
       "      <td>2.673154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9275 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              symbol    open    high     low   close  \\\n",
       "datetime                                                               \n",
       "2024-02-01 05:00:00  BINANCE:XRPUSDT  0.4977  0.4988  0.4954  0.4960   \n",
       "2024-02-01 06:00:00  BINANCE:XRPUSDT  0.4959  0.4974  0.4955  0.4957   \n",
       "2024-02-01 07:00:00  BINANCE:XRPUSDT  0.4956  0.4959  0.4919  0.4939   \n",
       "2024-02-01 08:00:00  BINANCE:XRPUSDT  0.4939  0.4940  0.4916  0.4929   \n",
       "2024-02-01 09:00:00  BINANCE:XRPUSDT  0.4929  0.4938  0.4900  0.4931   \n",
       "...                              ...     ...     ...     ...     ...   \n",
       "2025-02-21 11:00:00  BINANCE:XRPUSDT  2.6670  2.6787  2.6601  2.6757   \n",
       "2025-02-21 12:00:00  BINANCE:XRPUSDT  2.6758  2.6773  2.6507  2.6507   \n",
       "2025-02-21 13:00:00  BINANCE:XRPUSDT  2.6508  2.6661  2.6454  2.6656   \n",
       "2025-02-21 14:00:00  BINANCE:XRPUSDT  2.6656  2.7160  2.6655  2.6987   \n",
       "2025-02-21 15:00:00  BINANCE:XRPUSDT  2.6987  2.7012  2.6793  2.6851   \n",
       "\n",
       "                         volume    av_pr    diff  candle  7_day_SMA  ...  \\\n",
       "datetime                                                             ...   \n",
       "2024-02-01 05:00:00  17875875.0  0.49710 -0.0017       0   0.521835  ...   \n",
       "2024-02-01 06:00:00  10485001.0  0.49645 -0.0002       0   0.521746  ...   \n",
       "2024-02-01 07:00:00  26116194.0  0.49390 -0.0017       0   0.521644  ...   \n",
       "2024-02-01 08:00:00  17569499.0  0.49280 -0.0010       0   0.521520  ...   \n",
       "2024-02-01 09:00:00  18873523.0  0.49190  0.0002       1   0.521411  ...   \n",
       "...                         ...      ...     ...     ...        ...  ...   \n",
       "2025-02-21 11:00:00   4420326.0  2.66940  0.0087       1   2.684121  ...   \n",
       "2025-02-21 12:00:00   6597897.0  2.66400 -0.0251       0   2.683635  ...   \n",
       "2025-02-21 13:00:00   4207626.0  2.65575  0.0148       1   2.683442  ...   \n",
       "2025-02-21 14:00:00  16416120.0  2.69075  0.0331       1   2.683311  ...   \n",
       "2025-02-21 15:00:00   3973640.0  2.69025 -0.0136       0   2.683049  ...   \n",
       "\n",
       "                     Signal_Line  20_day_SMA  20_day_STD  Upper_Band  \\\n",
       "datetime                                                               \n",
       "2024-02-01 05:00:00    -0.019820    0.543675    0.025918    0.595512   \n",
       "2024-02-01 06:00:00    -0.019824    0.543457    0.025881    0.595220   \n",
       "2024-02-01 07:00:00    -0.019829    0.543245    0.025870    0.594985   \n",
       "2024-02-01 08:00:00    -0.019834    0.543034    0.025865    0.594764   \n",
       "2024-02-01 09:00:00    -0.019839    0.542825    0.025863    0.594550   \n",
       "...                          ...         ...         ...         ...   \n",
       "2025-02-21 11:00:00    -0.044497    2.562806    0.164862    2.892530   \n",
       "2025-02-21 12:00:00    -0.044301    2.562089    0.163724    2.889538   \n",
       "2025-02-21 13:00:00    -0.044106    2.561391    0.162561    2.886513   \n",
       "2025-02-21 14:00:00    -0.043909    2.560812    0.161570    2.883953   \n",
       "2025-02-21 15:00:00    -0.043711    2.560235    0.160625    2.881484   \n",
       "\n",
       "                     Lower_Band   lag_1   lag_2   lag_3  1_day_SMA  1_day_EMA  \n",
       "datetime                                                                       \n",
       "2024-02-01 05:00:00    0.491838  0.4978  0.4977  0.4940   0.505550   0.505323  \n",
       "2024-02-01 06:00:00    0.491694  0.4960  0.4978  0.4977   0.504871   0.504553  \n",
       "2024-02-01 07:00:00    0.491505  0.4957  0.4960  0.4978   0.504146   0.503701  \n",
       "2024-02-01 08:00:00    0.491304  0.4939  0.4957  0.4960   0.503392   0.502837  \n",
       "2024-02-01 09:00:00    0.491099  0.4929  0.4939  0.4957   0.502696   0.502058  \n",
       "...                         ...     ...     ...     ...        ...        ...  \n",
       "2025-02-21 11:00:00    2.233082  2.6670  2.6715  2.6596   2.678383   2.671862  \n",
       "2025-02-21 12:00:00    2.234641  2.6757  2.6670  2.6715   2.677108   2.670169  \n",
       "2025-02-21 13:00:00    2.236269  2.6507  2.6757  2.6670   2.676225   2.669803  \n",
       "2025-02-21 14:00:00    2.237671  2.6656  2.6507  2.6757   2.675996   2.672115  \n",
       "2025-02-21 15:00:00    2.238986  2.6987  2.6656  2.6507   2.675717   2.673154  \n",
       "\n",
       "[9275 rows x 27 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"symbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1_day_EMA",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "248bdc70-ceb0-4292-91f6-d7a848e12d70",
       "rows": [
        [
         "2024-02-01 05:00:00",
         "0.4977",
         "0.4988",
         "0.4954",
         "0.496",
         "17875875.0",
         "0.4971",
         "-0.0016999999999999793",
         "0",
         "0.521835119047619",
         "0.5564677777777778",
         "0.5217690565511647",
         "0.5541265191135628",
         "44.1161907905595",
         "0.5290693117335377",
         "0.549258785305369",
         "-0.020189473571831318",
         "-0.019820153741063586",
         "0.543675",
         "0.025918414633595385",
         "0.5955118292671908",
         "0.4918381707328092",
         "0.4978",
         "0.4977",
         "0.494",
         "0.50555",
         "0.5053228680111399"
        ],
        [
         "2024-02-01 06:00:00",
         "0.4959",
         "0.4974",
         "0.4955",
         "0.4957",
         "10485001.0",
         "0.49645",
         "-0.00020000000000003348",
         "0",
         "0.5217464285714286",
         "0.556281111111111",
         "0.5214605470061805",
         "0.553964448325453",
         "44.0851344662597",
         "0.528838382240572",
         "0.5490873971923917",
         "-0.020249014951819744",
         "-0.01982410637895074",
         "0.5434572916666666",
         "0.025881488152254092",
         "0.5952202679711748",
         "0.49169431536215835",
         "0.496",
         "0.4978",
         "0.4977",
         "0.5048708333333333",
         "0.5045530385702487"
        ],
        [
         "2024-02-01 07:00:00",
         "0.4956",
         "0.4959",
         "0.4919",
         "0.4939",
         "26116194.0",
         "0.4939",
         "-0.0016999999999999793",
         "0",
         "0.5216440476190476",
         "0.5560945833333334",
         "0.5211343866865807",
         "0.5537978340443838",
         "44.05605935696621",
         "0.5285965941281805",
         "0.5489107975213761",
         "-0.020314203393195562",
         "-0.0198286234021235",
         "0.5432454166666667",
         "0.025870011895699225",
         "0.5949854404580651",
         "0.49150539287526823",
         "0.4957",
         "0.496",
         "0.4978",
         "0.5041458333333333",
         "0.5037007954846289"
        ],
        [
         "2024-02-01 08:00:00",
         "0.4939",
         "0.494",
         "0.4916",
         "0.4929",
         "17569499.0",
         "0.4928",
         "-0.0010000000000000009",
         "0",
         "0.5215196428571429",
         "0.5559031944444445",
         "0.5208002519328934",
         "0.5536289080137474",
         "43.74276739957019",
         "0.5283495588746984",
         "0.5487315629693077",
         "-0.02038200409460933",
         "-0.019833723685003555",
         "0.5430335416666666",
         "0.025865000815384898",
         "0.5947635432974364",
         "0.4913035400358968",
         "0.4939",
         "0.4957",
         "0.496",
         "0.5033916666666667",
         "0.5028367318458585"
        ],
        [
         "2024-02-01 09:00:00",
         "0.4929",
         "0.4938",
         "0.49",
         "0.4931",
         "18873523.0",
         "0.4919",
         "0.00019999999999997797",
         "1",
         "0.5214113095238095",
         "0.5557090277777778",
         "0.5204724383005515",
         "0.553461005356289",
         "43.95020746887968",
         "0.5281056172907904",
         "0.5485535419678059",
         "-0.020447924677015505",
         "-0.01983938452363961",
         "0.5428247916666666",
         "0.02586281033072055",
         "0.5945504123281078",
         "0.49109917100522554",
         "0.4929",
         "0.4939",
         "0.4957",
         "0.5026958333333333",
         "0.5020577932981899"
        ],
        [
         "2024-02-01 10:00:00",
         "0.4931",
         "0.4961",
         "0.493",
         "0.4957",
         "14374976.0",
         "0.49455",
         "0.002599999999999991",
         "1",
         "0.5213172619047619",
         "0.5555118055555556",
         "0.520179273350249",
         "0.5533007806534975",
         "44.22027451628908",
         "0.5278813569635185",
         "0.548384410633509",
         "-0.0205030536699905",
         "-0.019845501289965425",
         "0.54261625",
         "0.025838319896080014",
         "0.59429288979216",
         "0.49093961020784",
         "0.4931",
         "0.4929",
         "0.4939",
         "0.5022625",
         "0.5015491698343347"
        ],
        [
         "2024-02-01 11:00:00",
         "0.4957",
         "0.4976",
         "0.4938",
         "0.4938",
         "16570530.0",
         "0.49570000000000003",
         "-0.0018999999999999573",
         "0",
         "0.5212029761904762",
         "0.5553134722222222",
         "0.519867092600542",
         "0.5531357299443339",
         "44.26419466975667",
         "0.5276454998219023",
         "0.5482097405194818",
         "-0.02056424069757945",
         "-0.019852125616302882",
         "0.5424020833333334",
         "0.02581596008737805",
         "0.5940340035080895",
         "0.4907701631585773",
         "0.4957",
         "0.4931",
         "0.4929",
         "0.5019166666666667",
         "0.500929236247588"
        ],
        [
         "2024-02-01 12:00:00",
         "0.4938",
         "0.495",
         "0.4924",
         "0.4927",
         "11659683.0",
         "0.4937",
         "-0.0010999999999999899",
         "0",
         "0.5210874999999999",
         "0.55512",
         "0.5195455885460977",
         "0.5529680857558614",
         "44.183740912095175",
         "0.5274036624528926",
         "0.5480321093498195",
         "-0.02062844689692689",
         "-0.019859280651147344",
         "0.5421775",
         "0.02577835820151729",
         "0.5937342164030346",
         "0.49062078359696537",
         "0.4938",
         "0.4957",
         "0.4931",
         "0.5013208333333333",
         "0.500270897347781"
        ],
        [
         "2024-02-01 13:00:00",
         "0.4928",
         "0.4954",
         "0.4926",
         "0.4946",
         "12144325.0",
         "0.494",
         "0.0017999999999999683",
         "1",
         "0.5210065476190476",
         "0.5549322222222222",
         "0.5192503744804634",
         "0.5528061770575096",
         "44.556585043017876",
         "0.5271766474878207",
         "0.5478611265999002",
         "-0.02068447911207949",
         "-0.019866886166916304",
         "0.5419625",
         "0.025743817588890657",
         "0.5934501351777813",
         "0.4904748648222187",
         "0.4927",
         "0.4938",
         "0.4957",
         "0.5007958333333334",
         "0.4998172255599585"
        ],
        [
         "2024-02-01 14:00:00",
         "0.4946",
         "0.4961",
         "0.4931",
         "0.4957",
         "11711475.0",
         "0.4946",
         "0.0010999999999999899",
         "1",
         "0.5209327380952381",
         "0.5547433333333333",
         "0.5189716718238899",
         "0.5526477687993749",
         "44.510680576254344",
         "0.5269588160173166",
         "0.5476942109947804",
         "-0.020735394977463795",
         "-0.01987489085641444",
         "0.5417489583333333",
         "0.025701438165131155",
         "0.5931518346635956",
         "0.49034608200307095",
         "0.4946",
         "0.4927",
         "0.4938",
         "0.5003791666666667",
         "0.49948784751516184"
        ],
        [
         "2024-02-01 15:00:00",
         "0.4957",
         "0.5003",
         "0.4952",
         "0.4997",
         "18079854.0",
         "0.49774999999999997",
         "0.0040000000000000036",
         "1",
         "0.5208791666666667",
         "0.55456875",
         "0.5187436047017138",
         "0.5525008956543004",
         "44.69384386862519",
         "0.5267701736919373",
         "0.5475406295195971",
         "-0.020770455827659795",
         "-0.019883144911448956",
         "0.5415427083333333",
         "0.02564061864680985",
         "0.592823945626953",
         "0.49026147103971357",
         "0.4957",
         "0.4946",
         "0.4927",
         "0.5001666666666666",
         "0.49950481971394894"
        ],
        [
         "2024-02-01 16:00:00",
         "0.4997",
         "0.5026",
         "0.4994",
         "0.4994",
         "15973829.0",
         "0.501",
         "-0.00029999999999996696",
         "0",
         "0.5208333333333334",
         "0.5543934722222222",
         "0.5185146863028769",
         "0.5523535977467988",
         "44.79735318444996",
         "0.5265807607252112",
         "0.5473865795051344",
         "-0.020805818779923158",
         "-0.019891648818070838",
         "0.5413595833333333",
         "0.02562702513680688",
         "0.5926136336069471",
         "0.4901055330597196",
         "0.4997",
         "0.4957",
         "0.4946",
         "0.4997833333333334",
         "0.49949643413683303"
        ],
        [
         "2024-02-01 17:00:00",
         "0.4995",
         "0.5008",
         "0.4975",
         "0.5002",
         "13043674.0",
         "0.49915",
         "0.0006999999999999784",
         "1",
         "0.5207940476190477",
         "0.5542170833333333",
         "0.5182979444531387",
         "0.5522089275727439",
         "45.33466866967117",
         "0.5263981949070436",
         "0.547235582450718",
         "-0.02083738754367437",
         "-0.019900365304021103",
         "0.5411918749999999",
         "0.025632439581489662",
         "0.5924567541629792",
         "0.48992699583702054",
         "0.4994",
         "0.4997",
         "0.4957",
         "0.49937499999999996",
         "0.4995527194058864"
        ],
        [
         "2024-02-01 18:00:00",
         "0.5002",
         "0.507",
         "0.5001",
         "0.5063",
         "18435984.0",
         "0.5035499999999999",
         "0.006099999999999994",
         "1",
         "0.5207833333333334",
         "0.5540552777777777",
         "0.5181559569448176",
         "0.5520815796460511",
         "46.12190666002325",
         "0.5262591070530156",
         "0.5471045885868757",
         "-0.020845481533860122",
         "-0.019909076052683217",
         "0.5410412499999999",
         "0.02562458628414888",
         "0.5922904225682977",
         "0.48979207743170217",
         "0.5002",
         "0.4994",
         "0.4997",
         "0.499075",
         "0.5000925018534156"
        ],
        [
         "2024-02-01 19:00:00",
         "0.5062",
         "0.5066",
         "0.504",
         "0.505",
         "6947841.0",
         "0.5053000000000001",
         "-0.0011999999999999789",
         "0",
         "0.5207416666666667",
         "0.5538877777777778",
         "0.5180002651466542",
         "0.5519509788703338",
         "46.045431935002505",
         "0.5261119852048978",
         "0.5469698539033977",
         "-0.020857868698499926",
         "-0.019917820685363557",
         "0.5408877083333333",
         "0.025619268643810696",
         "0.5921262456209547",
         "0.48964917104571193",
         "0.5063",
         "0.5002",
         "0.4994",
         "0.4987791666666667",
         "0.5004851017051424"
        ],
        [
         "2024-02-01 20:00:00",
         "0.505",
         "0.5107",
         "0.505",
         "0.5096",
         "12197349.0",
         "0.50785",
         "0.0046000000000000485",
         "1",
         "0.5207166666666667",
         "0.5537238888888889",
         "0.5179008537248004",
         "0.5518335004268655",
         "46.909272183449666",
         "0.5259977154110922",
         "0.5468502703709068",
         "-0.02085255495981464",
         "-0.019926435747800893",
         "0.5407410416666667",
         "0.0255963936606794",
         "0.5919338289880255",
         "0.4895482543453079",
         "0.505",
         "0.5063",
         "0.5002",
         "0.49872500000000003",
         "0.501214293568731"
        ],
        [
         "2024-02-01 21:00:00",
         "0.5096",
         "0.5099",
         "0.5071",
         "0.5078",
         "7515078.0",
         "0.5085",
         "-0.0018000000000000238",
         "0",
         "0.5206827380952381",
         "0.5535598611111111",
         "0.5177813169943294",
         "0.5517113547946134",
         "46.66334661354582",
         "0.5258717796643027",
         "0.54672530950572",
         "-0.020853529841417306",
         "-0.01993498039382501",
         "0.540589375",
         "0.025575396572451708",
         "0.5917401681449035",
         "0.48943858185509664",
         "0.5096",
         "0.505",
         "0.5063",
         "0.4988166666666667",
         "0.5017411500832326"
        ],
        [
         "2024-02-01 22:00:00",
         "0.5077",
         "0.5094",
         "0.507",
         "0.509",
         "5816505.0",
         "0.5082",
         "0.0012999999999999678",
         "1",
         "0.5206553571428572",
         "0.5533956944444445",
         "0.5176773960831539",
         "0.5515928766953219",
         "46.494587843463776",
         "0.5257550199434424",
         "0.5466045885153017",
         "-0.020849568571859267",
         "-0.01994340977795436",
         "0.5404489583333334",
         "0.025563395324976448",
         "0.5915757489832862",
         "0.4893221676833805",
         "0.5078",
         "0.5096",
         "0.505",
         "0.499025",
         "0.502321858076574"
        ],
        [
         "2024-02-01 23:00:00",
         "0.509",
         "0.5091",
         "0.5039",
         "0.5056",
         "8875061.0",
         "0.5065",
         "-0.0033999999999999586",
         "0",
         "0.5206005952380952",
         "0.5532266666666666",
         "0.5175344683188562",
         "0.5514652959000506",
         "46.08998837788479",
         "0.5256155388365674",
         "0.5464733738320527",
         "-0.020857834995485325",
         "-0.019951837660143586",
         "0.5403202083333334",
         "0.025582993355294043",
         "0.5914861950439214",
         "0.4891542216227453",
         "0.509",
         "0.5078",
         "0.5096",
         "0.49917083333333334",
         "0.5025841094304482"
        ],
        [
         "2024-02-02 00:00:00",
         "0.5056",
         "0.5063",
         "0.5046",
         "0.5058",
         "5432484.0",
         "0.50545",
         "0.00019999999999997797",
         "1",
         "0.5205529761904761",
         "0.5530616666666667",
         "0.5173955988712957",
         "0.5513386237893708",
         "46.16151545363909",
         "0.5254784070799129",
         "0.5463432190357902",
         "-0.020864811955877305",
         "-0.019960252169781686",
         "0.5401866666666667",
         "0.02559556225671297",
         "0.5913777911800926",
         "0.48899554215324076",
         "0.5056",
         "0.509",
         "0.5078",
         "0.49927499999999997",
         "0.5028413806760124"
        ],
        [
         "2024-02-02 01:00:00",
         "0.5057",
         "0.5075",
         "0.5047",
         "0.5049",
         "11571408.0",
         "0.5061",
         "-0.0008000000000000229",
         "0",
         "0.5205190476190475",
         "0.552892638888889",
         "0.5172477219615763",
         "0.5512098065250453",
         "46.26144879267278",
         "0.5253359959582526",
         "0.5462106007348757",
         "-0.020874604776623062",
         "-0.01996867938274797",
         "0.5400535416666667",
         "0.025612600222241544",
         "0.5912787421111498",
         "0.48882834122218366",
         "0.5058",
         "0.5056",
         "0.509",
         "0.4994541666666667",
         "0.5030060702219314"
        ],
        [
         "2024-02-02 02:00:00",
         "0.5048",
         "0.5067",
         "0.504",
         "0.5047",
         "9533932.0",
         "0.50535",
         "-9.999999999998899e-05",
         "0",
         "0.5204767857142857",
         "0.5527222222222222",
         "0.5170992282105518",
         "0.5510807918051421",
         "46.300000000000004",
         "0.5251931862976419",
         "0.5460777668125242",
         "-0.02088458051488229",
         "-0.019977120867836765",
         "0.5399197916666666",
         "0.025629270436124393",
         "0.5911783325389154",
         "0.4886612507944178",
         "0.5049",
         "0.5058",
         "0.5056",
         "0.4999",
         "0.5031415846041769"
        ],
        [
         "2024-02-02 03:00:00",
         "0.5046",
         "0.5069",
         "0.5041",
         "0.5068",
         "8855189.0",
         "0.5055000000000001",
         "0.0021999999999999797",
         "1",
         "0.5204392857142858",
         "0.5525565277777778",
         "0.5169773438530305",
         "0.5509579602051279",
         "46.38935108153078",
         "0.5250658978111531",
         "0.5459520779587241",
         "-0.020886180147571043",
         "-0.019985499294378095",
         "0.5397856249999999",
         "0.02563374320773814",
         "0.5910531114154762",
         "0.48851813858452364",
         "0.5047",
         "0.5049",
         "0.5058",
         "0.5002791666666667",
         "0.5034342578358427"
        ],
        [
         "2024-02-02 04:00:00",
         "0.5067",
         "0.5077",
         "0.5056",
         "0.5061",
         "10011046.0",
         "0.50665",
         "-0.0006000000000000449",
         "0",
         "0.5203958333333333",
         "0.5523898611111111",
         "0.5168486178902727",
         "0.5508335275831997",
         "46.35078969243558",
         "0.5249346459231866",
         "0.5458245513092562",
         "-0.020889905386069607",
         "-0.019993834834393688",
         "0.5396485416666666",
         "0.025637585721487534",
         "0.5909237131096418",
         "0.4883733702236916",
         "0.5068",
         "0.5047",
         "0.5049",
         "0.500625",
         "0.5036475172089753"
        ],
        [
         "2024-02-02 05:00:00",
         "0.506",
         "0.5072",
         "0.5056",
         "0.5065",
         "11980027.0",
         "0.5064",
         "0.0004999999999999449",
         "1",
         "0.52035",
         "0.5522133333333333",
         "0.5167261490395003",
         "0.5507105496980869",
         "46.32401862940785",
         "0.524807070518874",
         "0.5456987127450665",
         "-0.020891642226192553",
         "-0.02000210955689875",
         "0.5395097916666667",
         "0.02563638805371805",
         "0.5907825677741028",
         "0.4882370155592306",
         "0.5061",
         "0.5068",
         "0.5047",
         "0.5010625",
         "0.5038757158322572"
        ],
        [
         "2024-02-02 06:00:00",
         "0.5065",
         "0.5071",
         "0.505",
         "0.5067",
         "11490367.0",
         "0.50605",
         "0.000200000000000089",
         "1",
         "0.5203119047619048",
         "0.5520338888888889",
         "0.5166074963881453",
         "0.5505884677294376",
         "46.33294528521538",
         "0.5246817620723766",
         "0.5455739168642824",
         "-0.02089215479190576",
         "-0.020010312738788217",
         "0.5393660416666667",
         "0.025626485047009803",
         "0.5906190117606863",
         "0.48811307157264705",
         "0.5065",
         "0.5061",
         "0.5068",
         "0.5015208333333333",
         "0.5041016585656767"
        ],
        [
         "2024-02-02 07:00:00",
         "0.5066",
         "0.5067",
         "0.5028",
         "0.5048",
         "20439851.0",
         "0.50475",
         "-0.0018000000000000238",
         "0",
         "0.5202678571428572",
         "0.551853888888889",
         "0.5164677627030786",
         "0.5504614539493281",
         "46.17807992041122",
         "0.5245441720234328",
         "0.5454434403303167",
         "-0.020899268306883823",
         "-0.020018505877664676",
         "0.5392193750000001",
         "0.025622428271072032",
         "0.5904642315421441",
         "0.487974518457856",
         "0.5067",
         "0.5065",
         "0.5061",
         "0.5019750000000001",
         "0.5041575258804226"
        ],
        [
         "2024-02-02 08:00:00",
         "0.5047",
         "0.5076",
         "0.5047",
         "0.5069",
         "13277552.0",
         "0.5061500000000001",
         "0.0021999999999999797",
         "1",
         "0.5202404761904761",
         "0.5516802777777777",
         "0.5163545347420955",
         "0.5503406177386504",
         "46.65004156275977",
         "0.5244220670267309",
         "0.5453201013212596",
         "-0.020898034294528745",
         "-0.02002661213035467",
         "0.5390779166666666",
         "0.025613013961038916",
         "0.5903039445887445",
         "0.4878518887445888",
         "0.5048",
         "0.5067",
         "0.5065",
         "0.5025583333333333",
         "0.5043769238099889"
        ],
        [
         "2024-02-02 09:00:00",
         "0.5069",
         "0.5074",
         "0.504",
         "0.5048",
         "18840225.0",
         "0.5057",
         "-0.0020999999999999908",
         "0",
         "0.5201892857142857",
         "0.5515051388888889",
         "0.5162177946859761",
         "0.5502142914758524",
         "46.53399668325042",
         "0.5242862741753348",
         "0.5451904369970315",
         "-0.020904162821696715",
         "-0.02003470015515967",
         "0.5389302083333333",
         "0.025605812719974738",
         "0.5901418337732828",
         "0.48771858289338377",
         "0.5069",
         "0.5048",
         "0.5067",
         "0.5030458333333333",
         "0.5044107699051898"
        ],
        [
         "2024-02-02 10:00:00",
         "0.5047",
         "0.505",
         "0.5029",
         "0.5039",
         "17729161.0",
         "0.50395",
         "-0.0008000000000000229",
         "0",
         "0.5201309523809524",
         "0.5513227777777778",
         "0.5160720219677989",
         "0.5500858191000526",
         "46.10768461410236",
         "0.5241451926931525",
         "0.545058307598641",
         "-0.020913114905488528",
         "-0.02004279614364196",
         "0.538786875",
         "0.025608945597155864",
         "0.5900047661943117",
         "0.48756898380568825",
         "0.5048",
         "0.5069",
         "0.5048",
         "0.5033875",
         "0.5043699083127746"
        ],
        [
         "2024-02-02 11:00:00",
         "0.5039",
         "0.5066",
         "0.5029",
         "0.5052",
         "15196406.0",
         "0.50475",
         "0.0012999999999999678",
         "1",
         "0.5200553571428572",
         "0.5511452777777778",
         "0.5159433589859315",
         "0.5499613091996364",
         "46.27810158201499",
         "0.5240140840931998",
         "0.5449307610143254",
         "-0.020916676921125532",
         "-0.020050850344356098",
         "0.5386439583333333",
         "0.025604557530736257",
         "0.5898530733948059",
         "0.4874348432718608",
         "0.5039",
         "0.5048",
         "0.5069",
         "0.5038625",
         "0.5044363156477526"
        ],
        [
         "2024-02-02 12:00:00",
         "0.5052",
         "0.506",
         "0.5035",
         "0.5044",
         "14532207.0",
         "0.50475",
         "-0.0008000000000000229",
         "0",
         "0.5199559523809524",
         "0.5509868055555555",
         "0.5158067511872814",
         "0.5498349255402754",
         "46.17177097203728",
         "0.5238783464870185",
         "0.5448010625790795",
         "-0.020922716092060978",
         "-0.0200588859733672",
         "0.5384983333333333",
         "0.025600118193011133",
         "0.5896985697193555",
         "0.487298096947311",
         "0.5052",
         "0.5039",
         "0.5048",
         "0.50435",
         "0.5044334103959325"
        ],
        [
         "2024-02-02 13:00:00",
         "0.5044",
         "0.5051",
         "0.5033",
         "0.5037",
         "15265733.0",
         "0.5042",
         "-0.0006999999999999229",
         "0",
         "0.5198589285714286",
         "0.5509054166666666",
         "0.5156634760253017",
         "0.549706950712147",
         "46.091151031270805",
         "0.5237387039507762",
         "0.5446695391788264",
         "-0.020930835228050282",
         "-0.020066922372027875",
         "0.5383491666666667",
         "0.025593833240262726",
         "0.5895368331471921",
         "0.4871615001861412",
         "0.5044",
         "0.5052",
         "0.5039",
         "0.5047291666666666",
         "0.5043747375642579"
        ],
        [
         "2024-02-02 14:00:00",
         "0.5037",
         "0.5039",
         "0.4987",
         "0.5005",
         "31253317.0",
         "0.5013",
         "-0.0032000000000000917",
         "0",
         "0.5197553571428571",
         "0.5508111111111111",
         "0.515484026604884",
         "0.5495704543162743",
         "45.94594594594595",
         "0.523577882470148",
         "0.5445281966534542",
         "-0.020950314183306173",
         "-0.02007506423203966",
         "0.538198125",
         "0.02560284220230409",
         "0.5894038094046081",
         "0.4869924405953918",
         "0.5037",
         "0.5044",
         "0.5052",
         "0.5049291666666667",
         "0.5040647585591173"
        ],
        [
         "2024-02-02 15:00:00",
         "0.5005",
         "0.5019",
         "0.4989",
         "0.4999",
         "20519840.0",
         "0.5004",
         "-0.0005999999999999339",
         "0",
         "0.5196321428571429",
         "0.5507255555555556",
         "0.5152996002545305",
         "0.5494326721961181",
         "46.29134647510859",
         "0.523414021691808",
         "0.5443853864241631",
         "-0.02097136473235517",
         "-0.02008332506614395",
         "0.5380474999999999",
         "0.025615059383560842",
         "0.5892776187671216",
         "0.4868173812328782",
         "0.5005",
         "0.5037",
         "0.5044",
         "0.5049375",
         "0.5037315778743879"
        ],
        [
         "2024-02-02 16:00:00",
         "0.4999",
         "0.5042",
         "0.4999",
         "0.5027",
         "21392905.0",
         "0.50205",
         "0.0028000000000000247",
         "1",
         "0.5195214285714286",
         "0.5506230555555556",
         "0.5151504925592105",
         "0.5493030392635353",
         "46.963087248322154",
         "0.5232706720607229",
         "0.5442519931876059",
         "-0.020981321126883",
         "-0.02009160152753325",
         "0.5378985416666667",
         "0.025612279682217805",
         "0.5891231010311023",
         "0.48667398230223113",
         "0.4999",
         "0.5005",
         "0.5037",
         "0.505075",
         "0.503649051644437"
        ],
        [
         "2024-02-02 17:00:00",
         "0.5026",
         "0.5049",
         "0.5021",
         "0.5026",
         "19121253.0",
         "0.5035000000000001",
         "0.0",
         "0",
         "0.5193875",
         "0.5505222222222222",
         "0.5150019660200482",
         "0.5491734885304881",
         "47.960932145305016",
         "0.5231276224270847",
         "0.5441187068094056",
         "-0.02099108438232089",
         "-0.020099891692093506",
         "0.53775375",
         "0.02561497691342976",
         "0.5889837038268595",
         "0.4865237961731405",
         "0.5027",
         "0.4999",
         "0.5005",
         "0.505175",
         "0.5035651275128821"
        ],
        [
         "2024-02-02 18:00:00",
         "0.5025",
         "0.5064",
         "0.5021",
         "0.5028",
         "19525030.0",
         "0.50425",
         "0.000300000000000078",
         "1",
         "0.5192553571428571",
         "0.5504220833333333",
         "0.5148575640553139",
         "0.5490448519464923",
         "47.07215057511329",
         "0.522986946839354",
         "0.5439864869476154",
         "-0.02099954010826144",
         "-0.0201081833825651",
         "0.5376047916666666",
         "0.02560990230340356",
         "0.5888245962734737",
         "0.4863849870598595",
         "0.5026",
         "0.5027",
         "0.4999",
         "0.5050291666666668",
         "0.5035039173118515"
        ],
        [
         "2024-02-02 19:00:00",
         "0.5028",
         "0.5037",
         "0.5009",
         "0.5034",
         "9260259.0",
         "0.5023",
         "0.0005999999999999339",
         "1",
         "0.5190797619047619",
         "0.55032875",
         "0.5147219715812866",
         "0.5489182365458086",
         "46.52227504842402",
         "0.5228513970342373",
         "0.543856610189383",
         "-0.021005213155145697",
         "-0.020116450938072756",
         "0.5374583333333334",
         "0.025604065221762565",
         "0.5886664637768585",
         "0.48625020288980825",
         "0.5028",
         "0.5026",
         "0.5027",
         "0.5049625",
         "0.5034956039269034"
        ],
        [
         "2024-02-02 20:00:00",
         "0.5034",
         "0.5049",
         "0.5021",
         "0.5044",
         "7649530.0",
         "0.5035000000000001",
         "0.0010000000000000009",
         "1",
         "0.5189125",
         "0.5502323611111111",
         "0.514599818071449",
         "0.5487947462918673",
         "46.31430086618349",
         "0.5227237057052806",
         "0.543730349036777",
         "-0.021006643331496377",
         "-0.020124655476260994",
         "0.5373125",
         "0.02559256420095343",
         "0.5884976284019068",
         "0.4861273715980931",
         "0.5034",
         "0.5028",
         "0.5026",
         "0.5047458333333333",
         "0.5035679556127511"
        ],
        [
         "2024-02-02 21:00:00",
         "0.5044",
         "0.5055",
         "0.5039",
         "0.5051",
         "6808346.0",
         "0.5046999999999999",
         "0.0007000000000000339",
         "1",
         "0.5187601190476191",
         "0.5501168055555555",
         "0.5144873941889466",
         "0.5486735403382144",
         "46.47090040686361",
         "0.5226017423439984",
         "0.5436067319198593",
         "-0.021004989575860944",
         "-0.020132769154598322",
         "0.5371662500000001",
         "0.025575604619834717",
         "0.5883174592396695",
         "0.48601504076033064",
         "0.5044",
         "0.5034",
         "0.5028",
         "0.5046333333333334",
         "0.5036905191637311"
        ],
        [
         "2024-02-02 22:00:00",
         "0.505",
         "0.5086",
         "0.505",
         "0.5077",
         "10105783.0",
         "0.5068",
         "0.0027000000000000357",
         "1",
         "0.5186119047619048",
         "0.5500027777777778",
         "0.5144070699973614",
         "0.5485598828060695",
         "46.537102473498244",
         "0.5224986160994032",
         "0.5434918303777158",
         "-0.020993214278312577",
         "-0.02014069952440214",
         "0.5370218750000001",
         "0.025545855463094215",
         "0.5881135859261886",
         "0.4859301640738117",
         "0.5051",
         "0.5044",
         "0.5034",
         "0.5045791666666667",
         "0.5040112776306326"
        ],
        [
         "2024-02-02 23:00:00",
         "0.5076",
         "0.5142",
         "0.5076",
         "0.511",
         "29196757.0",
         "0.5109",
         "0.0033999999999999586",
         "1",
         "0.518485119047619",
         "0.5499026388888889",
         "0.5143667496423631",
         "0.5484556945042496",
         "46.86346863468635",
         "0.5224190409014834",
         "0.543387856520507",
         "-0.02096881561902364",
         "-0.020148331930804182",
         "0.5368858333333334",
         "0.025510096395216033",
         "0.5879060261237654",
         "0.4858656405429013",
         "0.5077",
         "0.5051",
         "0.5044",
         "0.5048041666666666",
         "0.504570375420182"
        ],
        [
         "2024-02-03 00:00:00",
         "0.511",
         "0.5114",
         "0.5088",
         "0.5105",
         "8673201.0",
         "0.5101",
         "-0.000500000000000056",
         "0",
         "0.5183553571428572",
         "0.5498029166666666",
         "0.5143209892915659",
         "0.5483504082504236",
         "47.02045133991537",
         "0.5223365561893624",
         "0.5432826153796414",
         "-0.02094605919027903",
         "-0.0201556842557763",
         "0.5367520833333334",
         "0.025479704884379895",
         "0.5877114931020931",
         "0.48579267356457356",
         "0.511",
         "0.5077",
         "0.5051",
         "0.505",
         "0.5050447453865675"
        ],
        [
         "2024-02-03 01:00:00",
         "0.5106",
         "0.5109",
         "0.5074",
         "0.5079",
         "7292121.0",
         "0.50915",
         "-0.0027000000000000357",
         "0",
         "0.5182172619047619",
         "0.5497020833333334",
         "0.5142450012526124",
         "0.5482382018475097",
         "47.22025495750709",
         "0.5222366492261142",
         "0.5431693910104265",
         "-0.02093274178431226",
         "-0.0201628460763158",
         "0.5366183333333333",
         "0.025462262331966856",
         "0.587542857997267",
         "0.4856938086693996",
         "0.5105",
         "0.511",
         "0.5077",
         "0.5051249999999999",
         "0.5052731657556422"
        ],
        [
         "2024-02-03 02:00:00",
         "0.5078",
         "0.5095",
         "0.5063",
         "0.5076",
         "4555860.0",
         "0.5079",
         "-0.00019999999999997797",
         "0",
         "0.5180773809523809",
         "0.5496108333333333",
         "0.5141663621845342",
         "0.5481254745192226",
         "46.7428163483848",
         "0.5221353575359682",
         "0.5430555689591932",
         "-0.020920211423224977",
         "-0.020169826402093763",
         "0.536478125",
         "0.02543630467740796",
         "0.587350734354816",
         "0.4856055156451841",
         "0.5079",
         "0.5105",
         "0.511",
         "0.5052458333333333",
         "0.5054593124951908"
        ],
        [
         "2024-02-03 03:00:00",
         "0.5076",
         "0.5079",
         "0.506",
         "0.5063",
         "3378520.0",
         "0.50695",
         "-0.0013000000000000789",
         "0",
         "0.5179208333333334",
         "0.5495052777777778",
         "0.5140732691409303",
         "0.5480094537854661",
         "46.734475374732334",
         "0.5220257702865843",
         "0.5429379511385237",
         "-0.020912180851939466",
         "-0.020176668378590036",
         "0.5363347916666666",
         "0.02541204853632268",
         "0.587158888739312",
         "0.4855106945940213",
         "0.5076",
         "0.5079",
         "0.5105",
         "0.5052249999999999",
         "0.5055265674955756"
        ],
        [
         "2024-02-03 04:00:00",
         "0.5063",
         "0.508",
         "0.5062",
         "0.5077",
         "4007558.0",
         "0.5071",
         "0.0014000000000000679",
         "1",
         "0.5177726190476191",
         "0.5494029166666666",
         "0.5139978458374873",
         "0.5478976383796811",
         "46.8293551834699",
         "0.5219266300077843",
         "0.5428251896948804",
         "-0.020898559687096085",
         "-0.020183321754705302",
         "0.5361970833333333",
         "0.02538768691723643",
         "0.5869724571678061",
         "0.48542170949886043",
         "0.5063",
         "0.5076",
         "0.5079",
         "0.5052916666666667",
         "0.5057004420959296"
        ],
        [
         "2024-02-03 05:00:00",
         "0.5077",
         "0.5083",
         "0.5069",
         "0.5074",
         "3834891.0",
         "0.5076",
         "-0.000300000000000078",
         "0",
         "0.517614880952381",
         "0.5492976388888889",
         "0.513919764821659",
         "0.547785300963926",
         "46.62379421221865",
         "0.5218260996963117",
         "0.5427118290878568",
         "-0.020885729391545094",
         "-0.02018979555780982",
         "0.5360612499999999",
         "0.025366924828621285",
         "0.5867950996572425",
         "0.48532740034275734",
         "0.5077",
         "0.5063",
         "0.5076",
         "0.5053291666666667",
         "0.5058364067282553"
        ],
        [
         "2024-02-03 06:00:00",
         "0.5075",
         "0.508",
         "0.5065",
         "0.5078",
         "3804494.0",
         "0.50725",
         "0.000300000000000078",
         "1",
         "0.5174738095238095",
         "0.5491955555555555",
         "0.5138473415693317",
         "0.5476743847337903",
         "46.72028596961574",
         "0.5217290332624271",
         "0.5426001112347756",
         "-0.02087107797234844",
         "-0.020196074658404648",
         "0.5359220833333332",
         "0.025338275317553876",
         "0.586598633968441",
         "0.4852455326982255",
         "0.5074",
         "0.5077",
         "0.5063",
         "0.505375",
         "0.5059934941899948"
        ]
       ],
       "shape": {
        "columns": 26,
        "rows": 9275
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>30_day_SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>1_day_SMA</th>\n",
       "      <th>1_day_EMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-01 05:00:00</th>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>17875875.0</td>\n",
       "      <td>0.49710</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521835</td>\n",
       "      <td>0.556468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019820</td>\n",
       "      <td>0.543675</td>\n",
       "      <td>0.025918</td>\n",
       "      <td>0.595512</td>\n",
       "      <td>0.491838</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.505550</td>\n",
       "      <td>0.505323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 06:00:00</th>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>10485001.0</td>\n",
       "      <td>0.49645</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521746</td>\n",
       "      <td>0.556281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019824</td>\n",
       "      <td>0.543457</td>\n",
       "      <td>0.025881</td>\n",
       "      <td>0.595220</td>\n",
       "      <td>0.491694</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.504871</td>\n",
       "      <td>0.504553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 07:00:00</th>\n",
       "      <td>0.4956</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>26116194.0</td>\n",
       "      <td>0.49390</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521644</td>\n",
       "      <td>0.556095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019829</td>\n",
       "      <td>0.543245</td>\n",
       "      <td>0.025870</td>\n",
       "      <td>0.594985</td>\n",
       "      <td>0.491505</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.504146</td>\n",
       "      <td>0.503701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 08:00:00</th>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>17569499.0</td>\n",
       "      <td>0.49280</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521520</td>\n",
       "      <td>0.555903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019834</td>\n",
       "      <td>0.543034</td>\n",
       "      <td>0.025865</td>\n",
       "      <td>0.594764</td>\n",
       "      <td>0.491304</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.503392</td>\n",
       "      <td>0.502837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 09:00:00</th>\n",
       "      <td>0.4929</td>\n",
       "      <td>0.4938</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>18873523.0</td>\n",
       "      <td>0.49190</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521411</td>\n",
       "      <td>0.555709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019839</td>\n",
       "      <td>0.542825</td>\n",
       "      <td>0.025863</td>\n",
       "      <td>0.594550</td>\n",
       "      <td>0.491099</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.502696</td>\n",
       "      <td>0.502058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 11:00:00</th>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6787</td>\n",
       "      <td>2.6601</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>4420326.0</td>\n",
       "      <td>2.66940</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>1</td>\n",
       "      <td>2.684121</td>\n",
       "      <td>2.738742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044497</td>\n",
       "      <td>2.562806</td>\n",
       "      <td>0.164862</td>\n",
       "      <td>2.892530</td>\n",
       "      <td>2.233082</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6715</td>\n",
       "      <td>2.6596</td>\n",
       "      <td>2.678383</td>\n",
       "      <td>2.671862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 12:00:00</th>\n",
       "      <td>2.6758</td>\n",
       "      <td>2.6773</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>6597897.0</td>\n",
       "      <td>2.66400</td>\n",
       "      <td>-0.0251</td>\n",
       "      <td>0</td>\n",
       "      <td>2.683635</td>\n",
       "      <td>2.737931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044301</td>\n",
       "      <td>2.562089</td>\n",
       "      <td>0.163724</td>\n",
       "      <td>2.889538</td>\n",
       "      <td>2.234641</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6715</td>\n",
       "      <td>2.677108</td>\n",
       "      <td>2.670169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 13:00:00</th>\n",
       "      <td>2.6508</td>\n",
       "      <td>2.6661</td>\n",
       "      <td>2.6454</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>4207626.0</td>\n",
       "      <td>2.65575</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>1</td>\n",
       "      <td>2.683442</td>\n",
       "      <td>2.737152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044106</td>\n",
       "      <td>2.561391</td>\n",
       "      <td>0.162561</td>\n",
       "      <td>2.886513</td>\n",
       "      <td>2.236269</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.676225</td>\n",
       "      <td>2.669803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 14:00:00</th>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.6655</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>16416120.0</td>\n",
       "      <td>2.69075</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>1</td>\n",
       "      <td>2.683311</td>\n",
       "      <td>2.736484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043909</td>\n",
       "      <td>2.560812</td>\n",
       "      <td>0.161570</td>\n",
       "      <td>2.883953</td>\n",
       "      <td>2.237671</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.675996</td>\n",
       "      <td>2.672115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 15:00:00</th>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.7012</td>\n",
       "      <td>2.6793</td>\n",
       "      <td>2.6851</td>\n",
       "      <td>3973640.0</td>\n",
       "      <td>2.69025</td>\n",
       "      <td>-0.0136</td>\n",
       "      <td>0</td>\n",
       "      <td>2.683049</td>\n",
       "      <td>2.735803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043711</td>\n",
       "      <td>2.560235</td>\n",
       "      <td>0.160625</td>\n",
       "      <td>2.881484</td>\n",
       "      <td>2.238986</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.675717</td>\n",
       "      <td>2.673154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9275 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close      volume    av_pr  \\\n",
       "datetime                                                                   \n",
       "2024-02-01 05:00:00  0.4977  0.4988  0.4954  0.4960  17875875.0  0.49710   \n",
       "2024-02-01 06:00:00  0.4959  0.4974  0.4955  0.4957  10485001.0  0.49645   \n",
       "2024-02-01 07:00:00  0.4956  0.4959  0.4919  0.4939  26116194.0  0.49390   \n",
       "2024-02-01 08:00:00  0.4939  0.4940  0.4916  0.4929  17569499.0  0.49280   \n",
       "2024-02-01 09:00:00  0.4929  0.4938  0.4900  0.4931  18873523.0  0.49190   \n",
       "...                     ...     ...     ...     ...         ...      ...   \n",
       "2025-02-21 11:00:00  2.6670  2.6787  2.6601  2.6757   4420326.0  2.66940   \n",
       "2025-02-21 12:00:00  2.6758  2.6773  2.6507  2.6507   6597897.0  2.66400   \n",
       "2025-02-21 13:00:00  2.6508  2.6661  2.6454  2.6656   4207626.0  2.65575   \n",
       "2025-02-21 14:00:00  2.6656  2.7160  2.6655  2.6987  16416120.0  2.69075   \n",
       "2025-02-21 15:00:00  2.6987  2.7012  2.6793  2.6851   3973640.0  2.69025   \n",
       "\n",
       "                       diff  candle  7_day_SMA  30_day_SMA  ...  Signal_Line  \\\n",
       "datetime                                                    ...                \n",
       "2024-02-01 05:00:00 -0.0017       0   0.521835    0.556468  ...    -0.019820   \n",
       "2024-02-01 06:00:00 -0.0002       0   0.521746    0.556281  ...    -0.019824   \n",
       "2024-02-01 07:00:00 -0.0017       0   0.521644    0.556095  ...    -0.019829   \n",
       "2024-02-01 08:00:00 -0.0010       0   0.521520    0.555903  ...    -0.019834   \n",
       "2024-02-01 09:00:00  0.0002       1   0.521411    0.555709  ...    -0.019839   \n",
       "...                     ...     ...        ...         ...  ...          ...   \n",
       "2025-02-21 11:00:00  0.0087       1   2.684121    2.738742  ...    -0.044497   \n",
       "2025-02-21 12:00:00 -0.0251       0   2.683635    2.737931  ...    -0.044301   \n",
       "2025-02-21 13:00:00  0.0148       1   2.683442    2.737152  ...    -0.044106   \n",
       "2025-02-21 14:00:00  0.0331       1   2.683311    2.736484  ...    -0.043909   \n",
       "2025-02-21 15:00:00 -0.0136       0   2.683049    2.735803  ...    -0.043711   \n",
       "\n",
       "                     20_day_SMA  20_day_STD  Upper_Band  Lower_Band   lag_1  \\\n",
       "datetime                                                                      \n",
       "2024-02-01 05:00:00    0.543675    0.025918    0.595512    0.491838  0.4978   \n",
       "2024-02-01 06:00:00    0.543457    0.025881    0.595220    0.491694  0.4960   \n",
       "2024-02-01 07:00:00    0.543245    0.025870    0.594985    0.491505  0.4957   \n",
       "2024-02-01 08:00:00    0.543034    0.025865    0.594764    0.491304  0.4939   \n",
       "2024-02-01 09:00:00    0.542825    0.025863    0.594550    0.491099  0.4929   \n",
       "...                         ...         ...         ...         ...     ...   \n",
       "2025-02-21 11:00:00    2.562806    0.164862    2.892530    2.233082  2.6670   \n",
       "2025-02-21 12:00:00    2.562089    0.163724    2.889538    2.234641  2.6757   \n",
       "2025-02-21 13:00:00    2.561391    0.162561    2.886513    2.236269  2.6507   \n",
       "2025-02-21 14:00:00    2.560812    0.161570    2.883953    2.237671  2.6656   \n",
       "2025-02-21 15:00:00    2.560235    0.160625    2.881484    2.238986  2.6987   \n",
       "\n",
       "                      lag_2   lag_3  1_day_SMA  1_day_EMA  \n",
       "datetime                                                   \n",
       "2024-02-01 05:00:00  0.4977  0.4940   0.505550   0.505323  \n",
       "2024-02-01 06:00:00  0.4978  0.4977   0.504871   0.504553  \n",
       "2024-02-01 07:00:00  0.4960  0.4978   0.504146   0.503701  \n",
       "2024-02-01 08:00:00  0.4957  0.4960   0.503392   0.502837  \n",
       "2024-02-01 09:00:00  0.4939  0.4957   0.502696   0.502058  \n",
       "...                     ...     ...        ...        ...  \n",
       "2025-02-21 11:00:00  2.6715  2.6596   2.678383   2.671862  \n",
       "2025-02-21 12:00:00  2.6670  2.6715   2.677108   2.670169  \n",
       "2025-02-21 13:00:00  2.6757  2.6670   2.676225   2.669803  \n",
       "2025-02-21 14:00:00  2.6507  2.6757   2.675996   2.672115  \n",
       "2025-02-21 15:00:00  2.6656  2.6507   2.675717   2.673154  \n",
       "\n",
       "[9275 rows x 26 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9275 entries, 2024-02-01 05:00:00 to 2025-02-21 15:00:00\n",
      "Data columns (total 26 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   open         9275 non-null   float64\n",
      " 1   high         9275 non-null   float64\n",
      " 2   low          9275 non-null   float64\n",
      " 3   close        9275 non-null   float64\n",
      " 4   volume       9275 non-null   float64\n",
      " 5   av_pr        9275 non-null   float64\n",
      " 6   diff         9275 non-null   float64\n",
      " 7   candle       9275 non-null   int64  \n",
      " 8   7_day_SMA    9275 non-null   float64\n",
      " 9   30_day_SMA   9275 non-null   float64\n",
      " 10  7_day_EMA    9275 non-null   float64\n",
      " 11  30_day_EMA   9275 non-null   float64\n",
      " 12  RSI          9275 non-null   float64\n",
      " 13  12_day_EMA   9275 non-null   float64\n",
      " 14  26_day_EMA   9275 non-null   float64\n",
      " 15  MACD         9275 non-null   float64\n",
      " 16  Signal_Line  9275 non-null   float64\n",
      " 17  20_day_SMA   9275 non-null   float64\n",
      " 18  20_day_STD   9275 non-null   float64\n",
      " 19  Upper_Band   9275 non-null   float64\n",
      " 20  Lower_Band   9275 non-null   float64\n",
      " 21  lag_1        9275 non-null   float64\n",
      " 22  lag_2        9275 non-null   float64\n",
      " 23  lag_3        9275 non-null   float64\n",
      " 24  1_day_SMA    9275 non-null   float64\n",
      " 25  1_day_EMA    9275 non-null   float64\n",
      "dtypes: float64(25), int64(1)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df['close'], linestyle='-', color='b')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Time Series Plot')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('close price')\n",
    "plt.grid(True)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/11.1 MB 13.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.5/11.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 12.6 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/40.9 MB 12.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.2/40.9 MB 9.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 6.0/40.9 MB 9.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.9/40.9 MB 9.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 11.3/40.9 MB 10.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.4/40.9 MB 11.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.7/40.9 MB 10.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 18.1/40.9 MB 10.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 20.7/40.9 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 23.3/40.9 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 26.0/40.9 MB 11.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.8/40.9 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.7/40.9 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 34.6/40.9 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.5/40.9 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.6/40.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.9/40.9 MB 11.7 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(scaled_data) * 0.8)\n",
    "train_data, test_data = scaled_data[:train_size], scaled_data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.55715722, 1.55279463, 1.56856217, ..., 1.61051403, 1.59829043,\n",
       "        1.59490787],\n",
       "       [1.54464991, 1.52484574, 1.51403559, ..., 1.59859764, 1.59206939,\n",
       "        1.58854403],\n",
       "       [1.50784269, 1.4924156 , 1.49008241, ..., 1.55832025, 1.58641073,\n",
       "        1.58219222],\n",
       "       ...,\n",
       "       [1.95167339, 1.9410129 , 1.97540506, ..., 1.97229555, 1.99031582,\n",
       "        1.98340566],\n",
       "       [1.96930274, 1.99985887, 1.99959897, ..., 1.9826628 , 1.99004209,\n",
       "        1.98616793],\n",
       "       [2.00873053, 1.98240556, 2.01620972, ..., 1.95287184, 1.98970864,\n",
       "        1.98740917]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.61303911, -0.61483605, -0.61250092, ..., -0.61713543,\n",
       "        -0.60242669, -0.60292837],\n",
       "       [-0.61518322, -0.61648704, -0.61238056, ..., -0.61272636,\n",
       "        -0.60323791, -0.60384824],\n",
       "       [-0.61554057, -0.61825595, -0.61671379, ..., -0.6126072 ,\n",
       "        -0.60410388, -0.60486659],\n",
       "       ...,\n",
       "       [ 1.59241591,  1.62720706,  1.61646852, ...,  1.54819132,\n",
       "         1.60556159,  1.60119979],\n",
       "       [ 1.60944967,  1.58593233,  1.59853373, ...,  1.54604637,\n",
       "         1.60745777,  1.60153066],\n",
       "       [ 1.59741883,  1.57260649,  1.58288593, ...,  1.59347359,\n",
       "         1.60469065,  1.59860406]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length, 3])  # Assuming 'close' price is the target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 168\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(60, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(60, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(30),\n",
    "    Dense(1)  # Output layer for predicting the next 'close' price\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,880</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,830</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │          \u001b[38;5;34m20,880\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)                  │          \u001b[38;5;34m29,040\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m1,830\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m31\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,781</span> (202.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,781\u001b[0m (202.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,781</span> (202.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,781\u001b[0m (202.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 111ms/step - loss: 0.0345 - val_loss: 0.4184\n",
      "Epoch 2/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 103ms/step - loss: 0.0037 - val_loss: 0.4121\n",
      "Epoch 3/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 108ms/step - loss: 0.0031 - val_loss: 0.3096\n",
      "Epoch 4/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 112ms/step - loss: 0.0026 - val_loss: 0.3486\n",
      "Epoch 5/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0017 - val_loss: 0.2538\n",
      "Epoch 6/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 113ms/step - loss: 0.0019 - val_loss: 0.1595\n",
      "Epoch 7/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 112ms/step - loss: 0.0022 - val_loss: 0.1371\n",
      "Epoch 8/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0022 - val_loss: 0.2156\n",
      "Epoch 9/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 118ms/step - loss: 0.0021 - val_loss: 0.1827\n",
      "Epoch 10/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0018 - val_loss: 0.1197\n",
      "Epoch 11/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 116ms/step - loss: 0.0014 - val_loss: 0.1762\n",
      "Epoch 12/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0015 - val_loss: 0.0393\n",
      "Epoch 13/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 113ms/step - loss: 0.0023 - val_loss: 0.1185\n",
      "Epoch 14/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 112ms/step - loss: 0.0017 - val_loss: 0.1399\n",
      "Epoch 15/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 112ms/step - loss: 0.0015 - val_loss: 0.1343\n",
      "Epoch 16/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 112ms/step - loss: 0.0018 - val_loss: 0.0597\n",
      "Epoch 17/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 112ms/step - loss: 0.0016 - val_loss: 0.1030\n",
      "Epoch 18/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 111ms/step - loss: 0.0012 - val_loss: 0.0614\n",
      "Epoch 19/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 113ms/step - loss: 0.0015 - val_loss: 0.1302\n",
      "Epoch 20/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 125ms/step - loss: 0.0017 - val_loss: 0.1235\n",
      "Epoch 21/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 112ms/step - loss: 0.0020 - val_loss: 0.1917\n",
      "Epoch 22/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 118ms/step - loss: 0.0017 - val_loss: 0.0924\n",
      "Epoch 23/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0013 - val_loss: 0.0451\n",
      "Epoch 24/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 116ms/step - loss: 0.0016 - val_loss: 0.1034\n",
      "Epoch 25/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0013 - val_loss: 0.1304\n",
      "Epoch 26/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 113ms/step - loss: 0.0015 - val_loss: 0.1716\n",
      "Epoch 27/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 112ms/step - loss: 0.0017 - val_loss: 0.1394\n",
      "Epoch 28/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 117ms/step - loss: 0.0013 - val_loss: 0.1347\n",
      "Epoch 29/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0012 - val_loss: 0.1309\n",
      "Epoch 30/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 113ms/step - loss: 0.0013 - val_loss: 0.0917\n",
      "Epoch 31/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 118ms/step - loss: 0.0017 - val_loss: 0.1909\n",
      "Epoch 32/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 116ms/step - loss: 0.0011 - val_loss: 0.1019\n",
      "Epoch 33/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 120ms/step - loss: 0.0014 - val_loss: 0.1744\n",
      "Epoch 34/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 113ms/step - loss: 0.0013 - val_loss: 0.0903\n",
      "Epoch 35/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0016 - val_loss: 0.0954\n",
      "Epoch 36/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0013 - val_loss: 0.1475\n",
      "Epoch 37/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 113ms/step - loss: 0.0013 - val_loss: 0.2217\n",
      "Epoch 38/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0013 - val_loss: 0.1732\n",
      "Epoch 39/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 113ms/step - loss: 0.0011 - val_loss: 0.1422\n",
      "Epoch 40/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 113ms/step - loss: 0.0012 - val_loss: 0.1405\n",
      "Epoch 41/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 112ms/step - loss: 0.0013 - val_loss: 0.0853\n",
      "Epoch 42/42\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - loss: 0.0012 - val_loss: 0.2528\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=42, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3296558],\n",
       "       [1.3488191],\n",
       "       [1.3483235],\n",
       "       ...,\n",
       "       [1.3675122],\n",
       "       [1.4046339],\n",
       "       [1.4607033]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_original = df['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.47396172384861013\n",
      "MSE: 0.25280893600824755\n",
      "RMSE: 0.5028010899035995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying another model RNN architecture\n",
    "\n",
    "def create_sequences(data, sequence_length, output_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length - output_steps + 1):\n",
    "        X.append(data[i:i+sequence_length])\n",
    "        y.append(data[i+sequence_length:i+sequence_length+output_steps, 4])  # Predict the 'close' price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Example usage\n",
    "sequence_length = 168  # 7 days of hourly data\n",
    "output_steps = 24  # Predict the next 24 hours\n",
    "X_train, y_train = create_sequences(train_data, sequence_length, output_steps)\n",
    "X_test, y_test = create_sequences(test_data, sequence_length, output_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, sequence_length, output_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length - output_steps + 1):\n",
    "        # Extract the sequence and target\n",
    "        sequence = data[i:i+sequence_length]\n",
    "        target = data[i+sequence_length:i+sequence_length+output_steps, 4]  # Predict the 'close' price (column index 4)\n",
    "\n",
    "        # Check for None or NaN values in the sequence or target\n",
    "        if (not np.isnan(sequence).any() and not np.isnan(target).any() and\n",
    "            not any(x is None for x in sequence.flatten()) and\n",
    "            not any(x is None for x in target.flatten())):\n",
    "            X.append(sequence)\n",
    "            y.append(target)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "sequence_length = 168  # 7 days of hourly data\n",
    "output_steps = 24  # Predict the next 24 hours\n",
    "X_train, y_train = create_sequences(train_data, sequence_length, output_steps)\n",
    "X_test, y_test = create_sequences(test_data, sequence_length, output_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03637958, -0.05687936,  0.01242318, ..., -0.43089353,\n",
       "        -0.1630807 , -0.28795218],\n",
       "       [-0.05687936,  0.01242318, -0.36920034, ..., -0.1630807 ,\n",
       "        -0.28795218, -0.4307031 ],\n",
       "       [ 0.01242318, -0.36920034, -0.13192148, ..., -0.28795218,\n",
       "        -0.4307031 , -0.37020068],\n",
       "       ...,\n",
       "       [ 0.8061974 ,  0.96830963,  2.68610989, ..., -0.06076102,\n",
       "         0.02625022,  0.80344493],\n",
       "       [ 0.96830963,  2.68610989,  0.85623754, ...,  0.02625022,\n",
       "         0.80344493,  0.09130678],\n",
       "       [ 2.68610989,  0.85623754,  0.30193956, ...,  0.80344493,\n",
       "         0.09130678, -0.01756168]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 194ms/step - loss: 0.2629 - mae: 0.5751 - val_loss: 0.2136 - val_mae: 0.5226\n",
      "Epoch 2/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 189ms/step - loss: 0.2568 - mae: 0.5637 - val_loss: 0.2144 - val_mae: 0.5255\n",
      "Epoch 3/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 186ms/step - loss: 0.2501 - mae: 0.5527 - val_loss: 0.2161 - val_mae: 0.5298\n",
      "Epoch 4/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 194ms/step - loss: 0.2438 - mae: 0.5422 - val_loss: 0.2185 - val_mae: 0.5353\n",
      "Epoch 5/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 195ms/step - loss: 0.2387 - mae: 0.5334 - val_loss: 0.2215 - val_mae: 0.5416\n",
      "Epoch 6/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 202ms/step - loss: 0.2347 - mae: 0.5261 - val_loss: 0.2242 - val_mae: 0.5470\n",
      "Epoch 7/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 198ms/step - loss: 0.2308 - mae: 0.5193 - val_loss: 0.2270 - val_mae: 0.5524\n",
      "Epoch 8/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 204ms/step - loss: 0.2273 - mae: 0.5127 - val_loss: 0.2299 - val_mae: 0.5577\n",
      "Epoch 9/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 199ms/step - loss: 0.2242 - mae: 0.5070 - val_loss: 0.2314 - val_mae: 0.5603\n",
      "Epoch 10/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 196ms/step - loss: 0.2209 - mae: 0.5003 - val_loss: 0.2335 - val_mae: 0.5639\n",
      "Epoch 11/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 199ms/step - loss: 0.2180 - mae: 0.4948 - val_loss: 0.2356 - val_mae: 0.5676\n",
      "Epoch 12/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 199ms/step - loss: 0.2156 - mae: 0.4898 - val_loss: 0.2367 - val_mae: 0.5693\n",
      "Epoch 13/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 197ms/step - loss: 0.2133 - mae: 0.4846 - val_loss: 0.2376 - val_mae: 0.5711\n",
      "Epoch 14/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 196ms/step - loss: 0.2114 - mae: 0.4810 - val_loss: 0.2389 - val_mae: 0.5733\n",
      "Epoch 15/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 203ms/step - loss: 0.2089 - mae: 0.4757 - val_loss: 0.2418 - val_mae: 0.5780\n",
      "Epoch 16/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 195ms/step - loss: 0.2072 - mae: 0.4710 - val_loss: 0.2450 - val_mae: 0.5827\n",
      "Epoch 17/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 196ms/step - loss: 0.2055 - mae: 0.4678 - val_loss: 0.2458 - val_mae: 0.5841\n",
      "Epoch 18/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 206ms/step - loss: 0.2041 - mae: 0.4643 - val_loss: 0.2492 - val_mae: 0.5888\n",
      "Epoch 19/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 198ms/step - loss: 0.2024 - mae: 0.4611 - val_loss: 0.2545 - val_mae: 0.5963\n",
      "Epoch 20/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 196ms/step - loss: 0.2009 - mae: 0.4578 - val_loss: 0.2599 - val_mae: 0.6036\n",
      "Epoch 21/500\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 200ms/step - loss: 0.1994 - mae: 0.4546 - val_loss: 0.2656 - val_mae: 0.6113\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define parameters\n",
    "sequence_length = 168  # 7 days of hourly data (adjust as needed)\n",
    "num_features = 26  # Number of input features\n",
    "output_steps = 24  # Predict the next 24 hours (1 day); adjust for weeks\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = keras.models.Sequential([\n",
    "    # First LSTM layer\n",
    "    layers.LSTM(128, return_sequences=True, input_shape=(sequence_length, num_features)),\n",
    "    layers.Dropout(0.2),  # Dropout for regularization\n",
    "\n",
    "    # Second LSTM layer\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    # Third LSTM layer\n",
    "    layers.LSTM(32, return_sequences=False),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    # Dense layers to process the output of the last LSTM layer\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "\n",
    "    # Output layer\n",
    "    layers.Dense(output_steps)  # Predict multiple time steps (e.g., 24 hours)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-5)  # Adam optimizer\n",
    "model.compile(loss=keras.losses.Huber(),  # Huber loss for robustness\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])  # Mean Absolute Error as a metric\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Train the model\n",
    "# Correct way to pass data to fit\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=500, validation_data=(X_test, y_test), \n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chidi\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attention layer must be called on a list of inputs, namely [query, value] or [query, value, key]. Received: inputs=(None, 168, 256).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m output_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24\u001b[39m  \u001b[38;5;66;03m# Predict the next 24 hours (1 day)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Bidirectional LSTM layer 1\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBidirectional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Dropout for regularization\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Bidirectional LSTM layer 2\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBidirectional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Attention mechanism\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Add attention layer\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# LSTM layer 3\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Dense layers\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregularizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregularizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Output layer\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Predict multiple time steps (e.g., 24 hours)\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     38\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)  \u001b[38;5;66;03m# Adam optimizer with a low learning rate\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\models\\sequential.py:76\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[1;34m(self, layers, trainable, name)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(layer, rebuild\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\models\\sequential.py:141\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    140\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput_shape\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:228\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[0;32m    227\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[1;32m--> 228\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\models\\sequential.py:187\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\layers\\attention\\attention.py:300\u001b[0m, in \u001b[0;36mAttention._validate_inputs\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    298\u001b[0m class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layer must be called on a list of inputs, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamely [query, value] or [query, value, key]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: inputs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m     )\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layer accepts inputs list of length 2 or 3, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamely [query, value] or [query, value, key]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    310\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Attention layer must be called on a list of inputs, namely [query, value] or [query, value, key]. Received: inputs=(None, 168, 256)."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "# Define parameters\n",
    "sequence_length = 168  # 7 days of hourly data\n",
    "num_features = 26  # Number of input features\n",
    "output_steps = 24  # Predict the next 24 hours (1 day)\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    # Bidirectional LSTM layer 1\n",
    "    layers.Bidirectional(layers.LSTM(256, return_sequences=True), input_shape=(sequence_length, num_features)),\n",
    "    layers.Dropout(0.3),  # Dropout for regularization\n",
    "\n",
    "    # Bidirectional LSTM layer 2\n",
    "    layers.Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    # Attention mechanism\n",
    "    layers.Attention(),  # Add attention layer\n",
    "\n",
    "    # LSTM layer 3\n",
    "    layers.LSTM(64, return_sequences=False),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    # Dense layers\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "\n",
    "    # Output layer\n",
    "    layers.Dense(output_steps)  # Predict multiple time steps (e.g., 24 hours)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=1e-4)  # Adam optimizer with a low learning rate\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.Huber(), metrics=['mae'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 20:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)  # Reduce learning rate exponentially\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, lr_callback]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_mae = history.history['val_mae'][-1]\n",
    "print(f\"Validation MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.3374 - mae: 0.4800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - loss: 1.3339 - mae: 0.4798 - val_loss: 0.8030 - val_mae: 1.0682 - learning_rate: 0.0010\n",
      "Epoch 2/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.3131 - mae: 0.4314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 2s/step - loss: 0.3127 - mae: 0.4314 - val_loss: 0.7209 - val_mae: 1.1704 - learning_rate: 0.0010\n",
      "Epoch 3/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 2s/step - loss: 0.2011 - mae: 0.4278 - val_loss: 0.8390 - val_mae: 1.3102 - learning_rate: 0.0010\n",
      "Epoch 4/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 2s/step - loss: 0.1920 - mae: 0.4254 - val_loss: 1.0113 - val_mae: 1.4886 - learning_rate: 0.0010\n",
      "Epoch 5/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - loss: 0.1880 - mae: 0.4203 - val_loss: 0.9608 - val_mae: 1.4370 - learning_rate: 0.0010\n",
      "Epoch 6/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - loss: 0.1856 - mae: 0.4168 - val_loss: 1.0213 - val_mae: 1.4996 - learning_rate: 0.0010\n",
      "Epoch 7/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 2s/step - loss: 0.1839 - mae: 0.4160 - val_loss: 1.1973 - val_mae: 1.6810 - learning_rate: 0.0010\n",
      "Epoch 8/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - loss: 0.1929 - mae: 0.4301 - val_loss: 1.0949 - val_mae: 1.5762 - learning_rate: 0.0010\n",
      "Epoch 9/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - loss: 0.1846 - mae: 0.4173 - val_loss: 1.0179 - val_mae: 1.4965 - learning_rate: 0.0010\n",
      "Epoch 10/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 2s/step - loss: 0.1818 - mae: 0.4119 - val_loss: 1.1902 - val_mae: 1.6740 - learning_rate: 0.0010\n",
      "Epoch 11/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 2s/step - loss: 0.1773 - mae: 0.4058 - val_loss: 1.3244 - val_mae: 1.8102 - learning_rate: 9.0484e-04\n",
      "Epoch 12/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 2s/step - loss: 0.1750 - mae: 0.4016 - val_loss: 1.2210 - val_mae: 1.7036 - learning_rate: 8.1873e-04\n",
      "Epoch 13/500\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 2s/step - loss: 0.1717 - mae: 0.3953 - val_loss: 1.3079 - val_mae: 1.7918 - learning_rate: 7.4082e-04\n",
      "Epoch 14/500\n",
      "\u001b[1m 95/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 0.1687 - mae: 0.3890"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 62\u001b[0m\n\u001b[0;32m     57\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_checkpoint.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     71\u001b[0m val_mae \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mae\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\Documents\\timeseries_projects\\tvenv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "# Define parameters\n",
    "sequence_length = 168  # 7 days of hourly data\n",
    "num_features = 26  # Number of input features\n",
    "output_steps = 24  # Predict the next 24 hours (1 day)\n",
    "\n",
    "# Define inputs\n",
    "inputs = layers.Input(shape=(sequence_length, num_features))\n",
    "\n",
    "# Bidirectional LSTM layer 1\n",
    "x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(inputs)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "# Bidirectional LSTM layer 2\n",
    "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "# Attention mechanism\n",
    "query = x  # Query is the output of the previous layer\n",
    "value = x  # Value is the same as the query\n",
    "attention_output = layers.Attention()([query, value])\n",
    "\n",
    "# LSTM layer 3\n",
    "x = layers.LSTM(64, return_sequences=False)(attention_output)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "# Dense layers\n",
    "x = layers.Dense(128, kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "x = layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = layers.Dense(output_steps)(x)\n",
    "\n",
    "# Define the model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=1e-6)  # Adam optimizer with a low learning rate\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.Huber(), metrics=['mae'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return float(lr)  # Ensure lr is a float\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.5))  # Convert tensor to float\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(patience=50, restore_best_weights=True)\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    \"my_checkpoint.h5\", save_best_only = True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, lr_callback, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_mae = history.history['val_mae'][-1]\n",
    "print(f\"Validation MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_windows(data, input_window, output_window, train_ratio=0.8, batch_size=None):\n",
    "    \"\"\"\n",
    "    Create sliding windows for time series forecasting.\n",
    "\n",
    "    Parameters:\n",
    "      data (np.array): Time series data with shape (num_timesteps, 26).\n",
    "      input_window (int): Number of time steps to use as input.\n",
    "      output_window (int): Number of time steps to forecast.\n",
    "      train_ratio (float): Fraction of windows used for training (default 0.8).\n",
    "      batch_size (int, optional): For stateful models, ensure number of samples is divisible by batch_size.\n",
    "\n",
    "    Returns:\n",
    "      X_train, y_train, X_test, y_test: Arrays of training and testing windows.\n",
    "         - X windows have shape (num_samples, input_window, 26)\n",
    "         - y windows have shape (num_samples, output_window, 26) \n",
    "           (or you may select only a subset of features for prediction)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    total_steps = data.shape[0]\n",
    "    # Create windows using a sliding window approach\n",
    "    for i in range(total_steps - input_window - output_window + 1):\n",
    "        X.append(data[i: i + input_window])\n",
    "        y.append(data[i + input_window: i + input_window + output_window])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    split_index = int(len(X) * train_ratio)\n",
    "    X_train, y_train = X[:split_index], y[:split_index]\n",
    "    X_test, y_test = X[split_index:], y[split_index:]\n",
    "    \n",
    "    # For stateful models, the number of samples must be divisible by batch_size\n",
    "    if batch_size is not None:\n",
    "        # Trim training set\n",
    "        remainder_train = len(X_train) % batch_size\n",
    "        if remainder_train != 0:\n",
    "            X_train = X_train[:-remainder_train]\n",
    "            y_train = y_train[:-remainder_train]\n",
    "        # Trim testing set\n",
    "        remainder_test = len(X_test) % batch_size\n",
    "        if remainder_test != 0:\n",
    "            X_test = X_test[:-remainder_test]\n",
    "            y_test = y_test[:-remainder_test]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Example usage:\n",
    "# For a stateless model (e.g., input window of 168 and output window of 24):\n",
    "X_train_stateless, y_train_stateless, X_test_stateless, y_test_stateless = create_windows(\n",
    "    scaled_data, input_window=168, output_window=24, train_ratio=0.8)\n",
    "\n",
    "# For a stateful model (e.g., input window of 30 and output window of 1) with a fixed batch size:\n",
    "X_train_stateful, y_train_stateful, X_test_stateful, y_test_stateful = create_windows(\n",
    "    scaled_data, input_window=30, output_window=1, train_ratio=0.8, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.4627 - mae: 0.5260\n",
      "Epoch 1: val_loss improved from inf to 2.51956, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-09\n",
      "Epoch 2/500\n",
      "\u001b[1m227/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4625 - mae: 0.5259\n",
      "Epoch 2: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-09\n",
      "Epoch 3/500\n",
      "\u001b[1m227/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.4625 - mae: 0.5259\n",
      "Epoch 3: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-09\n",
      "Epoch 4/500\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4627 - mae: 0.5260\n",
      "Epoch 4: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-09\n",
      "Epoch 5/500\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4627 - mae: 0.5260\n",
      "Epoch 5: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-09\n",
      "Epoch 6/500\n",
      "\u001b[1m227/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4625 - mae: 0.5259\n",
      "Epoch 6: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-09\n",
      "Epoch 7/500\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4627 - mae: 0.5260\n",
      "Epoch 7: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-09\n",
      "Epoch 8/500\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4627 - mae: 0.5260\n",
      "Epoch 8: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-09\n",
      "Epoch 9/500\n",
      "\u001b[1m227/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4625 - mae: 0.5259\n",
      "Epoch 9: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-09\n",
      "Epoch 10/500\n",
      "\u001b[1m226/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4624 - mae: 0.5257\n",
      "Epoch 10: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-09\n",
      "Epoch 11/500\n",
      "\u001b[1m227/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.4625 - mae: 0.5259\n",
      "Epoch 11: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-08\n",
      "Epoch 12/500\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4627 - mae: 0.5260\n",
      "Epoch 12: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-08\n",
      "Epoch 13/500\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4627 - mae: 0.5260\n",
      "Epoch 13: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-08\n",
      "Epoch 14/500\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4627 - mae: 0.5260\n",
      "Epoch 14: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-08\n",
      "Epoch 15/500\n",
      "\u001b[1m227/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4625 - mae: 0.5259\n",
      "Epoch 15: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-08\n",
      "Epoch 16/500\n",
      "\u001b[1m227/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.4625 - mae: 0.5259\n",
      "Epoch 16: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-08\n",
      "Epoch 17/500\n",
      "\u001b[1m226/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.4624 - mae: 0.5257\n",
      "Epoch 17: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-08\n",
      "Epoch 18/500\n",
      "\u001b[1m227/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4625 - mae: 0.5259\n",
      "Epoch 18: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-08\n",
      "Epoch 19/500\n",
      "\u001b[1m227/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.4625 - mae: 0.5259\n",
      "Epoch 19: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-08\n",
      "Epoch 20/500\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4627 - mae: 0.5260\n",
      "Epoch 20: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-08\n",
      "Epoch 21/500\n",
      "\u001b[1m227/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4625 - mae: 0.5259\n",
      "Epoch 21: val_loss did not improve from 2.51956\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 1.4628 - mae: 0.5261 - val_loss: 2.5196 - val_mae: 1.6884 - learning_rate: 1.0000e-07\n",
      "Epoch 1/500\n",
      "\u001b[1m229/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1801 - mae: 0.4955\n",
      "Epoch 1: val_loss improved from 2.51956 to 2.32765, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - loss: 1.1805 - mae: 0.4959 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-09\n",
      "Epoch 2/500\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1807 - mae: 0.4964\n",
      "Epoch 2: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 1.1808 - mae: 0.4965 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-09\n",
      "Epoch 3/500\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1804 - mae: 0.4959\n",
      "Epoch 3: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 1.1805 - mae: 0.4960 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-09\n",
      "Epoch 4/500\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1805 - mae: 0.4960\n",
      "Epoch 4: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 1.1806 - mae: 0.4962 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-09\n",
      "Epoch 5/500\n",
      "\u001b[1m230/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1806 - mae: 0.4963\n",
      "Epoch 5: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 1.1808 - mae: 0.4965 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-09\n",
      "Epoch 6/500\n",
      "\u001b[1m230/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1807 - mae: 0.4966\n",
      "Epoch 6: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 1.1809 - mae: 0.4968 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-09\n",
      "Epoch 7/500\n",
      "\u001b[1m230/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1807 - mae: 0.4966\n",
      "Epoch 7: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 1.1810 - mae: 0.4968 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-09\n",
      "Epoch 8/500\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1807 - mae: 0.4964\n",
      "Epoch 8: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 1.1808 - mae: 0.4965 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-09\n",
      "Epoch 9/500\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1804 - mae: 0.4959\n",
      "Epoch 9: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 1.1806 - mae: 0.4960 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-09\n",
      "Epoch 10/500\n",
      "\u001b[1m230/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1805 - mae: 0.4962\n",
      "Epoch 10: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - loss: 1.1807 - mae: 0.4964 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-09\n",
      "Epoch 11/500\n",
      "\u001b[1m230/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1806 - mae: 0.4964\n",
      "Epoch 11: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 1.1809 - mae: 0.4966 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-08\n",
      "Epoch 12/500\n",
      "\u001b[1m229/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1803 - mae: 0.4959\n",
      "Epoch 12: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - loss: 1.1807 - mae: 0.4962 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-08\n",
      "Epoch 13/500\n",
      "\u001b[1m230/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1804 - mae: 0.4959\n",
      "Epoch 13: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - loss: 1.1806 - mae: 0.4961 - val_loss: 2.3276 - val_mae: 1.7632 - learning_rate: 1.0000e-08\n",
      "Epoch 14/500\n",
      "\u001b[1m230/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1807 - mae: 0.4964\n",
      "Epoch 14: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - loss: 1.1809 - mae: 0.4967 - val_loss: 2.3277 - val_mae: 1.7632 - learning_rate: 1.0000e-08\n",
      "Epoch 15/500\n",
      "\u001b[1m230/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1804 - mae: 0.4959\n",
      "Epoch 15: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 1.1806 - mae: 0.4962 - val_loss: 2.3277 - val_mae: 1.7632 - learning_rate: 1.0000e-08\n",
      "Epoch 16/500\n",
      "\u001b[1m230/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1805 - mae: 0.4962\n",
      "Epoch 16: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - loss: 1.1808 - mae: 0.4965 - val_loss: 2.3277 - val_mae: 1.7632 - learning_rate: 1.0000e-08\n",
      "Epoch 17/500\n",
      "\u001b[1m229/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1805 - mae: 0.4961\n",
      "Epoch 17: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - loss: 1.1808 - mae: 0.4965 - val_loss: 2.3277 - val_mae: 1.7632 - learning_rate: 1.0000e-08\n",
      "Epoch 18/500\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1805 - mae: 0.4961\n",
      "Epoch 18: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 1.1806 - mae: 0.4962 - val_loss: 2.3277 - val_mae: 1.7632 - learning_rate: 1.0000e-08\n",
      "Epoch 19/500\n",
      "\u001b[1m230/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1804 - mae: 0.4960\n",
      "Epoch 19: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 1.1807 - mae: 0.4962 - val_loss: 2.3277 - val_mae: 1.7632 - learning_rate: 1.0000e-08\n",
      "Epoch 20/500\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1807 - mae: 0.4963\n",
      "Epoch 20: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 1.1808 - mae: 0.4964 - val_loss: 2.3277 - val_mae: 1.7632 - learning_rate: 1.0000e-08\n",
      "Epoch 21/500\n",
      "\u001b[1m229/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1802 - mae: 0.4956\n",
      "Epoch 21: val_loss did not improve from 2.32765\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 1.1805 - mae: 0.4959 - val_loss: 2.3277 - val_mae: 1.7633 - learning_rate: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "# Define parameters for each model\n",
    "# Stateless model: 7 days (168 hours) input to predict 24 hours ahead\n",
    "stateless_sequence_length = 168  # 7 days of hourly data\n",
    "stateless_output_steps = 24      # Predict the next 24 hours\n",
    "\n",
    "# Stateful model: 30-hour window input to predict the next 1 hour\n",
    "stateful_sequence_length = 30     # 30 hours of input data\n",
    "stateful_output_steps = 1         # Predict the next hour\n",
    "\n",
    "num_features = 26  # Number of input features (same for both models)\n",
    "batch_size = 32    # Batch size for training (stateful models require a fixed batch size)\n",
    "\n",
    "# ====================================================\n",
    "# Stateless Model (CNN-LSTM with Attention)\n",
    "# ====================================================\n",
    "def build_stateless_model():\n",
    "    inputs = layers.Input(shape=(stateless_sequence_length, num_features))\n",
    "    \n",
    "    # CNN for feature extraction\n",
    "    x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    # LSTM for temporal modeling\n",
    "    x = layers.LSTM(128, return_sequences=True)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Attention mechanism (using the same tensor for query and value)\n",
    "    attention_output = layers.Attention()([x, x])\n",
    "    \n",
    "    # Global pooling to collapse the time dimension\n",
    "    x = layers.GlobalAveragePooling1D()(attention_output)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(stateless_output_steps * 26)(x)\n",
    "    outputs = layers.Reshape((stateless_output_steps, 26))(outputs)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# ====================================================\n",
    "# Stateful Model (LSTM)\n",
    "# ====================================================\n",
    "def build_stateful_model():\n",
    "    # Note: For stateful models, the input shape includes the fixed batch size.\n",
    "    inputs = layers.Input(batch_shape=(batch_size, stateful_sequence_length, num_features))\n",
    "    \n",
    "    # Stateful LSTM layers\n",
    "    x = layers.LSTM(128, return_sequences=True, stateful=True)(inputs)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.LSTM(64, stateful=True)(x)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(stateful_output_steps)(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# ====================================================\n",
    "# Compile and Train Models\n",
    "# ====================================================\n",
    "\n",
    "# Instantiate models\n",
    "stateless_model = build_stateless_model()\n",
    "stateful_model = build_stateful_model()\n",
    "\n",
    "# Compile the stateless model\n",
    "stateless_model.compile(\n",
    "    optimizer=SGD(learning_rate=1e-9),\n",
    "    loss=tf.keras.losses.Huber(),\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Compile the stateful model\n",
    "stateful_model.compile(\n",
    "    optimizer=SGD(learning_rate=1e-9),\n",
    "    loss=tf.keras.losses.Huber(),\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch > 0 and epoch % 10 == 0:  # Update every 10 epochs\n",
    "        return lr * 10  # Increase learning rate by a factor of 10\n",
    "    return lr\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "# Model checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Training ---\n",
    "# Ensure you prepare the corresponding training data:\n",
    "# For stateless model:\n",
    "#   X_train_stateless, y_train_stateless, X_test_stateless, y_test_stateless\n",
    "# For stateful model:\n",
    "#   X_train_stateful, y_train_stateful, X_test_stateful, y_test_stateful\n",
    "\n",
    "# Train the stateless model (window=168, predict=24)\n",
    "stateless_history = stateless_model.fit(\n",
    "    X_train_stateless, y_train_stateless,\n",
    "    epochs=500,\n",
    "    batch_size=batch_size,  # Note: batch_size here does not need to match a fixed size requirement\n",
    "    validation_data=(X_test_stateless, y_test_stateless),\n",
    "    callbacks=[early_stopping, lr_callback, checkpoint_callback],\n",
    "    shuffle=False  # Do not shuffle time series data\n",
    ")\n",
    "\n",
    "# Train the stateful model (window=30, predict=1)\n",
    "# For stateful training, ensure that the number of samples in your training set\n",
    "# is a multiple of the batch_size. You may need to trim or pad your dataset accordingly.\n",
    "stateful_history = stateful_model.fit(\n",
    "    X_train_stateful, y_train_stateful,\n",
    "    epochs=500,\n",
    "    batch_size=batch_size,  # Fixed batch size required for stateful models\n",
    "    validation_data=(X_test_stateful, y_test_stateful),\n",
    "    callbacks=[early_stopping, lr_callback, checkpoint_callback],\n",
    "    shuffle=False  # Preserve the temporal order\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Prediction (Separate for Each Model)\n",
    "# ====================================================\n",
    "# The stateless model will output predictions of shape (num_samples, 24)\n",
    "stateless_predictions = stateless_model.predict(X_test_stateless)\n",
    "\n",
    "# The stateful model will output predictions of shape (num_samples, 1)\n",
    "# When predicting with stateful models, pass the fixed batch_size\n",
    "stateful_predictions = stateful_model.predict(X_test_stateful, batch_size=batch_size)\n",
    "\n",
    "# Note: Because these models predict different horizons, they cannot be directly ensembled.\n",
    "# You might use each model's predictions for their specific forecasting tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09564687],\n",
       "       [-0.09778274],\n",
       "       [-0.10224784],\n",
       "       ...,\n",
       "       [-0.1594107 ],\n",
       "       [-0.16193406],\n",
       "       [-0.16251808]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26_day_EMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Signal_Line",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20_day_STD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lower_Band",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1_day_SMA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1_day_EMA",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1283a34d-8413-43d6-b283-a732c129f034",
       "rows": [
        [
         "2024-02-01 05:00:00",
         "0.4977",
         "0.4988",
         "0.4954",
         "0.496",
         "17875875.0",
         "0.4971",
         "-0.0016999999999999793",
         "0",
         "0.521835119047619",
         "0.5564677777777778",
         "0.5217690565511647",
         "0.5541265191135628",
         "44.1161907905595",
         "0.5290693117335377",
         "0.549258785305369",
         "-0.020189473571831318",
         "-0.019820153741063586",
         "0.543675",
         "0.025918414633595385",
         "0.5955118292671908",
         "0.4918381707328092",
         "0.4978",
         "0.4977",
         "0.494",
         "0.50555",
         "0.5053228680111399"
        ],
        [
         "2024-02-01 06:00:00",
         "0.4959",
         "0.4974",
         "0.4955",
         "0.4957",
         "10485001.0",
         "0.49645",
         "-0.00020000000000003348",
         "0",
         "0.5217464285714286",
         "0.556281111111111",
         "0.5214605470061805",
         "0.553964448325453",
         "44.0851344662597",
         "0.528838382240572",
         "0.5490873971923917",
         "-0.020249014951819744",
         "-0.01982410637895074",
         "0.5434572916666666",
         "0.025881488152254092",
         "0.5952202679711748",
         "0.49169431536215835",
         "0.496",
         "0.4978",
         "0.4977",
         "0.5048708333333333",
         "0.5045530385702487"
        ],
        [
         "2024-02-01 07:00:00",
         "0.4956",
         "0.4959",
         "0.4919",
         "0.4939",
         "26116194.0",
         "0.4939",
         "-0.0016999999999999793",
         "0",
         "0.5216440476190476",
         "0.5560945833333334",
         "0.5211343866865807",
         "0.5537978340443838",
         "44.05605935696621",
         "0.5285965941281805",
         "0.5489107975213761",
         "-0.020314203393195562",
         "-0.0198286234021235",
         "0.5432454166666667",
         "0.025870011895699225",
         "0.5949854404580651",
         "0.49150539287526823",
         "0.4957",
         "0.496",
         "0.4978",
         "0.5041458333333333",
         "0.5037007954846289"
        ],
        [
         "2024-02-01 08:00:00",
         "0.4939",
         "0.494",
         "0.4916",
         "0.4929",
         "17569499.0",
         "0.4928",
         "-0.0010000000000000009",
         "0",
         "0.5215196428571429",
         "0.5559031944444445",
         "0.5208002519328934",
         "0.5536289080137474",
         "43.74276739957019",
         "0.5283495588746984",
         "0.5487315629693077",
         "-0.02038200409460933",
         "-0.019833723685003555",
         "0.5430335416666666",
         "0.025865000815384898",
         "0.5947635432974364",
         "0.4913035400358968",
         "0.4939",
         "0.4957",
         "0.496",
         "0.5033916666666667",
         "0.5028367318458585"
        ],
        [
         "2024-02-01 09:00:00",
         "0.4929",
         "0.4938",
         "0.49",
         "0.4931",
         "18873523.0",
         "0.4919",
         "0.00019999999999997797",
         "1",
         "0.5214113095238095",
         "0.5557090277777778",
         "0.5204724383005515",
         "0.553461005356289",
         "43.95020746887968",
         "0.5281056172907904",
         "0.5485535419678059",
         "-0.020447924677015505",
         "-0.01983938452363961",
         "0.5428247916666666",
         "0.02586281033072055",
         "0.5945504123281078",
         "0.49109917100522554",
         "0.4929",
         "0.4939",
         "0.4957",
         "0.5026958333333333",
         "0.5020577932981899"
        ],
        [
         "2024-02-01 10:00:00",
         "0.4931",
         "0.4961",
         "0.493",
         "0.4957",
         "14374976.0",
         "0.49455",
         "0.002599999999999991",
         "1",
         "0.5213172619047619",
         "0.5555118055555556",
         "0.520179273350249",
         "0.5533007806534975",
         "44.22027451628908",
         "0.5278813569635185",
         "0.548384410633509",
         "-0.0205030536699905",
         "-0.019845501289965425",
         "0.54261625",
         "0.025838319896080014",
         "0.59429288979216",
         "0.49093961020784",
         "0.4931",
         "0.4929",
         "0.4939",
         "0.5022625",
         "0.5015491698343347"
        ],
        [
         "2024-02-01 11:00:00",
         "0.4957",
         "0.4976",
         "0.4938",
         "0.4938",
         "16570530.0",
         "0.49570000000000003",
         "-0.0018999999999999573",
         "0",
         "0.5212029761904762",
         "0.5553134722222222",
         "0.519867092600542",
         "0.5531357299443339",
         "44.26419466975667",
         "0.5276454998219023",
         "0.5482097405194818",
         "-0.02056424069757945",
         "-0.019852125616302882",
         "0.5424020833333334",
         "0.02581596008737805",
         "0.5940340035080895",
         "0.4907701631585773",
         "0.4957",
         "0.4931",
         "0.4929",
         "0.5019166666666667",
         "0.500929236247588"
        ],
        [
         "2024-02-01 12:00:00",
         "0.4938",
         "0.495",
         "0.4924",
         "0.4927",
         "11659683.0",
         "0.4937",
         "-0.0010999999999999899",
         "0",
         "0.5210874999999999",
         "0.55512",
         "0.5195455885460977",
         "0.5529680857558614",
         "44.183740912095175",
         "0.5274036624528926",
         "0.5480321093498195",
         "-0.02062844689692689",
         "-0.019859280651147344",
         "0.5421775",
         "0.02577835820151729",
         "0.5937342164030346",
         "0.49062078359696537",
         "0.4938",
         "0.4957",
         "0.4931",
         "0.5013208333333333",
         "0.500270897347781"
        ],
        [
         "2024-02-01 13:00:00",
         "0.4928",
         "0.4954",
         "0.4926",
         "0.4946",
         "12144325.0",
         "0.494",
         "0.0017999999999999683",
         "1",
         "0.5210065476190476",
         "0.5549322222222222",
         "0.5192503744804634",
         "0.5528061770575096",
         "44.556585043017876",
         "0.5271766474878207",
         "0.5478611265999002",
         "-0.02068447911207949",
         "-0.019866886166916304",
         "0.5419625",
         "0.025743817588890657",
         "0.5934501351777813",
         "0.4904748648222187",
         "0.4927",
         "0.4938",
         "0.4957",
         "0.5007958333333334",
         "0.4998172255599585"
        ],
        [
         "2024-02-01 14:00:00",
         "0.4946",
         "0.4961",
         "0.4931",
         "0.4957",
         "11711475.0",
         "0.4946",
         "0.0010999999999999899",
         "1",
         "0.5209327380952381",
         "0.5547433333333333",
         "0.5189716718238899",
         "0.5526477687993749",
         "44.510680576254344",
         "0.5269588160173166",
         "0.5476942109947804",
         "-0.020735394977463795",
         "-0.01987489085641444",
         "0.5417489583333333",
         "0.025701438165131155",
         "0.5931518346635956",
         "0.49034608200307095",
         "0.4946",
         "0.4927",
         "0.4938",
         "0.5003791666666667",
         "0.49948784751516184"
        ],
        [
         "2024-02-01 15:00:00",
         "0.4957",
         "0.5003",
         "0.4952",
         "0.4997",
         "18079854.0",
         "0.49774999999999997",
         "0.0040000000000000036",
         "1",
         "0.5208791666666667",
         "0.55456875",
         "0.5187436047017138",
         "0.5525008956543004",
         "44.69384386862519",
         "0.5267701736919373",
         "0.5475406295195971",
         "-0.020770455827659795",
         "-0.019883144911448956",
         "0.5415427083333333",
         "0.02564061864680985",
         "0.592823945626953",
         "0.49026147103971357",
         "0.4957",
         "0.4946",
         "0.4927",
         "0.5001666666666666",
         "0.49950481971394894"
        ],
        [
         "2024-02-01 16:00:00",
         "0.4997",
         "0.5026",
         "0.4994",
         "0.4994",
         "15973829.0",
         "0.501",
         "-0.00029999999999996696",
         "0",
         "0.5208333333333334",
         "0.5543934722222222",
         "0.5185146863028769",
         "0.5523535977467988",
         "44.79735318444996",
         "0.5265807607252112",
         "0.5473865795051344",
         "-0.020805818779923158",
         "-0.019891648818070838",
         "0.5413595833333333",
         "0.02562702513680688",
         "0.5926136336069471",
         "0.4901055330597196",
         "0.4997",
         "0.4957",
         "0.4946",
         "0.4997833333333334",
         "0.49949643413683303"
        ],
        [
         "2024-02-01 17:00:00",
         "0.4995",
         "0.5008",
         "0.4975",
         "0.5002",
         "13043674.0",
         "0.49915",
         "0.0006999999999999784",
         "1",
         "0.5207940476190477",
         "0.5542170833333333",
         "0.5182979444531387",
         "0.5522089275727439",
         "45.33466866967117",
         "0.5263981949070436",
         "0.547235582450718",
         "-0.02083738754367437",
         "-0.019900365304021103",
         "0.5411918749999999",
         "0.025632439581489662",
         "0.5924567541629792",
         "0.48992699583702054",
         "0.4994",
         "0.4997",
         "0.4957",
         "0.49937499999999996",
         "0.4995527194058864"
        ],
        [
         "2024-02-01 18:00:00",
         "0.5002",
         "0.507",
         "0.5001",
         "0.5063",
         "18435984.0",
         "0.5035499999999999",
         "0.006099999999999994",
         "1",
         "0.5207833333333334",
         "0.5540552777777777",
         "0.5181559569448176",
         "0.5520815796460511",
         "46.12190666002325",
         "0.5262591070530156",
         "0.5471045885868757",
         "-0.020845481533860122",
         "-0.019909076052683217",
         "0.5410412499999999",
         "0.02562458628414888",
         "0.5922904225682977",
         "0.48979207743170217",
         "0.5002",
         "0.4994",
         "0.4997",
         "0.499075",
         "0.5000925018534156"
        ],
        [
         "2024-02-01 19:00:00",
         "0.5062",
         "0.5066",
         "0.504",
         "0.505",
         "6947841.0",
         "0.5053000000000001",
         "-0.0011999999999999789",
         "0",
         "0.5207416666666667",
         "0.5538877777777778",
         "0.5180002651466542",
         "0.5519509788703338",
         "46.045431935002505",
         "0.5261119852048978",
         "0.5469698539033977",
         "-0.020857868698499926",
         "-0.019917820685363557",
         "0.5408877083333333",
         "0.025619268643810696",
         "0.5921262456209547",
         "0.48964917104571193",
         "0.5063",
         "0.5002",
         "0.4994",
         "0.4987791666666667",
         "0.5004851017051424"
        ],
        [
         "2024-02-01 20:00:00",
         "0.505",
         "0.5107",
         "0.505",
         "0.5096",
         "12197349.0",
         "0.50785",
         "0.0046000000000000485",
         "1",
         "0.5207166666666667",
         "0.5537238888888889",
         "0.5179008537248004",
         "0.5518335004268655",
         "46.909272183449666",
         "0.5259977154110922",
         "0.5468502703709068",
         "-0.02085255495981464",
         "-0.019926435747800893",
         "0.5407410416666667",
         "0.0255963936606794",
         "0.5919338289880255",
         "0.4895482543453079",
         "0.505",
         "0.5063",
         "0.5002",
         "0.49872500000000003",
         "0.501214293568731"
        ],
        [
         "2024-02-01 21:00:00",
         "0.5096",
         "0.5099",
         "0.5071",
         "0.5078",
         "7515078.0",
         "0.5085",
         "-0.0018000000000000238",
         "0",
         "0.5206827380952381",
         "0.5535598611111111",
         "0.5177813169943294",
         "0.5517113547946134",
         "46.66334661354582",
         "0.5258717796643027",
         "0.54672530950572",
         "-0.020853529841417306",
         "-0.01993498039382501",
         "0.540589375",
         "0.025575396572451708",
         "0.5917401681449035",
         "0.48943858185509664",
         "0.5096",
         "0.505",
         "0.5063",
         "0.4988166666666667",
         "0.5017411500832326"
        ],
        [
         "2024-02-01 22:00:00",
         "0.5077",
         "0.5094",
         "0.507",
         "0.509",
         "5816505.0",
         "0.5082",
         "0.0012999999999999678",
         "1",
         "0.5206553571428572",
         "0.5533956944444445",
         "0.5176773960831539",
         "0.5515928766953219",
         "46.494587843463776",
         "0.5257550199434424",
         "0.5466045885153017",
         "-0.020849568571859267",
         "-0.01994340977795436",
         "0.5404489583333334",
         "0.025563395324976448",
         "0.5915757489832862",
         "0.4893221676833805",
         "0.5078",
         "0.5096",
         "0.505",
         "0.499025",
         "0.502321858076574"
        ],
        [
         "2024-02-01 23:00:00",
         "0.509",
         "0.5091",
         "0.5039",
         "0.5056",
         "8875061.0",
         "0.5065",
         "-0.0033999999999999586",
         "0",
         "0.5206005952380952",
         "0.5532266666666666",
         "0.5175344683188562",
         "0.5514652959000506",
         "46.08998837788479",
         "0.5256155388365674",
         "0.5464733738320527",
         "-0.020857834995485325",
         "-0.019951837660143586",
         "0.5403202083333334",
         "0.025582993355294043",
         "0.5914861950439214",
         "0.4891542216227453",
         "0.509",
         "0.5078",
         "0.5096",
         "0.49917083333333334",
         "0.5025841094304482"
        ],
        [
         "2024-02-02 00:00:00",
         "0.5056",
         "0.5063",
         "0.5046",
         "0.5058",
         "5432484.0",
         "0.50545",
         "0.00019999999999997797",
         "1",
         "0.5205529761904761",
         "0.5530616666666667",
         "0.5173955988712957",
         "0.5513386237893708",
         "46.16151545363909",
         "0.5254784070799129",
         "0.5463432190357902",
         "-0.020864811955877305",
         "-0.019960252169781686",
         "0.5401866666666667",
         "0.02559556225671297",
         "0.5913777911800926",
         "0.48899554215324076",
         "0.5056",
         "0.509",
         "0.5078",
         "0.49927499999999997",
         "0.5028413806760124"
        ],
        [
         "2024-02-02 01:00:00",
         "0.5057",
         "0.5075",
         "0.5047",
         "0.5049",
         "11571408.0",
         "0.5061",
         "-0.0008000000000000229",
         "0",
         "0.5205190476190475",
         "0.552892638888889",
         "0.5172477219615763",
         "0.5512098065250453",
         "46.26144879267278",
         "0.5253359959582526",
         "0.5462106007348757",
         "-0.020874604776623062",
         "-0.01996867938274797",
         "0.5400535416666667",
         "0.025612600222241544",
         "0.5912787421111498",
         "0.48882834122218366",
         "0.5058",
         "0.5056",
         "0.509",
         "0.4994541666666667",
         "0.5030060702219314"
        ],
        [
         "2024-02-02 02:00:00",
         "0.5048",
         "0.5067",
         "0.504",
         "0.5047",
         "9533932.0",
         "0.50535",
         "-9.999999999998899e-05",
         "0",
         "0.5204767857142857",
         "0.5527222222222222",
         "0.5170992282105518",
         "0.5510807918051421",
         "46.300000000000004",
         "0.5251931862976419",
         "0.5460777668125242",
         "-0.02088458051488229",
         "-0.019977120867836765",
         "0.5399197916666666",
         "0.025629270436124393",
         "0.5911783325389154",
         "0.4886612507944178",
         "0.5049",
         "0.5058",
         "0.5056",
         "0.4999",
         "0.5031415846041769"
        ],
        [
         "2024-02-02 03:00:00",
         "0.5046",
         "0.5069",
         "0.5041",
         "0.5068",
         "8855189.0",
         "0.5055000000000001",
         "0.0021999999999999797",
         "1",
         "0.5204392857142858",
         "0.5525565277777778",
         "0.5169773438530305",
         "0.5509579602051279",
         "46.38935108153078",
         "0.5250658978111531",
         "0.5459520779587241",
         "-0.020886180147571043",
         "-0.019985499294378095",
         "0.5397856249999999",
         "0.02563374320773814",
         "0.5910531114154762",
         "0.48851813858452364",
         "0.5047",
         "0.5049",
         "0.5058",
         "0.5002791666666667",
         "0.5034342578358427"
        ],
        [
         "2024-02-02 04:00:00",
         "0.5067",
         "0.5077",
         "0.5056",
         "0.5061",
         "10011046.0",
         "0.50665",
         "-0.0006000000000000449",
         "0",
         "0.5203958333333333",
         "0.5523898611111111",
         "0.5168486178902727",
         "0.5508335275831997",
         "46.35078969243558",
         "0.5249346459231866",
         "0.5458245513092562",
         "-0.020889905386069607",
         "-0.019993834834393688",
         "0.5396485416666666",
         "0.025637585721487534",
         "0.5909237131096418",
         "0.4883733702236916",
         "0.5068",
         "0.5047",
         "0.5049",
         "0.500625",
         "0.5036475172089753"
        ],
        [
         "2024-02-02 05:00:00",
         "0.506",
         "0.5072",
         "0.5056",
         "0.5065",
         "11980027.0",
         "0.5064",
         "0.0004999999999999449",
         "1",
         "0.52035",
         "0.5522133333333333",
         "0.5167261490395003",
         "0.5507105496980869",
         "46.32401862940785",
         "0.524807070518874",
         "0.5456987127450665",
         "-0.020891642226192553",
         "-0.02000210955689875",
         "0.5395097916666667",
         "0.02563638805371805",
         "0.5907825677741028",
         "0.4882370155592306",
         "0.5061",
         "0.5068",
         "0.5047",
         "0.5010625",
         "0.5038757158322572"
        ],
        [
         "2024-02-02 06:00:00",
         "0.5065",
         "0.5071",
         "0.505",
         "0.5067",
         "11490367.0",
         "0.50605",
         "0.000200000000000089",
         "1",
         "0.5203119047619048",
         "0.5520338888888889",
         "0.5166074963881453",
         "0.5505884677294376",
         "46.33294528521538",
         "0.5246817620723766",
         "0.5455739168642824",
         "-0.02089215479190576",
         "-0.020010312738788217",
         "0.5393660416666667",
         "0.025626485047009803",
         "0.5906190117606863",
         "0.48811307157264705",
         "0.5065",
         "0.5061",
         "0.5068",
         "0.5015208333333333",
         "0.5041016585656767"
        ],
        [
         "2024-02-02 07:00:00",
         "0.5066",
         "0.5067",
         "0.5028",
         "0.5048",
         "20439851.0",
         "0.50475",
         "-0.0018000000000000238",
         "0",
         "0.5202678571428572",
         "0.551853888888889",
         "0.5164677627030786",
         "0.5504614539493281",
         "46.17807992041122",
         "0.5245441720234328",
         "0.5454434403303167",
         "-0.020899268306883823",
         "-0.020018505877664676",
         "0.5392193750000001",
         "0.025622428271072032",
         "0.5904642315421441",
         "0.487974518457856",
         "0.5067",
         "0.5065",
         "0.5061",
         "0.5019750000000001",
         "0.5041575258804226"
        ],
        [
         "2024-02-02 08:00:00",
         "0.5047",
         "0.5076",
         "0.5047",
         "0.5069",
         "13277552.0",
         "0.5061500000000001",
         "0.0021999999999999797",
         "1",
         "0.5202404761904761",
         "0.5516802777777777",
         "0.5163545347420955",
         "0.5503406177386504",
         "46.65004156275977",
         "0.5244220670267309",
         "0.5453201013212596",
         "-0.020898034294528745",
         "-0.02002661213035467",
         "0.5390779166666666",
         "0.025613013961038916",
         "0.5903039445887445",
         "0.4878518887445888",
         "0.5048",
         "0.5067",
         "0.5065",
         "0.5025583333333333",
         "0.5043769238099889"
        ],
        [
         "2024-02-02 09:00:00",
         "0.5069",
         "0.5074",
         "0.504",
         "0.5048",
         "18840225.0",
         "0.5057",
         "-0.0020999999999999908",
         "0",
         "0.5201892857142857",
         "0.5515051388888889",
         "0.5162177946859761",
         "0.5502142914758524",
         "46.53399668325042",
         "0.5242862741753348",
         "0.5451904369970315",
         "-0.020904162821696715",
         "-0.02003470015515967",
         "0.5389302083333333",
         "0.025605812719974738",
         "0.5901418337732828",
         "0.48771858289338377",
         "0.5069",
         "0.5048",
         "0.5067",
         "0.5030458333333333",
         "0.5044107699051898"
        ],
        [
         "2024-02-02 10:00:00",
         "0.5047",
         "0.505",
         "0.5029",
         "0.5039",
         "17729161.0",
         "0.50395",
         "-0.0008000000000000229",
         "0",
         "0.5201309523809524",
         "0.5513227777777778",
         "0.5160720219677989",
         "0.5500858191000526",
         "46.10768461410236",
         "0.5241451926931525",
         "0.545058307598641",
         "-0.020913114905488528",
         "-0.02004279614364196",
         "0.538786875",
         "0.025608945597155864",
         "0.5900047661943117",
         "0.48756898380568825",
         "0.5048",
         "0.5069",
         "0.5048",
         "0.5033875",
         "0.5043699083127746"
        ],
        [
         "2024-02-02 11:00:00",
         "0.5039",
         "0.5066",
         "0.5029",
         "0.5052",
         "15196406.0",
         "0.50475",
         "0.0012999999999999678",
         "1",
         "0.5200553571428572",
         "0.5511452777777778",
         "0.5159433589859315",
         "0.5499613091996364",
         "46.27810158201499",
         "0.5240140840931998",
         "0.5449307610143254",
         "-0.020916676921125532",
         "-0.020050850344356098",
         "0.5386439583333333",
         "0.025604557530736257",
         "0.5898530733948059",
         "0.4874348432718608",
         "0.5039",
         "0.5048",
         "0.5069",
         "0.5038625",
         "0.5044363156477526"
        ],
        [
         "2024-02-02 12:00:00",
         "0.5052",
         "0.506",
         "0.5035",
         "0.5044",
         "14532207.0",
         "0.50475",
         "-0.0008000000000000229",
         "0",
         "0.5199559523809524",
         "0.5509868055555555",
         "0.5158067511872814",
         "0.5498349255402754",
         "46.17177097203728",
         "0.5238783464870185",
         "0.5448010625790795",
         "-0.020922716092060978",
         "-0.0200588859733672",
         "0.5384983333333333",
         "0.025600118193011133",
         "0.5896985697193555",
         "0.487298096947311",
         "0.5052",
         "0.5039",
         "0.5048",
         "0.50435",
         "0.5044334103959325"
        ],
        [
         "2024-02-02 13:00:00",
         "0.5044",
         "0.5051",
         "0.5033",
         "0.5037",
         "15265733.0",
         "0.5042",
         "-0.0006999999999999229",
         "0",
         "0.5198589285714286",
         "0.5509054166666666",
         "0.5156634760253017",
         "0.549706950712147",
         "46.091151031270805",
         "0.5237387039507762",
         "0.5446695391788264",
         "-0.020930835228050282",
         "-0.020066922372027875",
         "0.5383491666666667",
         "0.025593833240262726",
         "0.5895368331471921",
         "0.4871615001861412",
         "0.5044",
         "0.5052",
         "0.5039",
         "0.5047291666666666",
         "0.5043747375642579"
        ],
        [
         "2024-02-02 14:00:00",
         "0.5037",
         "0.5039",
         "0.4987",
         "0.5005",
         "31253317.0",
         "0.5013",
         "-0.0032000000000000917",
         "0",
         "0.5197553571428571",
         "0.5508111111111111",
         "0.515484026604884",
         "0.5495704543162743",
         "45.94594594594595",
         "0.523577882470148",
         "0.5445281966534542",
         "-0.020950314183306173",
         "-0.02007506423203966",
         "0.538198125",
         "0.02560284220230409",
         "0.5894038094046081",
         "0.4869924405953918",
         "0.5037",
         "0.5044",
         "0.5052",
         "0.5049291666666667",
         "0.5040647585591173"
        ],
        [
         "2024-02-02 15:00:00",
         "0.5005",
         "0.5019",
         "0.4989",
         "0.4999",
         "20519840.0",
         "0.5004",
         "-0.0005999999999999339",
         "0",
         "0.5196321428571429",
         "0.5507255555555556",
         "0.5152996002545305",
         "0.5494326721961181",
         "46.29134647510859",
         "0.523414021691808",
         "0.5443853864241631",
         "-0.02097136473235517",
         "-0.02008332506614395",
         "0.5380474999999999",
         "0.025615059383560842",
         "0.5892776187671216",
         "0.4868173812328782",
         "0.5005",
         "0.5037",
         "0.5044",
         "0.5049375",
         "0.5037315778743879"
        ],
        [
         "2024-02-02 16:00:00",
         "0.4999",
         "0.5042",
         "0.4999",
         "0.5027",
         "21392905.0",
         "0.50205",
         "0.0028000000000000247",
         "1",
         "0.5195214285714286",
         "0.5506230555555556",
         "0.5151504925592105",
         "0.5493030392635353",
         "46.963087248322154",
         "0.5232706720607229",
         "0.5442519931876059",
         "-0.020981321126883",
         "-0.02009160152753325",
         "0.5378985416666667",
         "0.025612279682217805",
         "0.5891231010311023",
         "0.48667398230223113",
         "0.4999",
         "0.5005",
         "0.5037",
         "0.505075",
         "0.503649051644437"
        ],
        [
         "2024-02-02 17:00:00",
         "0.5026",
         "0.5049",
         "0.5021",
         "0.5026",
         "19121253.0",
         "0.5035000000000001",
         "0.0",
         "0",
         "0.5193875",
         "0.5505222222222222",
         "0.5150019660200482",
         "0.5491734885304881",
         "47.960932145305016",
         "0.5231276224270847",
         "0.5441187068094056",
         "-0.02099108438232089",
         "-0.020099891692093506",
         "0.53775375",
         "0.02561497691342976",
         "0.5889837038268595",
         "0.4865237961731405",
         "0.5027",
         "0.4999",
         "0.5005",
         "0.505175",
         "0.5035651275128821"
        ],
        [
         "2024-02-02 18:00:00",
         "0.5025",
         "0.5064",
         "0.5021",
         "0.5028",
         "19525030.0",
         "0.50425",
         "0.000300000000000078",
         "1",
         "0.5192553571428571",
         "0.5504220833333333",
         "0.5148575640553139",
         "0.5490448519464923",
         "47.07215057511329",
         "0.522986946839354",
         "0.5439864869476154",
         "-0.02099954010826144",
         "-0.0201081833825651",
         "0.5376047916666666",
         "0.02560990230340356",
         "0.5888245962734737",
         "0.4863849870598595",
         "0.5026",
         "0.5027",
         "0.4999",
         "0.5050291666666668",
         "0.5035039173118515"
        ],
        [
         "2024-02-02 19:00:00",
         "0.5028",
         "0.5037",
         "0.5009",
         "0.5034",
         "9260259.0",
         "0.5023",
         "0.0005999999999999339",
         "1",
         "0.5190797619047619",
         "0.55032875",
         "0.5147219715812866",
         "0.5489182365458086",
         "46.52227504842402",
         "0.5228513970342373",
         "0.543856610189383",
         "-0.021005213155145697",
         "-0.020116450938072756",
         "0.5374583333333334",
         "0.025604065221762565",
         "0.5886664637768585",
         "0.48625020288980825",
         "0.5028",
         "0.5026",
         "0.5027",
         "0.5049625",
         "0.5034956039269034"
        ],
        [
         "2024-02-02 20:00:00",
         "0.5034",
         "0.5049",
         "0.5021",
         "0.5044",
         "7649530.0",
         "0.5035000000000001",
         "0.0010000000000000009",
         "1",
         "0.5189125",
         "0.5502323611111111",
         "0.514599818071449",
         "0.5487947462918673",
         "46.31430086618349",
         "0.5227237057052806",
         "0.543730349036777",
         "-0.021006643331496377",
         "-0.020124655476260994",
         "0.5373125",
         "0.02559256420095343",
         "0.5884976284019068",
         "0.4861273715980931",
         "0.5034",
         "0.5028",
         "0.5026",
         "0.5047458333333333",
         "0.5035679556127511"
        ],
        [
         "2024-02-02 21:00:00",
         "0.5044",
         "0.5055",
         "0.5039",
         "0.5051",
         "6808346.0",
         "0.5046999999999999",
         "0.0007000000000000339",
         "1",
         "0.5187601190476191",
         "0.5501168055555555",
         "0.5144873941889466",
         "0.5486735403382144",
         "46.47090040686361",
         "0.5226017423439984",
         "0.5436067319198593",
         "-0.021004989575860944",
         "-0.020132769154598322",
         "0.5371662500000001",
         "0.025575604619834717",
         "0.5883174592396695",
         "0.48601504076033064",
         "0.5044",
         "0.5034",
         "0.5028",
         "0.5046333333333334",
         "0.5036905191637311"
        ],
        [
         "2024-02-02 22:00:00",
         "0.505",
         "0.5086",
         "0.505",
         "0.5077",
         "10105783.0",
         "0.5068",
         "0.0027000000000000357",
         "1",
         "0.5186119047619048",
         "0.5500027777777778",
         "0.5144070699973614",
         "0.5485598828060695",
         "46.537102473498244",
         "0.5224986160994032",
         "0.5434918303777158",
         "-0.020993214278312577",
         "-0.02014069952440214",
         "0.5370218750000001",
         "0.025545855463094215",
         "0.5881135859261886",
         "0.4859301640738117",
         "0.5051",
         "0.5044",
         "0.5034",
         "0.5045791666666667",
         "0.5040112776306326"
        ],
        [
         "2024-02-02 23:00:00",
         "0.5076",
         "0.5142",
         "0.5076",
         "0.511",
         "29196757.0",
         "0.5109",
         "0.0033999999999999586",
         "1",
         "0.518485119047619",
         "0.5499026388888889",
         "0.5143667496423631",
         "0.5484556945042496",
         "46.86346863468635",
         "0.5224190409014834",
         "0.543387856520507",
         "-0.02096881561902364",
         "-0.020148331930804182",
         "0.5368858333333334",
         "0.025510096395216033",
         "0.5879060261237654",
         "0.4858656405429013",
         "0.5077",
         "0.5051",
         "0.5044",
         "0.5048041666666666",
         "0.504570375420182"
        ],
        [
         "2024-02-03 00:00:00",
         "0.511",
         "0.5114",
         "0.5088",
         "0.5105",
         "8673201.0",
         "0.5101",
         "-0.000500000000000056",
         "0",
         "0.5183553571428572",
         "0.5498029166666666",
         "0.5143209892915659",
         "0.5483504082504236",
         "47.02045133991537",
         "0.5223365561893624",
         "0.5432826153796414",
         "-0.02094605919027903",
         "-0.0201556842557763",
         "0.5367520833333334",
         "0.025479704884379895",
         "0.5877114931020931",
         "0.48579267356457356",
         "0.511",
         "0.5077",
         "0.5051",
         "0.505",
         "0.5050447453865675"
        ],
        [
         "2024-02-03 01:00:00",
         "0.5106",
         "0.5109",
         "0.5074",
         "0.5079",
         "7292121.0",
         "0.50915",
         "-0.0027000000000000357",
         "0",
         "0.5182172619047619",
         "0.5497020833333334",
         "0.5142450012526124",
         "0.5482382018475097",
         "47.22025495750709",
         "0.5222366492261142",
         "0.5431693910104265",
         "-0.02093274178431226",
         "-0.0201628460763158",
         "0.5366183333333333",
         "0.025462262331966856",
         "0.587542857997267",
         "0.4856938086693996",
         "0.5105",
         "0.511",
         "0.5077",
         "0.5051249999999999",
         "0.5052731657556422"
        ],
        [
         "2024-02-03 02:00:00",
         "0.5078",
         "0.5095",
         "0.5063",
         "0.5076",
         "4555860.0",
         "0.5079",
         "-0.00019999999999997797",
         "0",
         "0.5180773809523809",
         "0.5496108333333333",
         "0.5141663621845342",
         "0.5481254745192226",
         "46.7428163483848",
         "0.5221353575359682",
         "0.5430555689591932",
         "-0.020920211423224977",
         "-0.020169826402093763",
         "0.536478125",
         "0.02543630467740796",
         "0.587350734354816",
         "0.4856055156451841",
         "0.5079",
         "0.5105",
         "0.511",
         "0.5052458333333333",
         "0.5054593124951908"
        ],
        [
         "2024-02-03 03:00:00",
         "0.5076",
         "0.5079",
         "0.506",
         "0.5063",
         "3378520.0",
         "0.50695",
         "-0.0013000000000000789",
         "0",
         "0.5179208333333334",
         "0.5495052777777778",
         "0.5140732691409303",
         "0.5480094537854661",
         "46.734475374732334",
         "0.5220257702865843",
         "0.5429379511385237",
         "-0.020912180851939466",
         "-0.020176668378590036",
         "0.5363347916666666",
         "0.02541204853632268",
         "0.587158888739312",
         "0.4855106945940213",
         "0.5076",
         "0.5079",
         "0.5105",
         "0.5052249999999999",
         "0.5055265674955756"
        ],
        [
         "2024-02-03 04:00:00",
         "0.5063",
         "0.508",
         "0.5062",
         "0.5077",
         "4007558.0",
         "0.5071",
         "0.0014000000000000679",
         "1",
         "0.5177726190476191",
         "0.5494029166666666",
         "0.5139978458374873",
         "0.5478976383796811",
         "46.8293551834699",
         "0.5219266300077843",
         "0.5428251896948804",
         "-0.020898559687096085",
         "-0.020183321754705302",
         "0.5361970833333333",
         "0.02538768691723643",
         "0.5869724571678061",
         "0.48542170949886043",
         "0.5063",
         "0.5076",
         "0.5079",
         "0.5052916666666667",
         "0.5057004420959296"
        ],
        [
         "2024-02-03 05:00:00",
         "0.5077",
         "0.5083",
         "0.5069",
         "0.5074",
         "3834891.0",
         "0.5076",
         "-0.000300000000000078",
         "0",
         "0.517614880952381",
         "0.5492976388888889",
         "0.513919764821659",
         "0.547785300963926",
         "46.62379421221865",
         "0.5218260996963117",
         "0.5427118290878568",
         "-0.020885729391545094",
         "-0.02018979555780982",
         "0.5360612499999999",
         "0.025366924828621285",
         "0.5867950996572425",
         "0.48532740034275734",
         "0.5077",
         "0.5063",
         "0.5076",
         "0.5053291666666667",
         "0.5058364067282553"
        ],
        [
         "2024-02-03 06:00:00",
         "0.5075",
         "0.508",
         "0.5065",
         "0.5078",
         "3804494.0",
         "0.50725",
         "0.000300000000000078",
         "1",
         "0.5174738095238095",
         "0.5491955555555555",
         "0.5138473415693317",
         "0.5476743847337903",
         "46.72028596961574",
         "0.5217290332624271",
         "0.5426001112347756",
         "-0.02087107797234844",
         "-0.020196074658404648",
         "0.5359220833333332",
         "0.025338275317553876",
         "0.586598633968441",
         "0.4852455326982255",
         "0.5074",
         "0.5077",
         "0.5063",
         "0.505375",
         "0.5059934941899948"
        ]
       ],
       "shape": {
        "columns": 26,
        "rows": 9275
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>av_pr</th>\n",
       "      <th>diff</th>\n",
       "      <th>candle</th>\n",
       "      <th>7_day_SMA</th>\n",
       "      <th>30_day_SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>20_day_SMA</th>\n",
       "      <th>20_day_STD</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>1_day_SMA</th>\n",
       "      <th>1_day_EMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-01 05:00:00</th>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>17875875.0</td>\n",
       "      <td>0.49710</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521835</td>\n",
       "      <td>0.556468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019820</td>\n",
       "      <td>0.543675</td>\n",
       "      <td>0.025918</td>\n",
       "      <td>0.595512</td>\n",
       "      <td>0.491838</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.505550</td>\n",
       "      <td>0.505323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 06:00:00</th>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>10485001.0</td>\n",
       "      <td>0.49645</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521746</td>\n",
       "      <td>0.556281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019824</td>\n",
       "      <td>0.543457</td>\n",
       "      <td>0.025881</td>\n",
       "      <td>0.595220</td>\n",
       "      <td>0.491694</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.504871</td>\n",
       "      <td>0.504553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 07:00:00</th>\n",
       "      <td>0.4956</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>26116194.0</td>\n",
       "      <td>0.49390</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521644</td>\n",
       "      <td>0.556095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019829</td>\n",
       "      <td>0.543245</td>\n",
       "      <td>0.025870</td>\n",
       "      <td>0.594985</td>\n",
       "      <td>0.491505</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.504146</td>\n",
       "      <td>0.503701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 08:00:00</th>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>17569499.0</td>\n",
       "      <td>0.49280</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521520</td>\n",
       "      <td>0.555903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019834</td>\n",
       "      <td>0.543034</td>\n",
       "      <td>0.025865</td>\n",
       "      <td>0.594764</td>\n",
       "      <td>0.491304</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.503392</td>\n",
       "      <td>0.502837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 09:00:00</th>\n",
       "      <td>0.4929</td>\n",
       "      <td>0.4938</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>18873523.0</td>\n",
       "      <td>0.49190</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521411</td>\n",
       "      <td>0.555709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019839</td>\n",
       "      <td>0.542825</td>\n",
       "      <td>0.025863</td>\n",
       "      <td>0.594550</td>\n",
       "      <td>0.491099</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.502696</td>\n",
       "      <td>0.502058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 11:00:00</th>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6787</td>\n",
       "      <td>2.6601</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>4420326.0</td>\n",
       "      <td>2.66940</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>1</td>\n",
       "      <td>2.684121</td>\n",
       "      <td>2.738742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044497</td>\n",
       "      <td>2.562806</td>\n",
       "      <td>0.164862</td>\n",
       "      <td>2.892530</td>\n",
       "      <td>2.233082</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6715</td>\n",
       "      <td>2.6596</td>\n",
       "      <td>2.678383</td>\n",
       "      <td>2.671862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 12:00:00</th>\n",
       "      <td>2.6758</td>\n",
       "      <td>2.6773</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>6597897.0</td>\n",
       "      <td>2.66400</td>\n",
       "      <td>-0.0251</td>\n",
       "      <td>0</td>\n",
       "      <td>2.683635</td>\n",
       "      <td>2.737931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044301</td>\n",
       "      <td>2.562089</td>\n",
       "      <td>0.163724</td>\n",
       "      <td>2.889538</td>\n",
       "      <td>2.234641</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6715</td>\n",
       "      <td>2.677108</td>\n",
       "      <td>2.670169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 13:00:00</th>\n",
       "      <td>2.6508</td>\n",
       "      <td>2.6661</td>\n",
       "      <td>2.6454</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>4207626.0</td>\n",
       "      <td>2.65575</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>1</td>\n",
       "      <td>2.683442</td>\n",
       "      <td>2.737152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044106</td>\n",
       "      <td>2.561391</td>\n",
       "      <td>0.162561</td>\n",
       "      <td>2.886513</td>\n",
       "      <td>2.236269</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.676225</td>\n",
       "      <td>2.669803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 14:00:00</th>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.6655</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>16416120.0</td>\n",
       "      <td>2.69075</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>1</td>\n",
       "      <td>2.683311</td>\n",
       "      <td>2.736484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043909</td>\n",
       "      <td>2.560812</td>\n",
       "      <td>0.161570</td>\n",
       "      <td>2.883953</td>\n",
       "      <td>2.237671</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>2.675996</td>\n",
       "      <td>2.672115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 15:00:00</th>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.7012</td>\n",
       "      <td>2.6793</td>\n",
       "      <td>2.6851</td>\n",
       "      <td>3973640.0</td>\n",
       "      <td>2.69025</td>\n",
       "      <td>-0.0136</td>\n",
       "      <td>0</td>\n",
       "      <td>2.683049</td>\n",
       "      <td>2.735803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043711</td>\n",
       "      <td>2.560235</td>\n",
       "      <td>0.160625</td>\n",
       "      <td>2.881484</td>\n",
       "      <td>2.238986</td>\n",
       "      <td>2.6987</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.675717</td>\n",
       "      <td>2.673154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9275 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close      volume    av_pr  \\\n",
       "datetime                                                                   \n",
       "2024-02-01 05:00:00  0.4977  0.4988  0.4954  0.4960  17875875.0  0.49710   \n",
       "2024-02-01 06:00:00  0.4959  0.4974  0.4955  0.4957  10485001.0  0.49645   \n",
       "2024-02-01 07:00:00  0.4956  0.4959  0.4919  0.4939  26116194.0  0.49390   \n",
       "2024-02-01 08:00:00  0.4939  0.4940  0.4916  0.4929  17569499.0  0.49280   \n",
       "2024-02-01 09:00:00  0.4929  0.4938  0.4900  0.4931  18873523.0  0.49190   \n",
       "...                     ...     ...     ...     ...         ...      ...   \n",
       "2025-02-21 11:00:00  2.6670  2.6787  2.6601  2.6757   4420326.0  2.66940   \n",
       "2025-02-21 12:00:00  2.6758  2.6773  2.6507  2.6507   6597897.0  2.66400   \n",
       "2025-02-21 13:00:00  2.6508  2.6661  2.6454  2.6656   4207626.0  2.65575   \n",
       "2025-02-21 14:00:00  2.6656  2.7160  2.6655  2.6987  16416120.0  2.69075   \n",
       "2025-02-21 15:00:00  2.6987  2.7012  2.6793  2.6851   3973640.0  2.69025   \n",
       "\n",
       "                       diff  candle  7_day_SMA  30_day_SMA  ...  Signal_Line  \\\n",
       "datetime                                                    ...                \n",
       "2024-02-01 05:00:00 -0.0017       0   0.521835    0.556468  ...    -0.019820   \n",
       "2024-02-01 06:00:00 -0.0002       0   0.521746    0.556281  ...    -0.019824   \n",
       "2024-02-01 07:00:00 -0.0017       0   0.521644    0.556095  ...    -0.019829   \n",
       "2024-02-01 08:00:00 -0.0010       0   0.521520    0.555903  ...    -0.019834   \n",
       "2024-02-01 09:00:00  0.0002       1   0.521411    0.555709  ...    -0.019839   \n",
       "...                     ...     ...        ...         ...  ...          ...   \n",
       "2025-02-21 11:00:00  0.0087       1   2.684121    2.738742  ...    -0.044497   \n",
       "2025-02-21 12:00:00 -0.0251       0   2.683635    2.737931  ...    -0.044301   \n",
       "2025-02-21 13:00:00  0.0148       1   2.683442    2.737152  ...    -0.044106   \n",
       "2025-02-21 14:00:00  0.0331       1   2.683311    2.736484  ...    -0.043909   \n",
       "2025-02-21 15:00:00 -0.0136       0   2.683049    2.735803  ...    -0.043711   \n",
       "\n",
       "                     20_day_SMA  20_day_STD  Upper_Band  Lower_Band   lag_1  \\\n",
       "datetime                                                                      \n",
       "2024-02-01 05:00:00    0.543675    0.025918    0.595512    0.491838  0.4978   \n",
       "2024-02-01 06:00:00    0.543457    0.025881    0.595220    0.491694  0.4960   \n",
       "2024-02-01 07:00:00    0.543245    0.025870    0.594985    0.491505  0.4957   \n",
       "2024-02-01 08:00:00    0.543034    0.025865    0.594764    0.491304  0.4939   \n",
       "2024-02-01 09:00:00    0.542825    0.025863    0.594550    0.491099  0.4929   \n",
       "...                         ...         ...         ...         ...     ...   \n",
       "2025-02-21 11:00:00    2.562806    0.164862    2.892530    2.233082  2.6670   \n",
       "2025-02-21 12:00:00    2.562089    0.163724    2.889538    2.234641  2.6757   \n",
       "2025-02-21 13:00:00    2.561391    0.162561    2.886513    2.236269  2.6507   \n",
       "2025-02-21 14:00:00    2.560812    0.161570    2.883953    2.237671  2.6656   \n",
       "2025-02-21 15:00:00    2.560235    0.160625    2.881484    2.238986  2.6987   \n",
       "\n",
       "                      lag_2   lag_3  1_day_SMA  1_day_EMA  \n",
       "datetime                                                   \n",
       "2024-02-01 05:00:00  0.4977  0.4940   0.505550   0.505323  \n",
       "2024-02-01 06:00:00  0.4978  0.4977   0.504871   0.504553  \n",
       "2024-02-01 07:00:00  0.4960  0.4978   0.504146   0.503701  \n",
       "2024-02-01 08:00:00  0.4957  0.4960   0.503392   0.502837  \n",
       "2024-02-01 09:00:00  0.4939  0.4957   0.502696   0.502058  \n",
       "...                     ...     ...        ...        ...  \n",
       "2025-02-21 11:00:00  2.6715  2.6596   2.678383   2.671862  \n",
       "2025-02-21 12:00:00  2.6670  2.6715   2.677108   2.670169  \n",
       "2025-02-21 13:00:00  2.6757  2.6670   2.676225   2.669803  \n",
       "2025-02-21 14:00:00  2.6507  2.6757   2.675996   2.672115  \n",
       "2025-02-21 15:00:00  2.6656  2.6507   2.675717   2.673154  \n",
       "\n",
       "[9275 rows x 26 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define the model\n",
    "model_2 = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(25),\n",
    "    Dense(1)  # Output layer for predicting the next 'close' price\n",
    "])\n",
    "\n",
    "# Compile the model with SGD\n",
    "model_2.compile(optimizer=SGD(learning_rate=1e-5, momentum=0.9), loss='mean_squared_error')\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.Dense(1, input_shape=[window_size])\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9)\n",
    "model.compile(loss=keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "model.fit(train_set, epochs=500,\n",
    "          validation_data=valid_set,\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candle(row):\n",
    "    if row['open'] < row['close']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "xrp_usdt['candle'] = xrp_usdt.apply(candle, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ave(row):\n",
    "    av_pr = (row['low'] + row['high']) / 2\n",
    "    return av_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(row):\n",
    "    pr_diff = row['close'] - row['open']\n",
    "    return pr_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrp_usdt_hr['av_pr'] = xrp_usdt.apply(ave, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "av_pr",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9999aae5-3d65-48c2-a499-b7072e9e11c0",
       "rows": [
        [
         "2021-02-23 01:00:00",
         "BINANCE:XRPUSDT",
         "0.56637",
         "0.57172",
         "0.365",
         "0.47579",
         "2563543339.6000013",
         "0",
         "-0.09058000000000005",
         "0.46836"
        ],
        [
         "2021-02-24 01:00:00",
         "BINANCE:XRPUSDT",
         "0.4758",
         "0.49999",
         "0.4512",
         "0.4686",
         "984714285.3999994",
         "0",
         "-0.007199999999999984",
         "0.475595"
        ],
        [
         "2021-02-25 01:00:00",
         "BINANCE:XRPUSDT",
         "0.46864",
         "0.48233",
         "0.4244",
         "0.43601",
         "709823716.2000002",
         "0",
         "-0.03262999999999999",
         "0.453365"
        ],
        [
         "2021-02-26 01:00:00",
         "BINANCE:XRPUSDT",
         "0.43599",
         "0.45067",
         "0.41111",
         "0.42788",
         "908467259.4999994",
         "0",
         "-0.008110000000000006",
         "0.43089"
        ],
        [
         "2021-02-27 01:00:00",
         "BINANCE:XRPUSDT",
         "0.42794",
         "0.45945",
         "0.42681",
         "0.43589",
         "612147484.7999984",
         "1",
         "0.007950000000000013",
         "0.44313"
        ],
        [
         "2021-02-28 01:00:00",
         "BINANCE:XRPUSDT",
         "0.43586",
         "0.43876",
         "0.39268",
         "0.41565",
         "674797992.7999996",
         "0",
         "-0.020210000000000006",
         "0.41572"
        ],
        [
         "2021-03-01 01:00:00",
         "BINANCE:XRPUSDT",
         "0.4157",
         "0.454",
         "0.41207",
         "0.44537",
         "600649056.6000001",
         "1",
         "0.029669999999999974",
         "0.433035"
        ],
        [
         "2021-03-02 01:00:00",
         "BINANCE:XRPUSDT",
         "0.44537",
         "0.45532",
         "0.42159",
         "0.4357",
         "645438020.0000004",
         "0",
         "-0.009670000000000012",
         "0.43845500000000004"
        ],
        [
         "2021-03-03 01:00:00",
         "BINANCE:XRPUSDT",
         "0.43572",
         "0.46869",
         "0.43011",
         "0.44846",
         "642007608.9999999",
         "1",
         "0.012740000000000029",
         "0.4494"
        ],
        [
         "2021-03-04 01:00:00",
         "BINANCE:XRPUSDT",
         "0.44841",
         "0.49449",
         "0.43411",
         "0.48096",
         "1244989352.0000017",
         "1",
         "0.03255000000000002",
         "0.4643"
        ],
        [
         "2021-03-05 01:00:00",
         "BINANCE:XRPUSDT",
         "0.4812",
         "0.48488",
         "0.44575",
         "0.45457",
         "751282004.700001",
         "0",
         "-0.026630000000000043",
         "0.465315"
        ],
        [
         "2021-03-06 01:00:00",
         "BINANCE:XRPUSDT",
         "0.45441",
         "0.4765",
         "0.44901",
         "0.46285",
         "365972027.50000054",
         "1",
         "0.008440000000000003",
         "0.462755"
        ],
        [
         "2021-03-07 01:00:00",
         "BINANCE:XRPUSDT",
         "0.46292",
         "0.4689",
         "0.45641",
         "0.46558",
         "325973214.89999986",
         "1",
         "0.0026599999999999957",
         "0.462655"
        ],
        [
         "2021-03-08 01:00:00",
         "BINANCE:XRPUSDT",
         "0.46579",
         "0.48987",
         "0.45505",
         "0.47412",
         "680852595.9000009",
         "1",
         "0.008330000000000004",
         "0.47246"
        ],
        [
         "2021-03-09 01:00:00",
         "BINANCE:XRPUSDT",
         "0.47413",
         "0.48736",
         "0.471",
         "0.4849",
         "495494328.9999997",
         "1",
         "0.010770000000000002",
         "0.47918"
        ],
        [
         "2021-03-10 01:00:00",
         "BINANCE:XRPUSDT",
         "0.48481",
         "0.4887",
         "0.4545",
         "0.46155",
         "597205849.6999995",
         "0",
         "-0.023260000000000003",
         "0.4716"
        ],
        [
         "2021-03-11 01:00:00",
         "BINANCE:XRPUSDT",
         "0.4617",
         "0.46427",
         "0.44058",
         "0.45187",
         "535040848.19999987",
         "0",
         "-0.009830000000000005",
         "0.452425"
        ],
        [
         "2021-03-12 01:00:00",
         "BINANCE:XRPUSDT",
         "0.45187",
         "0.46488",
         "0.42205",
         "0.43934",
         "665250842.6999995",
         "0",
         "-0.012529999999999986",
         "0.443465"
        ],
        [
         "2021-03-13 01:00:00",
         "BINANCE:XRPUSDT",
         "0.43934",
         "0.46646",
         "0.43205",
         "0.45787",
         "547809975.1999998",
         "1",
         "0.01852999999999999",
         "0.44925499999999996"
        ],
        [
         "2021-03-14 01:00:00",
         "BINANCE:XRPUSDT",
         "0.45786",
         "0.46155",
         "0.43857",
         "0.43905",
         "415693265.59999996",
         "0",
         "-0.018809999999999993",
         "0.45006"
        ],
        [
         "2021-03-15 01:00:00",
         "BINANCE:XRPUSDT",
         "0.439",
         "0.44815",
         "0.42268",
         "0.43574",
         "531041051.90000033",
         "0",
         "-0.003259999999999985",
         "0.435415"
        ],
        [
         "2021-03-16 01:00:00",
         "BINANCE:XRPUSDT",
         "0.43566",
         "0.52221",
         "0.42723",
         "0.46024",
         "1446818353.7999978",
         "1",
         "0.02457999999999999",
         "0.47472"
        ],
        [
         "2021-03-17 01:00:00",
         "BINANCE:XRPUSDT",
         "0.46037",
         "0.48245",
         "0.45317",
         "0.4698",
         "564997453.6999996",
         "1",
         "0.009429999999999994",
         "0.46781"
        ],
        [
         "2021-03-18 01:00:00",
         "BINANCE:XRPUSDT",
         "0.46993",
         "0.4905",
         "0.46558",
         "0.46893",
         "555296456.600001",
         "0",
         "-0.0010000000000000009",
         "0.47804"
        ],
        [
         "2021-03-19 01:00:00",
         "BINANCE:XRPUSDT",
         "0.46899",
         "0.47536",
         "0.45848",
         "0.46651",
         "336947303.50000006",
         "0",
         "-0.0024800000000000377",
         "0.46692"
        ],
        [
         "2021-03-20 01:00:00",
         "BINANCE:XRPUSDT",
         "0.4665",
         "0.54999",
         "0.46424",
         "0.52613",
         "1164006494.7000003",
         "1",
         "0.05962999999999996",
         "0.507115"
        ],
        [
         "2021-03-21 01:00:00",
         "BINANCE:XRPUSDT",
         "0.52584",
         "0.54691",
         "0.49508",
         "0.51651",
         "879573341.2999986",
         "0",
         "-0.00932999999999995",
         "0.520995"
        ],
        [
         "2021-03-22 01:00:00",
         "BINANCE:XRPUSDT",
         "0.51661",
         "0.6",
         "0.50082",
         "0.5441",
         "1648699048.0000007",
         "1",
         "0.027490000000000014",
         "0.5504100000000001"
        ],
        [
         "2021-03-23 01:00:00",
         "BINANCE:XRPUSDT",
         "0.54403",
         "0.59638",
         "0.5378",
         "0.5498",
         "1094151403.2999997",
         "1",
         "0.005769999999999942",
         "0.56709"
        ],
        [
         "2021-03-24 01:00:00",
         "BINANCE:XRPUSDT",
         "0.54945",
         "0.56302",
         "0.45212",
         "0.48021",
         "894167588.1000005",
         "0",
         "-0.06923999999999997",
         "0.50757"
        ],
        [
         "2021-03-25 01:00:00",
         "BINANCE:XRPUSDT",
         "0.48022",
         "0.5248",
         "0.454",
         "0.51058",
         "914285330.6",
         "1",
         "0.030360000000000054",
         "0.48940000000000006"
        ],
        [
         "2021-03-26 01:00:00",
         "BINANCE:XRPUSDT",
         "0.51034",
         "0.57689",
         "0.50999",
         "0.56357",
         "737749968.4999996",
         "1",
         "0.05323",
         "0.54344"
        ],
        [
         "2021-03-27 01:00:00",
         "BINANCE:XRPUSDT",
         "0.56348",
         "0.57464",
         "0.5342",
         "0.54752",
         "455498717.6999997",
         "0",
         "-0.015959999999999974",
         "0.55442"
        ],
        [
         "2021-03-28 01:00:00",
         "BINANCE:XRPUSDT",
         "0.54735",
         "0.56075",
         "0.53879",
         "0.54552",
         "341522011.49999994",
         "0",
         "-0.0018299999999999983",
         "0.54977"
        ],
        [
         "2021-03-29 02:00:00",
         "BINANCE:XRPUSDT",
         "0.5455",
         "0.57082",
         "0.54317",
         "0.56538",
         "534252547.2999997",
         "1",
         "0.01988000000000001",
         "0.556995"
        ],
        [
         "2021-03-30 02:00:00",
         "BINANCE:XRPUSDT",
         "0.56528",
         "0.588",
         "0.55903",
         "0.5621",
         "574769642.4999994",
         "0",
         "-0.0031799999999999606",
         "0.573515"
        ],
        [
         "2021-03-31 02:00:00",
         "BINANCE:XRPUSDT",
         "0.56207",
         "0.57682",
         "0.52624",
         "0.56982",
         "666984204.2999998",
         "1",
         "0.007750000000000035",
         "0.5515300000000001"
        ],
        [
         "2021-04-01 02:00:00",
         "BINANCE:XRPUSDT",
         "0.5698",
         "0.59555",
         "0.54864",
         "0.57087",
         "710468435.6000001",
         "1",
         "0.0010700000000000154",
         "0.572095"
        ],
        [
         "2021-04-02 02:00:00",
         "BINANCE:XRPUSDT",
         "0.57061",
         "0.61",
         "0.56522",
         "0.60701",
         "800475396.400002",
         "1",
         "0.0364000000000001",
         "0.58761"
        ],
        [
         "2021-04-03 02:00:00",
         "BINANCE:XRPUSDT",
         "0.60701",
         "0.64262",
         "0.573",
         "0.57831",
         "991064844.799999",
         "0",
         "-0.02870000000000006",
         "0.60781"
        ],
        [
         "2021-04-04 02:00:00",
         "BINANCE:XRPUSDT",
         "0.57836",
         "0.63599",
         "0.56591",
         "0.635",
         "664457346.2",
         "1",
         "0.056640000000000024",
         "0.6009500000000001"
        ],
        [
         "2021-04-05 02:00:00",
         "BINANCE:XRPUSDT",
         "0.63501",
         "0.93999",
         "0.6194",
         "0.91584",
         "3325470561.469996",
         "1",
         "0.28083",
         "0.779695"
        ],
        [
         "2021-04-06 02:00:00",
         "BINANCE:XRPUSDT",
         "0.91584",
         "1.119",
         "0.7931",
         "1.09663",
         "4053245753.0899997",
         "1",
         "0.18079",
         "0.9560500000000001"
        ],
        [
         "2021-04-07 02:00:00",
         "BINANCE:XRPUSDT",
         "1.09666",
         "1.10882",
         "0.856",
         "0.91542",
         "2128341583.9",
         "0",
         "-0.18123999999999996",
         "0.98241"
        ],
        [
         "2021-04-08 02:00:00",
         "BINANCE:XRPUSDT",
         "0.91544",
         "1.07294",
         "0.90128",
         "1.05599",
         "1232242484.399998",
         "1",
         "0.14054999999999995",
         "0.9871099999999999"
        ],
        [
         "2021-04-09 02:00:00",
         "BINANCE:XRPUSDT",
         "1.05571",
         "1.0849",
         "0.9808",
         "1.01721",
         "964539570.1000007",
         "0",
         "-0.03849999999999998",
         "1.03285"
        ],
        [
         "2021-04-10 02:00:00",
         "BINANCE:XRPUSDT",
         "1.01754",
         "1.399",
         "1.00617",
         "1.3728",
         "2713439019.679999",
         "1",
         "0.35526000000000013",
         "1.202585"
        ],
        [
         "2021-04-11 02:00:00",
         "BINANCE:XRPUSDT",
         "1.37215",
         "1.5",
         "1.305",
         "1.35118",
         "1972667902.3999999",
         "0",
         "-0.020969999999999933",
         "1.4024999999999999"
        ],
        [
         "2021-04-12 02:00:00",
         "BINANCE:XRPUSDT",
         "1.35118",
         "1.475",
         "1.31804",
         "1.46843",
         "1129501823.7999997",
         "1",
         "0.11724999999999985",
         "1.3965200000000002"
        ],
        [
         "2021-04-13 02:00:00",
         "BINANCE:XRPUSDT",
         "1.4685",
         "1.88888",
         "1.41778",
         "1.79611",
         "2515240116.42",
         "1",
         "0.3276100000000002",
         "1.65333"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 1460
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>candle</th>\n",
       "      <th>diff</th>\n",
       "      <th>av_pr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-23 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.56637</td>\n",
       "      <td>0.57172</td>\n",
       "      <td>0.36500</td>\n",
       "      <td>0.47579</td>\n",
       "      <td>2.563543e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.09058</td>\n",
       "      <td>0.468360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-24 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.47580</td>\n",
       "      <td>0.49999</td>\n",
       "      <td>0.45120</td>\n",
       "      <td>0.46860</td>\n",
       "      <td>9.847143e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00720</td>\n",
       "      <td>0.475595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-25 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.46864</td>\n",
       "      <td>0.48233</td>\n",
       "      <td>0.42440</td>\n",
       "      <td>0.43601</td>\n",
       "      <td>7.098237e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.03263</td>\n",
       "      <td>0.453365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-26 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.43599</td>\n",
       "      <td>0.45067</td>\n",
       "      <td>0.41111</td>\n",
       "      <td>0.42788</td>\n",
       "      <td>9.084673e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00811</td>\n",
       "      <td>0.430890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-27 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>0.42794</td>\n",
       "      <td>0.45945</td>\n",
       "      <td>0.42681</td>\n",
       "      <td>0.43589</td>\n",
       "      <td>6.121475e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00795</td>\n",
       "      <td>0.443130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-17 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.72830</td>\n",
       "      <td>2.76480</td>\n",
       "      <td>2.60750</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.128134e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.06840</td>\n",
       "      <td>2.686150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-18 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.65990</td>\n",
       "      <td>2.66990</td>\n",
       "      <td>2.46930</td>\n",
       "      <td>2.56280</td>\n",
       "      <td>2.271700e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.09710</td>\n",
       "      <td>2.569600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.56290</td>\n",
       "      <td>2.74700</td>\n",
       "      <td>2.51210</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.085771e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17490</td>\n",
       "      <td>2.629550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-20 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.73780</td>\n",
       "      <td>2.74900</td>\n",
       "      <td>2.66710</td>\n",
       "      <td>2.68770</td>\n",
       "      <td>1.616046e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.05010</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 01:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.68780</td>\n",
       "      <td>2.69750</td>\n",
       "      <td>2.63960</td>\n",
       "      <td>2.68990</td>\n",
       "      <td>8.294545e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>2.668550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              symbol     open     high      low    close  \\\n",
       "datetime                                                                   \n",
       "2021-02-23 01:00:00  BINANCE:XRPUSDT  0.56637  0.57172  0.36500  0.47579   \n",
       "2021-02-24 01:00:00  BINANCE:XRPUSDT  0.47580  0.49999  0.45120  0.46860   \n",
       "2021-02-25 01:00:00  BINANCE:XRPUSDT  0.46864  0.48233  0.42440  0.43601   \n",
       "2021-02-26 01:00:00  BINANCE:XRPUSDT  0.43599  0.45067  0.41111  0.42788   \n",
       "2021-02-27 01:00:00  BINANCE:XRPUSDT  0.42794  0.45945  0.42681  0.43589   \n",
       "...                              ...      ...      ...      ...      ...   \n",
       "2025-02-17 01:00:00  BINANCE:XRPUSDT  2.72830  2.76480  2.60750  2.65990   \n",
       "2025-02-18 01:00:00  BINANCE:XRPUSDT  2.65990  2.66990  2.46930  2.56280   \n",
       "2025-02-19 01:00:00  BINANCE:XRPUSDT  2.56290  2.74700  2.51210  2.73780   \n",
       "2025-02-20 01:00:00  BINANCE:XRPUSDT  2.73780  2.74900  2.66710  2.68770   \n",
       "2025-02-21 01:00:00  BINANCE:XRPUSDT  2.68780  2.69750  2.63960  2.68990   \n",
       "\n",
       "                           volume  candle     diff     av_pr  \n",
       "datetime                                                      \n",
       "2021-02-23 01:00:00  2.563543e+09       0 -0.09058  0.468360  \n",
       "2021-02-24 01:00:00  9.847143e+08       0 -0.00720  0.475595  \n",
       "2021-02-25 01:00:00  7.098237e+08       0 -0.03263  0.453365  \n",
       "2021-02-26 01:00:00  9.084673e+08       0 -0.00811  0.430890  \n",
       "2021-02-27 01:00:00  6.121475e+08       1  0.00795  0.443130  \n",
       "...                           ...     ...      ...       ...  \n",
       "2025-02-17 01:00:00  2.128134e+08       0 -0.06840  2.686150  \n",
       "2025-02-18 01:00:00  2.271700e+08       0 -0.09710  2.569600  \n",
       "2025-02-19 01:00:00  2.085771e+08       1  0.17490  2.629550  \n",
       "2025-02-20 01:00:00  1.616046e+08       0 -0.05010  2.708050  \n",
       "2025-02-21 01:00:00  8.294545e+07       1  0.00210  2.668550  \n",
       "\n",
       "[1460 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrp_usdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "candle",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "53e39ac3-e917-4a6d-b676-4744d133aefa",
       "rows": [
        [
         "2024-11-23 15:00:00",
         "BINANCE:XRPUSDT",
         "1.5445",
         "1.5759",
         "1.5421",
         "1.5643",
         "33710210.0",
         "1"
        ],
        [
         "2024-11-23 16:00:00",
         "BINANCE:XRPUSDT",
         "1.5644",
         "1.5954",
         "1.5477",
         "1.5557",
         "59564036.0",
         "0"
        ],
        [
         "2024-11-23 17:00:00",
         "BINANCE:XRPUSDT",
         "1.5557",
         "1.5764",
         "1.4033",
         "1.4615",
         "149974625.0",
         "0"
        ],
        [
         "2024-11-23 18:00:00",
         "BINANCE:XRPUSDT",
         "1.4617",
         "1.514",
         "1.428",
         "1.4995",
         "77135699.0",
         "1"
        ],
        [
         "2024-11-23 19:00:00",
         "BINANCE:XRPUSDT",
         "1.4996",
         "1.4997",
         "1.4695",
         "1.497",
         "24749802.0",
         "0"
        ],
        [
         "2024-11-23 20:00:00",
         "BINANCE:XRPUSDT",
         "1.497",
         "1.5055",
         "1.4666",
         "1.4752",
         "26026334.0",
         "0"
        ],
        [
         "2024-11-23 21:00:00",
         "BINANCE:XRPUSDT",
         "1.4751",
         "1.4754",
         "1.4206",
         "1.4636",
         "41813196.0",
         "0"
        ],
        [
         "2024-11-23 22:00:00",
         "BINANCE:XRPUSDT",
         "1.4633",
         "1.4964",
         "1.4586",
         "1.4956",
         "24858070.0",
         "1"
        ],
        [
         "2024-11-23 23:00:00",
         "BINANCE:XRPUSDT",
         "1.4955",
         "1.4966",
         "1.464",
         "1.483",
         "18978562.0",
         "0"
        ],
        [
         "2024-11-24 00:00:00",
         "BINANCE:XRPUSDT",
         "1.4828",
         "1.4852",
         "1.4557",
         "1.4685",
         "18775681.0",
         "0"
        ],
        [
         "2024-11-24 01:00:00",
         "BINANCE:XRPUSDT",
         "1.4686",
         "1.4825",
         "1.4403",
         "1.4724",
         "36934288.0",
         "1"
        ],
        [
         "2024-11-24 02:00:00",
         "BINANCE:XRPUSDT",
         "1.4724",
         "1.4867",
         "1.4691",
         "1.4774",
         "21108250.0",
         "1"
        ],
        [
         "2024-11-24 03:00:00",
         "BINANCE:XRPUSDT",
         "1.4775",
         "1.513",
         "1.4768",
         "1.4901",
         "36121027.0",
         "1"
        ],
        [
         "2024-11-24 04:00:00",
         "BINANCE:XRPUSDT",
         "1.4902",
         "1.4954",
         "1.47",
         "1.4724",
         "21134039.0",
         "0"
        ],
        [
         "2024-11-24 05:00:00",
         "BINANCE:XRPUSDT",
         "1.4725",
         "1.4828",
         "1.446",
         "1.4634",
         "23012717.0",
         "0"
        ],
        [
         "2024-11-24 06:00:00",
         "BINANCE:XRPUSDT",
         "1.4634",
         "1.47",
         "1.4362",
         "1.4527",
         "19073783.0",
         "0"
        ],
        [
         "2024-11-24 07:00:00",
         "BINANCE:XRPUSDT",
         "1.4526",
         "1.464",
         "1.4429",
         "1.4601",
         "18214770.0",
         "1"
        ],
        [
         "2024-11-24 08:00:00",
         "BINANCE:XRPUSDT",
         "1.4601",
         "1.4765",
         "1.459",
         "1.4649",
         "11487459.0",
         "1"
        ],
        [
         "2024-11-24 09:00:00",
         "BINANCE:XRPUSDT",
         "1.4649",
         "1.4685",
         "1.4321",
         "1.4385",
         "20157787.0",
         "0"
        ],
        [
         "2024-11-24 10:00:00",
         "BINANCE:XRPUSDT",
         "1.4385",
         "1.4498",
         "1.4278",
         "1.4422",
         "17618968.0",
         "1"
        ],
        [
         "2024-11-24 11:00:00",
         "BINANCE:XRPUSDT",
         "1.4421",
         "1.4576",
         "1.4228",
         "1.4344",
         "19891489.0",
         "0"
        ],
        [
         "2024-11-24 12:00:00",
         "BINANCE:XRPUSDT",
         "1.4344",
         "1.4396",
         "1.3784",
         "1.3833",
         "84454505.0",
         "0"
        ],
        [
         "2024-11-24 13:00:00",
         "BINANCE:XRPUSDT",
         "1.3833",
         "1.4033",
         "1.2775",
         "1.3374",
         "148857014.0",
         "0"
        ],
        [
         "2024-11-24 14:00:00",
         "BINANCE:XRPUSDT",
         "1.3373",
         "1.3886",
         "1.3259",
         "1.3734",
         "63424093.0",
         "1"
        ],
        [
         "2024-11-24 15:00:00",
         "BINANCE:XRPUSDT",
         "1.3731",
         "1.3739",
         "1.3362",
         "1.3656",
         "51774365.0",
         "0"
        ],
        [
         "2024-11-24 16:00:00",
         "BINANCE:XRPUSDT",
         "1.3656",
         "1.3708",
         "1.3044",
         "1.3077",
         "63239656.0",
         "0"
        ],
        [
         "2024-11-24 17:00:00",
         "BINANCE:XRPUSDT",
         "1.3078",
         "1.3699",
         "1.2984",
         "1.352",
         "57351722.0",
         "1"
        ],
        [
         "2024-11-24 18:00:00",
         "BINANCE:XRPUSDT",
         "1.3519",
         "1.3532",
         "1.3239",
         "1.3394",
         "30470807.0",
         "0"
        ],
        [
         "2024-11-24 19:00:00",
         "BINANCE:XRPUSDT",
         "1.3392",
         "1.4",
         "1.335",
         "1.3962",
         "46520126.0",
         "1"
        ],
        [
         "2024-11-24 20:00:00",
         "BINANCE:XRPUSDT",
         "1.3963",
         "1.4062",
         "1.3743",
         "1.3791",
         "33433708.0",
         "0"
        ],
        [
         "2024-11-24 21:00:00",
         "BINANCE:XRPUSDT",
         "1.3791",
         "1.4211",
         "1.3728",
         "1.4198",
         "43969469.0",
         "1"
        ],
        [
         "2024-11-24 22:00:00",
         "BINANCE:XRPUSDT",
         "1.4197",
         "1.4424",
         "1.4008",
         "1.4386",
         "29263349.0",
         "1"
        ],
        [
         "2024-11-24 23:00:00",
         "BINANCE:XRPUSDT",
         "1.4386",
         "1.4607",
         "1.4271",
         "1.443",
         "36360818.0",
         "1"
        ],
        [
         "2024-11-25 00:00:00",
         "BINANCE:XRPUSDT",
         "1.4429",
         "1.4572",
         "1.419",
         "1.4331",
         "26753861.0",
         "0"
        ],
        [
         "2024-11-25 01:00:00",
         "BINANCE:XRPUSDT",
         "1.4334",
         "1.4342",
         "1.3962",
         "1.3996",
         "26947739.0",
         "0"
        ],
        [
         "2024-11-25 02:00:00",
         "BINANCE:XRPUSDT",
         "1.3995",
         "1.4025",
         "1.355",
         "1.3789",
         "32378458.0",
         "0"
        ],
        [
         "2024-11-25 03:00:00",
         "BINANCE:XRPUSDT",
         "1.379",
         "1.398",
         "1.3783",
         "1.3865",
         "21427449.0",
         "1"
        ],
        [
         "2024-11-25 04:00:00",
         "BINANCE:XRPUSDT",
         "1.3866",
         "1.4121",
         "1.3826",
         "1.4027",
         "17865216.0",
         "1"
        ],
        [
         "2024-11-25 05:00:00",
         "BINANCE:XRPUSDT",
         "1.4027",
         "1.4661",
         "1.4015",
         "1.4407",
         "38130404.0",
         "1"
        ],
        [
         "2024-11-25 06:00:00",
         "BINANCE:XRPUSDT",
         "1.4406",
         "1.4763",
         "1.4369",
         "1.4597",
         "35556546.0",
         "1"
        ],
        [
         "2024-11-25 07:00:00",
         "BINANCE:XRPUSDT",
         "1.4597",
         "1.4718",
         "1.4494",
         "1.458",
         "23327622.0",
         "0"
        ],
        [
         "2024-11-25 08:00:00",
         "BINANCE:XRPUSDT",
         "1.458",
         "1.5064",
         "1.4459",
         "1.4793",
         "47879088.0",
         "1"
        ],
        [
         "2024-11-25 09:00:00",
         "BINANCE:XRPUSDT",
         "1.4792",
         "1.5393",
         "1.4768",
         "1.5183",
         "54351266.0",
         "1"
        ],
        [
         "2024-11-25 10:00:00",
         "BINANCE:XRPUSDT",
         "1.5183",
         "1.5192",
         "1.4965",
         "1.5088",
         "34425175.0",
         "0"
        ],
        [
         "2024-11-25 11:00:00",
         "BINANCE:XRPUSDT",
         "1.5088",
         "1.512",
         "1.4817",
         "1.4909",
         "25455823.0",
         "0"
        ],
        [
         "2024-11-25 12:00:00",
         "BINANCE:XRPUSDT",
         "1.4908",
         "1.4937",
         "1.4652",
         "1.479",
         "24142008.0",
         "0"
        ],
        [
         "2024-11-25 13:00:00",
         "BINANCE:XRPUSDT",
         "1.479",
         "1.4868",
         "1.4606",
         "1.4673",
         "19226854.0",
         "0"
        ],
        [
         "2024-11-25 14:00:00",
         "BINANCE:XRPUSDT",
         "1.4673",
         "1.4733",
         "1.4235",
         "1.4284",
         "45544122.0",
         "0"
        ],
        [
         "2024-11-25 15:00:00",
         "BINANCE:XRPUSDT",
         "1.4284",
         "1.4496",
         "1.386",
         "1.3869",
         "61521665.0",
         "0"
        ],
        [
         "2024-11-25 16:00:00",
         "BINANCE:XRPUSDT",
         "1.387",
         "1.4408",
         "1.3732",
         "1.423",
         "59360052.0",
         "1"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 2160
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>candle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-23 15:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>1.5445</td>\n",
       "      <td>1.5759</td>\n",
       "      <td>1.5421</td>\n",
       "      <td>1.5643</td>\n",
       "      <td>33710210.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-23 16:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>1.5644</td>\n",
       "      <td>1.5954</td>\n",
       "      <td>1.5477</td>\n",
       "      <td>1.5557</td>\n",
       "      <td>59564036.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-23 17:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>1.5557</td>\n",
       "      <td>1.5764</td>\n",
       "      <td>1.4033</td>\n",
       "      <td>1.4615</td>\n",
       "      <td>149974625.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-23 18:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>1.4617</td>\n",
       "      <td>1.5140</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>1.4995</td>\n",
       "      <td>77135699.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-23 19:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>1.4996</td>\n",
       "      <td>1.4997</td>\n",
       "      <td>1.4695</td>\n",
       "      <td>1.4970</td>\n",
       "      <td>24749802.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 10:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6714</td>\n",
       "      <td>2.6950</td>\n",
       "      <td>2.6466</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>11537344.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 11:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6670</td>\n",
       "      <td>2.6787</td>\n",
       "      <td>2.6601</td>\n",
       "      <td>2.6757</td>\n",
       "      <td>4420326.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 12:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6758</td>\n",
       "      <td>2.6773</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>2.6507</td>\n",
       "      <td>6597897.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 13:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6508</td>\n",
       "      <td>2.6661</td>\n",
       "      <td>2.6454</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>4207626.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 14:00:00</th>\n",
       "      <td>BINANCE:XRPUSDT</td>\n",
       "      <td>2.6656</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.6655</td>\n",
       "      <td>2.7057</td>\n",
       "      <td>13809512.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              symbol    open    high     low   close  \\\n",
       "datetime                                                               \n",
       "2024-11-23 15:00:00  BINANCE:XRPUSDT  1.5445  1.5759  1.5421  1.5643   \n",
       "2024-11-23 16:00:00  BINANCE:XRPUSDT  1.5644  1.5954  1.5477  1.5557   \n",
       "2024-11-23 17:00:00  BINANCE:XRPUSDT  1.5557  1.5764  1.4033  1.4615   \n",
       "2024-11-23 18:00:00  BINANCE:XRPUSDT  1.4617  1.5140  1.4280  1.4995   \n",
       "2024-11-23 19:00:00  BINANCE:XRPUSDT  1.4996  1.4997  1.4695  1.4970   \n",
       "...                              ...     ...     ...     ...     ...   \n",
       "2025-02-21 10:00:00  BINANCE:XRPUSDT  2.6714  2.6950  2.6466  2.6670   \n",
       "2025-02-21 11:00:00  BINANCE:XRPUSDT  2.6670  2.6787  2.6601  2.6757   \n",
       "2025-02-21 12:00:00  BINANCE:XRPUSDT  2.6758  2.6773  2.6507  2.6507   \n",
       "2025-02-21 13:00:00  BINANCE:XRPUSDT  2.6508  2.6661  2.6454  2.6656   \n",
       "2025-02-21 14:00:00  BINANCE:XRPUSDT  2.6656  2.7160  2.6655  2.7057   \n",
       "\n",
       "                          volume  candle  \n",
       "datetime                                  \n",
       "2024-11-23 15:00:00   33710210.0       1  \n",
       "2024-11-23 16:00:00   59564036.0       0  \n",
       "2024-11-23 17:00:00  149974625.0       0  \n",
       "2024-11-23 18:00:00   77135699.0       1  \n",
       "2024-11-23 19:00:00   24749802.0       0  \n",
       "...                          ...     ...  \n",
       "2025-02-21 10:00:00   11537344.0       0  \n",
       "2025-02-21 11:00:00    4420326.0       1  \n",
       "2025-02-21 12:00:00    6597897.0       0  \n",
       "2025-02-21 13:00:00    4207626.0       1  \n",
       "2025-02-21 14:00:00   13809512.0       1  \n",
       "\n",
       "[2160 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrp_usdt_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (75.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting TA-Lib\n",
      "  Using cached ta_lib-0.6.3.tar.gz (376 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from TA-Lib) (75.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\chidi\\documents\\timeseries_projects\\tvenv\\lib\\site-packages (from TA-Lib) (2.0.2)\n",
      "Building wheels for collected packages: TA-Lib\n",
      "  Building wheel for TA-Lib (pyproject.toml): started\n",
      "  Building wheel for TA-Lib (pyproject.toml): finished with status 'error'\n",
      "Failed to build TA-Lib\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for TA-Lib (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [32 lines of output]\n",
      "  <string>:83: UserWarning: Cannot find ta-lib library, installation may fail.\n",
      "  C:\\Users\\chidi\\AppData\\Local\\Temp\\pip-build-env-1c_4lln6\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:81: SetuptoolsWarning: `install_requires` overwritten in `pyproject.toml` (dependencies)\n",
      "    corresp(dist, value, root_dir)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\abstract.py -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\deprecated.py -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\stream.py -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\__init__.py -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  running egg_info\n",
      "  writing ta_lib.egg-info\\PKG-INFO\n",
      "  writing dependency_links to ta_lib.egg-info\\dependency_links.txt\n",
      "  writing requirements to ta_lib.egg-info\\requires.txt\n",
      "  writing top-level names to ta_lib.egg-info\\top_level.txt\n",
      "  reading manifest file 'ta_lib.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  adding license file 'LICENSE'\n",
      "  adding license file 'AUTHORS'\n",
      "  writing manifest file 'ta_lib.egg-info\\SOURCES.txt'\n",
      "  copying talib\\_abstract.pxi -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\_common.pxi -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\_func.pxi -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\_stream.pxi -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\_ta_lib.c -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\_ta_lib.pyi -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\_ta_lib.pyx -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  copying talib\\py.typed -> build\\lib.win-amd64-cpython-312\\talib\n",
      "  running build_ext\n",
      "  building 'talib._ta_lib' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for TA-Lib\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (TA-Lib)\n"
     ]
    }
   ],
   "source": [
    "pip install TA-Lib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_envc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
